<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Lecture 14: Matrix Representation of Composition and Matrix Multiplication</title>
  <link rel="stylesheet" href="/assets/css/nemo-theme.css">
  <!-- MathJax if you want math -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <div class="container">
    <nav class="sidebar">
      <!-- You can generate links here manually, or use site.pages or a _data file -->
      <h2>Contents</h2>
      <ul>
        <li><a href="/">Home</a></li>
        <li><a href="/about/">About</a></li>
        <li><a href="/jekyll/update/2024/07/11/linear-algebra.html">Linear Algebra</a></li>
        <li><a href="/jekyll/update/2024/12/05/abstract-algebra.html">Abstract Algebra</a></li>
        <li><a href="/jekyll/update/2025/01/03/number-theory.html">Number Theory</a></li>
        <li><a href="/jekyll/update/2024/07/09/realanalysis.html">Real Analysis</a></li>
        <!-- Add more links as needed -->
      </ul>
    </nav>
    <main class="content">
		<header class="content-header">
		        nemo's notebook
		      </header>
      <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Lecture 14: Matrix Representation of Composition and Matrix Multiplication</h1>
    <!--
    <p class="post-meta">
      <time class="dt-published" datetime="2024-08-06T01:01:36-07:00" itemprop="datePublished">Aug 6, 2024
      </time></p>
     -->
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h4><b>The Vector Space of Linear Transformations</b></h4>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Given vector spaces \(V, W\) define
$$
\begin{align*}
\mathcal{L}(V, W) = \{T: V \rightarrow W \ | \ T \text{ is linear}\}.
\end{align*}
$$
</div>
<p><br />
FACT: The set of linear transformations \(\mathcal{L}(V, W)\) is a vector space. We can think of this as a way to get a new vector space from two vector spaces \(W\) and \(V\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>The Composition of Linear Transformations</b></h4>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Define the linear maps \(S \in \mathcal{L}(X, Y)\) and \(T \in \mathcal{L}(Y, Z)\). We define composition
$$
\begin{align*}
T \circ S: X &amp;\rightarrow Z \\
x &amp;\rightarrow T(S(x))
\end{align*}
$$
</div>
<p><br />
Next, we will show that the composition of two linear transformations is also linear!
<br /></p>
<div class="purdiv">
Theorem
</div>
<div class="purbdiv">
\(T \circ S: X \rightarrow Z\) is linear (\(T \circ S \in \mathcal{L}(X, Z))\) 
</div>
<p><br />
Proof: We want to show that</p>
<div>
$$
\begin{align*}
(T \circ S)(x_1 + cx_2) = (T \circ S)(x_1) + c(T \circ S)(x_2).	 
\end{align*}
$$
</div>
<p>To see expand the left hand side as follows:</p>
<div>
$$
\begin{align*}
(T \circ S)(x_1 + cx_2) &amp;= T(S(x_1 + cx_2)) \\
                     &amp;= T(S(x_1) + cS(x_2)) \text{ (because $S$ is linear)} \\
                     &amp;= T(S(x_1)) + cT(S(x_2)) \text{ (because $T$ is linear)} \\
                     &amp;= (T \circ S)(x_1) + c(T \circ S)(x_2). \ \blacksquare			 
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>The Matrix of Linear Composition</b></h4>
<p>Suppose now that \(X\), \(Y\) and \(Z\) are finite dimensional with fixed bases \(\alpha = \{x_1,...,x_n\}, \beta = \{y_1,...,y_m\}\) and \(\gamma = \{z_1,...,z_n\}\).
<br />
<br />
How are \([S]_{\alpha}^{\beta}, [T]_{\beta}^{\gamma}\) and \([T \circ S]_{\alpha}^{\gamma}\) related?
<br />
<br />
To answer this question, we need to define matrix multiplication.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Matrix Multiplication</b></h4>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Given \(A \in M_{m \times n}\) and \(B \in M_{n \times p}\). We define their product \(AB \in M_{m \times p}\) by
$$
\begin{align*}
(AB)_{ij} = \sum_k^n A_{ik}B_{kj}.
\end{align*}
$$
Alternatively,
$$
\begin{align*}
AB &amp;= A \begin{pmatrix} | &amp;  &amp; | \\ \bar{b}_1 &amp; ... &amp; \bar{b}_p \\ | &amp;  &amp; |  \end{pmatrix}
   = \begin{pmatrix} | &amp;  &amp; | \\ A\bar{b}_1 &amp; ... &amp; A\bar{b}_p \\ | &amp;  &amp; |  \end{pmatrix} .
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<div>
$$
\begin{align*}
A =
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix},
B =
\begin{pmatrix} 1 &amp; 2 \\ 1 &amp; 2 \\ 2 &amp; 1 \end{pmatrix}.
\end{align*}
$$
</div>
<div>
$$
\begin{align*}
A\bar{b}_1 &amp;= 
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}
*
\begin{pmatrix} 1 \\ 1 \\ 2 \\ \end{pmatrix} = 1
\begin{pmatrix} 1  \\ 4  \end{pmatrix}
+ 1
\begin{pmatrix} 2  \\ 5  \end{pmatrix}
+ 
\begin{pmatrix} 3 \\ 6 \end{pmatrix}
=
\begin{pmatrix} 9 \\ 21 \end{pmatrix}
\\
A\bar{b}_1 &amp;= 
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}
*
\begin{pmatrix} 2 \\ 2 \\ 1 \\ \end{pmatrix} = 
\begin{pmatrix} 9 \\ 24 \end{pmatrix} \\
AB &amp;= 
\begin{pmatrix} 9 &amp; 9 \\ 21 &amp; 24 \end{pmatrix}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Matrix Composition Using Matrix Multiplication</b></h4>
<p>Now that we defined matrix multiplication, we are ready to answer the question of how \([S]_{\alpha}^{\beta}, [T]_{\beta}^{\gamma}\) and \([T \circ S]_{\alpha}^{\gamma}\) related.</p>
<div class="purdiv">
Theorem 2.11
</div>
<div class="purbdiv">
Given \(S \in \mathcal{L}(X, Y)\) and \(T \in \mathcal{L}(Y, Z)\) and finite bases \(\alpha, \beta, \gamma\) for \(X, Y, Z\), then
$$
\begin{align*}
[T \circ S]_{\alpha}^{\gamma} = [T]^{\gamma}_{\beta} [S]^{\beta}_{\alpha}
\end{align*}
$$
</div>
<p><br />
In other words, the composition of the linear transformations \(S\) and \(T\) is equal to the matrix multiplication of the two matrices representing these linear transformations.
<br /></p>
<h4><b>Proof</b></h4>
<p>Fix the basis \(\alpha\) such that \(\alpha = \{x_1,...,x_n\}\). Then,</p>
<div>
$$
\begin{align*}
[T \circ S]_{\alpha}^{\gamma} &amp;= ([(T \circ S)(x_1)]_{\gamma} ... [(T \circ S)(x_n)]_{\gamma}) \\
&amp;= ([(T(S(x_1))]_{\gamma} ... [(T(S(x_n))]_{\gamma}) \text{( by definition)}\\
&amp;= ([T]_{\beta}^{\gamma}[(S(x_1)]_{\beta} ... [T]_{\beta}^{\gamma}[(S(x_n)]_{\beta}) \text{( by theorem 2.14 (lecture 13))}\\
&amp;= [T]_{\beta}^{\gamma}([(S(x_1)]_{\beta} ... [(S(x_n)]_{\beta}) \\
&amp;= [T]^{\gamma}_{\beta} \circ [S]^{\beta}_{\alpha}. \blacksquare					 
\end{align*}
$$
</div>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<div>
$$
\begin{align*}
A &amp;\in M_{m \times n} \rightarrow L_A: \mathbf{R}^n \rightarrow \mathbf{R}^m \\
B &amp;\in M_{p \times m} \rightarrow L_B: \mathbf{R}^m \rightarrow \mathbf{R}^p
\end{align*}
$$
</div>
<p>If we choose the standard basis for all vector spaces, then the theorem tells us</p>
<div>
$$
\begin{align*}
[L_B \circ L_A]_{\alpha}^{\gamma} &amp;= [L_B]^{\gamma}_{\beta} \circ [L_A]^{\beta}_{\alpha}.
\end{align*}
$$
</div>
<p>But since we chose the standard basis then we know that \([L_A]^{\beta}_{\alpha} = A\) and \([L_B]^{\gamma}_{\beta} = B\). So we can also write</p>
<div>
$$
\begin{align*}
[L_B \circ L_A]_{\alpha}^{\gamma} &amp;= [L_B]^{\gamma}_{\beta} \circ [L_A]^{\beta}_{\alpha} = BA = [L_{BA}]^{\gamma}_{\alpha}.
\end{align*}
$$
</div>
<p>In particular, this shows that these maps are equal \(L_B \circ L_A = L_{BA}\).</p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Let</p>
<div>
$$
\begin{align*}
T_d: P_3 &amp;\rightarrow P_2 \\
f &amp;\rightarrow f'			 
\end{align*}
$$
</div>
<p>and</p>
<div>
$$
\begin{align*}
T_i: P_2 &amp;\rightarrow P_3 \\
f &amp;\rightarrow \int_0^x f(t)dt			 
\end{align*}
$$
</div>
<p>For standard bases \(\beta = \{1,x,x^2, x^3\}\) of \(P_3\) and \(\gamma = \{1, x, x^2\}\) of \(P_2\). 
<br />
<br />
Extra notes: As a reminder, to find the matrix representative of of \(T_d\), we first apply the transformation on the vectors of \(\beta\).</p>
<div>
$$
\begin{align*}
T(1) = 0, T(x) = 1, T(x^2) = 2x, T(x^3) = 3x^2. 		 
\end{align*}
$$
</div>
<p>and then we find the coordinates of these images with respect to \(\gamma\) which will be the column vectors of the matrix,</p>
<div>
$$
\begin{align*}
T(1) &amp;= 0 = 0(1) + 0(x) + 0(x^2) \\
T(x) &amp;= 1 = 1(1) + 0(x) + 0(x^2) \\
T(x^2) &amp;= 2x = 0(1) + 2(x) + 0(x^2) \\
T(x^3) &amp;= 3x^2 = 0(1) + 0(x) + 3(x^2).
\end{align*}
$$
</div>
<p>Therefore, \(T_d\) and \(T_i\) (can be found using the same method) are:</p>
<div>
$$
\begin{align*}
[T_d]^{\gamma}_{\beta} &amp;= 
\begin{pmatrix}
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 3
\end{pmatrix}, [T_i]_{\gamma}^{\beta} = 
\begin{pmatrix}
0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1/2 &amp; 0 \\
0 &amp; 0 &amp; 1/3
\end{pmatrix}.
\end{align*}
$$
</div>
<p>To compose these matrices we just multiply them,</p>
<div>
$$
\begin{align*}
[T_i]_{\gamma}^{\beta}[T_d]^{\gamma}_{\beta} = 
\begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix}.
\end{align*}
$$
</div>
<p>To verify, want to compute \([T_i \circ T_d]^{\beta}_{\beta}\) but instead of applying the composition on each vector. Let’s just apply it on a general object. In this case we need an object from \(P_3\):</p>
<div>
$$
\begin{align*}
(T_i \circ T_d)(a_0 + a_1x + a_2x^2 + a_3x^3) &amp;= T_i(T_d(a_0 + a_1x + a_2x^2 + a_3x^3)) \\
                                              &amp;= T_i(a_1 + 2a_2x + 3a_3x^2) \\
                        &amp;= a_1x + a_2x^2 + a_3x^3
\end{align*}
$$
</div>
<p>So now the first column of this matrix should be the image of the first vector in the basis \(\beta\) so the image of \(1\) and that’s simply all zeros. For \(x\), we see \(a_1x\) just got mapped to itself again in the final equation. Similarly we get the same for the last two basis vectors so</p>
<div>
$$
\begin{align*}
[T_i \circ T_d]^{\beta}_{\beta} = 
\begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix} = 
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Matrix Multiplication Properties</b></h4>
<div class="purdiv">
Theorem
</div>
<div class="purbdiv">
<ol style="list-style-type:lower-alpha">
	<li>\(A(BC) = (AB)C\)</li>
	<li>\(A(B+C) = AB + AC\)</li>
	<li>Not commutative. In general \(AB \neq BA\)</li>
</ol>
</div>
<p><br />
<b>Proof (b):</b>
<br /> 
As a reminder we know that \((AB)_{ij} = \sum_{k=1}^n A_{ik}B_{kj}\). We also know that \(B+C\) is just summing the matching coordinates from each matrix, \(B_{ij} + C_{ij}\). Now, expand \(A(B+C)\).</p>
<div>
$$
\begin{align*}
(A(B+C))_{ij} &amp;= \sum_k A_{ik}(B_{kj} + C_{kj}) \\
             &amp;= \sum_k A_{ik}B_{kj} + A_{ik}C_{kj} \\
			 &amp;= \sum_k A_{ik}B_{kj} + \sum_k A_{ik}C_{kj} \\
			 &amp;= (AB)_{ij} + (AC)_{ij} \\
			 &amp;= (AB + AC)_{ij} \\
			 &amp;= AB + AC
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li>Math416 by Ely Kerman</li>
</ul>


  </div>
<!-- stupid ads<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = /jekyll/update/2024/08/06/lec14-composition-matrix-multiplication.html;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier =  /jekyll/update/2024/08/06/lec14-composition-matrix-multiplication; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://strncat-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
-->
  <a class="u-url" href="/jekyll/update/2024/08/06/lec14-composition-matrix-multiplication.html" hidden></a>
</article>

    </main>
  </div>

</body>
</html>
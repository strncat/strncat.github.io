<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-08T16:09:06-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">nemo’s notebook</title><subtitle>personal study notes</subtitle><entry><title type="html">Subspaces</title><link href="http://localhost:4000/jekyll/update/2024/07/19/subspaces.html" rel="alternate" type="text/html" title="Subspaces" /><published>2024-07-19T01:01:36-07:00</published><updated>2024-07-19T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/19/subspaces</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/19/subspaces.html"><![CDATA[<p>Consider \(\mathbf{R}^2 = \{(x,y) | x,y \in \mathbf{R}\}\) with component wise addition and component wise scalar multiplication defined in the previous lecture. This is a vector space. Now, consider a line \(L_m\) through the origin.</p>
<div>
$$
\begin{align*}
L_m &amp;= \{(x,y) | y = mx\} = \{(x, mx) | x \in \mathbf{R}\}.
\end{align*}
$$
</div>
<p>If we add two vectors in \(L_m\), the result is in \(L_m\).</p>
<div>
$$
\begin{align*}
(x, mx) + (\tilde{x}, m\tilde{x}) = (x + \tilde{x}, mx + m\tilde{x}) 
                                  &amp;= (x + \tilde{x}, m(x + \tilde{x})).
\end{align*}
$$
</div>
<p>Similarly, scalar multiplication also preserves \(L_m\). So \(L_m\) seems to inherit the same structure of a vector space from \(\mathbf{R}^2\). Let’s introduce the following definition</p>
<div class="bdiv">
  Definition
</div>
<div class="bbdiv">
  Let \(W\) be a subset of a vector space \(V\). \(W\) is a subspace if
  <ol style="list-style-type:lower-alpha">
      <li>\(\bar{0} \in W\).</li>
	  <li>For any \(w_1, w_2 \in W\). \(w_1 + w_2 \in W\). (\(W\) is closed under addition)</li>
      <li>For any \(c \in \mathbf{R}\) and \(w \in W\), \(cw \in W\). (\(W\) is closed under scalar multiplication).</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 1: \([0, 1]\)</b></h4>
<p>Let \(W = [0, 1] \subset \mathbf{R}\). It is not closed under addition. For example, for \(w_1 = 1\) and \(w_2 = 1\), \(w_1 + w_2 \notin \mathbf{R}\). It is not closed under scalar multiplication either. \(\bar{0} \in [0,1]\). 
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 2: \(\mathbf{Z}\)</b></h4>
<p>\(\bar{0} \in [0,1]\). It is closed under addition. But it is not closed under scalar multiplication because we defined scalar multiplication as \(\{c(x, y) = (cx, cy) | c \in \mathbf{R}\}\). (Remember that the vector spaces we’re defining are over \(\mathbf{R}\)).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Subspaces are Vector Spaces</b></h4>
<div class="purdiv">
  Theorem
</div>
<div class="purbdiv">
  If \(W \subset V\) is a subspace and \(V\) is a vector space, then \(W\) is a vector space with the operations are inherited from \(V\).
</div>
<p><br />
<b>Proof:</b>
Let \(V\) be a vector space and \(W \subset V\). Since \(V\) is a vector space, then we know it satisfies conditions (1)-(8) of vector spaces. We also know that \(W\) satisfies properties (a)-(c) since it’s a subspace of \(V\). To verify that \(W\) is a vector space, we need to show that it satisfies conditions (1)-(8) of vector spaces.
<br />
<br />
Conditions (1)-(2) and (5)-(8) are inherited from \(V\). For condition (3), we need a \(\bar{0}\). But we already we know that there exists a zero element since it’s property (1) in the subspaces definition. For property (4), we need to prove that for each \(w \in W\), there exists a \(z \in W\) such that \(w + z = \bar{0}\). But we know there is a \(u \in V\) such that \(w + u = \bar{0}\) since \(V\) is a vector space. We also know that \(u = (-1)w\) (In the previous lecture we proved that \(u\) is unique). But \(u=(-1)w\) must also be in \(W\) since \(W\) is closed under scalar multiplication.
Therefore \(W\) is a vector space as we wanted to show. \(\blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 3</b></h4>
<p>Show that \(W = \{(t_1 + t_2, t_1 - t_2, t_1) | t_1, t_2 \in \mathbf{R}\}\) is a vector space.
<br />
<br />
Proof: \(W\) is a subset of \(\mathbf{R}^3\) so by the previous theorem, it suffices to show that \(W\) is a subspace of \(\mathbf{R}^3\). For condition one, set \(t_1\) and \(t_2\) to 0 to get \(\bar{0} = (0,0,0) \in W\). For any \(w \in W\), we see that \(w + \bar{0} = w + (0,0,0) = w\) as required. For condition 2, let \(w_1, w_2 \in W\).</p>
<div>
$$
\begin{align*}
w_1 + w_2 &amp;= (t_1 + t_2, t_1 - t_2, t_1) + (s_1 + s_2, s_1 - s_2, s_1) \\
          &amp;= (t_1 + t_2 + s_1 + s_2, t_1 - t_2 + s_1 + s_2, t_1 + s_1) \\
		  &amp;= ((t_1 + s_1) + (t_2 + s_2), (t_1 + s_1) - (t_2 + s_2), (t_1 + s_1)).
\end{align*}
$$
</div>
<p>Therefore, \(w_1 + w_2 \in W\). For condition 3, let \(w \in W\) and \(c \in \mathbf{R}\),</p>
<div>
$$
\begin{align*}
cw &amp;= c(t_1 + t_2, t_1 - t_2, t_1) \\
   &amp;= ( c(t_1 + t_2), ct_1 - ct_2, ct_1).
\end{align*}
$$
</div>
<p>This is also clearly in \(W\), Therefore, we can conclude that \(W\) is a vector space. \(\blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Are Solution Sets Vector Spaces?</b></h4>
<p>From the previous example, \(W\) has the form of a solution set of a linear system so does this mean that every solution set is a vector space? The answer is no. Consider \(W' = \{t_1 + t_2, t_1 - t_2, t_1 + 1\}\). \(W'\) is not a subspace of \(\mathbf{R}^3\). We don’t have a zero vector \(\bar{0}\) in \(W\). To show that, we need to prove that there isn’t a solution for the system \(\{t_1 + t_2, t_1 - t_2, t_1 + 1\}\) where \(t_1+t_2 = 0\), \(t_1 - t_2 = 0\) and \(t_1 + 1 = 0\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 4: Polynomials of Degree at Most \(k\)</b></h4>
<p>Consider \(P_k\) which is the set of all polynomials of degree at most \(k\). \(P_k\) is a subspace of \(P_{k+1}\). To show this, we know that \(P_{k+1}\) is a vector space so now we just need to prove the three conditions of subspaces. The zero polynomial is in \(P_k\). For condition 2, if we take any two polynomials in \(k\), then</p>
<div>
$$
\begin{align*}
(a_kx^k + a_{k-1}x^{k-1} + ... + a_0) + (b_kx^k + b_{k-1}x^{k-1} + ... + b_0) = \\
(a_k + b_k)x^k + (a_{k-1}+b_{k-1})x^{k-1} + ... + (a_0+b_0).
\end{align*}
$$
</div>
<p>The result is in \(P_k\) which means that \(P_k\) is closed under addition. For condition 3, take a polynomial in \(P_k\) and a scalar \(c \in \mathbf{R}\), then</p>
<div>
$$
\begin{align*}
c(a_kx^k + a_{k-1}x^{k-1} + ... + a_0) =  (ca_k)x^k + (ca_{k-1})x^{k-1} + ... + (ca_0).
\end{align*}
$$
</div>
<p>This is also in \(P_k\) which means that \(P_k\) is closed under scalar multiplication. Therefore, \(P_k\) is a subspace of \(P_{k+1}\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 4: Continuous Functions</b></h4>
<p>The claim is that \(C^0(\mathbf{R})\) is a subspace of \(F(\mathbf{R})\). For the zero vector, \(\bar{0}(x) = 0\) is a continuous function so it belongs to \(C^0(\mathbf{R})\). For condition 2, if \(f\) and \(g\) are continuous then we know that \(f+g\) is also continuous (from calculus, needs to be proved). For condition 3, a scalar multiplied by \(f\) is also continuous. 
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 5: Continuous Functions</b></h4>
<p>Consider the map transpose: \(M_{m \times n} \rightarrow M_{n \times m}\).</p>
<div>
$$
\begin{align*}
A = (a_{ij}) \rightarrow A^t = (a_{ij} = a_{ji}).
\end{align*}
$$
</div>
<p>Example:</p>
<div>
$$
\begin{align*}
\begin{bmatrix}
a &amp; b \\
c &amp; d
\end{bmatrix}^t
= 
\begin{bmatrix}
a &amp; c \\
b &amp; d
\end{bmatrix}
\end{align*}
$$
</div>
<div class="bdiv">
  Definition
</div>
<div class="bbdiv">
  \(A \in M_{n \times n}\) is symmetric if \(A = A^t\).
</div>
<p><br />
We can show that the set of symmetric matrices in \(M_{n \times n}\) is a subspace. Let the set of symmetric matrices in \(M_{n \times n}\) be \(S\). To show that \(S\) is a subspace, we’ll verify the three conditions</p>
<ol style="list-style-type:lower-alpha">
<li>\(\bar{0} = \begin{bmatrix} 0... &amp;... 0 \\ 0... &amp;... 0 \end{bmatrix}^t\) is symmetric and therefore it is in \(S\)</li>
<li>The sum of two symmetric matrices is symmetric and therefore it is in \(S\) and so \(S\) is closed under addition.</li>
<li>For any \(c \in \mathbf{R}\) and \(s_1 \in S\), \(cS\) is a symmetric matrix and therefore it is in \(S\). So (\(S\) is closed under scalar multiplication).</li>
</ol>
<p><br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References:</b></h4>
<ul>
<li>Video Lectures from Math416 by Ely Kerman.</li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Consider \(\mathbf{R}^2 = \{(x,y) | x,y \in \mathbf{R}\}\) with component wise addition and component wise scalar multiplication defined in the previous lecture. This is a vector space. Now, consider a line \(L_m\) through the origin. $$ \begin{align*} L_m &amp;= \{(x,y) | y = mx\} = \{(x, mx) | x \in \mathbf{R}\}. \end{align*} $$ If we add two vectors in \(L_m\), the result is in \(L_m\). $$ \begin{align*} (x, mx) + (\tilde{x}, m\tilde{x}) = (x + \tilde{x}, mx + m\tilde{x}) &amp;= (x + \tilde{x}, m(x + \tilde{x})). \end{align*} $$ Similarly, scalar multiplication also preserves \(L_m\). So \(L_m\) seems to inherit the same structure of a vector space from \(\mathbf{R}^2\). Let’s introduce the following definition Definition Let \(W\) be a subset of a vector space \(V\). \(W\) is a subspace if \(\bar{0} \in W\). For any \(w_1, w_2 \in W\). \(w_1 + w_2 \in W\). (\(W\) is closed under addition) For any \(c \in \mathbf{R}\) and \(w \in W\), \(cw \in W\). (\(W\) is closed under scalar multiplication). Example 1: \([0, 1]\) Let \(W = [0, 1] \subset \mathbf{R}\). It is not closed under addition. For example, for \(w_1 = 1\) and \(w_2 = 1\), \(w_1 + w_2 \notin \mathbf{R}\). It is not closed under scalar multiplication either. \(\bar{0} \in [0,1]\). Example 2: \(\mathbf{Z}\) \(\bar{0} \in [0,1]\). It is closed under addition. But it is not closed under scalar multiplication because we defined scalar multiplication as \(\{c(x, y) = (cx, cy) | c \in \mathbf{R}\}\). (Remember that the vector spaces we’re defining are over \(\mathbf{R}\)). Subspaces are Vector Spaces Theorem If \(W \subset V\) is a subspace and \(V\) is a vector space, then \(W\) is a vector space with the operations are inherited from \(V\). Proof: Let \(V\) be a vector space and \(W \subset V\). Since \(V\) is a vector space, then we know it satisfies conditions (1)-(8) of vector spaces. We also know that \(W\) satisfies properties (a)-(c) since it’s a subspace of \(V\). To verify that \(W\) is a vector space, we need to show that it satisfies conditions (1)-(8) of vector spaces. Conditions (1)-(2) and (5)-(8) are inherited from \(V\). For condition (3), we need a \(\bar{0}\). But we already we know that there exists a zero element since it’s property (1) in the subspaces definition. For property (4), we need to prove that for each \(w \in W\), there exists a \(z \in W\) such that \(w + z = \bar{0}\). But we know there is a \(u \in V\) such that \(w + u = \bar{0}\) since \(V\) is a vector space. We also know that \(u = (-1)w\) (In the previous lecture we proved that \(u\) is unique). But \(u=(-1)w\) must also be in \(W\) since \(W\) is closed under scalar multiplication. Therefore \(W\) is a vector space as we wanted to show. \(\blacksquare\) Example 3 Show that \(W = \{(t_1 + t_2, t_1 - t_2, t_1) | t_1, t_2 \in \mathbf{R}\}\) is a vector space. Proof: \(W\) is a subset of \(\mathbf{R}^3\) so by the previous theorem, it suffices to show that \(W\) is a subspace of \(\mathbf{R}^3\). For condition one, set \(t_1\) and \(t_2\) to 0 to get \(\bar{0} = (0,0,0) \in W\). For any \(w \in W\), we see that \(w + \bar{0} = w + (0,0,0) = w\) as required. For condition 2, let \(w_1, w_2 \in W\). $$ \begin{align*} w_1 + w_2 &amp;= (t_1 + t_2, t_1 - t_2, t_1) + (s_1 + s_2, s_1 - s_2, s_1) \\ &amp;= (t_1 + t_2 + s_1 + s_2, t_1 - t_2 + s_1 + s_2, t_1 + s_1) \\ &amp;= ((t_1 + s_1) + (t_2 + s_2), (t_1 + s_1) - (t_2 + s_2), (t_1 + s_1)). \end{align*} $$ Therefore, \(w_1 + w_2 \in W\). For condition 3, let \(w \in W\) and \(c \in \mathbf{R}\), $$ \begin{align*} cw &amp;= c(t_1 + t_2, t_1 - t_2, t_1) \\ &amp;= ( c(t_1 + t_2), ct_1 - ct_2, ct_1). \end{align*} $$ This is also clearly in \(W\), Therefore, we can conclude that \(W\) is a vector space. \(\blacksquare\) Are Solution Sets Vector Spaces? From the previous example, \(W\) has the form of a solution set of a linear system so does this mean that every solution set is a vector space? The answer is no. Consider \(W' = \{t_1 + t_2, t_1 - t_2, t_1 + 1\}\). \(W'\) is not a subspace of \(\mathbf{R}^3\). We don’t have a zero vector \(\bar{0}\) in \(W\). To show that, we need to prove that there isn’t a solution for the system \(\{t_1 + t_2, t_1 - t_2, t_1 + 1\}\) where \(t_1+t_2 = 0\), \(t_1 - t_2 = 0\) and \(t_1 + 1 = 0\). Example 4: Polynomials of Degree at Most \(k\) Consider \(P_k\) which is the set of all polynomials of degree at most \(k\). \(P_k\) is a subspace of \(P_{k+1}\). To show this, we know that \(P_{k+1}\) is a vector space so now we just need to prove the three conditions of subspaces. The zero polynomial is in \(P_k\). For condition 2, if we take any two polynomials in \(k\), then $$ \begin{align*} (a_kx^k + a_{k-1}x^{k-1} + ... + a_0) + (b_kx^k + b_{k-1}x^{k-1} + ... + b_0) = \\ (a_k + b_k)x^k + (a_{k-1}+b_{k-1})x^{k-1} + ... + (a_0+b_0). \end{align*} $$ The result is in \(P_k\) which means that \(P_k\) is closed under addition. For condition 3, take a polynomial in \(P_k\) and a scalar \(c \in \mathbf{R}\), then $$ \begin{align*} c(a_kx^k + a_{k-1}x^{k-1} + ... + a_0) = (ca_k)x^k + (ca_{k-1})x^{k-1} + ... + (ca_0). \end{align*} $$ This is also in \(P_k\) which means that \(P_k\) is closed under scalar multiplication. Therefore, \(P_k\) is a subspace of \(P_{k+1}\). Example 4: Continuous Functions The claim is that \(C^0(\mathbf{R})\) is a subspace of \(F(\mathbf{R})\). For the zero vector, \(\bar{0}(x) = 0\) is a continuous function so it belongs to \(C^0(\mathbf{R})\). For condition 2, if \(f\) and \(g\) are continuous then we know that \(f+g\) is also continuous (from calculus, needs to be proved). For condition 3, a scalar multiplied by \(f\) is also continuous. Example 5: Continuous Functions Consider the map transpose: \(M_{m \times n} \rightarrow M_{n \times m}\). $$ \begin{align*} A = (a_{ij}) \rightarrow A^t = (a_{ij} = a_{ji}). \end{align*} $$ Example: $$ \begin{align*} \begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}^t = \begin{bmatrix} a &amp; c \\ b &amp; d \end{bmatrix} \end{align*} $$ Definition \(A \in M_{n \times n}\) is symmetric if \(A = A^t\). We can show that the set of symmetric matrices in \(M_{n \times n}\) is a subspace. Let the set of symmetric matrices in \(M_{n \times n}\) be \(S\). To show that \(S\) is a subspace, we’ll verify the three conditions \(\bar{0} = \begin{bmatrix} 0... &amp;... 0 \\ 0... &amp;... 0 \end{bmatrix}^t\) is symmetric and therefore it is in \(S\) The sum of two symmetric matrices is symmetric and therefore it is in \(S\) and so \(S\) is closed under addition. For any \(c \in \mathbf{R}\) and \(s_1 \in S\), \(cS\) is a symmetric matrix and therefore it is in \(S\). So (\(S\) is closed under scalar multiplication). References: Video Lectures from Math416 by Ely Kerman.]]></summary></entry><entry><title type="html">Vector Spaces</title><link href="http://localhost:4000/jekyll/update/2024/07/17/vector-spaces.html" rel="alternate" type="text/html" title="Vector Spaces" /><published>2024-07-17T01:01:36-07:00</published><updated>2024-07-17T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/17/vector-spaces</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/17/vector-spaces.html"><![CDATA[<div class="bdiv">
  Definition
</div>
<div class="bbdiv">
  A <i>vector space</i> is a set \(V\) with two operations: addition: \(V \times V \rightarrow V\), and a scalar multiplication: \(\mathbf{R} \times V \rightarrow V\), such that the following properties hold:
  <ol>
      <li>\(u + v = v + u\) for all \(u,v \in V\).</li>
	  <li> \((u + v) + w = u + (v + w)\) for all \(u, v, w \in V\).</li>
      <li>There exists an element \(\bar{0} \in V\) such that \(v + \bar{0} = v\) for all \(v \in V\).</li>
	  <li>For all \(v \in V\), there exists \(w \in V\) such that \(v + w = \bar{0}\). </li>
      <li>\(1v = v\) for all \(v \in V\)</li>
	  <li>\(a(bv) = a(bv)\) for all \(v \in V\) and for all \(a, b \in \mathbf{F}\) </li>
	  <li>\(a(u + v) = au + av\) for all \(u, v \in V\) and for all \(a \in \mathbf{F}\)</li>
      <li>\((a + b)v = av + bv\) for all \(u, v \in V\) and for all \(a, b \in \mathbf{F}\)</li>
</ol>
</div>
<p><br />
For property (4), we don’t call it \(-v\) yet because we didn’t prove yet if it’s unique.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 1: \(\mathbf{R}\)</b></h4>
<p>\(\mathbf{R}\) is a vector space equipped with the usual addition and scalar multiplication. The number 0 is the zero vector. We can additionally verify that all the 8 properties.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 2: A Set of Matrices</b></h4>
<p>The set of \(m\) by \(n\) matrices (\(M_{m \times n}\)) equipped with component wise addition such that</p>
<div>
$$
\begin{align*}
\begin{pmatrix}
a &amp; b &amp; c \\
d &amp; e &amp; f \\
\end{pmatrix}
+
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
\end{pmatrix}
=
\begin{pmatrix}
1+a &amp; 2+b &amp; 3+c \\
4+d &amp; 5+e &amp; 6+f \\
\end{pmatrix}
\end{align*}
$$
</div>
<p>and component wise scalar multiplication such that</p>
<div>
$$
\begin{align*}
c
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
\end{pmatrix}
=
\begin{pmatrix}
1c &amp; 2c &amp; 3c \\
4c &amp; 5c &amp; 6c \\
\end{pmatrix}
\end{align*}
$$
</div>
<p>is a vector space.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 3: Sets of Functions</b></h4>
<p>let \(S\) be a nonempty set. For example \(S = \mathbf{R}\), or \(S = \{\pi, \pi^2\}\), \(S = \{\)atoms in the universe\(\}\). Basically any non-empty set. 
Now consider \(F(S) = \{f: S \rightarrow \mathbf{R}\}\), the set of all functions or mappings from \(S\) to \(\mathbf{R}\). One way to think of this is the all the ways we can label the elements in the set \(S\) with real numbers.
<br /><br />
Define addition as \((f+g)(s) = f(s) + g(s)\) for all \(s \in S\). So addition of functions works as addition of their values and produces a real number which is what we want. Define scalar multiplication as \(cf(s) =c(f(s))\) for all \(s \in S\). 
<br /><br />
\(F(S)\) is a vector space. It satisfies all 8 conditions. For example. The zero vector in this space is \(\bar{0}(s) = 0\) for all \(s \in S\). Note also that \(C^1(\mathbf{R})\) (the functions where with continues derivatives) is a subset of \(C^0(\mathbf{R})\) (the set of continuous functions) which is a subset of \(F(S)\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 4: The Set of all Sequences</b></h4>
<p>Consider the set of all natural numbers \(\mathbf{N}\) and the set of functions \(F(\mathbf{N}) = \{\sigma: \mathbf{N} \rightarrow \mathbf{R}\). \(\sigma\) is a function that takes a natural number and assigns it a real number. But</p>
<div>
$$
\begin{align*}
    \sigma(1), \sigma(2), \sigma(3), ...
\end{align*}
$$
</div>
<p>is a sequence. So we’re giving the set of sequences the structure of a vector space. Let \(\sigma(1) =a_1, \sigma(2) = a_2, ...\) and so on. So now we can write the sequence as</p>
<div>
$$
\begin{align*}
    a_1, a_2, a_3 .... = \{a_n\}
\end{align*}
$$
</div>
<p>Let \(V = \{\) sequences \(\{a_n\}\) is a vector space. Define the addition of two sequences as \(\{a_n\} + \{b_n\} = \{a_n + b_n\}\). Adding the terms one by one. Define scalar multiplication as \(c\{a_n\} = \{ca_n\}\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 5: The Set of Polynomials</b></h4>
<div class="bdiv">
  Definition: Degree of a Polynomial
</div>
<div class="bbdiv">
Let \(f\) be defined as follows,
$$
\begin{align*}
    f(x) = a_nx^n + a_{n-1}x^{n-1}+...+a_1x+a_0.
\end{align*}
$$
the degree of \(f\) is the largest \(k\) such that \(x^k\) appears in \(f\) with \(a_k \neq 0\).
</div>
<p><br />
Let \(P_n = \{\) polynomials \(f(x)\) of degree at most \(n\}\).<br />
Define the addition operation as follows,</p>
<div>
$$
\begin{align*}
f(x)+g(x) = (a_nx^n + ...+a_0) + (b_nx^n + ...+b_0) = (a_n+b_n)x^n + ...+(a_0+b_0). 
\end{align*}
$$
</div>
<p>and define scalar multiplication as</p>
<div>
$$
\begin{align*}
cf(x) = ca_nx^n + ca_{n-1}x^{n-1} +...ca_0.
\end{align*}
$$
</div>
<p>\(P_n\) is a vector space. The zero vector is the function \(f\bar{0} = 0 = 0x^n + .... + 0\).
Question: why did we define the polynomials to have at most \(n\) and not just \(n\)? because take \((X^5 + 1)\) and \((-x^5 + 9)\). The addition of these two will generate a 0 and so we have to say at most.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Additional Vector Space Results</b></h4>
<div class="purdiv">
  Theorem
</div>
<div class="purbdiv">
  Let \(u, v, w\) be elements of a vector space \(V\). if \(u + w = v + w\), then \(u = v\).
</div>
<p><br />
<b>Proof:</b>
Let \(V\) be a vector space and \(u, v, w\) be elements in \(V\). By property (4) there is a \(z \in V\) such that</p>
<div>
$$
\begin{align*}
    w + z = \bar{0} 
\end{align*}
$$
</div>
<p>We also know that by property (3) that</p>
<div>
$$
\begin{align*}
    u = u + \bar{0}.
\end{align*}
$$
</div>
<p>But \(\bar{0} = w+z\) and so</p>
<div>
$$
\begin{align*}
u &amp;= u + \bar{0} \\
  &amp;= u + (w + z) \\
  &amp;= (u + w) + z \quad \text{ (by property (2)) } \\
  &amp;= (v + w) + z \quad \text { (by the hypothesis)} \\
  &amp;= v + (w + z) \quad \text{ (by property (2))} \\
  &amp;= v + \bar{0} \\
  &amp;= v \quad
\end{align*}
$$
</div>
<p>Therefore \(u = v\) as we wanted to show. \(\blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="purdiv">
  Theorem
</div>
<div class="purbdiv">
  The zero vector in a vector space is unique.
</div>
<p><br />
<b>Proof:</b>
Suppose \(V\) is a vector space. Now suppose for the sake of contradiction that \(\bar{0}\) and \(\bar{0}'\) are additive inverses of \(V\) where \(\bar{0} \neq \bar{0}'\). This means that</p>
<div>
$$
\begin{align*}
\bar{0}' &amp;= \bar{0}' + \bar{0} \quad \text{(By property 3)}\\
         &amp;= \bar{0} + \bar{0}' \quad \text{By property 1}\\
		 &amp;= \bar{0}. \quad \text{(by property 3)}
\end{align*}
$$
</div>
<p>Therefore, \(\bar{0} = \bar{0}'\) which is a contradiction and the zero vector must be unique. \(\blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="purdiv">
  Theorem
</div>
<div class="purbdiv">
   For all \(v \in V\), there exists a \(w \in V\) such that \(v + w = \bar{0}\). This \(w\) is unique. We call \(w = -v\).
</div>
<p><br />
<b>Proof:</b> 
Suppose \(V\) is a vector space. Let \(v \in V\). Suppose for the sake of contradiction that \(w\) is not unique and there exists two additive inverses \(w\) and \(w'\) such that \(w \neq w'\). Then</p>
<div>
$$
\begin{align*}
w &amp;= w + 0  \quad \text{By property 3}\\
  &amp;= w + (v + w')  \quad \text{By property 3}\\
  &amp;= (w + v) + w'  \quad \text{By property 1}\\
  &amp;= 0 + w'  \quad \text{By the hypothesis}\\
  &amp;= w'.  \quad \text{By property 3}\\
\end{align*}
$$
</div>
<p>Since \(w = w'\), we can conclude that \(w\) is a unique additive inverse. \(\blacksquare\)
<br />
<br />
Two additional implications mentioned in the class is that \(w = (-1)v\) and \(0v = \bar{0}\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 6: A Non Example</b></h4>
<p>Consider the set \(\mathbf{R}^2\) equipped with a different set of operations. Let’s define addition as</p>
<div>
$$
\begin{align*}
   (a_1, a_2) + (b_1, b_2) = (a_1+b_1, a_2*b_2).
\end{align*}
$$
</div>
<p>and scalar multiplication.</p>
<div>
$$
\begin{align*}
    c(a_1, a_2) = (ca_1, a_2).
\end{align*}
$$
</div>

<p>Is this a vector space? No. why?</p>

<p>What is the zero vector is this space?</p>
<div>
$$
\begin{align*}
    \bar{0} = (0, 1)
\end{align*}
$$
</div>
<p>because for every vector \(v\), we want \(v + \bar{0} = v\). \((0, 1)\) works here because</p>
<div>
$$
\begin{align*}
(a_1,a_2)+(0,1) = (a_1+0, a_2*1) = (a_1,a_2)
\end{align*}
$$
</div>
<p><br />
The claim is that property 4 can’t be true. Let \(v = (0,0)\). There is no \((a_1, a_2) \in \mathbf{R}^2\) such that 
\(v + (a_1, a_2) = \bar{0}\). To see this,</p>
<div>
$$
\begin{align*}
    (0,0) + (a_1, a_2) = (a_1+0, 0*a_2) = (a_1, 0).
\end{align*}
$$
</div>
<p>so it can never be equal to (0, 1).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References:</b></h4>
<ul>
<li>Video Lectures from Math416 by Ely Kerman.</li>
<li>Linear Algebra Done Right for the last two proofs</li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition A vector space is a set \(V\) with two operations: addition: \(V \times V \rightarrow V\), and a scalar multiplication: \(\mathbf{R} \times V \rightarrow V\), such that the following properties hold: \(u + v = v + u\) for all \(u,v \in V\). \((u + v) + w = u + (v + w)\) for all \(u, v, w \in V\). There exists an element \(\bar{0} \in V\) such that \(v + \bar{0} = v\) for all \(v \in V\). For all \(v \in V\), there exists \(w \in V\) such that \(v + w = \bar{0}\). \(1v = v\) for all \(v \in V\) \(a(bv) = a(bv)\) for all \(v \in V\) and for all \(a, b \in \mathbf{F}\) \(a(u + v) = au + av\) for all \(u, v \in V\) and for all \(a \in \mathbf{F}\) \((a + b)v = av + bv\) for all \(u, v \in V\) and for all \(a, b \in \mathbf{F}\) For property (4), we don’t call it \(-v\) yet because we didn’t prove yet if it’s unique. Example 1: \(\mathbf{R}\) \(\mathbf{R}\) is a vector space equipped with the usual addition and scalar multiplication. The number 0 is the zero vector. We can additionally verify that all the 8 properties. Example 2: A Set of Matrices The set of \(m\) by \(n\) matrices (\(M_{m \times n}\)) equipped with component wise addition such that $$ \begin{align*} \begin{pmatrix} a &amp; b &amp; c \\ d &amp; e &amp; f \\ \end{pmatrix} + \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ \end{pmatrix} = \begin{pmatrix} 1+a &amp; 2+b &amp; 3+c \\ 4+d &amp; 5+e &amp; 6+f \\ \end{pmatrix} \end{align*} $$ and component wise scalar multiplication such that $$ \begin{align*} c \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \\ \end{pmatrix} = \begin{pmatrix} 1c &amp; 2c &amp; 3c \\ 4c &amp; 5c &amp; 6c \\ \end{pmatrix} \end{align*} $$ is a vector space. Example 3: Sets of Functions let \(S\) be a nonempty set. For example \(S = \mathbf{R}\), or \(S = \{\pi, \pi^2\}\), \(S = \{\)atoms in the universe\(\}\). Basically any non-empty set. Now consider \(F(S) = \{f: S \rightarrow \mathbf{R}\}\), the set of all functions or mappings from \(S\) to \(\mathbf{R}\). One way to think of this is the all the ways we can label the elements in the set \(S\) with real numbers. Define addition as \((f+g)(s) = f(s) + g(s)\) for all \(s \in S\). So addition of functions works as addition of their values and produces a real number which is what we want. Define scalar multiplication as \(cf(s) =c(f(s))\) for all \(s \in S\). \(F(S)\) is a vector space. It satisfies all 8 conditions. For example. The zero vector in this space is \(\bar{0}(s) = 0\) for all \(s \in S\). Note also that \(C^1(\mathbf{R})\) (the functions where with continues derivatives) is a subset of \(C^0(\mathbf{R})\) (the set of continuous functions) which is a subset of \(F(S)\). Example 4: The Set of all Sequences Consider the set of all natural numbers \(\mathbf{N}\) and the set of functions \(F(\mathbf{N}) = \{\sigma: \mathbf{N} \rightarrow \mathbf{R}\). \(\sigma\) is a function that takes a natural number and assigns it a real number. But $$ \begin{align*} \sigma(1), \sigma(2), \sigma(3), ... \end{align*} $$ is a sequence. So we’re giving the set of sequences the structure of a vector space. Let \(\sigma(1) =a_1, \sigma(2) = a_2, ...\) and so on. So now we can write the sequence as $$ \begin{align*} a_1, a_2, a_3 .... = \{a_n\} \end{align*} $$ Let \(V = \{\) sequences \(\{a_n\}\) is a vector space. Define the addition of two sequences as \(\{a_n\} + \{b_n\} = \{a_n + b_n\}\). Adding the terms one by one. Define scalar multiplication as \(c\{a_n\} = \{ca_n\}\). Example 5: The Set of Polynomials Definition: Degree of a Polynomial Let \(f\) be defined as follows, $$ \begin{align*} f(x) = a_nx^n + a_{n-1}x^{n-1}+...+a_1x+a_0. \end{align*} $$ the degree of \(f\) is the largest \(k\) such that \(x^k\) appears in \(f\) with \(a_k \neq 0\). Let \(P_n = \{\) polynomials \(f(x)\) of degree at most \(n\}\). Define the addition operation as follows, $$ \begin{align*} f(x)+g(x) = (a_nx^n + ...+a_0) + (b_nx^n + ...+b_0) = (a_n+b_n)x^n + ...+(a_0+b_0). \end{align*} $$ and define scalar multiplication as $$ \begin{align*} cf(x) = ca_nx^n + ca_{n-1}x^{n-1} +...ca_0. \end{align*} $$ \(P_n\) is a vector space. The zero vector is the function \(f\bar{0} = 0 = 0x^n + .... + 0\). Question: why did we define the polynomials to have at most \(n\) and not just \(n\)? because take \((X^5 + 1)\) and \((-x^5 + 9)\). The addition of these two will generate a 0 and so we have to say at most. Additional Vector Space Results Theorem Let \(u, v, w\) be elements of a vector space \(V\). if \(u + w = v + w\), then \(u = v\). Proof: Let \(V\) be a vector space and \(u, v, w\) be elements in \(V\). By property (4) there is a \(z \in V\) such that $$ \begin{align*} w + z = \bar{0} \end{align*} $$ We also know that by property (3) that $$ \begin{align*} u = u + \bar{0}. \end{align*} $$ But \(\bar{0} = w+z\) and so $$ \begin{align*} u &amp;= u + \bar{0} \\ &amp;= u + (w + z) \\ &amp;= (u + w) + z \quad \text{ (by property (2)) } \\ &amp;= (v + w) + z \quad \text { (by the hypothesis)} \\ &amp;= v + (w + z) \quad \text{ (by property (2))} \\ &amp;= v + \bar{0} \\ &amp;= v \quad \end{align*} $$ Therefore \(u = v\) as we wanted to show. \(\blacksquare\) Theorem The zero vector in a vector space is unique. Proof: Suppose \(V\) is a vector space. Now suppose for the sake of contradiction that \(\bar{0}\) and \(\bar{0}'\) are additive inverses of \(V\) where \(\bar{0} \neq \bar{0}'\). This means that $$ \begin{align*} \bar{0}' &amp;= \bar{0}' + \bar{0} \quad \text{(By property 3)}\\ &amp;= \bar{0} + \bar{0}' \quad \text{By property 1}\\ &amp;= \bar{0}. \quad \text{(by property 3)} \end{align*} $$ Therefore, \(\bar{0} = \bar{0}'\) which is a contradiction and the zero vector must be unique. \(\blacksquare\) Theorem For all \(v \in V\), there exists a \(w \in V\) such that \(v + w = \bar{0}\). This \(w\) is unique. We call \(w = -v\). Proof: Suppose \(V\) is a vector space. Let \(v \in V\). Suppose for the sake of contradiction that \(w\) is not unique and there exists two additive inverses \(w\) and \(w'\) such that \(w \neq w'\). Then $$ \begin{align*} w &amp;= w + 0 \quad \text{By property 3}\\ &amp;= w + (v + w') \quad \text{By property 3}\\ &amp;= (w + v) + w' \quad \text{By property 1}\\ &amp;= 0 + w' \quad \text{By the hypothesis}\\ &amp;= w'. \quad \text{By property 3}\\ \end{align*} $$ Since \(w = w'\), we can conclude that \(w\) is a unique additive inverse. \(\blacksquare\) Two additional implications mentioned in the class is that \(w = (-1)v\) and \(0v = \bar{0}\). Example 6: A Non Example Consider the set \(\mathbf{R}^2\) equipped with a different set of operations. Let’s define addition as $$ \begin{align*} (a_1, a_2) + (b_1, b_2) = (a_1+b_1, a_2*b_2). \end{align*} $$ and scalar multiplication. $$ \begin{align*} c(a_1, a_2) = (ca_1, a_2). \end{align*} $$]]></summary></entry><entry><title type="html">Traversing Diagonals of a Grid</title><link href="http://localhost:4000/jekyll/update/2024/07/15/traversal-diagonals.html" rel="alternate" type="text/html" title="Traversing Diagonals of a Grid" /><published>2024-07-15T01:01:36-07:00</published><updated>2024-07-15T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/15/traversal-diagonals</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/15/traversal-diagonals.html"><![CDATA[<p>This is kind of a misleading title but I didn’t know what to call it. But what I wanted here to print each and every “diagonal” of this grid in both the left and right direction. For example, if left to right, then we’ll have</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/1.png" width="35%" class="center" /></p>
<p>And we’ll print</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="mi">1</span> <span class="mi">6</span> <span class="mi">11</span>
<span class="mi">2</span> <span class="mi">7</span> <span class="mi">12</span>
<span class="mi">3</span> <span class="mi">8</span>
<span class="mi">4</span>
<span class="mi">5</span> <span class="mi">10</span>
<span class="mi">9</span></code></pre></figure>

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Approach</b></h4>
<p>We’re going to divide this problem into two subproblems. In the first subproblem, we’ll print the diagonals starting from the cells in the first column below.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/2.png" width="35%" class="center" /></p>
<p>In the second subproblem, we’ll print the remaining diagonals starting from the cells in the first row but skipping the first overlapping element with the first column since we did that in the first subproblem.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/6.png" width="32%" class="center" /></p>

<!------------------------------------------------------------------------------------>
<h4><b>First Subproblem</b></h4>
<p>We’ll iterate over the first column. From the first cell, we’ll print the following diagonal.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/3.png" width="32%" class="center" /></p>
<p>Next, we’ll move to the next cell in the column and print the diagonal starting from it.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/4.png" width="32%" class="center" /></p>
<p>And finally the last cell in the column.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/5.png" width="32%" class="center" /></p>
<p>This is process is captured in the following code:</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="c1">// left to right direction in an m by n grid</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="c1">// print the diagonal</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">k</span> <span class="o">&lt;</span> <span class="n">m</span> <span class="o">&amp;&amp;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"%d</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]);</span>
        <span class="n">k</span><span class="o">++</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>The above code will output</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="mi">1</span> <span class="mi">6</span> <span class="mi">11</span>
<span class="mi">5</span> <span class="mi">10</span>
<span class="mi">9</span></code></pre></figure>

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Second Subproblem</b></h4>
<p>We’ll iterate over the row column starting at the second cell and print the diagonal from there.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/7.png" width="32%" class="center" /></p>
<p>We’ll move on to the third cell and print the diagonal again.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/8.png" width="32%" class="center" /></p>
<p>Finally, we’ll print the very last diagonal.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/9.png" width="32%" class="center" /></p>
<p>This process is captured in the following code:</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">s</span> <span class="o">=</span> <span class="n">j</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="c1">// print the diagonal</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"d: "</span><span class="p">);</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span> <span class="o">&amp;&amp;</span> <span class="n">s</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"%d</span><span class="se">\t</span><span class="s">"</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">s</span><span class="p">]);</span>
        <span class="n">i</span><span class="o">++</span><span class="p">;</span>
        <span class="n">s</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span></code></pre></figure>

<p>which will print the following</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="mi">2</span> <span class="mi">7</span> <span class="mi">12</span>
<span class="mi">3</span> <span class="mi">8</span>
<span class="mi">4</span></code></pre></figure>

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>The Right to Left Direction</b></h4>
<p>What about the complete other direction (right to left) below. How do we print these diagonals?</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/competitive-programming/traversal-d/10.png" width="32%" class="center" /></p>
<p>We’ll do the same thing, divide the problem into two subproblems and tackle each separately. This is captured in the following code:</p>

<figure class="highlight"><pre><code class="language-c--" data-lang="c++"><span class="c1">// right to left</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">m</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">k</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"%d "</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]);</span>
        <span class="n">k</span><span class="o">--</span><span class="p">;</span>
        <span class="n">j</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">j</span><span class="p">;</span>
        <span class="k">while</span> <span class="p">(</span><span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">s</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">"%d "</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">s</span><span class="p">]);</span>
            <span class="n">i</span><span class="o">--</span><span class="p">;</span>
            <span class="n">s</span><span class="o">++</span><span class="p">;</span>
        <span class="p">}</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="p">}</span></code></pre></figure>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[This is kind of a misleading title but I didn’t know what to call it. But what I wanted here to print each and every “diagonal” of this grid in both the left and right direction. For example, if left to right, then we’ll have And we’ll print 1 6 11 2 7 12 3 8 4 5 10 9 Approach We’re going to divide this problem into two subproblems. In the first subproblem, we’ll print the diagonals starting from the cells in the first column below. In the second subproblem, we’ll print the remaining diagonals starting from the cells in the first row but skipping the first overlapping element with the first column since we did that in the first subproblem.]]></summary></entry><entry><title type="html">Subspaces</title><link href="http://localhost:4000/jekyll/update/2024/07/14/subspaces.html" rel="alternate" type="text/html" title="Subspaces" /><published>2024-07-14T01:01:36-07:00</published><updated>2024-07-14T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/14/subspaces</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/14/subspaces.html"><![CDATA[<div class="ydiv">
  1.33 definition: subspace
</div>
<div class="ybdiv">
  A subset \(U\) of \(V\) is called a <i>subspace</i> of \(V\) if \(U\) is also a vector space with the same additive identity, addition and scalar multiplication as on \(V\).
</div>
<p><br />
Next are the conditions that we must verify to prove that a subset is a subspace.
<br /></p>
<div class="bdiv">
  1.34 conditions for a subspace
</div>
<div class="bbdiv">
  A subset \(U\) of \(V\) is a subspace of \(V\) if and only if \(U\) satisfies the following three conditions.<br />
  <b>additive identity</b><br />
  \(0 \in U\).<br />
  <b>closed under addition</b><br />
  \(u, w \in U implies u + w \in U\).
  <b>closed under multiplication</b><br />
  \(a \in \mathbf{F} and u \in U implies au \in U\).
</div>
<p><br />
This is something that also threw me off. The example in the book defines \(S\) as the interval \([0,1]\) and \(F = R\) and so \(R^{[0,1]}\) is the set of all functions from \([0,1]\) to \(R\) or in other words, the set of real-valued functions on \([0,1]\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>The Vector Space \(\mathbf{F}^S\)</b></h4>
<p>\(\mathbf{F}^S\) is another example of a vector space over \(\mathbf{F}\) along with the operations of addition and scalar multiplication defined previously above. Moreever, let the function 0 defined as \(0(x) = 0\) be the additive identity for all \(x \in S\). For the additive inverse, let \(-f: S \rightarrow \mathbf{F}\) be defined as \((-f)(x) = -f(x)\) be the additive inverse of \(f\) for all \(x \in S\).
<br />
<br />
What’s more interesting is to know that \(F^{n}\) (which is what we usually see) is a special case of the vector space \(\mathbf{F}^S\). [Why? TODO. I didn’t get the explanation in the book]
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4>Additional Vector Space Results</h4>
<div class="bdiv">
  1.26 unique additive identity
</div>
<div class="bbdiv">
  A vector space has a unique additive identity.
</div>
<p><br />
<b>Proof:</b>
Suppose \(V\) is a vector space. Now suppose for the sake of contradiction that 0 and 0’ are additive inverses of \(V\) where \(0 \neq 0'\). This means that</p>
<div>
$$
\begin{align*}
0' = 0' + 0 = 0 + 0' = 0.
\end{align*}
$$
</div>
<p>The first equality holds because 0 is an additive identity. The second equality comes from the fact that addition must be commutative and lastly the last equality holds because 0’ is an additive identity. Therefore, \(0 = 0'\) which is a contradiction and the additive identity must be unique. \(\blacksquare\)
<br />
<br /></p>
<div class="bdiv">
  1.27 unique additive inverse
</div>
<div class="bbdiv">
  Every element in a vector space has a unique additive inverse.
</div>
<p><br />
<b>Proof:</b> 
Suppose \(V\) is a vector space. Let \(v \in V\). Suppose for the sake of contradiction that \(v\) has two additive inverses \(w\) and \(w'\) such that \(w \neq w'\). Then</p>
<div>
$$
\begin{align*}
w = w + 0 = w + (v + w') = (w + v) + w' = 0 + w' = w'.
\end{align*}
$$
</div>
<p>The first equality holds because 0 is the additive identity. The second equality holds because \(v + w' = 0\) since \(w'\) is an additive inverse. The third equality holds because addition is associative and finally \(w + v =\) since \(w\) is also an additive inverse. Since \(w = w'\), we can conclude that \(V\) must have a unique additive inverse. \(\blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4>References:</h4>
<ul>
<li><a href="https://linear.axler.net">Linear Algebra Done Right by Sheldon Axler</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[1.33 definition: subspace A subset \(U\) of \(V\) is called a subspace of \(V\) if \(U\) is also a vector space with the same additive identity, addition and scalar multiplication as on \(V\). Next are the conditions that we must verify to prove that a subset is a subspace. 1.34 conditions for a subspace A subset \(U\) of \(V\) is a subspace of \(V\) if and only if \(U\) satisfies the following three conditions. additive identity \(0 \in U\). closed under addition \(u, w \in U implies u + w \in U\). closed under multiplication \(a \in \mathbf{F} and u \in U implies au \in U\). This is something that also threw me off. The example in the book defines \(S\) as the interval \([0,1]\) and \(F = R\) and so \(R^{[0,1]}\) is the set of all functions from \([0,1]\) to \(R\) or in other words, the set of real-valued functions on \([0,1]\). The Vector Space \(\mathbf{F}^S\) \(\mathbf{F}^S\) is another example of a vector space over \(\mathbf{F}\) along with the operations of addition and scalar multiplication defined previously above. Moreever, let the function 0 defined as \(0(x) = 0\) be the additive identity for all \(x \in S\). For the additive inverse, let \(-f: S \rightarrow \mathbf{F}\) be defined as \((-f)(x) = -f(x)\) be the additive inverse of \(f\) for all \(x \in S\). What’s more interesting is to know that \(F^{n}\) (which is what we usually see) is a special case of the vector space \(\mathbf{F}^S\). [Why? TODO. I didn’t get the explanation in the book] Additional Vector Space Results 1.26 unique additive identity A vector space has a unique additive identity. Proof: Suppose \(V\) is a vector space. Now suppose for the sake of contradiction that 0 and 0’ are additive inverses of \(V\) where \(0 \neq 0'\). This means that $$ \begin{align*} 0' = 0' + 0 = 0 + 0' = 0. \end{align*} $$ The first equality holds because 0 is an additive identity. The second equality comes from the fact that addition must be commutative and lastly the last equality holds because 0’ is an additive identity. Therefore, \(0 = 0'\) which is a contradiction and the additive identity must be unique. \(\blacksquare\) 1.27 unique additive inverse Every element in a vector space has a unique additive inverse. Proof: Suppose \(V\) is a vector space. Let \(v \in V\). Suppose for the sake of contradiction that \(v\) has two additive inverses \(w\) and \(w'\) such that \(w \neq w'\). Then $$ \begin{align*} w = w + 0 = w + (v + w') = (w + v) + w' = 0 + w' = w'. \end{align*} $$ The first equality holds because 0 is the additive identity. The second equality holds because \(v + w' = 0\) since \(w'\) is an additive inverse. The third equality holds because addition is associative and finally \(w + v =\) since \(w\) is also an additive inverse. Since \(w = w'\), we can conclude that \(V\) must have a unique additive inverse. \(\blacksquare\) References: Linear Algebra Done Right by Sheldon Axler]]></summary></entry><entry><title type="html">Vector Spaces Exercise 2</title><link href="http://localhost:4000/jekyll/update/2024/07/13/ch1-exercise-2.html" rel="alternate" type="text/html" title="Vector Spaces Exercise 2" /><published>2024-07-13T01:01:36-07:00</published><updated>2024-07-13T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/13/ch1-exercise-2</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/13/ch1-exercise-2.html"><![CDATA[<div class="pdiv">
  Suppose \(a \in \mathbf{F}, v \in V\) and \(av = 0\). Prove that \(a = 0\) or \(v = 0\).
</div>
<p><br />
<b>Proof:</b>
Suppose \(V\) is a vector space, \(a \in \mathbf{F}\), \(v \in V\) and \(av = 0\). We have two cases</p>
<ul> 
	<li> Case 1: \(a = 0\): This means that
	<div>
	$$
	\begin{align*}
	av &amp;= 0v \\
	   &amp;= 0.
	\end{align*}
	$$
	</div>
	by <a href="https://linear.axler.net/LADR4e.pdf">1.30</a>. So \(a = 0\) and \(av = 0\) as required.</li>
	<li> Case 2: \(a \neq 0\). Here we need to prove that \(v = 0\). Since \(a \in \mathbf{F}\) then \(a\) has a multiplicative inverse \(\frac{1}{a}\). So
	<div>
	$$
	\begin{align*}
	v &amp;= 1v \\
	&amp;= \left(\frac{1}{a}a\right)v \\
	&amp;= \frac{1}{a}(av) \quad \quad \text{(because multiplication is commutative)} \\
	&amp;= \frac{1}{a}(0) \quad \quad \text{because $$av = 0$$} \\
	&amp;= 0.
	\end{align*}
	$$
	</div>
As we wanted to show. \(\blacksquare\)
</li>
</ul>
<p><br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4>References:</h4>
<ul>
<li><a href="https://linear.axler.net">Linear Algebra Done Right by Sheldon Axler</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Suppose \(a \in \mathbf{F}, v \in V\) and \(av = 0\). Prove that \(a = 0\) or \(v = 0\). Proof: Suppose \(V\) is a vector space, \(a \in \mathbf{F}\), \(v \in V\) and \(av = 0\). We have two cases Case 1: \(a = 0\): This means that $$ \begin{align*} av &amp;= 0v \\ &amp;= 0. \end{align*} $$ by 1.30. So \(a = 0\) and \(av = 0\) as required. Case 2: \(a \neq 0\). Here we need to prove that \(v = 0\). Since \(a \in \mathbf{F}\) then \(a\) has a multiplicative inverse \(\frac{1}{a}\). So $$ \begin{align*} v &amp;= 1v \\ &amp;= \left(\frac{1}{a}a\right)v \\ &amp;= \frac{1}{a}(av) \quad \quad \text{(because multiplication is commutative)} \\ &amp;= \frac{1}{a}(0) \quad \quad \text{because $$av = 0$$} \\ &amp;= 0. \end{align*} $$ As we wanted to show. \(\blacksquare\) References: Linear Algebra Done Right by Sheldon Axler]]></summary></entry><entry><title type="html">Vector Spaces</title><link href="http://localhost:4000/jekyll/update/2024/07/12/vector-space.html" rel="alternate" type="text/html" title="Vector Spaces" /><published>2024-07-12T01:01:36-07:00</published><updated>2024-07-12T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/12/vector-space</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/12/vector-space.html"><![CDATA[<p>Lots of definitions and notations are presented in <a href="https://linear.axler.net">Chapter 1: Vector Spaces</a>. I’m going to write down the definitions that made me pause and maybe more important than the rest of the definitions in the chapter. We’ll start with the definition of a vector space from chapter 1.
<br /></p>
<div class="ydiv">
  1.20 definition: vector space
</div>
<div class="ybdiv">
  A <i>vector space</i> is a set \(V\) along with an addition on \(V\) and a scalar multiplication on \(V\) such that the following properties hold.
  <br />
  <br />
  <b>commutativity</b><br />
  \(u + v = v + u\) for all \(u, v \in V\).<br />
  <b>associativity</b><br />
  \((u + v) + w = u + (v + w)\) and \(a(bv) = a(bv)\) for all \(u, v, w \in V\) and for all \(a, b \in \mathbf{F}\).<br />
  <b>additive identity</b><br />
  There exists an element \(0 \in V\) such that \(v + 0 = v\) for all \(v \in V\). <br />
  <b>additive inverse</b><br />
  For every \(v \in V\), there exists \(w \in V\) such that \(v + w = 0\). <br />
  <b>multiplicative identity</b><br />
  \(1v = v\) for all \(v \in V\).<br />
  <b>distributive properties</b><br />
  \(a(u + v) = au + av\) and \((a + b)v = av + bv\) for all \(u, v \in V\) and for all \(a, b \in \mathbf{F}\).<br />
</div>
<p><br />
Seeing this definition for the first time, I immediately was thinking that this is very similar to the definition of a Field except for the scalar multiplication here instead of the normal multiplication in a field. I also saw this discussion <a href=" https://math.stackexchange.com/questions/969720/what-is-the-main-difference-between-a-vector-space-and-a-field">here</a> which is also interesting. Still not sure though what the point is of a vector space … too early to tell.
<br />
<br /></p>
<div class="ydiv">
  1.24 notation: \(\mathbf{F}^S\)
</div>
<div class="ybdiv">
  <ul>
  <li>If \(S\) is a set, then \(\mathbf{F}^S\) denotes the set of functions from \(S\) to \(\mathbf{F}\).</li>
  <li>For \(f, g \in \mathbf{F}^S\), the sum \(f + g \in \mathbf{F}^S\) is the function defined by
	  $$
	  \begin{align*}
	  (f + g)(x) = f(x) + g(x)
	  \end{align*}
	  $$ for all \(x \in S\).
   for all \(x \in S\).</li>
  <li>For \(\lambda \in \mathbf{F}\) and \(f \in \mathbf{F}^S\), the product \(\lambda f \in \mathbf{F}^S\) is the function defined by
  $$
  \begin{align*}
  (\lambda f)(x) = \lambda f(x)
  \end{align*}
  $$ for all \(x \in S\).
  </li>
  </ul>
</div>
<p><br />
This is something that also threw me off. The example in the book defines \(S\) as the interval \([0,1]\) and \(F = R\) and so \(R^{[0,1]}\) is the set of all functions from \([0,1]\) to \(R\) or in other words, the set of real-valued functions on \([0,1]\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>The Vector Space \(\mathbf{F}^S\)</b></h4>
<p>\(\mathbf{F}^S\) is another example of a vector space over \(\mathbf{F}\) along with the operations of addition and scalar multiplication defined previously above. Moreever, let the function 0 defined as \(0(x) = 0\) be the additive identity for all \(x \in S\). For the additive inverse, let \(-f: S \rightarrow \mathbf{F}\) be defined as \((-f)(x) = -f(x)\) be the additive inverse of \(f\) for all \(x \in S\).
<br />
<br />
What’s more interesting is to know that \(F^{n}\) (which is what we usually see) is a special case of the vector space \(\mathbf{F}^S\). [Why? TODO. I didn’t get the explanation in the book]
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4>Additional Vector Space Results</h4>
<div class="bdiv">
  1.26 unique additive identity
</div>
<div class="bbdiv">
  A vector space has a unique additive identity.
</div>
<p><br />
<b>Proof:</b>
Suppose \(V\) is a vector space. Now suppose for the sake of contradiction that 0 and 0’ are additive inverses of \(V\) where \(0 \neq 0'\). This means that</p>
<div>
$$
\begin{align*}
0' = 0' + 0 = 0 + 0' = 0.
\end{align*}
$$
</div>
<p>The first equality holds because 0 is an additive identity. The second equality comes from the fact that addition must be commutative and lastly the last equality holds because 0’ is an additive identity. Therefore, \(0 = 0'\) which is a contradiction and the additive identity must be unique. \(\blacksquare\)
<br />
<br /></p>
<div class="bdiv">
  1.27 unique additive inverse
</div>
<div class="bbdiv">
  Every element in a vector space has a unique additive inverse.
</div>
<p><br />
<b>Proof:</b> 
Suppose \(V\) is a vector space. Let \(v \in V\). Suppose for the sake of contradiction that \(v\) has two additive inverses \(w\) and \(w'\) such that \(w \neq w'\). Then</p>
<div>
$$
\begin{align*}
w = w + 0 = w + (v + w') = (w + v) + w' = 0 + w' = w'.
\end{align*}
$$
</div>
<p>The first equality holds because 0 is the additive identity. The second equality holds because \(v + w' = 0\) since \(w'\) is an additive inverse. The third equality holds because addition is associative and finally \(w + v =\) since \(w\) is also an additive inverse. Since \(w = w'\), we can conclude that \(V\) must have a unique additive inverse. \(\blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4>References:</h4>
<ul>
<li><a href="https://linear.axler.net">Linear Algebra Done Right by Sheldon Axler</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Lots of definitions and notations are presented in Chapter 1: Vector Spaces. I’m going to write down the definitions that made me pause and maybe more important than the rest of the definitions in the chapter. We’ll start with the definition of a vector space from chapter 1. 1.20 definition: vector space A vector space is a set \(V\) along with an addition on \(V\) and a scalar multiplication on \(V\) such that the following properties hold. commutativity \(u + v = v + u\) for all \(u, v \in V\). associativity \((u + v) + w = u + (v + w)\) and \(a(bv) = a(bv)\) for all \(u, v, w \in V\) and for all \(a, b \in \mathbf{F}\). additive identity There exists an element \(0 \in V\) such that \(v + 0 = v\) for all \(v \in V\). additive inverse For every \(v \in V\), there exists \(w \in V\) such that \(v + w = 0\). multiplicative identity \(1v = v\) for all \(v \in V\). distributive properties \(a(u + v) = au + av\) and \((a + b)v = av + bv\) for all \(u, v \in V\) and for all \(a, b \in \mathbf{F}\). Seeing this definition for the first time, I immediately was thinking that this is very similar to the definition of a Field except for the scalar multiplication here instead of the normal multiplication in a field. I also saw this discussion here which is also interesting. Still not sure though what the point is of a vector space … too early to tell. 1.24 notation: \(\mathbf{F}^S\) If \(S\) is a set, then \(\mathbf{F}^S\) denotes the set of functions from \(S\) to \(\mathbf{F}\). For \(f, g \in \mathbf{F}^S\), the sum \(f + g \in \mathbf{F}^S\) is the function defined by $$ \begin{align*} (f + g)(x) = f(x) + g(x) \end{align*} $$ for all \(x \in S\). for all \(x \in S\). For \(\lambda \in \mathbf{F}\) and \(f \in \mathbf{F}^S\), the product \(\lambda f \in \mathbf{F}^S\) is the function defined by $$ \begin{align*} (\lambda f)(x) = \lambda f(x) \end{align*} $$ for all \(x \in S\). This is something that also threw me off. The example in the book defines \(S\) as the interval \([0,1]\) and \(F = R\) and so \(R^{[0,1]}\) is the set of all functions from \([0,1]\) to \(R\) or in other words, the set of real-valued functions on \([0,1]\). The Vector Space \(\mathbf{F}^S\) \(\mathbf{F}^S\) is another example of a vector space over \(\mathbf{F}\) along with the operations of addition and scalar multiplication defined previously above. Moreever, let the function 0 defined as \(0(x) = 0\) be the additive identity for all \(x \in S\). For the additive inverse, let \(-f: S \rightarrow \mathbf{F}\) be defined as \((-f)(x) = -f(x)\) be the additive inverse of \(f\) for all \(x \in S\). What’s more interesting is to know that \(F^{n}\) (which is what we usually see) is a special case of the vector space \(\mathbf{F}^S\). [Why? TODO. I didn’t get the explanation in the book] Additional Vector Space Results 1.26 unique additive identity A vector space has a unique additive identity. Proof: Suppose \(V\) is a vector space. Now suppose for the sake of contradiction that 0 and 0’ are additive inverses of \(V\) where \(0 \neq 0'\). This means that $$ \begin{align*} 0' = 0' + 0 = 0 + 0' = 0. \end{align*} $$ The first equality holds because 0 is an additive identity. The second equality comes from the fact that addition must be commutative and lastly the last equality holds because 0’ is an additive identity. Therefore, \(0 = 0'\) which is a contradiction and the additive identity must be unique. \(\blacksquare\) 1.27 unique additive inverse Every element in a vector space has a unique additive inverse. Proof: Suppose \(V\) is a vector space. Let \(v \in V\). Suppose for the sake of contradiction that \(v\) has two additive inverses \(w\) and \(w'\) such that \(w \neq w'\). Then $$ \begin{align*} w = w + 0 = w + (v + w') = (w + v) + w' = 0 + w' = w'. \end{align*} $$ The first equality holds because 0 is the additive identity. The second equality holds because \(v + w' = 0\) since \(w'\) is an additive inverse. The third equality holds because addition is associative and finally \(w + v =\) since \(w\) is also an additive inverse. Since \(w = w'\), we can conclude that \(V\) must have a unique additive inverse. \(\blacksquare\) References: Linear Algebra Done Right by Sheldon Axler]]></summary></entry><entry><title type="html">Linear Algebra</title><link href="http://localhost:4000/jekyll/update/2024/07/11/linear-algebra.html" rel="alternate" type="text/html" title="Linear Algebra" /><published>2024-07-11T09:01:36-07:00</published><updated>2024-07-11T09:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/11/linear-algebra</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/11/linear-algebra.html"><![CDATA[<!------------------------------------------------------------------->
<h3> Linear Algebra (Math416) </h3>
<ul style="list-style-type:none;">
       <li><a href="/jekyll/update/2024/07/17/vector-spaces.html">
           Vector Spaces
       </a></li>
       <li><a href="/jekyll/update/2024/07/19/subspaces.html">
           Subspaces
       </a></li>
   </ul>
<p><br />
<!-------------------------------------------------------------------></p>
<h3> Essense of Linear Algebra (3Blue1Brown) </h3>
<ul style="list-style-type:none;">
       <li><a href="/jekyll/update/2023/09/11/vectors.html">
           Vectors
       </a></li>
       <li><a href="/jekyll/update/2023/09/12/linear-combinations.html">
           Linear Combinations
       </a></li>
       <li><a href="/jekyll/update/2023/09/22/linear-transformations.html">
           Linear Transformations
       </a></li>
       <li><a href="/jekyll/update/2023/09/25/matrix-multiplication-as-composition.html">
           Matrix Multiplication As Composition
       </a></li>
       <li><a href="/jekyll/update/2023/09/26/determinants.html">
           Determinants
       </a></li>
       <li><a href="/jekyll/update/2023/09/27/system-of-linear-equations.html">
           Inverse Matrices, Column Space and Null Space 
       </a></li>
	   <!--
       <li><a href="/jekyll/update/2023/09/29/dot-product.html">
           Dot Product
       </a></li>
       <li><a href="/jekyll/update/2023/10/02/cross-product.html">
           Cross Product
       </a></li>
	   -->
   </ul>
<p><br /></p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Linear Algebra (Math416) Vector Spaces Subspaces Essense of Linear Algebra (3Blue1Brown) Vectors Linear Combinations Linear Transformations Matrix Multiplication As Composition Determinants Inverse Matrices, Column Space and Null Space]]></summary></entry><entry><title type="html">Elementary Stuff</title><link href="http://localhost:4000/jekyll/update/2024/07/10/math-other.html" rel="alternate" type="text/html" title="Elementary Stuff" /><published>2024-07-10T09:01:36-07:00</published><updated>2024-07-10T09:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/10/math-other</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/10/math-other.html"><![CDATA[<!------------------------------------------------------------------->
<h3> Limits </h3>
<ul style="list-style-type:none;">
    <li><a href="/jekyll/update/2024/04/16/limit-rational-functions.html">
            The Limit of Rational Functions As x Approaches Plus or Negative Infinity
    </a></li>
    <li><a href="/jekyll/update/2024/04/14/limit-sin-x.html">
          The Limit of sin(x) / x
    </a></li>
  </ul>
<p><br /></p>

<!------------------------------------------------------------------->
<h3> Trigonometry </h3>
<ul style="list-style-type:none;">
    <li><a href="/jekyll/update/2024/04/12/trigonometry-cheat-sheet.html">
           Trigonometry Cheat Sheet
      </a></li>
    <li><a href="/jekyll/update/2024/03/26/radians.html">
          Radians
    </a></li>
    <li><a href="/jekyll/update/2024/04/08/the-unit-circle.html">
          Sine, Cosine and The Unit Circle
    </a></li>
    <li><a href="/jekyll/update/2024/03/28/unit-circle-point.html">
          Finding a Point on the Unit Circle
    </a></li>
    <li><a href="/jekyll/update/2024/04/13/graphing-sine-cosine.html">
          Graphing the Sine and Cosine Functions
    </a></li>
  </ul>
<p><br /></p>

<!------------------------------------------------------------------->
<h3> Graphing Functions </h3>
<ul style="list-style-type:none;">
    <li><a href="/jekyll/update/2024/04/09/graph-vertical-asymptotes.html">
         Graphing Rational Functions: Vertical Asymptotes
    </a></li>
    <li><a href="/jekyll/update/2024/04/10/graph-horizontal-asymptotes.html">
         Graphing Rational Functions: Horizontal Asymptotes
    </a></li>
    <li><a href="/jekyll/update/2024/04/11/graph-slanted-asymptotes.html">
         Graphing Rational Functions: Slanted Asymptotes
    </a></li>
    <li><a href="/jekyll/update/2024/04/04/graph-function-linear-over-linear.html">
          Graphing Rational Functions (Example: Linear Over Linear)
    </a></li>
    <li><a href="/jekyll/update/2024/04/07/graph-function-quadratic-over-linear.html">
          Graphing Rational Functions (Example: Quadratic Over Linear)
    </a></li>
    <li><a href="/jekyll/update/2024/04/15/graph-function-exponential.html">
          Graphing the Exponential Function
    </a></li>
    <li><a href="/jekyll/update/2024/04/03/graph-function-logarithm.html">
          Graphing a Logarithmic Function
    </a></li>
    <li><a href="/jekyll/update/2024/04/05/graph-function-absolute-value.html">
          Graphing the Absolute Value Function
    </a></li>
  </ul>
<p><br /></p>

<!------------------------------------------------------------------->
<h3> Other Topics </h3>
<ul style="list-style-type:none;">
    <li><a href="/jekyll/update/2024/04/01/rational-equations.html">
          Solving a Rational Equation
    </a></li>
    <li><a href="/jekyll/update/2024/04/02/partial-decomposition.html">
          Partial Decomposition
    </a></li>
    <li><a href="/jekyll/update/2024/04/06/inverse-rational-function.html">
          Inverse of a Rational Function
    </a></li>
    <li><a href="/jekyll/update/2023/09/28/implicit-representation.html">
          Implicit Representation of an Equation
    </a></li>
    <li><a href="/jekyll/update/2023/09/30/parametric-representation.html">
           Parametric Representation an Equation
    </a></li>
   </ul>
<p><br /></p>

<!------------------------------------------------------------------->
<!--
   <h3> Abstract Algebra </h3>
   <ul style="list-style-type:none;">
       <li><a href="/jekyll/update/2019/09/07/groups.html">
           Groups
       </a></li>
   </ul>
-->

<!------------------------------------------------------------------->
<!--
   <h3> Number Theory </h3>
   <ul style="list-style-type:none;">
       <li><a href="/jekyll/update/2019/08/23/prime-numbers.html">
           Prime Numbers
       </a></li>
       <li><a href="/jekyll/update/2019/08/22/congruences.html">
           Congruences
       </a></li>
   </ul>
-->

<!--
<li><a href="/jekyll/update/2022/09/23/proof1.html">
   <b>09/23/2022:</b> If $n \in N,$ then $1 + (-1)^n(2n-1)$ is a multiple of $4$.
</a></li>
<li><a href="/jekyll/update/2022/09/24/proof2.html">
   <b>09/24/2022:</b> If two integers have opposite parity, then their sum is odd.
</a></li>
<li><a href="/jekyll/update/2022/09/25/proof3.html">
   <b>09/25/2022:</b> If $n \in N,$ then $1 + (-1)^n(2n-1)$ is a multiple of $4$.
</a></li>
-->
<p><br /></p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Limits The Limit of Rational Functions As x Approaches Plus or Negative Infinity The Limit of sin(x) / x]]></summary></entry><entry><title type="html">Real Analysis</title><link href="http://localhost:4000/jekyll/update/2024/07/09/realanalysis.html" rel="alternate" type="text/html" title="Real Analysis" /><published>2024-07-09T09:01:36-07:00</published><updated>2024-07-09T09:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/09/realanalysis</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/09/realanalysis.html"><![CDATA[<!------------------------------------------------------------------->
<ol type="1">
    <li><a href="/jekyll/update/2024/05/14/analysis-psquared-even-then-p-even.html">
          Prove that if \(p^2\) is even, then \(p\) is even.
	</a></li>
    <li><a href="/jekyll/update/2024/05/01/analysis-square-root-two-irrational.html">
          Prove that \(\sqrt{2}\) is irrational.
    </a></li>
    <li><a href="/jekyll/update/2024/05/15/analysis-square-root-three-irrational.html">
          Prove that \(\sqrt{3}\) is irrational.
    </a></li>
	<!--
    <li><a href="/jekyll/update/2024/05/29/analysis-square-root-3-5-irrational.html">
          Prove that \(\sqrt{3} + \sqrt{5}\) is irrational.
    </a></li>
	-->
    <li><a href="/jekyll/update/2024/05/02/analysis-epsilon-proof-for-equal-real-numbers.html">
          Two real numbers \(a\) and \(b\) are equal if and only if for every real number \(\epsilon &gt; 0\) it follows that \(|a - b| &lt; \epsilon\).   
    </a></li>
</ol>
<p><br />
<!---------------------------- The Absolute Value Function -------------------------------></p>
<h3> The Absolute Value Function </h3>
<ol>
    <p><a href="/jekyll/update/2024/05/26/analysis-absolute-value-properties.html">
          Definition and Properties  
    </a></p>
    <li><a href="/jekyll/update/2024/04/25/analysis-absolute-value-pr1.html">
          Let \(x \in \mathbf{R}\), \(|x| \geq 0\).   
    </a></li>
    <li><a href="/jekyll/update/2024/04/26/analysis-absolute-value-pr2.html">
          Let \(x \in \mathbf{R}\), \(-|x| \leq x \leq |x|\).   
    </a></li>
    <li><a href="/jekyll/update/2024/05/13/analysis-absolute-value-max-x-y.html">
          For two real numbers \(x\) and \(y\), prove that \(\max(x,y) = \frac{1}{2}(x+y+|x - y|)\).   
    </a></li>
    <li><a href="/jekyll/update/2024/05/24/analysis-absolute-value-product.html">
          \(|ab| = |a|\cdot|b|\) holds for all real numbers \(a\) and \(b\).   
    </a></li>
    <li><a href="/jekyll/update/2024/05/25/analysis-absolute-value-triangle-inquality.html">
          \(|a+b| \leq |a|+|b|\) holds for all real numbers \(a\) and \(b\). 
    </a></li>
    <li><a href="/jekyll/update/2024/05/27/analysis-absolute-value-triangle-inquality-subtract.html">
          \(|a - c| \leq |a - b|+|b - c|\) holds for all real numbers \(a\), \(b\) and \(c\).   
    </a></li>
</ol>
<p><br />
<!-------------------------------------- Bounds ---------------------------------------></p>
<h3> Upper and Lower Bounds </h3>
<ol>
    <p><a href="/jekyll/update/2024/05/03/analysis-set-bounded.html">
          Bounds Definitions
    </a></p>
    <li><a href="/jekyll/update/2024/05/05/analysis-least-upper-bound-epsilon.html">
          [Lemma 1.3.8] If \(s\) is an upper bound for \(A\), then \(s = \sup A\) if and only if for every choice of \(\epsilon &gt; 0\), there exists an element \(a \in A\) satisfying \(s - \epsilon &lt; a\).
    </a></li>
    <li><a href="/jekyll/update/2024/04/30/analysis-nested-internval-property.html">
          The Nested Interval Property
    </a></li>
    <li><a href="/jekyll/update/2024/05/16/analysis-archimedian-principle.html">
          The Archimedean Principle
    </a></li>
	<!--
    <li><a href="/jekyll/update/2024/05/19/analysis-bounds-alpha-n.html">
          Fix \(\alpha \in (0,1)\). Determine \(\inf(A)\) for \(A=\{\alpha^n: n \in \mathbf{N}\}\).
    </a></li>
    <li><a href="/jekyll/update/2024/05/10/analysis-least-upper-bound-1.3.7.html">
          (11) [1.3.7] If \(a\) is an upper bound for \(A\) and \(a \in A\), then \(a = \sup A\).
    </a></li>
	-->
    <li><a href="/jekyll/update/2024/05/20/analysis-density-of-q-in-r.html">
          [Density of \(\mathbf{Q}\) in \(\mathbf{R}\)] For every two real numbers \(a\) and \(b\) with \(a &lt; b\), there exists a rational number \(r\) satisfying \(a &lt; r &lt; b\).
    </a></li>
    <p>
          Exercises
    </p>
    <li><a href="/jekyll/update/2024/05/04/analysis-least-upper-bound-constant.html">
          The set defined as \(c+A = \{c + a : a \in A\}\) where \(c\) is a constant has a least upper bound equal to \(c + sup A\).
    </a></li>
    <li><a href="/jekyll/update/2024/05/06/analysis-least-upper-bound-multiply.html">
          [1.3.5] The set defined as \(cA = \{ca : a \in A\}\) where \(c \geq 0\) has \(\sup cA = c\sup A\).
    </a></li>
    <li><a href="/jekyll/update/2024/05/07/analysis-least-upper-bound-sum.html">
          [1.3.6] The set defined as \(A + B = \{a + b: a \in A \text{ and } b \in B\}\) has \(\sup (A+B) = \sup A + \sup B\).
    </a></li>
    <li><a href="/jekyll/update/2024/05/08/analysis-least-upper-bound-sum-alternative.html">
          [1.3.6] The set defined as \(A + B = \{a + b: a \in A \text{ and } b \in B\}\) has \(\sup (A+B) = \sup A + \sup B\) (Alternative Proof).
    </a></li>
    <li><a href="/jekyll/update/2024/05/09/analysis-least-upper-bound-union.html">
          [1.3.4] Let \(A\) and \(B\) be nonempty and bounded above. Find a formula for \(\sup (A \cup B)\) and prove that it is correct.
    </a></li>
    <li><a href="/jekyll/update/2024/05/11/analysis-least-upper-bound-infb-infa-supb-supa.html">
          [1.3.11] If \(A\) and \(B\) are nonempty and bounded sets of real numbers such that \(A \subseteq B\) then \(\inf B \leq \inf A \leq \sup A \leq \sup B\).
    </a></li>
    <li><a href="/jekyll/update/2024/05/23/analysis-least-upper-bound-sup0.html">
          Let \(A = \{x \in \mathbf{R}: x &lt; 0\}\). Then \(\sup(A) = 0\).
    </a></li>
    <li><a href="/jekyll/update/2024/05/17/analysis-archimedian-principle-inf-N.html">
          Show that \(\inf\big(\{\frac{1}{n}: n \in \mathbf{N}\} \big) = 0.\)
    </a></li>
    <li><a href="/jekyll/update/2024/05/18/analysis-archimedian-principle-sup-N.html">
          Show that \(\sup\big(\{\frac{1}{n}: n \in \mathbf{N}\} \big) = 1.\)
    </a></li>
</ol>
<p><br />
<!-------------------------------------- Cardinality ---------------------------------------></p>
<h3>Cardinality</h3>
<ol>
    <p><a href="/jekyll/update/2024/06/07/analysis-card-definitions.html">
          Definitions
    </a></p>
    <li><a href="/jekyll/update/2024/06/09/analysis-card-cantor-r-uncountable.html">
		  The open interval \((0,1) = \{x \in \mathbf{R}: 0 &lt; x &lt; 1\}\) is uncountable.
    </a></li>
	<!--
    <li><a href="/jekyll/update/2024/06/08/analysis-card-q-countable-r-uncountable.html">
		  The set \(\mathbf{Q}\) is countable and the set \(\mathbf{R}\) is uncountable.
    </a></li>
	-->
</ol>
<p><br />
<!-------------------------------------- Sequences ---------------------------------------></p>
<h3>Sequences and Subsequences</h3>
<ol>
    <p><a href="/jekyll/update/2024/05/21/analysis-seq-definitions.html">
          Sequences Definitions
    </a></p>
    <li><a href="/jekyll/update/2024/05/12/analysis-seq-limit-template.html">
          Show the Limit Template + Example \(\lim\big(\frac{1}{\sqrt{n}}\big)= 0\).
    </a></li>
    <li><a href="/jekyll/update/2024/04/27/analysis-seq-limits-unique.html">
          [Uniqueness of Limits (2.2.7)] The limit of a sequence, when it exists must be unique.
    </a></li>
    <li><a href="/jekyll/update/2024/06/03/analysis-seq-bounded.html">
          [Bounded Sequences (2.3.1)] A sequence \(x_n\) is bounded if there exists a number \(M &gt; 0\) such that every term in the sequence \(|x_n| \leq M\) for all \(n \in \mathbf{N}\).
    </a></li>
    <li><a href="/jekyll/update/2024/06/12/analysis-seq-if-convergent-then-bounded.html">
          [Convergent Sequences (2.3.2)] Every convergent sequence is bounded.
    </a></li>
    <li><a href="/jekyll/update/2024/05/30/analysis-seq-algebraic-limit-theorem-i.html">
		  [The Algebraic Limit Theorem (2.3.3)] (i) \(\lim (ca_n) = ca\) for all \(c \in \mathbf{R}\).
    </a></li>
    <li><a href="/jekyll/update/2024/05/31/analysis-seq-algebraic-limit-theorem-ii.html">
		  [The Algebraic Limit Theorem (2.3.3)] (ii) \(\lim (a_n + b_n) = a + b\).
    </a></li>
    <li><a href="/jekyll/update/2024/06/01/analysis-seq-algebraic-limit-theorem-iii.html">
		  [The Algebraic Limit Theorem (2.3.3)] (iii) \(\lim (a_nb_n) = ab\).
    </a></li>
    <li><a href="/jekyll/update/2024/06/02/analysis-seq-order-limit-theorem.html">
		  [The Order Limit Theorem ((2.3.4)]
    </a></li>
    <li><a href="/jekyll/update/2024/04/29/analysis-seq-monotone-convergence-theorem.html">
		  [Monotone Convergence Theorem (2.4.2)] If a sequence is monotone and bounded, then it converges.
    </a></li>
    <p><a href="/jekyll/update/2024/02/10/analysis-seq-subsequences.html">
          Subsequences Definitions
    </a></p>
    <li><a href="/jekyll/update/2024/06/11/analysis-seq-subseq-convergence.html">
		  [Convergence of Subsequence (2.5.2)] Subsequences of a convergent sequence converge to the same limit as the original sequence.
    </a></li>
    <li><a href="/jekyll/update/2024/06/14/analysis-seq-subseq-bolzano-weierstrass-theorem.html">
		  [Bolzano-Weierstrass Theorem (2.5.5)] Every bounded sequence contains a convergent subsequence.
    </a></li>
    <li><a href="/jekyll/update/2024/06/16/analysis-seq-cauchy-sequences-bounded.html">
		  (2.6.3) Cauchy Sequences are Bounded
    </a></li>
    <li><a href="/jekyll/update/2024/06/17/analysis-seq-convergent-sequences-are-cauchy.html">
		  Every convergent sequence is a Cauchy sequence
    </a></li>
    <li><a href="/jekyll/update/2024/06/18/analysis-seq-cauchy-critertion.html">
		  [Cauchy Criterion (2.6.4)] A sequence converges if and only if it is a Cauchy sequence.
    </a></li>
    <p>
          Exercises
    </p>
    <li><a href="/jekyll/update/2024/05/22/analysis-seq-limit-example.html">
          Show that \(\lim\big(\frac{n+1}{n}\big)= 1\).
    </a></li>
    <li><a href="/jekyll/update/2024/06/04/analysis-seq-sqrt.html">
		  Let \(x_n \geq 0\) for all \(n \in \mathbf{N}\). Show that if \((x_n) \longrightarrow x\), Then \((\sqrt{x_n}) \longrightarrow \sqrt{x}\).
    </a></li>
    <li><a href="/jekyll/update/2024/06/05/analysis-seq-squeeze-theorem.html">
		  [Squeeze Theorem] Show that if \(x_n \leq y_n \leq z_n\) for all \(n \in \mathbf{N}\), and if \(\lim x_n = \lim z_n = l\), then \(\lim y_n = l\) as well.
    </a></li>
    <li><a href="/jekyll/update/2024/06/06/analysis-seq-abs-value.html">
		  Show that if \((|x_n|) \rightarrow 0\) for all \(n \in \mathbf{N}\), then \(x_n \rightarrow 0\).
    </a></li>
    <li><a href="/jekyll/update/2024/06/15/analysis-seq-sqrt-2.html">
		  Show that \((\sqrt{n + 1} - \sqrt{n})\) converges to 0.
    </a></li>
    <li><a href="/jekyll/update/2024/06/13/analysis-seq-subseq-convergence-example.html">
		  Prove that \(b &gt; b^2 &gt; b^3 &gt; b^4 &gt; ... &gt; 0\) converges to 0 if \(0 &lt; b &lt; 1\). (Example of 2.5.2).
    </a></li>
    <li><a href="/jekyll/update/2024/06/19/analysis-seq-subseq-convergence.html">
		  A sequence \(a_n\) converges to \(a\) if and only if every subsequence of \(a_n\) also converges to \(a\).
    </a></li>
    <li><a href="/jekyll/update/2024/06/20/analysis-seq-subseq-divergence.html">
		  If two subsequences of \(a_n\) converge to different limits, or if any subsequences of \(a_n\) diverges then \(a_n\) diverges.
    </a></li>
    <li><a href="/jekyll/update/2024/06/21/analysis-seq-1n-diverges.html">
		  Prove that \((a_n) = (-1)^n\) diverges.
</a></li>
</ol>
<p><br />
<!-------------------------------------- Series ---------------------------------------></p>
<h3>Series</h3>
<ol>
    <p><a href="/jekyll/update/2024/06/10/analysis-series-definitions.html">
          Series Definitions
    </a></p>
    <li><a href="/jekyll/update/2024/02/08/analysis-series-cauchy-condensation-test.html">
		  (2.4.6) Cauchy Condensation Test
    </a></li>
    <li><a href="/jekyll/update/2024/02/01/analysis-series-algebraic-limit-theorem.html">
		  (2.7.1) The Algebraic Limit Theorem for Series
    </a></li>
    <li><a href="/jekyll/update/2024/02/02/analysis-series-cauchy-criteria.html">
		  (2.7.2) Cauchy Criterion for Series
    </a></li>
    <li><a href="/jekyll/update/2024/02/03/analysis-series-converges-zero.html">
		  (2.7.3) If the series \(\sum_{n=1}^{\infty} a_n\) converges then \((a_n) \rightarrow 0\).
    </a></li>
    <li><a href="/jekyll/update/2024/02/04/analysis-series-comparison-test.html">
		  (2.7.4) Comparison Test for Series
    </a></li>
    <li><a href="/jekyll/update/2024/02/05/analysis-series-geometric.html">
		  (2.7.5) The Geometric Series
    </a></li>
    <li><a href="/jekyll/update/2024/02/06/analysis-series-absolute-convergence-test.html">
		  (2.7.6) [The Absolute Convergence Test] If the series \(\sum_{n=1}^{\infty}|a_n|\) converges, then \(\sum_{n=1}^{\infty} a_n\) converges as well.
    </a></li>
    <li><a href="/jekyll/update/2024/02/07/analysis-series-alternating-series-test.html">
		  (2.7.7) The Alternating Series Test
    </a></li>
	<!-- don't get this one!
    <li><a href="/jekyll/update/2024/02/07/analysis-series-rearrangement.html">
		  (2.7.10) If a series converges absolutely, then any rearrangements of this series converges to the same limit.
    </a></li>
	-->
</ol>
<p><br />
<!-------------------------------------- Topology of R ---------------------------------------></p>
<h3>Topology of R</h3>
<ol>
    <p><a href="/jekyll/update/2024/04/24/analysis-sets-cantor.html">
		  Cantor Sets
    </a></p>
    <p><a href="/jekyll/update/2024/06/22/analysis-sets-open.html">
		  Open Sets
    </a></p>
    <li><a href="/jekyll/update/2024/06/23/analysis-sets-open-sets-union.html">
		  (3.2.3) The union of an arbitrary collection of open sets is open and the intersection of a finite collection of open sets is open.
    </a></li>
    <p><a href="/jekyll/update/2024/06/24/analysis-sets-limit-points.html">
		  Limit Points
    </a></p>
    <p><a href="/jekyll/update/2024/06/25/analysis-sets-closed.html">
		  Closed Sets
    </a></p>
    <li><a href="/jekyll/update/2024/06/26/analysis-sets-closed-contains-limit-points.html">
		  Prove that a set \(F \subseteq \mathbf{R}\) is closed if and only if it contains its limit points.
    </a></li>
    <li><a href="/jekyll/update/2024/06/27/analysis-sets-closed-example.html">
		  Prove that a closed interval \([c,d] = \{c \leq x \leq d\}\) is a closed set.
    </a></li>
    <p><a href="/jekyll/update/2024/06/28/analysis-sets-closure.html">
		  Closure
    </a></p>
	<!--
    <li><a href="/jekyll/update/2024/06/29/analysis-sets-closure-smallest.html">
		  (3.2.12) For any \(A \subseteq R\), the closure \(\overline{A}\) is a closed set and is the smallest closed set containing \(A\).
    </a></li>
	-->
	<li><a href="/jekyll/update/2024/06/30/analysis-sets-complement.html">
		  (3.2.13) A set \(O\) is open if and only if \(O^c\) is closed. Likewise, a set \(F\) is closed if and only if \(F^c\) is open.
    </a></li>
    <p><a href="/jekyll/update/2024/07/01/analysis-sets-compact.html">
		  Compact Sets
    </a></p>
	<li><a href="/jekyll/update/2024/07/02/analysis-sets-compact-theorem.html">
		  (Theorem 3.3.4) [Characterization of Compactness in R] A set \(K \in \mathbf{R}\) is compact if and only if it is closed and bounded.
    </a></li>
	<li><a href="/jekyll/update/2024/07/03/analysis-sets-compact-nested.html">
		  (Theorem 3.3.5) [Nested Compact Set Property]   If \( K_1 \supseteq K_2 \supseteq K_3 \supseteq K_4 \supseteq ...\) is a nested sequence of nonempty compact sets, then the intersection \(\bigcap_{n=1}^{\infty} K_n\) is not empty.
    </a></li>
    <p><a href="/jekyll/update/2024/07/05/analysis-sets-open-cover.html">
		  Open Cover
    </a></p>
	<li><a href="/jekyll/update/2024/07/06/analysis-sets-heine-borel.html">
		  (Theorem 3.3.8) [Heine-Borel Theorem] Let \(K\) be a subset of \(\mathbf{R}\). All of the following statements are equivalent in the sense that any one of them implies the other two (i) \(K\) is compact. (ii) \(K\) is closed and bounded (iii) Every open cover for \(K\) has a finite subcover.
    </a></li>
    <p><a href="/jekyll/update/2024/07/07/analysis-sets-perfect.html">
		  Perfect Sets
    </a></p>
	<!--
	<li><a href="/jekyll/update/2024/07/08/analysis-sets-perfect-uncountable.html">
		  (Theorem 3.4.3) A nonempty perfect set is uncountable.
    </a></li>
    <p>
          Exercises
    </p>
    <li><a href="/jekyll/update/2024/07/04/analysis-sets-compact-sup.html">
          [E3.3.1] Show that if \(K\) is compact and nonempty, then \(\sup K\) and \(\inf K\) both exist and are elements of \(K\).
    </a></li>
	-->
  </ol>
<p><br /></p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Prove that if \(p^2\) is even, then \(p\) is even. Prove that \(\sqrt{2}\) is irrational. Prove that \(\sqrt{3}\) is irrational. Two real numbers \(a\) and \(b\) are equal if and only if for every real number \(\epsilon &gt; 0\) it follows that \(|a - b| &lt; \epsilon\). The Absolute Value Function Definition and Properties Let \(x \in \mathbf{R}\), \(|x| \geq 0\). Let \(x \in \mathbf{R}\), \(-|x| \leq x \leq |x|\). For two real numbers \(x\) and \(y\), prove that \(\max(x,y) = \frac{1}{2}(x+y+|x - y|)\). \(|ab| = |a|\cdot|b|\) holds for all real numbers \(a\) and \(b\). \(|a+b| \leq |a|+|b|\) holds for all real numbers \(a\) and \(b\). \(|a - c| \leq |a - b|+|b - c|\) holds for all real numbers \(a\), \(b\) and \(c\). Upper and Lower Bounds Bounds Definitions [Lemma 1.3.8] If \(s\) is an upper bound for \(A\), then \(s = \sup A\) if and only if for every choice of \(\epsilon &gt; 0\), there exists an element \(a \in A\) satisfying \(s - \epsilon &lt; a\). The Nested Interval Property The Archimedean Principle [Density of \(\mathbf{Q}\) in \(\mathbf{R}\)] For every two real numbers \(a\) and \(b\) with \(a &lt; b\), there exists a rational number \(r\) satisfying \(a &lt; r &lt; b\). Exercises The set defined as \(c+A = \{c + a : a \in A\}\) where \(c\) is a constant has a least upper bound equal to \(c + sup A\). [1.3.5] The set defined as \(cA = \{ca : a \in A\}\) where \(c \geq 0\) has \(\sup cA = c\sup A\). [1.3.6] The set defined as \(A + B = \{a + b: a \in A \text{ and } b \in B\}\) has \(\sup (A+B) = \sup A + \sup B\). [1.3.6] The set defined as \(A + B = \{a + b: a \in A \text{ and } b \in B\}\) has \(\sup (A+B) = \sup A + \sup B\) (Alternative Proof). [1.3.4] Let \(A\) and \(B\) be nonempty and bounded above. Find a formula for \(\sup (A \cup B)\) and prove that it is correct. [1.3.11] If \(A\) and \(B\) are nonempty and bounded sets of real numbers such that \(A \subseteq B\) then \(\inf B \leq \inf A \leq \sup A \leq \sup B\). Let \(A = \{x \in \mathbf{R}: x &lt; 0\}\). Then \(\sup(A) = 0\). Show that \(\inf\big(\{\frac{1}{n}: n \in \mathbf{N}\} \big) = 0.\) Show that \(\sup\big(\{\frac{1}{n}: n \in \mathbf{N}\} \big) = 1.\) Cardinality Definitions The open interval \((0,1) = \{x \in \mathbf{R}: 0 &lt; x &lt; 1\}\) is uncountable. Sequences and Subsequences Sequences Definitions Show the Limit Template + Example \(\lim\big(\frac{1}{\sqrt{n}}\big)= 0\). [Uniqueness of Limits (2.2.7)] The limit of a sequence, when it exists must be unique. [Bounded Sequences (2.3.1)] A sequence \(x_n\) is bounded if there exists a number \(M &gt; 0\) such that every term in the sequence \(|x_n| \leq M\) for all \(n \in \mathbf{N}\). [Convergent Sequences (2.3.2)] Every convergent sequence is bounded. [The Algebraic Limit Theorem (2.3.3)] (i) \(\lim (ca_n) = ca\) for all \(c \in \mathbf{R}\). [The Algebraic Limit Theorem (2.3.3)] (ii) \(\lim (a_n + b_n) = a + b\). [The Algebraic Limit Theorem (2.3.3)] (iii) \(\lim (a_nb_n) = ab\). [The Order Limit Theorem ((2.3.4)] [Monotone Convergence Theorem (2.4.2)] If a sequence is monotone and bounded, then it converges. Subsequences Definitions [Convergence of Subsequence (2.5.2)] Subsequences of a convergent sequence converge to the same limit as the original sequence. [Bolzano-Weierstrass Theorem (2.5.5)] Every bounded sequence contains a convergent subsequence. (2.6.3) Cauchy Sequences are Bounded Every convergent sequence is a Cauchy sequence [Cauchy Criterion (2.6.4)] A sequence converges if and only if it is a Cauchy sequence. Exercises Show that \(\lim\big(\frac{n+1}{n}\big)= 1\). Let \(x_n \geq 0\) for all \(n \in \mathbf{N}\). Show that if \((x_n) \longrightarrow x\), Then \((\sqrt{x_n}) \longrightarrow \sqrt{x}\). [Squeeze Theorem] Show that if \(x_n \leq y_n \leq z_n\) for all \(n \in \mathbf{N}\), and if \(\lim x_n = \lim z_n = l\), then \(\lim y_n = l\) as well. Show that if \((|x_n|) \rightarrow 0\) for all \(n \in \mathbf{N}\), then \(x_n \rightarrow 0\). Show that \((\sqrt{n + 1} - \sqrt{n})\) converges to 0. Prove that \(b &gt; b^2 &gt; b^3 &gt; b^4 &gt; ... &gt; 0\) converges to 0 if \(0 &lt; b &lt; 1\). (Example of 2.5.2). A sequence \(a_n\) converges to \(a\) if and only if every subsequence of \(a_n\) also converges to \(a\). If two subsequences of \(a_n\) converge to different limits, or if any subsequences of \(a_n\) diverges then \(a_n\) diverges. Prove that \((a_n) = (-1)^n\) diverges. Series Series Definitions (2.4.6) Cauchy Condensation Test (2.7.1) The Algebraic Limit Theorem for Series (2.7.2) Cauchy Criterion for Series (2.7.3) If the series \(\sum_{n=1}^{\infty} a_n\) converges then \((a_n) \rightarrow 0\). (2.7.4) Comparison Test for Series (2.7.5) The Geometric Series (2.7.6) [The Absolute Convergence Test] If the series \(\sum_{n=1}^{\infty}|a_n|\) converges, then \(\sum_{n=1}^{\infty} a_n\) converges as well. (2.7.7) The Alternating Series Test Topology of R Cantor Sets Open Sets (3.2.3) The union of an arbitrary collection of open sets is open and the intersection of a finite collection of open sets is open. Limit Points Closed Sets Prove that a set \(F \subseteq \mathbf{R}\) is closed if and only if it contains its limit points. Prove that a closed interval \([c,d] = \{c \leq x \leq d\}\) is a closed set. Closure (3.2.13) A set \(O\) is open if and only if \(O^c\) is closed. Likewise, a set \(F\) is closed if and only if \(F^c\) is open. Compact Sets (Theorem 3.3.4) [Characterization of Compactness in R] A set \(K \in \mathbf{R}\) is compact if and only if it is closed and bounded. (Theorem 3.3.5) [Nested Compact Set Property] If \( K_1 \supseteq K_2 \supseteq K_3 \supseteq K_4 \supseteq ...\) is a nested sequence of nonempty compact sets, then the intersection \(\bigcap_{n=1}^{\infty} K_n\) is not empty. Open Cover (Theorem 3.3.8) [Heine-Borel Theorem] Let \(K\) be a subset of \(\mathbf{R}\). All of the following statements are equivalent in the sense that any one of them implies the other two (i) \(K\) is compact. (ii) \(K\) is closed and bounded (iii) Every open cover for \(K\) has a finite subcover. Perfect Sets]]></summary></entry><entry><title type="html">Perfect Sets are Uncountable</title><link href="http://localhost:4000/jekyll/update/2024/07/08/analysis-sets-perfect-uncountable.html" rel="alternate" type="text/html" title="Perfect Sets are Uncountable" /><published>2024-07-08T01:01:36-07:00</published><updated>2024-07-08T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/07/08/analysis-sets-perfect-uncountable</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/07/08/analysis-sets-perfect-uncountable.html"><![CDATA[<div style="background-color: #E3F4F4; padding: 15px 15px 15px 15px; border:1px solid black;">
  (Theorem 3.4.3) A nonempty perfect set is uncountable.
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Proof</b></h4>
<p>If \(P\) is perfect and nonempty, then it must be infinite because otherwise it would consist only of isolated points. Suppose for the sake of contradiction that \(P\) is countable. This means we can write</p>
<div>
$$
\begin{align*}
P = \{x_1, x_2, x_3, x_4,...\}.
\end{align*}
$$
</div>
<p>We will construct a sequence of nested compact sets \(K_n\), all contained in \(P\) such that \(K_n\) is not empty and \(x_1 \not\in K_2\), \(x_2 \notin K_3\), …. We can then use <a href="https://strncat.github.io/jekyll/update/2024/07/03/analysis-sets-compact-nested.html">theorem 3.3.5</a> to produce an \(x\) such that</p>
<div>
$$
\begin{align*}
x \in \bigcap_{n=1}^{\infty} K_n \subseteq P.
\end{align*}
$$
</div>
<p>and \(x\) is not on the list \(\{x_1, x_2, ...\}\).
<br />
<br />
Let \(I_1=[a_1, b_1]\) be a closed interval in \(P\) that contains \(x_1\) such that \(x_1 \neq a_1\) and \(x_1 \neq b_1\) so \(x_1\) is an interior point. We know that \(P\) is a perfect set. Therefore \(x_1\) is not isolated and so it’s a limit point. This means that there exists an element \(y_2\) in the interior of \(I_1\) (why? because by definition, every \(\epsilon\)-neighborhood \(V_{\epsilon}(x)\) of \(x_1\) must intersect \(P\) at some point other than \(x_1\)). So now construct a closed interval \(I_2\) centered around \(y_2\) such that \(I_2 \subseteq I_1\) but \(x_1 \notin I_2\). In other words, set</p>
<div>
$$
\begin{align*}
\epsilon = \min\{y_2 - a, b - y_2, |x_1 - y_2|\}.
\end{align*}
$$
</div>
<p style="text-align:center;"><img src="http://localhost:4000/assets/math/real-analysis/perfect-set-1.png" width="70%" class="center" /></p>
<p>Then the interval</p>
<div>
$$
\begin{align*}
I_2 = [y_2 - \frac{\epsilon}{2}, y_2 + \frac{\epsilon}{2}].
\end{align*}
$$
</div>
<p>will be contained entirely in \(I_1\) (but formally why though?). We can iteratively continue this process to construct another set contained in \(I_2\). In general, let \(I_n = [a_n, b_n] \in P\) such that \(x_n \in I_n\). Since \(x_n\) is not isolated, then we can find \(y_{n+1} \in [a_n, b_n] \cap P\). Now we can set \(\epsilon_{n+1} = \min\{y_{n+1} - a_n, b_n - y_{n+1}, |x_{n} - y_{n+1}|\}\) and let the interval \(I_{n+1} = [y_{n+1} - \frac{\epsilon_{n+1}}{2}, y_{n+1} + \frac{\epsilon_{n+1}}{2}]\). From this we can observe that</p>

<ul>
<li>\(I_{n+1} \subseteq I_{n}\) by construction.</li>
<li>\(x_n \notin I_{n+1}\) also by how we constructed the next interval in each iteration.</li>
<li>\(I_n \cap P \neq \emptyset\). This was because \(x_n\) is a limit point in \(I_n\) and so the intersection with P must be nonempty.</li>
</ul>

<p>Next, let \(K_n = I_n \cap P\). For each \(n \in \mathbf{N}\), we know that</p>
<ul>
<li>\(K_n\) is closed since \(K_n\) is the intersection of two closed sets.</li>
<li>\(K_n\) is bounded since it is contained in \(I_n\) and \(I_n\) is bounded by construction.</li>
</ul>

<p>From this we know that \(K_n\) is compact. But \(K_{n+1}\) is contained in \(K_n\) by construction since we constructed \(I_{n+1}\) to be contained in \(I_n\). Finally, we can use the <a href="https://strncat.github.io/jekyll/update/2024/07/03/analysis-sets-compact-nested.html"> Nested Compact Set Property (Theorem 3.3.5)</a> to conclude that the intersection</p>
<div>
$$
\begin{align*}
\bigcap_{n=1}^{\infty} K_n
\end{align*}
$$
</div>
<p>is not empty. But we also know that each \(K_n\) is a subset of \(P\) and \(x_n \notin K_{n+1}\). 
<br />
<br />
<!------------------------------------------------------------------------------------>
<b>Other Definitions and Properties</b></p>
<ul>
<li><a href="https://strncat.github.io/jekyll/update/2024/06/22/analysis-sets-open.html">Open Sets</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/06/24/analysis-sets-limit-points.html">Limit Points</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/06/25/analysis-sets-closed.html">Closed Sets</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/07/01/analysis-sets-compact.html">Compact Sets</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/06/28/analysis-sets-closure.html">Closure</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/05/26/analysis-absolute-value-properties.html">Absolute Value Function</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/05/21/analysis-seq-definitions.html">Sequences, Subsequences and Convergence</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/06/10/analysis-series-definitions.html">Series and Series Convergence</a></li>
<li><a href="https://strncat.github.io/jekyll/update/2024/05/12/analysis-seq-limit-template.html">Show the Limit Template</a></li>
</ul>
<p><br />
<!------------------------------------------------------------------------------------>
<b>References:</b></p>
<ul>
<li><a href="https://www.amazon.com/Understanding-Analysis-Undergraduate-Texts-Mathematics/dp/1493927116">Understanding Analysis by Stephen Abbott</a></li>
<li><a href="https://www.youtube.com/watch?v=5N9wNNc0HH4">Wrath of Math</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[(Theorem 3.4.3) A nonempty perfect set is uncountable. Proof If \(P\) is perfect and nonempty, then it must be infinite because otherwise it would consist only of isolated points. Suppose for the sake of contradiction that \(P\) is countable. This means we can write $$ \begin{align*} P = \{x_1, x_2, x_3, x_4,...\}. \end{align*} $$ We will construct a sequence of nested compact sets \(K_n\), all contained in \(P\) such that \(K_n\) is not empty and \(x_1 \not\in K_2\), \(x_2 \notin K_3\), …. We can then use theorem 3.3.5 to produce an \(x\) such that $$ \begin{align*} x \in \bigcap_{n=1}^{\infty} K_n \subseteq P. \end{align*} $$ and \(x\) is not on the list \(\{x_1, x_2, ...\}\). Let \(I_1=[a_1, b_1]\) be a closed interval in \(P\) that contains \(x_1\) such that \(x_1 \neq a_1\) and \(x_1 \neq b_1\) so \(x_1\) is an interior point. We know that \(P\) is a perfect set. Therefore \(x_1\) is not isolated and so it’s a limit point. This means that there exists an element \(y_2\) in the interior of \(I_1\) (why? because by definition, every \(\epsilon\)-neighborhood \(V_{\epsilon}(x)\) of \(x_1\) must intersect \(P\) at some point other than \(x_1\)). So now construct a closed interval \(I_2\) centered around \(y_2\) such that \(I_2 \subseteq I_1\) but \(x_1 \notin I_2\). In other words, set $$ \begin{align*} \epsilon = \min\{y_2 - a, b - y_2, |x_1 - y_2|\}. \end{align*} $$ Then the interval $$ \begin{align*} I_2 = [y_2 - \frac{\epsilon}{2}, y_2 + \frac{\epsilon}{2}]. \end{align*} $$ will be contained entirely in \(I_1\) (but formally why though?). We can iteratively continue this process to construct another set contained in \(I_2\). In general, let \(I_n = [a_n, b_n] \in P\) such that \(x_n \in I_n\). Since \(x_n\) is not isolated, then we can find \(y_{n+1} \in [a_n, b_n] \cap P\). Now we can set \(\epsilon_{n+1} = \min\{y_{n+1} - a_n, b_n - y_{n+1}, |x_{n} - y_{n+1}|\}\) and let the interval \(I_{n+1} = [y_{n+1} - \frac{\epsilon_{n+1}}{2}, y_{n+1} + \frac{\epsilon_{n+1}}{2}]\). From this we can observe that]]></summary></entry></feed>
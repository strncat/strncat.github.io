<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Lecture 14: Matrix Representation of Composition and Matrix Multiplication</title>
  <link rel="stylesheet" href="/assets/css/nemo-theme.css">
  <!-- MathJax if you want math -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <div class="container">
    <nav class="sidebar">
      <!-- You can generate links here manually, or use site.pages or a _data file -->
      <h2>Contents</h2>
      <ul>
        <li><a href="/">Home</a></li>
        <li><a href="/about/">About</a></li>
        <li><a href="/jekyll/update/2024/07/11/linear-algebra.html">Linear Algebra</a></li>
        <li><a href="/jekyll/update/2024/12/05/abstract-algebra.html">Abstract Algebra</a></li>
        <li><a href="/jekyll/update/2025/01/03/number-theory.html">Number Theory</a></li>
        <li><a href="/jekyll/update/2024/07/09/realanalysis.html">Real Analysis</a></li>
        <!-- Add more links as needed -->
      </ul>
    </nav>
    <main class="content">
		<header class="content-header">
		        nemo's notebook
		      </header>
      <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Lecture 14: Matrix Representation of Composition and Matrix Multiplication</h1>
    <!--
    <p class="post-meta">
      <time class="dt-published" datetime="2024-08-06T01:01:36-07:00" itemprop="datePublished">Aug 6, 2024
      </time></p>
     -->
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h4><b>The Vector Space of Linear Transformations</b></h4>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Given vector spaces \(V, W\) define
$$
\begin{align*}
\mathcal{L}(V, W) = \{T: V \rightarrow W \ | \ T \text{ is linear}\}.
\end{align*}
$$
</div>
<p><br />
FACT: The set of linear transformations \(\mathcal{L}(V, W)\) is a vector space. We can think of this as a way to get a new vector space from two vector spaces \(W\) and \(V\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>The Composition of Linear Transformations</b></h4>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Define the linear maps \(S \in \mathcal{L}(X, Y)\) and \(T \in \mathcal{L}(Y, Z)\). We define composition
$$
\begin{align*}
T \circ S: X &amp;\rightarrow Z \\
x &amp;\rightarrow T(S(x))
\end{align*}
$$
</div>
<p><br />
Next, we will show that the composition of two linear transformations is also linear!
<br /></p>
<div class="purdiv">
Theorem
</div>
<div class="purbdiv">
\(T \circ S: X \rightarrow Z\) is linear (\(T \circ S \in \mathcal{L}(X, Z))\) 
</div>
<p><br />
Proof: We want to show that</p>
<div>
$$
\begin{align*}
(T \circ S)(x_1 + cx_2) = (T \circ S)(x_1) + c(T \circ S)(x_2).	 
\end{align*}
$$
</div>
<p>To see expand the left hand side as follows:</p>
<div>
$$
\begin{align*}
(T \circ S)(x_1 + cx_2) &amp;= T(S(x_1 + cx_2)) \\
                     &amp;= T(S(x_1) + cS(x_2)) \text{ (because $S$ is linear)} \\
                     &amp;= T(S(x_1)) + cT(S(x_2)) \text{ (because $T$ is linear)} \\
                     &amp;= (T \circ S)(x_1) + c(T \circ S)(x_2). \ \blacksquare			 
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>The Matrix of Linear Composition</b></h4>
<p>Suppose now that \(X\), \(Y\) and \(Z\) are finite dimensional with fixed bases \(\alpha = \{x_1,...,x_n\}, \beta = \{y_1,...,y_m\}\) and \(\gamma = \{z_1,...,z_n\}\).
<br />
<br />
How are \([S]_{\alpha}^{\beta}, [T]_{\beta}^{\gamma}\) and \([T \circ S]_{\alpha}^{\gamma}\) related?
<br />
<br />
To answer this question, we need to define matrix multiplication.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Matrix Multiplication</b></h4>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Given \(A \in M_{m \times n}\) and \(B \in M_{n \times p}\). We define their product \(AB \in M_{m \times p}\) by
$$
\begin{align*}
(AB)_{ij} = \sum_k^n A_{ik}B_{kj}.
\end{align*}
$$
Alternatively,
$$
\begin{align*}
AB &amp;= A \begin{pmatrix} | &amp;  &amp; | \\ \bar{b}_1 &amp; ... &amp; \bar{b}_p \\ | &amp;  &amp; |  \end{pmatrix}
   = \begin{pmatrix} | &amp;  &amp; | \\ A\bar{b}_1 &amp; ... &amp; A\bar{b}_p \\ | &amp;  &amp; |  \end{pmatrix} .
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<div>
$$
\begin{align*}
A =
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix},
B =
\begin{pmatrix} 1 &amp; 2 \\ 1 &amp; 2 \\ 2 &amp; 1 \end{pmatrix}.
\end{align*}
$$
</div>
<div>
$$
\begin{align*}
A\bar{b}_1 &amp;= 
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}
*
\begin{pmatrix} 1 \\ 1 \\ 2 \\ \end{pmatrix} = 1
\begin{pmatrix} 1  \\ 4  \end{pmatrix}
+ 1
\begin{pmatrix} 2  \\ 5  \end{pmatrix}
+ 
\begin{pmatrix} 3 \\ 6 \end{pmatrix}
=
\begin{pmatrix} 9 \\ 21 \end{pmatrix}
\\
A\bar{b}_1 &amp;= 
\begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}
*
\begin{pmatrix} 2 \\ 2 \\ 1 \\ \end{pmatrix} = 
\begin{pmatrix} 9 \\ 24 \end{pmatrix} \\
AB &amp;= 
\begin{pmatrix} 9 &amp; 9 \\ 21 &amp; 24 \end{pmatrix}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Matrix Composition Using Matrix Multiplication</b></h4>
<p>Now that we defined matrix multiplication, we are ready to answer the question of how \([S]_{\alpha}^{\beta}, [T]_{\beta}^{\gamma}\) and \([T \circ S]_{\alpha}^{\gamma}\) related.</p>
<div class="purdiv">
Theorem 2.11
</div>
<div class="purbdiv">
Given \(S \in \mathcal{L}(X, Y)\) and \(T \in \mathcal{L}(Y, Z)\) and finite bases \(\alpha, \beta, \gamma\) for \(X, Y, Z\), then
$$
\begin{align*}
[T \circ S]_{\alpha}^{\gamma} = [T]^{\gamma}_{\beta} [S]^{\beta}_{\alpha}
\end{align*}
$$
</div>
<p><br />
In other words, the composition of the linear transformations \(S\) and \(T\) is equal to the matrix multiplication of the two matrices representing these linear transformations.
<br /></p>
<h4><b>Proof</b></h4>
<p>Fix the basis \(\alpha\) such that \(\alpha = \{x_1,...,x_n\}\). Then,</p>
<div>
$$
\begin{align*}
[T \circ S]_{\alpha}^{\gamma} &amp;= ([(T \circ S)(x_1)]_{\gamma} ... [(T \circ S)(x_n)]_{\gamma}) \\
&amp;= ([(T(S(x_1))]_{\gamma} ... [(T(S(x_n))]_{\gamma}) \text{( by definition)}\\
&amp;= ([T]_{\beta}^{\gamma}[(S(x_1)]_{\beta} ... [T]_{\beta}^{\gamma}[(S(x_n)]_{\beta}) \text{( by theorem 2.14 (lecture 13))}\\
&amp;= [T]_{\beta}^{\gamma}([(S(x_1)]_{\beta} ... [(S(x_n)]_{\beta}) \\
&amp;= [T]^{\gamma}_{\beta} \circ [S]^{\beta}_{\alpha}. \blacksquare					 
\end{align*}
$$
</div>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<div>
$$
\begin{align*}
A &amp;\in M_{m \times n} \rightarrow L_A: \mathbf{R}^n \rightarrow \mathbf{R}^m \\
B &amp;\in M_{p \times m} \rightarrow L_B: \mathbf{R}^m \rightarrow \mathbf{R}^p
\end{align*}
$$
</div>
<p>If we choose the standard basis for all vector spaces, then the theorem tells us</p>
<div>
$$
\begin{align*}
[L_B \circ L_A]_{\alpha}^{\gamma} &amp;= [L_B]^{\gamma}_{\beta} \circ [L_A]^{\beta}_{\alpha}.
\end{align*}
$$
</div>
<p>But since we chose the standard basis then we know that \([L_A]^{\beta}_{\alpha} = A\) and \([L_B]^{\gamma}_{\beta} = B\). So we can also write</p>
<div>
$$
\begin{align*}
[L_B \circ L_A]_{\alpha}^{\gamma} &amp;= [L_B]^{\gamma}_{\beta} \circ [L_A]^{\beta}_{\alpha} = BA = [L_{BA}]^{\gamma}_{\alpha}.
\end{align*}
$$
</div>
<p>In particular, this shows that these maps are equal \(L_B \circ L_A = L_{BA}\).</p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Let</p>
<div>
$$
\begin{align*}
T_d: P_3 &amp;\rightarrow P_2 \\
f &amp;\rightarrow f'			 
\end{align*}
$$
</div>
<p>and</p>
<div>
$$
\begin{align*}
T_i: P_2 &amp;\rightarrow P_3 \\
f &amp;\rightarrow \int_0^x f(t)dt			 
\end{align*}
$$
</div>
<p>For standard bases \(\beta = \{1,x,x^2, x^3\}\) of \(P_3\) and \(\gamma = \{1, x, x^2\}\) of \(P_2\). 
<br />
<br />
Extra notes: As a reminder, to find the matrix representative of of \(T_d\), we first apply the transformation on the vectors of \(\beta\).</p>
<div>
$$
\begin{align*}
T(1) = 0, T(x) = 1, T(x^2) = 2x, T(x^3) = 3x^2. 		 
\end{align*}
$$
</div>
<p>and then we find the coordinates of these images with respect to \(\gamma\) which will be the column vectors of the matrix,</p>
<div>
$$
\begin{align*}
T(1) &amp;= 0 = 0(1) + 0(x) + 0(x^2) \\
T(x) &amp;= 1 = 1(1) + 0(x) + 0(x^2) \\
T(x^2) &amp;= 2x = 0(1) + 2(x) + 0(x^2) \\
T(x^3) &amp;= 3x^2 = 0(1) + 0(x) + 3(x^2).
\end{align*}
$$
</div>
<p>Therefore, \(T_d\) and \(T_i\) (can be found using the same method) are:</p>
<div>
$$
\begin{align*}
[T_d]^{\gamma}_{\beta} &amp;= 
\begin{pmatrix}
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 3
\end{pmatrix}, [T_i]_{\gamma}^{\beta} = 
\begin{pmatrix}
0 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1/2 &amp; 0 \\
0 &amp; 0 &amp; 1/3
\end{pmatrix}.
\end{align*}
$$
</div>
<p>To compose these matrices we just multiply them,</p>
<div>
$$
\begin{align*}
[T_i]_{\gamma}^{\beta}[T_d]^{\gamma}_{\beta} = 
\begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix}.
\end{align*}
$$
</div>
<p>To verify, want to compute \([T_i \circ T_d]^{\beta}_{\beta}\) but instead of applying the composition on each vector. Letâ€™s just apply it on a general object. In this case we need an object from \(P_3\):</p>
<div>
$$
\begin{align*}
(T_i \circ T_d)(a_0 + a_1x + a_2x^2 + a_3x^3) &amp;= T_i(T_d(a_0 + a_1x + a_2x^2 + a_3x^3)) \\
                                              &amp;= T_i(a_1 + 2a_2x + 3a_3x^2) \\
                        &amp;= a_1x + a_2x^2 + a_3x^3
\end{align*}
$$
</div>
<p>So now the first column of this matrix should be the image of the first vector in the basis \(\beta\) so the image of \(1\) and thatâ€™s simply all zeros. For \(x\), we see \(a_1x\) just got mapped to itself again in the final equation. Similarly we get the same for the last two basis vectors so</p>
<div>
$$
\begin{align*}
[T_i \circ T_d]^{\beta}_{\beta} = 
\begin{pmatrix}
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix} = 
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Matrix Multiplication Properties</b></h4>
<div class="purdiv">
Theorem
</div>
<div class="purbdiv">
<ol style="list-style-type:lower-alpha">
	<li>\(A(BC) = (AB)C\)</li>
	<li>\(A(B+C) = AB + AC\)</li>
	<li>Not commutative. In general \(AB \neq BA\)</li>
</ol>
</div>
<p><br />
<b>Proof (b):</b>
<br /> 
As a reminder we know that \((AB)_{ij} = \sum_{k=1}^n A_{ik}B_{kj}\). We also know that \(B+C\) is just summing the matching coordinates from each matrix, \(B_{ij} + C_{ij}\). Now, expand \(A(B+C)\).</p>
<div>
$$
\begin{align*}
(A(B+C))_{ij} &amp;= \sum_k A_{ik}(B_{kj} + C_{kj}) \\
             &amp;= \sum_k A_{ik}B_{kj} + A_{ik}C_{kj} \\
			 &amp;= \sum_k A_{ik}B_{kj} + \sum_k A_{ik}C_{kj} \\
			 &amp;= (AB)_{ij} + (AC)_{ij} \\
			 &amp;= (AB + AC)_{ij} \\
			 &amp;= AB + AC
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li>Math416 by Ely Kerman</li>
</ul>


  </div>
<!-- stupid ads<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = /jekyll/update/2024/08/06/lec14-composition-matrix-multiplication.html;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier =  /jekyll/update/2024/08/06/lec14-composition-matrix-multiplication; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://strncat-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
-->
  <a class="u-url" href="/jekyll/update/2024/08/06/lec14-composition-matrix-multiplication.html" hidden></a>
</article>

    </main>
  </div>

</body>
</html>
---
layout: post
title:  "Worst Case vs Expected Case vs Average Case run time"
date:   2019-07-19 07:01:36 -0700
categories: jekyll update
mathjax: true
---

<b>0 References</b>
<br>
<br>
(1) Class study notes from http://web.stanford.edu/class/cs161/schedule.html
(2) CLRS (Chapter 5)
<br>
<br>
<hr>
<!------------------------------------------------------------------------------------>
<br>
<b>Introduction</b>
<br>
<br>
So the first time I read chapter 5 in CLRS I was utterly confused. What is going one with the average case and the expected case runtimes, what is the difference? Why is CLRS switching between the two?
<br>
<br>
<hr>
<!------------------------------------------------------------------------------------>
<br>
<b>Average Case Running Time</b>
<br>
<br>
In this case, we assume some knowledge of the distribution of the input given to us. For
 we must use knowledge of, or make assumptions about, the distribution of the inputs. Then we analyze our algorithm, computing an average-case running time, where we take the average over the distribution of the possible inputs. Thus we are, in effect, averaging the running time over all possible inputs. When reporting such a running time, we will refer to it as the average-case running time.
<br>
<br>
<hr>
<!------------------------------------------------------------------------------------>
<br>
<b>Expected Case Running Time</b>
<br>
<br>
 we must use knowledge of, or make assumptions about, the distribution of the inputs. Then we analyze our algorithm, computing an average-case running time, where we take the average over the distribution of the possible inputs. Thus we are, in effect, averaging the running time over all possible inputs. When reporting such a running time, we will refer to it as the average-case running time.
<br>
<br>
<hr>











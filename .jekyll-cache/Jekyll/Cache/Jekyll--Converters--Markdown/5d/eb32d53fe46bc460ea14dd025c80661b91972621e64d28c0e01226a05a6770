I"Ò<!------------------------------------------------------------------------------------>
<h3>Note</h3>
<p>These are my rough notes based on attending CS148. They might contain errors so proceed with caution!
<br />
<br />
Our goal is to mimic human vision in a virtual world. We do this by:</p>
<ul>
  <li>Creating a virtual camera and placing it somewhere to point at something.</li>
  <li>Putting a film that contains pixels with RGB values between 0 and 255 into the camera.</li>
  <li>Placing some objects in the world. (geometric modeling, transformations, texture mapping).</li>
  <li>Putting lights in the scene.</li>
  <li>And Finally taking the picture. The light will bounce around the room hitting the objects and back hitting the camera onto the virtual film.
<br />
<br />
<!------------------------------------------------------------------------------------></li>
</ul>
<h3>Pupil</h3>
<p>What is the role of the pupil in the eye? So we know that the lights goes off every point of an object in every direction and this is why we all see the same point on the same object. We looked at this in the previous lecture. What we didn‚Äôt discuss is that without the pupil, this light that is bouncing from every single point on the object, is actually hitting every single cone (or pixel in the camera). The image that we‚Äôll see is just going to be a blurred image averaging all these points. We won‚Äôt see any details.
<br />
<br />
The reason why we don‚Äôt see everything as a blurry image is the pupil (or the aperture in the camera). The pupil‚Äôs rol is to restrict the light bouncing from all these points on every single object. The pupil will only allow some point, enough to see clearly. Moreover, when the pupil gets small, we‚Äôd get a sharper image and as the pupil gets larger, we‚Äôd see a blurred image. But the pupil (and the aperture) can‚Äôt be too small because otherwise the light will bend as it gets through the tiny point due to the particle/wave length duality. Therefore, it has to be small enough but not too small.
<br />
<br />
The Camera mimic the human eyes but instead of cones we have mechanical pixels. And instead of the pupil, we have an aperture. Cameras have also complex lens system. 
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h3>Pinhole Camera</h3>
<p style="text-align:center;"><img src="http://localhost:4000/assets/graphics/virtual-world/01-pinhole.png" width="80%" class="center" /></p>
<p>Since this is a virtual world, then we won‚Äôt have the light bending issue (particle/wave duality) so we can just use a simple camera model, the pinhole camera, where the aperture is just a single point. Light will go through this one point from an object to a pixel. 
<br />
<br />
Here are some more properties of the Pinhole Camera:</p>
<ul>
  <li>The images created can‚Äôt do stuff like depth of field (not blurry as you go farther).</li>
  <li>Object occlude things that appear behind them.</li>
  <li>more distant objects subtend smaller visual angels and appear smaller</li>
  <li>The image will be an upside version of the real world object.
<br />
<br />
To solve this last issue and make the camera more efficient:</li>
  <li>We‚Äôll move the film out in front of the pinhole so that the image is not upside down.</li>
  <li>We‚Äôll only render objects further away from the camera than the film plane.</li>
  <li>We‚Äôll add a clipping plane for efficiency so we don‚Äôt have to process every single object knowing that we won‚Äôt render it since it‚Äôs occluded.</li>
  <li>The volume between the film (front clipping plane) and the back clipping plane is called the <b>viewing frustum</b>.
<br />
<br />
<!------------------------------------------------------------------------------------></li>
</ul>
<h3>Objects in the Virtual World</h3>
<ul>
  <li>We‚Äôll model the objects with 3D points. Each object will be a collection of points.</li>
  <li>Objects are created in a reference space that we call the ‚Äúobject space‚Äù.</li>
  <li>Once objects are created, we‚Äôll place the objects into the scene. This space is called the ‚Äúworld space‚Äù. It‚Äôs important to know that we don‚Äôt have geometry in the actual space. Instead, we have code that tell us where to place the objects around us via some rigid body motion such as Rotations (3 ways to rotate) and Translate (3 ways to translate) so a total of 6 degrees of freedom. We can also scale the object.</li>
</ul>

<p><br />
An important question arises here is why create the objects in their object space and then place them via transformations in the virtual world? why not just integrate an object such as a lamp in the virtual world? Because it‚Äôs a waste. if the lamp consisted of 100k vertices and the scene needed 100 of these, then we‚Äôll have 10 million vertices just for lamps. Instead we can just create one lamp and then use the transformations that we described to place this lamp 100 times around the scene.
<br />
<br />
Finally, when we take a virtual picture, points on the object are projected on the 2d film plane which we refer to as a ‚Äúscene space‚Äù. This projection is nonlinear and the source of undesirable distortion.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h3>References</h3>
<p><a href="https://www.amazon.com/Fundamentals-Computer-Graphics-Steve-Marschner/dp/1482229390">Fundamentals of Computer Graphics, 4th Edition</a>
<br />
<a href="https://web.stanford.edu/class/cs148/lectures.html"> CS148 Lectures </a>
<br />
<br /></p>

:ET
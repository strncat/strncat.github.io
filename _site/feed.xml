<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-05-15T05:52:02-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">nemo’s notebook</title><subtitle>personal study notes</subtitle><entry><title type="html">Math417 Crt Notes</title><link href="http://localhost:4000/2025/03/04/math417-crt-notes.html" rel="alternate" type="text/html" title="Math417 Crt Notes" /><published>2025-03-04T00:00:00-08:00</published><updated>2025-03-04T00:00:00-08:00</updated><id>http://localhost:4000/2025/03/04/math417-crt-notes</id><content type="html" xml:base="http://localhost:4000/2025/03/04/math417-crt-notes.html"><![CDATA[<p>(1) Define the map 
Z \rightarrow Z_a \times Z_b
\phi(x) = ([x]_a, [x]_b)
This map is a homomorphism (easy check).
This map is surjective iff gcd(a,b) = 1 why?
Because given some element in Z_a \times Z_b so ([r]_a, [s]_b) we want to find integer x such that</p>

<p>x \equiv r (mod a)
x \euqiv s (mod b)</p>

<p>This set of equations by the Chinese remainder only has a solution if and only if gcd(a,b) = 1</p>

<p>—————————————————————&gt;
why (proof)
=&gt;
Suppose a solution exists, then
x \equiv r (mod a)
x \euqiv s (mod b)</p>

<p>this means that
a | x - r
b | x - s</p>

<p>therefore
x - r = ma
x - s = nb</p>

<p>(x - r) - (x - s) = ma - nb
s - r = am - nb
so (s - r) can be written as a linear combination of a and B
therefore, s - r \in aZ + bZ which is I(a,b)
but I(a,b) = gcd(a,b) (By the GCD Theorem) lecture notes</p>

<p>so r - s \in gcd(a,b)Z</p>

<table>
  <tbody>
    <tr>
      <td>so gcd(a,b)</td>
      <td>r - s</td>
    </tr>
  </tbody>
</table>

<p>&lt;=
Suppose d=gcd(a,b) | (r-s)
so r - s = dk for some k
so now because gcd(a,b) = d then d is a factor of a and b so</p>

<p>a = d (a_1) for some a_1 
b = d (b_1) for some b_1</p>

<p>by definition of gcd, then we must have gcd(a_1,b_1) = 1</p>

<p>so now we want to find x such that
x \equiv r (mod a)
x \equiv s (mod b)</p>

<p>x = r + at for some t 
x = r + (a_1d)t
substitute this into the second congruence</p>

<p>(r + (a_1d)t) \equiv s (mod b)
a_1dt \equiv s - r (mod b=db_1)
a_1dt \equiv dk (mod db_1)</p>

<p>cancel d</p>

<p>a_1t \equiv k (mod b_1)
but gcd(a_1, b_1) = 1 so this congruence has a solution for any k
This is true because we can only have a multiplicative inverse if the gcd is 1 and then we can multiply by the inverse on both sides to get a solution</p>

<p>x = r + da_1t_0</p>

<p>—————————————————————-&gt;</p>

<p>SO NOW back to the
Z \rightarrow Z_a \times Z_b
\phi(x) = ([x]_a, [x]_b)
This is surjective if and only if gcd(a, b) = 1 (by the Chinese remainder theorem)
the kernel of this map is lcm(a,b)\Z</p>

<p>So now, if it was surjective, then we get an isomorphism</p>

<p>Z_m \rightarrow Z_a \times Z_b 
This isomorphism takes a [x]_m to ([x]_a, [x]_b)</p>]]></content><author><name></name></author><summary type="html"><![CDATA[(1) Define the map Z \rightarrow Z_a \times Z_b \phi(x) = ([x]_a, [x]_b) This map is a homomorphism (easy check). This map is surjective iff gcd(a,b) = 1 why? Because given some element in Z_a \times Z_b so ([r]_a, [s]_b) we want to find integer x such that]]></summary></entry><entry><title type="html">Lecture 40: Fermat’s Theorem on Sum of Squares</title><link href="http://localhost:4000/jekyll/update/2025/03/03/math417-40-fermat-sum-of-squares.html" rel="alternate" type="text/html" title="Lecture 40: Fermat’s Theorem on Sum of Squares" /><published>2025-03-03T00:01:36-08:00</published><updated>2025-03-03T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/03/03/math417-40-fermat-sum-of-squares</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/03/03/math417-40-fermat-sum-of-squares.html"><![CDATA[<p>Question: For which integer \(m \in \mathbf{Z}\), can we write \(m\) as the sum of squares of two integers so \(m = a^2 + b^2\) for some \(a, b \in \mathbf{Z}\)?
<br />
<br />
We know that this is closely related to the Gaussian integers. Recall that \(a^2 + b^2 = N(a + bi)\) where \(a + bi \in \mathbf{Z}[i]\). So sums of squares appear as norms of Gaussian integers.</p>
<div>
$$
\begin{align*}
\{\text{Sum of two squares in }\mathbf{Z}\} = \text{image}[N: \mathbf{Z}[i] \rightarrow \mathbf{Z}]
\end{align*}
$$
</div>
<p>The norm function is not a homomorphism of rings but it’s a multiplicative function (meaning it only satisfies \(N(xy) =N(x)N(y)\)). So this subset of \(\mathbf{Z}\) is closed under multiplication. So for example, \(5 = 2^2 + 1^1\) and \(17 = 4^2 + 1^1\). Therefore, we expect that \(5*17 = 85\) is also a sum of squares. In fact \(85 = 9^2 + 2^2\). 
<br />
<br />
It turns out that when \(m\) in \(m = a^2 + b^2\) is prime, then we have a solution using the following theorem
<br />
<!---------------------------------------></p>
<div class="yellowheaderdiv">
Theorem (Fermat)
</div>
<div class="yellowbodydiv">
If \(p \in \mathbf{N}\) is a prime number, then \(p = a^2 + b^2\) for some \(a, b \in \mathbf{Z}\) if and only if either \(p = 2\) or \(p \equiv 1 (\bmod 4)\)  
</div>
<!--------------------------------------->
<p><br />
We already know that \(2 = 1^2 + 1^2\) and we also know that if \(p \equiv -1 (\bmod 4)\), then \(p\) is not a sum of two squares. Because \(\bmod 4\), a square of a number is congruent to either 0 or 1. So the sum will not be 3 which is the same as \(-1 \bmod 4\). So the remaining case is when \(p \equiv 1 (\bmod 4)\), we want to show that \(p\) is a sum of two squares. To show this we’ll present the following lemma first.
<br />
<!---------------------------------------></p>
<div class="yellowheaderdiv">
Lemma (Lagrange)
</div>
<div class="yellowbodydiv">
If \(p = 4n + 1\) is a prime number, then there exists some \(m \in \mathbf{Z}\) such that \(p \ | \ m^2 + 1\)  
</div>
<!--------------------------------------->
<p><br />
<b>Proof</b>
<br />
We want to show that \(p \ | \ m^2 + 1\). In other words, there exists a \(k\) such that \(kp = m^2 + 1\). This is equivalent to</p>
<div>
$$
\begin{align*}
m^2 + 1 \equiv 0 (\bmod p)
\end{align*}
$$
</div>
<p>(So \(m^2 + 1\) leaves a remainder of 0 when divided by \(p\) because it is divisible by \(p\)). We can re-write this to be</p>
<div>
$$
\begin{align*}
m^2 \equiv -1 (\bmod p)
\end{align*}
$$
</div>
<p>We can also say that \(m^2\) and \(-1\) are congruent to each other in \(Z_p\). In other words, if we let \(a = [m]_p\), then what we want is</p>
<div>
$$
\begin{align*}
a^2 = -1 \quad \in \mathbf{Z}_p
\end{align*}
$$
</div>
<p>In other words, an element whose square is -1 in the field \(\mathbf{Z}_p\). Since both of the elements are non-zero, then this is also in \(\mathbf{Z}_p^{\times}\) (the units) which is the same as the group \(\Phi(p)\) (the multiplicative group). 
<br />
<br />
In assignment 6, we showed two results</p>
<ol>
	<li>We also showed that if \(p\) is an odd prime, then there is also a unique element \(a \in \mathbf{Z}_p^{\times}\) such that \(o(a) = 2\). In this case though, we know the element has to be \(-1\) since \(-1^2 = 1\). </li>
	<li> If \(p\) is prime and \(p \ | \ 4n + 1\), then this group has an element of order 4. There exists an \(a \in \mathbf{Z}_p^{\times}\) such that \(o(a) = 4\).</li>
</ol>
<p>So we know we have an element of order 2 which is -1. We also know we have an element of order 4. \(\mathbf{Z}_p^{\times}\) is cyclic so if \(a\) has order 4, then \(a^4 = 1\). Then \(a^2\) has order 2. This means that \(a^2 = -1\) in \(\mathbf{Z}_p^{\times}\). Therefore</p>
<div>
$$
\begin{align*}
a^2 \equiv -1 (\bmod p)
\end{align*}
$$
</div>
<p>which is what we wanted to show. \(\ \blacksquare\).
<!--------------------------------------->
<br />
<br />
We also need this next proposition <br />
<!---------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(p = 4n + 1\) is a prime number, then \(p\) is reducible \(\mathbf{Z}[i]\)  
</div>
<!--------------------------------------->
<p><br />
<b>Proof</b>
<br />
Suppose for the sake of contradiction that it wasn’t. So it has to be irreducible. By the lemma we just proved, \(p \ | \ m^2 + 1\). But now since \(\mathbf{Z}[i]\) is a PID and \(p\) is irreducible, then \(p\) is also prime (PID implies that irreducible is also prime). Since \(p\) is prime, then it must divide either \(m^2+1\). But \(m^2+1 = (m + i)(m - i)\) in \(\mathbf{Z}[i]\). So \(p\) must divide either \((m+i)\) or \((m-i)\). But this is impossible (because if \(p\) divides \(m+i\) then \(m + i = p(a + bi) = pa + pbi\). This implies that \(m = pa\) and \(1 = pb\). But this \(1 = pb\) is impossible since \(p\) is prime). Therefore, \(p\) must be reducible. \(\ \blacksquare\)
<br />
<br />
<b>Proof (Fermat)</b>
<br />
So now we’re back to proving that \(p = a^2 + b^2\) if and only if \(p \equiv 1 (\bmod 4\)). By the proposition we just proved, if \(p = 4n + 1\), then we know that \(p\) is reducible in \(\mathbf{Z}[i]\). So \(p = uv\) where \(u,v \in \mathbf{Z}\) and \(u,v\) are not units. Because they are not units, then \(N(u) \neq 1\) and \(N(v) \neq 1\). We also know that \(N(p) = (p + 0i)(p - 0i) = p^2\). Then</p>
<div>
$$
\begin{align*}
p^2 = N(p) = N(v)N(u)
\end{align*}
$$
</div>
<p>But \(p\) is prime and we have \(N(u) \neq 1\) and \(N(v) \neq 1\). Therefore, \(N(v) = N(u) = p\). Therefore, if we write \(u = a + bi\), then</p>
<div>
$$
\begin{align*}
p = N(u) = (a + bi)(a - bi) = a^2 + b^2
\end{align*}
$$
</div>
<p>So \(p\) can be written as a sum of squares which is what we wanted to show. \(\ \blacksquare\).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Generalizing Fermat's Theorem</b></h4>
<p>[Lecture 40] So far we know that if \(p\) is prime, then \(p = a^2 + b^2\) for some \(a,b \in \mathbf{Z}\) if and only if \(p = 2\) or \(p \equiv 1 \bmod 4\). It’s also not a sum of squares when \(p \equiv -1 \bmod 4\). 
<br />
<br />
So now we want to generalize this so \(p\) doesn’t need to be a prime number. To do this, consider the following set</p>
<div>
$$
\begin{align*}
S = \{m = a^2 + b^2, a, b \in \mathbf{Z}\}
\end{align*}
$$
</div>
<p>This set is exactly the image of the norm function where</p>
<div>
$$
\begin{align*}
N: \mathbf{Z}[i] &amp;\rightarrow \mathbf{Z} \\
N(a + bi) &amp;= (a + bi)(a - bi) = a^2 + b^2
\end{align*}
$$
</div>
<p>Note that this function is multiplicative. Therefore, this set is closed under multiplication. So for any \(m,n \in S\), we have \(mn \in S\). In particular, we know that \(0,1 \in S\). That \(2 \in S\) and we know that if \(p\) is prime and \(p \equiv 1 (\bmod 4)\), then \(p\) is also in \(S\). But if \(p \equiv -1 (\bmod 4)\), then we know that \(p \not\in S\). However, \(p^2 \in S\). This leads to the following theorem
<br />
<br />
<!---------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
The set \(S\) includes the following
	$$
	\begin{align*}
	S = \{0\} \cup \{m = p_1^{k_1} ... p_r^{k_r}\}
	\end{align*}
	$$
where  \(r \geq 0\) and \(p_1,...p_r\) are distinct primes such that if \( p_i \equiv -1 (\bmod 4) \), then \(2 \ | \ k_i\) (so the exponent is even)
</div>
<!--------------------------------------->
<p><br />
For example \(2 \cdot 3^2 \cdot 5 \in S\) since 3 is raised to an even power.
<br />
<br />
<b>Sketch of Proof</b>
<br />
\(\{0\} \cup \{m = p_1^{k_1} ... p_r^{k_r}\} \subseteq S\): Easy part
<br />
<br />
\(S \subseteq \{0\} \cup \{m = p_1^{k_1} ... p_r^{k_r}\}\): We want to show that if we have an element that can be written as a sum of squares, then it can have a prime factorization with the conditions in the theorem. The proof for this is an induction on \(m = a^2 + b^2\). We will show that</p>
<ol>
	<li>if (\(p = 2\) or \(p \equiv 1 (\bmod 4)\)) and if \(p \ | \ m\), then \(m/p \in S\). </li>
	<li>if \(p \equiv -1 (\bmod 4)\) and \(p \ | \ m\), then \(p^2 \ | \ m\) and \(m/p^2 \in S\) </li>
</ol>
<p>So suppose that \(m = a^2 + b^2\) and \(p\) is a prime such that \(p \equiv -1 (\bmod 4)\) such that \(p \ | \ m\). We know \(m=a^2 + b^2 \in \mathbf{Z}[i]\), so we can factor \(m\) into \(m = (a + bi)(a - bi)\). Last lecture we showed that \(p \equiv -1 (\bmod 4)\), then \(p\) is irreducible in the Gaussian integers. This implies \(p\) is prime since \(\mathbf{Z}[i]\) is a PID. Since \(p\) is prime, then it must divide one of the factors. So \(p \ | \ (a + bi)\) or \(p \ | \ (a - bi)\). Suppose that \(p \ | \ (a + bi)\). Since this is a gaussian integer, then \(p\) must divide both of the coefficients. So \(p \ | \ a\) and \(p \ | \ b\). So \(a = pa'\) and \(b = pb'\). Then</p>
<div>
$$
\begin{align*}
m &amp;= a^2 + b^2 \\
 &amp;= (pa')^2 + (pb')^2 \\
 &amp;= p^2(a'^2 + b'^2)
\end{align*}
$$
</div>
<p>Therefore, \(p^2 \ | \ m\) and the remaining product is a sum of two squares so it’s in \(S\).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Irreducible Elements of the Gaussian Integers</b></h4>
<p>Recall that \(R = \mathbf{Z}[i]\) is a PID and since it’s a PID, then it’s a UFD. So every element has a factorization into irreducible unique up to units. As a reminder, we only have 4 units, \(R^{\times} = \{ \pm 1, \pm i\}\). So in this case, what are the irreducibles of the Gaussian integers? As an example, we just showed that if \(p\) is prime and if \(p \equiv 1 (\bmod 4)\), then \(p\) is irreducible in \(\mathbf{Z}[i]\). Before answering this question, we need the following proposition
<br />
<!---------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(u\) is irreducible in \(R\), let \(I = Ru \cap \mathbf{Z}\). Then \(I = \mathbf{Z}p\), where \(p\) is some prime number. Furthermore, \(N(u) \in \{p, p^2\}\). 
</div>
<!--------------------------------------->
<p><br />
So if we have an irreducible element in the Gaussian integers \(u\), we want to ask what ordinary prime numbers does it divide? The answer is that it divides one specific prime number. So \(p\) is the only prime divisible by \(u\). In other words, the intersection of \(\mathbf{Z}\) and \(Ru\) is \(I = \mathbf{Z}_p\) which is the set of multiples of \(p\). We say that “\(u\) lies over \(p\)”.
<br />
<br />
Example: \(1+i\) is irreducible (we showed that its norm is 2). It divides \(2\) so \(1 + i\) lies over \(2\). 3 is irreducible in \(\mathbf{Z}[i]\) and only divides \(3\). \(2 \pm i\) only divides 5 (recall that they are not associates unlike \(1 \pm i\)). \(3 \pm 2 i\) divides \(13\) and so on.
<br />
<br />
<b>Proof</b>
<br />
Suppose \(u\) is irreducible. Consider the ideal generated by \(u\). Observe that \(Ru \cap \mathbf{Z} = I\) is an ideal in \(\mathbf{Z}\) (Exercise: show this). Moreover, \(\mathbf{Z}\) is a PID. so \(I\) is a principle ideal and is generated by some element \(p \in \mathbf{Z}_{\geq 0}\) so \(I = \mathbf{Z}p\). 
<br />
<br />
Suppose that \(u = a + bi\). It’s non-zero since \(u\) is irreducible. Therefore, \(0 \neq u\bar{u} = N(u) = a^2 + b^2 \in I\). So \(I \neq \{0\}\) and \(p &gt; 0\). We claim that \(p \neq 1\). This is because 1 can’t be in \(I\) since then, \(Ru = R\) and \(u\) is a unit and that’s a contradiction. 
<br />
<br />
We also claim that \(p\) is a prime number. To show this, we need to show that if \(p \ | \ ab\) then either \(p \ | \ a\) or \(p \ | \ b\). Observe that \(p\) is actually a multiple of \(u\) since \(Ru \cap \mathbf{Z} = I = \mathbf{Z}p\). So we can write \(p = uv\) for some \(v \in \mathbf{Z}[i]\). This implies that \(u \ | \ ab\). But you \(u\) is irreducible so it’s prime in \(\mathbf{Z}[i]\) so \(u\) divides \(a\) or \(b\). This shows that \(a \in Ru\) or \(b \in Ru\). But \(a\) and \(b\) are integers so in fact \(b \in Ru \cap \mathbf{Z} = \mathbf{Z}p\) or \(a \in Ru \cap \mathbf{Z} = \mathbf{Z}p\). This means that \(a \ | \ p\) or \(b \ | \ p\) so \(p\) is a prime number.
<br />
<br />
Since \(p = uv\) where \(v \in R\), then \(N(p) = N(u)N(v)\). \(u\) is a not a unit so \(N(u) \neq 1\). So \(N(u) \in \{p, p^2\}\). \(\ \blacksquare\) 
<br />
<br />
(So if we want to find the prime that lies over \(u\), we just compute its norm). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Classification of Irreducibles Theorem</b></h4>
<p>We finally can now state the theorem that classifies irreducibles as follows
<br />
<!---------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
Every irreducible \(u \in R = \mathbf{Z}[i]\) is the same up to units to exactly one of
<ol>
	<li> \(u = 1 + i\) (Lies over 2) </li>
	<li> For \(p\) prime number, \(p \equiv -1 (\bmod 4)\), \(u = p\) (Lies over \(p\)</li>
	<li> For \(p\) prime number, \(p \equiv 1 (\bmod 4)\), \(u = a + bi\) or \(u = a - bi\) where \(a^2 + b^2 = p\) and \(a &gt; b &gt; 0, a, b \in \mathbf{Z}\)</li>
</ol>
</div>
<!--------------------------------------->
<p><br /></p>
<h4><b>Examples</b></h4>
<ul>
	<li>To factor \(z = 3 + 9i\) into irreducibles, \(N(z) = 3^2 + 9^2 = 90 = 2 \cdot 3^2 \cdot 5\). The norm is a multiplicative function, so the norms of each factor will multiply to \( 2 \cdot 3^2 \cdot 5\). Since we only have 3 of them, then the only possible irreducible factors are \(1 + i, 2 \pm i, 3\). In fact, \(1+i\) must be a factor since it's the only one with norm equals 2. \(3\) has to be a factor since it's the only one with norm 3. We don't know which of \(2 + i\) or \(2 - i\) is factor but we can check and we will get \(2 - i\).
	</li>
	<!-------------->
	<li> Take \(R = \mathbf{Z}[\omega] = \{a + b\omega, a,b \in \mathbf{Z}\} \subseteq \mathbf{C}\). Using \(w^2 = -1 -w\), we know it's a subring. Additionally, we can show that this is a PID and therefore it's a UFD. (the categorization here are prime numbers modulo 3 instead of 4 in the Gaussian integers)
	</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Final Thoughts</b></h4>
<p>Returning to the counter example where \(R = \mathbf{Z}[\sqrt{-5}] = \{ a + b\sqrt{-5}, a,b \in \mathbf{Z} \} \subseteq \mathbf{Z}\). This is not a UFD and not a PID because we had no unique factorization. In fact 6 had two different factorizations of irreducibles</p>
<div>
$$
\begin{align*}
6 = 2 \cdot 3 = ( 1 + \sqrt{-5})( 1 - \sqrt{-5})
\end{align*}
$$
</div>
<p>It turns out that we can fix this and this is where the notion of an ideal was invented. It was invented to fix this factorization problem. This was introduced by Dedekind in the 1870s. He said that you get a unique factorization in \(R\) if you add new “ideal numbers (irreducibles)” \(P, Q, Q'\). These new numbers will be factors of irreducibles such that</p>
<ul>
	<li>Let \(2 \sim P^2\) so that \(1 + \sqrt{-5} \sim PQ\)</li>
	<li>Let \(3 \sim QQ'\) so that \(1 - \sqrt{-5} \sim PQ'\)</li>
	<li>\(6 \sim P^2QQ'\)</li>
</ul>
<p><br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Question: For which integer \(m \in \mathbf{Z}\), can we write \(m\) as the sum of squares of two integers so \(m = a^2 + b^2\) for some \(a, b \in \mathbf{Z}\)? We know that this is closely related to the Gaussian integers. Recall that \(a^2 + b^2 = N(a + bi)\) where \(a + bi \in \mathbf{Z}[i]\). So sums of squares appear as norms of Gaussian integers. $$ \begin{align*} \{\text{Sum of two squares in }\mathbf{Z}\} = \text{image}[N: \mathbf{Z}[i] \rightarrow \mathbf{Z}] \end{align*} $$ The norm function is not a homomorphism of rings but it’s a multiplicative function (meaning it only satisfies \(N(xy) =N(x)N(y)\)). So this subset of \(\mathbf{Z}\) is closed under multiplication. So for example, \(5 = 2^2 + 1^1\) and \(17 = 4^2 + 1^1\). Therefore, we expect that \(5*17 = 85\) is also a sum of squares. In fact \(85 = 9^2 + 2^2\). It turns out that when \(m\) in \(m = a^2 + b^2\) is prime, then we have a solution using the following theorem Theorem (Fermat) If \(p \in \mathbf{N}\) is a prime number, then \(p = a^2 + b^2\) for some \(a, b \in \mathbf{Z}\) if and only if either \(p = 2\) or \(p \equiv 1 (\bmod 4)\) We already know that \(2 = 1^2 + 1^2\) and we also know that if \(p \equiv -1 (\bmod 4)\), then \(p\) is not a sum of two squares. Because \(\bmod 4\), a square of a number is congruent to either 0 or 1. So the sum will not be 3 which is the same as \(-1 \bmod 4\). So the remaining case is when \(p \equiv 1 (\bmod 4)\), we want to show that \(p\) is a sum of two squares. To show this we’ll present the following lemma first. Lemma (Lagrange) If \(p = 4n + 1\) is a prime number, then there exists some \(m \in \mathbf{Z}\) such that \(p \ | \ m^2 + 1\) Proof We want to show that \(p \ | \ m^2 + 1\). In other words, there exists a \(k\) such that \(kp = m^2 + 1\). This is equivalent to $$ \begin{align*} m^2 + 1 \equiv 0 (\bmod p) \end{align*} $$ (So \(m^2 + 1\) leaves a remainder of 0 when divided by \(p\) because it is divisible by \(p\)). We can re-write this to be $$ \begin{align*} m^2 \equiv -1 (\bmod p) \end{align*} $$ We can also say that \(m^2\) and \(-1\) are congruent to each other in \(Z_p\). In other words, if we let \(a = [m]_p\), then what we want is $$ \begin{align*} a^2 = -1 \quad \in \mathbf{Z}_p \end{align*} $$ In other words, an element whose square is -1 in the field \(\mathbf{Z}_p\). Since both of the elements are non-zero, then this is also in \(\mathbf{Z}_p^{\times}\) (the units) which is the same as the group \(\Phi(p)\) (the multiplicative group). In assignment 6, we showed two results We also showed that if \(p\) is an odd prime, then there is also a unique element \(a \in \mathbf{Z}_p^{\times}\) such that \(o(a) = 2\). In this case though, we know the element has to be \(-1\) since \(-1^2 = 1\). If \(p\) is prime and \(p \ | \ 4n + 1\), then this group has an element of order 4. There exists an \(a \in \mathbf{Z}_p^{\times}\) such that \(o(a) = 4\). So we know we have an element of order 2 which is -1. We also know we have an element of order 4. \(\mathbf{Z}_p^{\times}\) is cyclic so if \(a\) has order 4, then \(a^4 = 1\). Then \(a^2\) has order 2. This means that \(a^2 = -1\) in \(\mathbf{Z}_p^{\times}\). Therefore $$ \begin{align*} a^2 \equiv -1 (\bmod p) \end{align*} $$ which is what we wanted to show. \(\ \blacksquare\). We also need this next proposition Proposition If \(p = 4n + 1\) is a prime number, then \(p\) is reducible \(\mathbf{Z}[i]\) Proof Suppose for the sake of contradiction that it wasn’t. So it has to be irreducible. By the lemma we just proved, \(p \ | \ m^2 + 1\). But now since \(\mathbf{Z}[i]\) is a PID and \(p\) is irreducible, then \(p\) is also prime (PID implies that irreducible is also prime). Since \(p\) is prime, then it must divide either \(m^2+1\). But \(m^2+1 = (m + i)(m - i)\) in \(\mathbf{Z}[i]\). So \(p\) must divide either \((m+i)\) or \((m-i)\). But this is impossible (because if \(p\) divides \(m+i\) then \(m + i = p(a + bi) = pa + pbi\). This implies that \(m = pa\) and \(1 = pb\). But this \(1 = pb\) is impossible since \(p\) is prime). Therefore, \(p\) must be reducible. \(\ \blacksquare\) Proof (Fermat) So now we’re back to proving that \(p = a^2 + b^2\) if and only if \(p \equiv 1 (\bmod 4\)). By the proposition we just proved, if \(p = 4n + 1\), then we know that \(p\) is reducible in \(\mathbf{Z}[i]\). So \(p = uv\) where \(u,v \in \mathbf{Z}\) and \(u,v\) are not units. Because they are not units, then \(N(u) \neq 1\) and \(N(v) \neq 1\). We also know that \(N(p) = (p + 0i)(p - 0i) = p^2\). Then $$ \begin{align*} p^2 = N(p) = N(v)N(u) \end{align*} $$ But \(p\) is prime and we have \(N(u) \neq 1\) and \(N(v) \neq 1\). Therefore, \(N(v) = N(u) = p\). Therefore, if we write \(u = a + bi\), then $$ \begin{align*} p = N(u) = (a + bi)(a - bi) = a^2 + b^2 \end{align*} $$ So \(p\) can be written as a sum of squares which is what we wanted to show. \(\ \blacksquare\). Generalizing Fermat's Theorem [Lecture 40] So far we know that if \(p\) is prime, then \(p = a^2 + b^2\) for some \(a,b \in \mathbf{Z}\) if and only if \(p = 2\) or \(p \equiv 1 \bmod 4\). It’s also not a sum of squares when \(p \equiv -1 \bmod 4\). So now we want to generalize this so \(p\) doesn’t need to be a prime number. To do this, consider the following set $$ \begin{align*} S = \{m = a^2 + b^2, a, b \in \mathbf{Z}\} \end{align*} $$ This set is exactly the image of the norm function where $$ \begin{align*} N: \mathbf{Z}[i] &amp;\rightarrow \mathbf{Z} \\ N(a + bi) &amp;= (a + bi)(a - bi) = a^2 + b^2 \end{align*} $$ Note that this function is multiplicative. Therefore, this set is closed under multiplication. So for any \(m,n \in S\), we have \(mn \in S\). In particular, we know that \(0,1 \in S\). That \(2 \in S\) and we know that if \(p\) is prime and \(p \equiv 1 (\bmod 4)\), then \(p\) is also in \(S\). But if \(p \equiv -1 (\bmod 4)\), then we know that \(p \not\in S\). However, \(p^2 \in S\). This leads to the following theorem Theorem The set \(S\) includes the following $$ \begin{align*} S = \{0\} \cup \{m = p_1^{k_1} ... p_r^{k_r}\} \end{align*} $$ where \(r \geq 0\) and \(p_1,...p_r\) are distinct primes such that if \( p_i \equiv -1 (\bmod 4) \), then \(2 \ | \ k_i\) (so the exponent is even) For example \(2 \cdot 3^2 \cdot 5 \in S\) since 3 is raised to an even power. Sketch of Proof \(\{0\} \cup \{m = p_1^{k_1} ... p_r^{k_r}\} \subseteq S\): Easy part \(S \subseteq \{0\} \cup \{m = p_1^{k_1} ... p_r^{k_r}\}\): We want to show that if we have an element that can be written as a sum of squares, then it can have a prime factorization with the conditions in the theorem. The proof for this is an induction on \(m = a^2 + b^2\). We will show that if (\(p = 2\) or \(p \equiv 1 (\bmod 4)\)) and if \(p \ | \ m\), then \(m/p \in S\). if \(p \equiv -1 (\bmod 4)\) and \(p \ | \ m\), then \(p^2 \ | \ m\) and \(m/p^2 \in S\) So suppose that \(m = a^2 + b^2\) and \(p\) is a prime such that \(p \equiv -1 (\bmod 4)\) such that \(p \ | \ m\). We know \(m=a^2 + b^2 \in \mathbf{Z}[i]\), so we can factor \(m\) into \(m = (a + bi)(a - bi)\). Last lecture we showed that \(p \equiv -1 (\bmod 4)\), then \(p\) is irreducible in the Gaussian integers. This implies \(p\) is prime since \(\mathbf{Z}[i]\) is a PID. Since \(p\) is prime, then it must divide one of the factors. So \(p \ | \ (a + bi)\) or \(p \ | \ (a - bi)\). Suppose that \(p \ | \ (a + bi)\). Since this is a gaussian integer, then \(p\) must divide both of the coefficients. So \(p \ | \ a\) and \(p \ | \ b\). So \(a = pa'\) and \(b = pb'\). Then $$ \begin{align*} m &amp;= a^2 + b^2 \\ &amp;= (pa')^2 + (pb')^2 \\ &amp;= p^2(a'^2 + b'^2) \end{align*} $$ Therefore, \(p^2 \ | \ m\) and the remaining product is a sum of two squares so it’s in \(S\). Irreducible Elements of the Gaussian Integers Recall that \(R = \mathbf{Z}[i]\) is a PID and since it’s a PID, then it’s a UFD. So every element has a factorization into irreducible unique up to units. As a reminder, we only have 4 units, \(R^{\times} = \{ \pm 1, \pm i\}\). So in this case, what are the irreducibles of the Gaussian integers? As an example, we just showed that if \(p\) is prime and if \(p \equiv 1 (\bmod 4)\), then \(p\) is irreducible in \(\mathbf{Z}[i]\). Before answering this question, we need the following proposition Proposition If \(u\) is irreducible in \(R\), let \(I = Ru \cap \mathbf{Z}\). Then \(I = \mathbf{Z}p\), where \(p\) is some prime number. Furthermore, \(N(u) \in \{p, p^2\}\). So if we have an irreducible element in the Gaussian integers \(u\), we want to ask what ordinary prime numbers does it divide? The answer is that it divides one specific prime number. So \(p\) is the only prime divisible by \(u\). In other words, the intersection of \(\mathbf{Z}\) and \(Ru\) is \(I = \mathbf{Z}_p\) which is the set of multiples of \(p\). We say that “\(u\) lies over \(p\)”. Example: \(1+i\) is irreducible (we showed that its norm is 2). It divides \(2\) so \(1 + i\) lies over \(2\). 3 is irreducible in \(\mathbf{Z}[i]\) and only divides \(3\). \(2 \pm i\) only divides 5 (recall that they are not associates unlike \(1 \pm i\)). \(3 \pm 2 i\) divides \(13\) and so on. Proof Suppose \(u\) is irreducible. Consider the ideal generated by \(u\). Observe that \(Ru \cap \mathbf{Z} = I\) is an ideal in \(\mathbf{Z}\) (Exercise: show this). Moreover, \(\mathbf{Z}\) is a PID. so \(I\) is a principle ideal and is generated by some element \(p \in \mathbf{Z}_{\geq 0}\) so \(I = \mathbf{Z}p\). Suppose that \(u = a + bi\). It’s non-zero since \(u\) is irreducible. Therefore, \(0 \neq u\bar{u} = N(u) = a^2 + b^2 \in I\). So \(I \neq \{0\}\) and \(p &gt; 0\). We claim that \(p \neq 1\). This is because 1 can’t be in \(I\) since then, \(Ru = R\) and \(u\) is a unit and that’s a contradiction. We also claim that \(p\) is a prime number. To show this, we need to show that if \(p \ | \ ab\) then either \(p \ | \ a\) or \(p \ | \ b\). Observe that \(p\) is actually a multiple of \(u\) since \(Ru \cap \mathbf{Z} = I = \mathbf{Z}p\). So we can write \(p = uv\) for some \(v \in \mathbf{Z}[i]\). This implies that \(u \ | \ ab\). But you \(u\) is irreducible so it’s prime in \(\mathbf{Z}[i]\) so \(u\) divides \(a\) or \(b\). This shows that \(a \in Ru\) or \(b \in Ru\). But \(a\) and \(b\) are integers so in fact \(b \in Ru \cap \mathbf{Z} = \mathbf{Z}p\) or \(a \in Ru \cap \mathbf{Z} = \mathbf{Z}p\). This means that \(a \ | \ p\) or \(b \ | \ p\) so \(p\) is a prime number. Since \(p = uv\) where \(v \in R\), then \(N(p) = N(u)N(v)\). \(u\) is a not a unit so \(N(u) \neq 1\). So \(N(u) \in \{p, p^2\}\). \(\ \blacksquare\) (So if we want to find the prime that lies over \(u\), we just compute its norm). Classification of Irreducibles Theorem We finally can now state the theorem that classifies irreducibles as follows Theorem Every irreducible \(u \in R = \mathbf{Z}[i]\) is the same up to units to exactly one of \(u = 1 + i\) (Lies over 2) For \(p\) prime number, \(p \equiv -1 (\bmod 4)\), \(u = p\) (Lies over \(p\) For \(p\) prime number, \(p \equiv 1 (\bmod 4)\), \(u = a + bi\) or \(u = a - bi\) where \(a^2 + b^2 = p\) and \(a &gt; b &gt; 0, a, b \in \mathbf{Z}\) Examples To factor \(z = 3 + 9i\) into irreducibles, \(N(z) = 3^2 + 9^2 = 90 = 2 \cdot 3^2 \cdot 5\). The norm is a multiplicative function, so the norms of each factor will multiply to \( 2 \cdot 3^2 \cdot 5\). Since we only have 3 of them, then the only possible irreducible factors are \(1 + i, 2 \pm i, 3\). In fact, \(1+i\) must be a factor since it's the only one with norm equals 2. \(3\) has to be a factor since it's the only one with norm 3. We don't know which of \(2 + i\) or \(2 - i\) is factor but we can check and we will get \(2 - i\). Take \(R = \mathbf{Z}[\omega] = \{a + b\omega, a,b \in \mathbf{Z}\} \subseteq \mathbf{C}\). Using \(w^2 = -1 -w\), we know it's a subring. Additionally, we can show that this is a PID and therefore it's a UFD. (the categorization here are prime numbers modulo 3 instead of 4 in the Gaussian integers) Final Thoughts Returning to the counter example where \(R = \mathbf{Z}[\sqrt{-5}] = \{ a + b\sqrt{-5}, a,b \in \mathbf{Z} \} \subseteq \mathbf{Z}\). This is not a UFD and not a PID because we had no unique factorization. In fact 6 had two different factorizations of irreducibles $$ \begin{align*} 6 = 2 \cdot 3 = ( 1 + \sqrt{-5})( 1 - \sqrt{-5}) \end{align*} $$ It turns out that we can fix this and this is where the notion of an ideal was invented. It was invented to fix this factorization problem. This was introduced by Dedekind in the 1870s. He said that you get a unique factorization in \(R\) if you add new “ideal numbers (irreducibles)” \(P, Q, Q'\). These new numbers will be factors of irreducibles such that Let \(2 \sim P^2\) so that \(1 + \sqrt{-5} \sim PQ\) Let \(3 \sim QQ'\) so that \(1 - \sqrt{-5} \sim PQ'\) \(6 \sim P^2QQ'\) References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 39: Unique Factorization Domain</title><link href="http://localhost:4000/jekyll/update/2025/03/02/math417-39-unique-factorization-domain.html" rel="alternate" type="text/html" title="Lecture 39: Unique Factorization Domain" /><published>2025-03-02T00:01:36-08:00</published><updated>2025-03-02T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/03/02/math417-39-unique-factorization-domain</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/03/02/math417-39-unique-factorization-domain.html"><![CDATA[<p>Recall from the last lecture, that an element \(p \in R\) is irreducible if</p>
<ul>
	<li>\(p\) is not 0</li>
	<li>\(p\) is not a unit so \(p \not\in R^{\times}\)</li>
	<li>If \(p = ab\), then either \(a\) or \(b\) is a unit so \(a R^{\times}\) or \(b \in R^{\times}\)</li>
</ul>
<p>Also recall that defined a element \(p \in R\) to be prime if</p>
<ul>
	<li>\(p\) is not 0</li>
	<li>\(p\) is not a unit so \(p \not\in R^{\times}\)</li>
	<li>If \(p \ | \ ab\), then either \(p \ | \ a\) or \(p \ | \ b\)</li>
</ul>
<p>From this, we should that if an element is prime, then it must be irreducible but the converse isn’t true.
<br />
<br />
We also defined a PID which is a principle ideal domain. a domain \(R\) is a PID if every ideal is principle in \(R\). An example of a PID is \(\mathbf{Z}\), \(\mathbf{Z}[i]\), \(K\) and \(K[x]\) where \(K\) is a field. Domains that were not PIDs were \(K[x,y], \mathbf{Z}[x], \mathbf{Z}[\sqrt{-5}]\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Unique Factorization Domain (UFD)</b></h4>
<p>We have a new defintion for a domain that has a unique factorization property
<br />
<!---------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A domain \(R\) is such that every non-zero and non-unit can be a factored as a product of irreducible elements. This factorization is unique up to re-ordering and units. i.e.
<ol>
	<li>Factorization: If \(a \in R\), \(a \neq 0\), \(a \in R^{\times}\), then there exists \(p_1,p_2,...,p_m \in R\), \(m \geq 1\) and \(p_i\) irreducible, and \(a = p_1p_2...p_m\).</li>
	<li>Uniqueness: If \(a = p_1p_2,...p_m = q_1q_2...q_n\), where \(p_i,q_j\) are irreducible, then \(m = n\) and there exists \(\sigma \in S_n\) such that \(q_k = p_{\sigma(k)}u_k\) for some \(u_k \in R^{\times}, \ \forall k = 1,...,n\). So these sequences are the same up to unit and re-ordering</li>
</ol>
</div>
<p><br />
Example: \(R = \mathbf{Z}\) is a UFD.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Every PID is a UFD</b></h4>
<p>Next, we will show that every principle domain is actually a unique factorization domain
<br />
<!---------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
Every principle ideal domain (PID) is a unique factorization domain (UFD)
</div>
<!--------------------------------------->
<p><br />
Fact: If \(R\) is a UFD, then so is \(R[x]\). As a consequence, \(K[x,y]\) is a UFD but not a PID. Also note that \(\mathbf{Z}[\sqrt{-5}]\) is not a UFD. Recall that we showed \(6 = 2 (3) = (1 + \sqrt{-5})(1 - \sqrt{-5})\).
<br />
<br />
Take another example where \(R\) is a subring \(R \subseteq Q[x]\). \(R\) is the set of all polynomials with rational coefficients but additionally we’ll add the condition that the constant term must be integer. This subring also has 1 so it’s a domain. However, it is not a UFD. Observe that \(x \in R\) but \(x\) has no irreducible factorization in \(R\). \(x = 2\frac{1}{2}x = 2(2)\frac{1}{4}x = 2(2)(2)\frac{1}{8}x = ...\). Here \(x\) is irreducible in \(Q[x]\) but it is not irreducible in \(R\). 
<br />
<br />
<b>Proof (Existence)</b>
<br />
Let \(R\) be a PID. Let \(a \in R\). We know that \(a \neq 0\) and \(a \in R^{\times}\). Suppose for the sake of contradiction that \(a\) has no factorization into irreducibles. Since it has no factorization into irreducibles, then \(a\) itself can’t be irreducible. So \(a\) must be reducible. So \(a = bc\) where \(b\) and \(c\) must both be non-units (by the definition of reducible). Then either \(b\) or \(c\) has no irreducible factorization (why? If both had irreducible factorization, then \(a\) will have an irreducible factorization).
<br />
<br />
So now take \(a = a_0 = a_1b_1\) where \(a_1, b_1 \in R^{\times}\) and suppose without the loss of generality that \(a_1\) has no irreducible factorization. But now we can take \(a_1\) again and let \(a_1 = a_2b_2\) where \(a_2\) and \(b_2\) are non-units and \(a_2\) has no irreducible factorization. Inductively, we will get</p>
<div>
$$
\begin{align*}
a_k = a_{k+1}b_{k+1}, \quad a_{k+1},b_{k+1} \not\in R^{\times} 
\end{align*}
$$
</div>
<p>where \(a_{k+1}\) has no irreducible factorization. Now, consider the principle ideals generated by these elements. So \(Ra_0, Ra_1, Ra_2,...Ra_{k+1}\). But \(a_0 = a_1b_1\) so \(a_0\) is a multiple of \(a_1\). So \(Ra_0 \subseteq Ra_1\). In fact</p>
<div>
$$
\begin{align*}
Ra_0 \subseteq Ra_1 \subseteq Ra_2 \subseteq ... \subseteq R_k \subseteq Ra_{k+1}
\end{align*}
$$
</div>
<p>We claim that \(a_{k+1} \not\in R_{a_k}\) so \(R_{a_k} \subset R_{a_{k+1}}\). This is because \(a_k = a_{k+1}b_{k+1}\)  but \(b_{k+1} \not\in R^{\times}\) (not a unit) [If \(a_{k+1} \in R_{a_k}\), then we can write \(a_{k+1} = a_kc = a_{k+1}b_{k+1}c\) so now we cancel to get \(1 = b_{k+1}c\) so \(b_{k+1}\) is a unit which is a contradiction]. So we have a chain of proper inclusions.
<br />
<br />
Now, let \(I = \bigcup_{k \geq 0} Ra_k \subseteq R\). Observe that \(I\) is an ideal in \(R\) (union of a chain of ideals is an ideal (union of random ideals is not an ideal). This only works because it is a chain). We know by assumption that \(R\) is a PID. Thus, \(I\) is also a principle ideal and generated by some element \(c \in R\). Since \(c \in I\) and \(I\) is a union of ideals, then \(c\) is contained in one of these ideals so \(c \in  Ra_k\) for some \(k \geq 0\). But this is a problem since this implies that \(c \in R_{a_k} \subset R_{a_{k+1}} \subseteq I = R_c\) (the same also for \(Rc\), the ideal generated by \(c\) also satisfies \(Rc \in R_{a_k} \subset R_{a_{k+1}} \subseteq I = R_c\)). But since \(c\) is in all of them, then they are all the same subset. So \(R_{a_{k+1}} = R_{a_k}\). This is a contradiction since we assumed that it’s a proper inclusion. \(\ \blacksquare\)
<br />
<br />
<b>Proof (Uniqueness)</b>
<br />
Suppose that \(a = p_1p_2,...p_m = q_1q_2...q_n\) where (m \geq n). We want to show that \(m = n\) and that these sequences are the same up to units and re-ordering. (This is the same proof as proving that the prime factorization is unique). We know that irreducibles are primes in a PID. 
<br />
<br />
We will use induction on \(m\). <br />
Case \(m = 1\). \(a = p_1\) so \(a\) is irreducible and therefore, it is prime as well. We know that \(a = q_1...q_n\). \(a\) must divide itself. But since it’s irreducible, then it must divide one of the factors \(q_i\) for some \(i=1,..,n\). But \(q_i\) itself is also irreducible, so we can write \(q_i = au\) for some \(u \in R^{\times}\). \(u\) must be a unit here since one of the factors must be a unit and we know that \(a\) is not a unit. This implies that \(a\) and \(q_i\) are associates (the same up to unit). Thus</p>
<div>
$$
\begin{align*}
a &amp;= q_1...q_i...q_n \\
a &amp;= q_1...(au)...q_n \\
1 &amp;= q_1...q_{i-1}uq_{i+1}...q_n \text{(we can cancel since we're in a domain)}
\end{align*}
$$
</div>
<p>But this shows that the terms \(q_i\)s are units. This is a contradiction since all the \(q\) terms are irreducible and so \(n = 1\)
<br />
<br />
Induction Case: Suppose \(m \geq 2\). Then \(a = p_1...p_m\).  \(p_1,...,p_m\) are irreducible so they are prime since \(R\) is a PID. So for example \(p_m\) must divide the whole product. Thus, it must divide one of the \(q\)s. Let that be \(q_i\). Then \(q_i = p_mu\) for some unit \(u\) just like before. \(p_m\) and \(q_i\) are the same up to unit or associates. Then</p>
<div>
$$
\begin{align*}
a &amp;= q_1...q_i...q_n \\
a &amp;= q_1...(p_mu)...q_n \\
p_1...p_{m-1} &amp;= q_1...q_{i-1}q_{i+1}...(q_nu) \text{(we can cancel since we're in a domain)}
\end{align*}
$$
</div>
<p>This is a factorization of an element that has \(m-1\) \(p\) factors and \(n - 1\) \(q\) factors. So now we can use the induction hypothesis to conclude that the factorization is unique up to reordering and up to units. \(\ \blacksquare\)
<br />
<br />
Note: We will apply this to an example involving the Gaussian integers next lecture.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Recall from the last lecture, that an element \(p \in R\) is irreducible if \(p\) is not 0 \(p\) is not a unit so \(p \not\in R^{\times}\) If \(p = ab\), then either \(a\) or \(b\) is a unit so \(a R^{\times}\) or \(b \in R^{\times}\) Also recall that defined a element \(p \in R\) to be prime if \(p\) is not 0 \(p\) is not a unit so \(p \not\in R^{\times}\) If \(p \ | \ ab\), then either \(p \ | \ a\) or \(p \ | \ b\) From this, we should that if an element is prime, then it must be irreducible but the converse isn’t true. We also defined a PID which is a principle ideal domain. a domain \(R\) is a PID if every ideal is principle in \(R\). An example of a PID is \(\mathbf{Z}\), \(\mathbf{Z}[i]\), \(K\) and \(K[x]\) where \(K\) is a field. Domains that were not PIDs were \(K[x,y], \mathbf{Z}[x], \mathbf{Z}[\sqrt{-5}]\). Unique Factorization Domain (UFD) We have a new defintion for a domain that has a unique factorization property Definition A domain \(R\) is such that every non-zero and non-unit can be a factored as a product of irreducible elements. This factorization is unique up to re-ordering and units. i.e. Factorization: If \(a \in R\), \(a \neq 0\), \(a \in R^{\times}\), then there exists \(p_1,p_2,...,p_m \in R\), \(m \geq 1\) and \(p_i\) irreducible, and \(a = p_1p_2...p_m\). Uniqueness: If \(a = p_1p_2,...p_m = q_1q_2...q_n\), where \(p_i,q_j\) are irreducible, then \(m = n\) and there exists \(\sigma \in S_n\) such that \(q_k = p_{\sigma(k)}u_k\) for some \(u_k \in R^{\times}, \ \forall k = 1,...,n\). So these sequences are the same up to unit and re-ordering Example: \(R = \mathbf{Z}\) is a UFD. Every PID is a UFD Next, we will show that every principle domain is actually a unique factorization domain Theorem Every principle ideal domain (PID) is a unique factorization domain (UFD) Fact: If \(R\) is a UFD, then so is \(R[x]\). As a consequence, \(K[x,y]\) is a UFD but not a PID. Also note that \(\mathbf{Z}[\sqrt{-5}]\) is not a UFD. Recall that we showed \(6 = 2 (3) = (1 + \sqrt{-5})(1 - \sqrt{-5})\). Take another example where \(R\) is a subring \(R \subseteq Q[x]\). \(R\) is the set of all polynomials with rational coefficients but additionally we’ll add the condition that the constant term must be integer. This subring also has 1 so it’s a domain. However, it is not a UFD. Observe that \(x \in R\) but \(x\) has no irreducible factorization in \(R\). \(x = 2\frac{1}{2}x = 2(2)\frac{1}{4}x = 2(2)(2)\frac{1}{8}x = ...\). Here \(x\) is irreducible in \(Q[x]\) but it is not irreducible in \(R\). Proof (Existence) Let \(R\) be a PID. Let \(a \in R\). We know that \(a \neq 0\) and \(a \in R^{\times}\). Suppose for the sake of contradiction that \(a\) has no factorization into irreducibles. Since it has no factorization into irreducibles, then \(a\) itself can’t be irreducible. So \(a\) must be reducible. So \(a = bc\) where \(b\) and \(c\) must both be non-units (by the definition of reducible). Then either \(b\) or \(c\) has no irreducible factorization (why? If both had irreducible factorization, then \(a\) will have an irreducible factorization). So now take \(a = a_0 = a_1b_1\) where \(a_1, b_1 \in R^{\times}\) and suppose without the loss of generality that \(a_1\) has no irreducible factorization. But now we can take \(a_1\) again and let \(a_1 = a_2b_2\) where \(a_2\) and \(b_2\) are non-units and \(a_2\) has no irreducible factorization. Inductively, we will get $$ \begin{align*} a_k = a_{k+1}b_{k+1}, \quad a_{k+1},b_{k+1} \not\in R^{\times} \end{align*} $$ where \(a_{k+1}\) has no irreducible factorization. Now, consider the principle ideals generated by these elements. So \(Ra_0, Ra_1, Ra_2,...Ra_{k+1}\). But \(a_0 = a_1b_1\) so \(a_0\) is a multiple of \(a_1\). So \(Ra_0 \subseteq Ra_1\). In fact $$ \begin{align*} Ra_0 \subseteq Ra_1 \subseteq Ra_2 \subseteq ... \subseteq R_k \subseteq Ra_{k+1} \end{align*} $$ We claim that \(a_{k+1} \not\in R_{a_k}\) so \(R_{a_k} \subset R_{a_{k+1}}\). This is because \(a_k = a_{k+1}b_{k+1}\) but \(b_{k+1} \not\in R^{\times}\) (not a unit) [If \(a_{k+1} \in R_{a_k}\), then we can write \(a_{k+1} = a_kc = a_{k+1}b_{k+1}c\) so now we cancel to get \(1 = b_{k+1}c\) so \(b_{k+1}\) is a unit which is a contradiction]. So we have a chain of proper inclusions. Now, let \(I = \bigcup_{k \geq 0} Ra_k \subseteq R\). Observe that \(I\) is an ideal in \(R\) (union of a chain of ideals is an ideal (union of random ideals is not an ideal). This only works because it is a chain). We know by assumption that \(R\) is a PID. Thus, \(I\) is also a principle ideal and generated by some element \(c \in R\). Since \(c \in I\) and \(I\) is a union of ideals, then \(c\) is contained in one of these ideals so \(c \in Ra_k\) for some \(k \geq 0\). But this is a problem since this implies that \(c \in R_{a_k} \subset R_{a_{k+1}} \subseteq I = R_c\) (the same also for \(Rc\), the ideal generated by \(c\) also satisfies \(Rc \in R_{a_k} \subset R_{a_{k+1}} \subseteq I = R_c\)). But since \(c\) is in all of them, then they are all the same subset. So \(R_{a_{k+1}} = R_{a_k}\). This is a contradiction since we assumed that it’s a proper inclusion. \(\ \blacksquare\) Proof (Uniqueness) Suppose that \(a = p_1p_2,...p_m = q_1q_2...q_n\) where (m \geq n). We want to show that \(m = n\) and that these sequences are the same up to units and re-ordering. (This is the same proof as proving that the prime factorization is unique). We know that irreducibles are primes in a PID. We will use induction on \(m\). Case \(m = 1\). \(a = p_1\) so \(a\) is irreducible and therefore, it is prime as well. We know that \(a = q_1...q_n\). \(a\) must divide itself. But since it’s irreducible, then it must divide one of the factors \(q_i\) for some \(i=1,..,n\). But \(q_i\) itself is also irreducible, so we can write \(q_i = au\) for some \(u \in R^{\times}\). \(u\) must be a unit here since one of the factors must be a unit and we know that \(a\) is not a unit. This implies that \(a\) and \(q_i\) are associates (the same up to unit). Thus $$ \begin{align*} a &amp;= q_1...q_i...q_n \\ a &amp;= q_1...(au)...q_n \\ 1 &amp;= q_1...q_{i-1}uq_{i+1}...q_n \text{(we can cancel since we're in a domain)} \end{align*} $$ But this shows that the terms \(q_i\)s are units. This is a contradiction since all the \(q\) terms are irreducible and so \(n = 1\) Induction Case: Suppose \(m \geq 2\). Then \(a = p_1...p_m\). \(p_1,...,p_m\) are irreducible so they are prime since \(R\) is a PID. So for example \(p_m\) must divide the whole product. Thus, it must divide one of the \(q\)s. Let that be \(q_i\). Then \(q_i = p_mu\) for some unit \(u\) just like before. \(p_m\) and \(q_i\) are the same up to unit or associates. Then $$ \begin{align*} a &amp;= q_1...q_i...q_n \\ a &amp;= q_1...(p_mu)...q_n \\ p_1...p_{m-1} &amp;= q_1...q_{i-1}q_{i+1}...(q_nu) \text{(we can cancel since we're in a domain)} \end{align*} $$ This is a factorization of an element that has \(m-1\) \(p\) factors and \(n - 1\) \(q\) factors. So now we can use the induction hypothesis to conclude that the factorization is unique up to reordering and up to units. \(\ \blacksquare\) Note: We will apply this to an example involving the Gaussian integers next lecture. References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 37/38: R-Domain</title><link href="http://localhost:4000/jekyll/update/2025/03/01/math417-37-r-domains.html" rel="alternate" type="text/html" title="Lecture 37/38: R-Domain" /><published>2025-03-01T00:01:36-08:00</published><updated>2025-03-01T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/03/01/math417-37-r-domains</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/03/01/math417-37-r-domains.html"><![CDATA[<p>We’ll start by defining Quotient Rings
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Domain
</div>
<div class="mintbodydiv">
A domain \(R\) is a commutative ring with 1 such that
<ol>
	<li>\(1 \neq 0\).</li>
	<li>If \(a,b \in R/\{0\}\), then \(ab \in R/\{0\}\). So non-zero elements multiply to non-zero elements. In other words, \(ab = 0\) then either \(a = 0\) or \(b = 0\).</li>
</ol>
</div>
<!----------------------------------------------------------------------------->
<p><br />
Fact: Every field is a domain. Other examples:</p>
<ol>
	<li>\(\mathbf{Z}\) and \(K[x]\) are domains.</li>
	<li>The Gaussian integers are a domain \(\mathbf{Z}[i] = \{a + bi \in \mathbf{C} \ | \ a, b \in \mathbf{Z}\).</li>
	<li>\(\mathbf{Z}_4\) is not a domain, \([2] \neq 0\) but \([2][2] = [4] = [0]]\).</li>
	<li>\(\mathbf{Q}/(f_1f_2)\) where \(\deg(f_i) \geq 1\) is not a domain. (Exercise)</li>
</ol>
<p>Fact: If \(K\) is a field and \(R \subseteq K\) is a subring such that \(1_K \in R\), then \(R\) is a domain
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Every domain \(R\) is (isomorphic) a subring of a field \(F = \text{Frac}(R)\) (field of fraction)
</div>
<!----------------------------------------------------------------------------->
<p><br />
So basically every domain can be enlarge to be a field.
<br />
<br />
<b>Proof</b>
<br />
Let \(X = \{(a,b) \ | \ a, b \in R, b \neq 0\}\). Define a relation on \(X\):</p>
<div>
$$
\begin{align*}
(a,b) \sim (a',b') \quad \text{ iff } ab' = ba'
\end{align*}
$$
</div>
<p>We claim that this relation is an equivalence relation. (Exercise, hard to prove but use that \(R\) is a domain Side note: domains have cancellations so if \(ab = bc\) and \(a \neq 0\), then \(b = c\).)
<br />
<br />
Since we have an equivalence relation on a set \(X\), then define \(F: X/\sim\) to be the set of equivalence classes. Write \([\frac{a}{b}] \in F\) for the equivalence class of \((a,b)\). Now, define</p>
<div>
$$
\begin{align*}
\big[\frac{a}{b}\big] + \big[\frac{a'}{b'}\big] &amp;= \big[\frac{ab'+ba'}{bb'}\big] \\
\big[\frac{a}{b}\big]\big[\frac{a'}{b'}\big] &amp;= \big[\frac{aa'}{bb'}\big]
\end{align*}
$$
</div>
<p>Check that these operations are well defined and make \(F\) a field. Finally, define \(\varphi: R \rightarrow F\) by \(\varphi(a) = [\frac{a}{1}]\). Check that \(\varphi\) is an injective ring homomorphism.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<ol>
	<li>Suppose \(R = \mathbf{Z}\), then \(\text{Frac}(\mathbf{Z}) \cong \mathbf{Q}\).</li>
	<li>Suppose \(R = K[x]\) the ring of polynomials over a field. Then \(\text{Frac}(K[x]) = K[x]\) is the field of rational polynomials. elements in \(\text{Frac}(K[x]) = K[x]\) are of the form \(\frac{f}{g}\).</li>
</ol>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Element Types</b></h4>
<p>We want to discuss factorization in a domain but before doing so, we need to see the types of elements we can find in a domain.</p>
<ol>
	<li>Zero: the element zero is in \(R\).</li>
	<li>Units: These are the elements that have a multiplicative inverse.</li>
	<li>Reducible: If \(a \in R\), \(a \neq 0\) and \(a \not\in R^{\times}\) (not a unit), then there exists \(b,c \in R\) such that \(a = bc\). (\(b\) and \(b\) must both be non-units!)</li>
	<li>Irreducible: Not a zero, not a unit and not reducible. This means \(a \in R\), \(a \not\in R^{\times}\) and if \(a = bc\), then either \(b \in R^{\times}\) or \(c \in R^{\times}\).</li>
</ol>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<ol>
	<li>\(R = \mathbf{Z}\)</li>
	<ul>
		<li>Units: \(\mathbf{Z}^{\times} = \{-1, +1\}\)</li>
		<li>Reducible: \(\{\pm n, n \in \mathbf{N}, \text{composite}\}\)</li>
		<li>Irreducible: These are the elements that don't factor so \(\{\pm p, p \in \mathbf{N}, \text{prime}\}\)</li>
	</ul>
	<!---------------Field----------------->
	<li>\(R = K\) where \(K\) is a field</li>
	<ul>
		<li>\(0 \in K\)</li>
		<li>Units: \(K^{\times} = K / \{0\}\)</li>
		<li>Reducible: none.</li>
		<li>Irreducible: none.</li>
	</ul>
	<!---------------Polynomial Rings----------------->
	<li>\(R = K[x]\) where \(K\) is a field</li>
	<ul>
		<li>\(0 \in K[x]\)</li>
		<li>Units: these are polynomials of degree 0 so \(K^{\times}\)</li>
		<li>Reducible: polynomials that you can factor into smaller ones. \(f, \deg(f) \geq 1\) such that \(f = gh, 0 &lt; \deg(g), \deg(h) &lt; \deg(f)\)</li>
		<li>Irreducible: polynomials that you can't factor. \(f, \deg(f) \geq 1\) such that there is no \(g,h, \deg(h), \deg(g) &lt; \deg(f)\) such that \(f = gh\)</li>
	</ul>
	<!------------ polynomials over the complex numbers ----------------->
	<li>\(R = \mathbf{C}[x]\)</li>
	<ul>
		<li>\(0 \in C[x]\)</li>
		<li>Units: \(C^{\times}\)</li>
		<li>Reducible: \(f, \deg(f) \geq 2\)</li>
		<li>Irreducible: \(f, \deg(f) = 1\)</li>
	</ul>
	<!--------- polynomials over the real numbers ------------->
	<li>\(R = \mathbf{C}[x]\)</li>
	<ul>
		<li>\(0 \in R[x]\)</li>
		<li>Units: \(R^{\times}\)</li>
		<li>Irreducible: One form is \(ax + b, a \neq 0\) and another form is \(ax^2 + bx + c\) where \(a \neq 0, b^2 - 4ac &lt; 0\)</li>
		<li>Reducible: The rest of polynomials are reducible</li>
	</ul>
</ol>
<p>Warning: If we take a look at the polynomials over the rational numbers, we will find out that there are a lot more irreducible polynomials there. Note here that the ring of polynomials with rational coefficients is contained in the ring of polynomials with the real coefficients and that’s contained in the field of rational functions over \(\mathbf{R}\). In other words, \(\mathbf{Q}[x] \subseteq \mathbf{R}[x] \subseteq \mathbf{R}(x)\). Now, take \(x^p - 2\) where \(p \geq 2\), then \(x^p - 2\) is irreducible in \(Q[x]\), reducible in \(R[x]\). (The proof is not obvious). It is a unit in \(\mathbf{R}(x)\)! so it’s important to consider the context in which we’re in.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Norm Functions</b></h4>
<p>Another Example is the Gaussian Integers: \(R = \mathbf{Z}[i] = \{a + bi \ | \ a, b \in \mathbf{Z}\} \subseteq \mathbf{C}\). So \(R\) is a subring of the complex numbers and it is a domain. Since it’s a domain, we want to categorize the elements in it. But to do so, we need another tool defined as follows
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Norm Functions
</div>
<div class="mintbodydiv">
The norm of \(a + bi\) is defined to be \(N(a + bi)  = a^2 + b^2 = (a + bi)(a - bi) = \lVert a + bi \rVert^2 \)
</div>
<!----------------------------------------------------------------------------->
<p><br />
So this is a function defined on the complex numbers and therefore defined on the Gaussian integers. Some properties:</p>
<ol>
	<li>If \(z \in \mathbf{Z}[i], N(z) \in \mathbf{Z}_{\geq 0}\)</li>
	<li>\(N(z) = 0\) if and only if \(z = 0\)</li>
	<li>If \(z, w \in \mathbf{Z}[i], N(zw) = N(z)N(w)\)</li>
	<li>If \(z \in \mathbf{Z}[i]\), then \(z \in \mathbf{Z}[i]^{\times}\) if and only if \(N(z) = 1\)</li>
</ol>
<p>Proof of (4):
<br />
If \(z \in \mathbf{Z}[i]^{\times}\), then \(z\) is a unit and \(zz^{-1} = 1\). We know that \(z^{-1} \in \mathbf{Z}[i]\) so \(z^{-1}\) is a Gaussian integer. So</p>
<div>
$$
\begin{align*}
1 = N(1) = N(z)N(z^{-1})
\end{align*}
$$
</div>
<p>But \(N(z)\) and \(N(z^{-1})\) are positive integers by (1). Therefore \(N(z) = N(z^{-1}) = 1\). 
<br />
<br />
For the other direction when \(N(z) = 1\). Write \(z = a + bi\) where \(a, b \in \mathbf{Z}\). By definition</p>
<div>
$$
\begin{align*}
1 = N(z) = N(a + bi) = (a + bi)(a - bi)
\end{align*}
$$
</div>
<p>Therefore, \((a + bi)^{-1} = (a - bi)\). 
<br />
<br />
In fact the units are just \(\mathbf{Z}^{-1}[i] = \{ \pm 1, \pm i\}\).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 1</b></h4>
<p>Example: \(2 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). So 2 is also a Gaussian integer since \(\mathbf{Z}\) is a subring of the Gaussian integers. \(2\) is a prime number so it’s irreducible as an integer. However, is it reducible as a Gaussian integer? Observe that</p>
<div>
$$
\begin{align*}
2 = (1 + i)(1 - i)
\end{align*}
$$
</div>
<p>So it’s definitely reducible as a Gaussian integer.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 2</b></h4>
<p>Example: Take \(1 + i \in \mathbf{Z}[i]\). Is it reducible or irreducible in \(\mathbf{Z}[i]\)? It is in fact irreducible. We know this because \(N(1 + i) = 2\) and if there were factors \(1 + i = zw\), then</p>
<div>
$$
\begin{align*}
N(1 + i) = N(z)N(w) = 2
\end{align*}
$$
</div>
<p>But the norm is a non-negative integer. So the only way to make this work is that either \(N(z) = 1\) or \(N(w) = 1\) so one of the factors is a unit. Thus, by definition, \(z\) is irreducible. 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Associate Elements</b></h4>
<p>Next, we have this definition for when two elements are associate when one element is a product of some unit times the other element.
<br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
\(a, b \in R\) are the <b>same up-to-units</b> or <b>associate</b> (we write \(a \sim b\)) if there exists an element \(u \in R^{\times}\) such that \(b = ua\).
</div>
<p><br />
<!----------------------------------------------------------------------------->
This is in fact an equivalence relation (Exercise)
<br />
<br />
Example: In \(\mathbf{Z}\), associate classes are \(\{0\}\), \(\{\pm n\}, n &gt; 0\). Another example is \(K[x]\), \(f \sim g\) if \(g = fc\) for some \(c \in K/\{0\}\). 
<br />
<br />
Fact: If two elements are associate, then they are of the same type!
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 3</b></h4>
<p>\(3 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). Is it reducible? It is irreducible in \(\mathbf{Z}\) since it is prime. In \(\mathbf{Z}[i]\), we know that \(N(3) = N(3 + 0i) = 9\). Suppose it was reducible. This means that there exists \(z,w \in \mathbf{Z}[i]\)</p>
<div>
$$
\begin{align*}
9 = N(3) = N(z)N(w)
\end{align*}
$$
</div>
<p>To be reducible, neither \(z\) or \(w\) can be units so they can’t have a norm of 1. Therefore, we must have \(N(z) = N(w) = 3\). This a contradiction since we don’t have any Gaussian integers with norm 3 (square root of 3 from the origin).</p>
<div>
$$
\begin{align*}
N(a + bi) = a^2 + b^2, \quad a^2, b^2 \in \{0,1,4,9,16,...\}
\end{align*}
$$
</div>
<p>So it’s not possible to construct an element of the form \(a + bi\) in \(\mathbf{Z}[i]\) such that \(a^2 + b^2 = 3\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 4</b></h4>
<p>\(4 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). Is it reducible? It is reducible in \(\mathbf{Z}\). In \(\mathbf{Z}[i]\), we know that \(4 = (2)(2)\) and \(2\) is not a unit in \(\mathbf{Z}[i]\). Not just that but we also saw that \(2\) can be factored using the previous example \(2 = (1 + i)(1 - i)\). Furthermore, we also have another way too to factor 4. Below are some of the ways</p>
<div>
$$
\begin{align*}
4 = 2(2) = (1 + i)^2(1 - i)^2 = -(1 + i)^4
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 5</b></h4>
<p>\(5 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). Is it reducible in \(\mathbf{Z}[i]\)? It is reducible because</p>
<div>
$$
\begin{align*}
5 = (2 + i)(2 - i)
\end{align*}
$$
</div>
<p>The factors themselves \((2+i)\) and \((2-i)\) are irreducible since the the norm \(N(2 + i) = 5\). Also note that \((2+i)\) and \((2-i)\) are not associate. 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>When is \(p\) reducible in \(\mathbf{Z}[i]\)?</b></h4>
<p>We went through a few examples of doing this calculation but in fact we do have a proposition about this as follows
<br /></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(p \in \mathbf{N}\) is a prime number, then \(p\) is reducible in \(\mathbf{Z}[i]\) if and only if \(p = a^2 + b^2\) for some \(a,b \in \mathbf{Z}\)
</div>
<p><br />
<!----------------------------------------------------------------------------->
<b>Proof</b>
<br />
\(\Leftarrow:\) Suppose that \(p = a^2 + b^2\). Then we can write</p>
<div>
$$
\begin{align*}
p = (a - bi)(a + bi)
\end{align*}
$$
</div>
<p>Recall that \(N(a + bi) = a^2 + b^2\) but that means \(N(a + bi) = p\) and \(p\) is prime so it’s not 1. So neither (a + bi) or (a - bi) is a unit. Therefore, \(p\) is reducible. 
<br />
<br />
\(\Rightarrow:\) Suppose that \(p\) is reducible so \(p = zw\). Therefore,</p>
<div>
$$
\begin{align*}
N(p) = N(z)N(w) = p^2 \quad (\text{since } p \in \mathbf{Z}, N(p)=p^2)
\end{align*}
$$
</div>
<p>But \(p\) is prime and so we must have \(N(z)=N(w)=p\). This means that there exists some \(a, b\) such that \(z = a + bi\) where \(N(z) = p\). This means</p>
<div>
$$
\begin{align*}
N(z) = a^2 + b^2 = p.
\end{align*}
$$
</div>
<p>So \(p = a^2 + b^2\) as we wanted to show. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<p>The proof shows that for a prime to be a sum of squares is related to whether it factors as a Gaussian integer</p>

<div>
<table style="max-width: 700px; margin: 20px auto;">
  <tr>
    <td>Reducible in \(Z[i]\)</td>
	<td>Irreducible in \(Z[i]\)</td>
  </tr>
  <tr>
    <td>\(2 = 1^2 + 1^2\)</td>
	<td>3</td>
  </tr>
  <tr>
    <td>\(5 = 2^2 + 1^2\)</td>
	<td>7</td>
  </tr>
  <tr>
    <td>\(13 = 3^2 + 2^2\)</td>
	<td>11</td>
  </tr>
  <tr>
    <td>\(17 = 4^2 + 2^2\)</td>
	<td>19</td>
  </tr>
  <tr>
    <td>\(29 = 5^2 + 2^2\)</td>
	<td>23</td>
  </tr>
  <tr>
    <td>\(37 = 6^2 + 1^2\)</td>
	<td>31</td>
  </tr>
</table>
</div>
<p>Notice the pattern here. The left prime numbers are congruent to 1 mod 4 while the right prime numbers are congruent to -1 mod 4.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Irreducible Elements in \(R\)</b></h4>
<p>Lecture 38: To state things again, \(a \in R\) is irreducible if</p>
<ol>
	<li>\(a \neq 0\)</li>
	<li>\(a \not\in R^{\times}\)</li>
	<li>If \(a = bc\), then one of \(b\) or \(c\) is a unit</li>	
</ol>
<p>This notion of irreducible element is kind of the replacement we have to the notion of a prime number. In fact, we can re-write this condition to make it closer.</p>
<ul>
	<li>Given two elements in a domain \(a,b \in R\), we say that \(a\) divides \(b\) (write \(a \ | \ b\)) if there exists an element \(c \in R\) such that \(b = ac\)</li>
	<li>In terms of ideals. This is equivalent to saying \(b\) is in \(Ra\). It is also equivalent to saying that \(Rb \subseteq Ra\). </li>
	<li>\(a\) is irreducible if whenever \(b \ | \ a\), either \(b\) is a unit or \(b \sim a\). This is similar to how we defined prime numbers. if an element divides \(p\), then it's either \(p\) or \(1\)</li>
</ul>
<p><br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Prime Elements in \(R\)</b></h4>
<p>The reason we’re discussing this is because of another definition that might make things confusing.
<br />
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
\(p \neq 0 \in R\) is prime if for every \(a, b \in R\), if \(p \ | \ ab\), then either \(p \ | \ a \) or \(p \ | \ b\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
This is the definition a prime element in a domain. The confusing part is that the definition of an irreducible element is the one equivalent to a prime number. 
<br />
<br />
Now, this notion is actually related to irreducibility. In fact, in \(R = \mathbf{Z}\), the prime elements and the irreducible elements are exactly the same. 
<br />
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(p \in R\) where \(R\) is a domain. Then if \(p\) is prime, then \(p\) is irreducible.
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
Suppose that \(p\) is prime. We want to show that \(p\) is irreducible so suppose that \(p = ab\) where \(a, b \in R\). We want to show that either \(a\) or \(b\) is a unit so \(a \in R^{\times}\) or \(b \in R^{\times}\). Since \(p = ab\), then \(p \ | \ ab\). But prime means that \(p \ | \ a\) or \(p \ | \ b\). So, suppose \(p \ | \ a\). This means that \(p\) is a factor of \(a\) so \(a = pc\) for some \(c \in R\). Plugging this back in the original equation to see that</p>
<div>
$$
\begin{align*}
p &amp;= ab \\
p &amp;= pcb \\
1 &amp;= cb \quad (p \neq 0)
\end{align*}
$$
</div>
<p>But this means that \(b\) is a unit. Therefore, \(p\) is irreducible. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Irreducible but not Prime elements</b></h4>
<p>The converse of the previous proposition is not true. If an element is irreducible, it won’t necessarily be prime. An example is the domain \(R = \mathbf{Z}[\sqrt{-5}] \subseteq \mathbf{C}\). It is defined as the set</p>
<div>
$$
\begin{align*}
R = \mathbf{Z}[\sqrt{-5}] = \{a + b\sqrt{-5} \ | \ a, b \in \mathbf{Z}\}
\end{align*}
$$
</div>
<p>It is a subring of \(\mathbf{C}\) and it has a 1 so it’s a domain. Next, we’re going to produce an element that is irreducible but not prime!
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Claim
</div>
<div class="peachbodydiv">
\(2 \in R\) is irreducible but not prime in \(R\)
</div>
<!----------------------------------------------------------------------------->
<p><br />
In order to show this, we need to define the norm function for \(R\) so
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Define the norm function for \(R =  \mathbf{Z}[\sqrt{-5}]\) as follows
$$
\begin{align*}
N: \mathbf{Z}[\sqrt{-5}] &amp;\rightarrow \mathbf{Z} \\
 N(a + b\sqrt{5}) &amp;= (a + b\sqrt{5})(a - b\sqrt{5}) = a^2 + 5b^2 
\end{align*}
$$
for any \(a, b \in \mathbf{Z}\). 
</div>
<!----------------------------------------------------------------------------->
<p><br />
The norm function has the following properties
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
The norm function defined above has the following properties
<ol>
	<li>The norm is a non-negative integer. \(N(a + b\sqrt{-5}) \in \mathbf{Z}_{\geq 0}\)</li>
	<li>\(N(z) = 0\) if and only if \(z = 0\)</li>
	<li>\(N(zw) = N(z)N(w)\), \(N(1)\)</li>
	<li>If \(N(z) = 1\) if and only if \(z \in R^{\times}\)</li>
</ol>
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof (4)</b>
<br />
\(\Rightarrow\): Suppose that \(N(a + b \sqrt{-5}) = 1\). Then</p>
<div>
$$
\begin{align*}
N((a+b\sqrt{-5}) &amp;= (a+b\sqrt{-5})(a - b\sqrt{-5}) \quad \text{(By defintion of the norm above)}  \\
1 &amp;= (a+b\sqrt{-5})(a - b\sqrt{-5}) \\
(a+b\sqrt{-5})^{-1} &amp;= (a - b\sqrt{-5})
\end{align*}
$$
</div>
<p>Thus, \((a + b\sqrt{-5})\) is a unit in \(R\).
<br />
<br />
\(\Leftarrow\): Suppose that \(z \in R^{\times}\) so \(z\) is a unit. Observe that</p>
<div>
$$
\begin{align*}
N(1) &amp;= N(z\bar{z}) = N(z)N(\bar{z})
\end{align*}
$$
</div>
<p>But since \(N(z)\) and \(N(\bar{z})\) are non-negative integers, then the only solution is that \(N(z) = N(\bar{z}) = 1\). \(\ \blacksquare\)
<br />
<br />
Note that we can also conclude here that the possible units in this ring are</p>
<div>
$$
\begin{align*}
(\mathbf{Z}[\sqrt{-5}])^{\times} = \{ \pm 1\}
\end{align*}
$$
</div>
<p>So now back to the claim that \(2\) is irreducible but not prime. We’ll show that \(2\) is irreducible first. Computing the norm, we see that</p>
<div>
$$
\begin{align*}
N(2) = 2^2 + 0^2 = 4
\end{align*}
$$
</div>
<p>So now suppose that \(2 = uv\) where \(u,v \in R\). Observe that</p>
<div>
$$
\begin{align*}
4 = N(2) = N(uv) = N(u)N(v)
\end{align*}
$$
</div>
<p>To show that \(2\) is irreducible, we need to show that \(u\) or \(v\) is a unit. So the claim is that \(u\) or \(v\) is a unit. So we need to show that either \(N(u)\) or \(N(v)\) is 1. This means that we want to show that \(N(u)=2\) is not possible. Suppose for the sake of contradiction that \(N(u)=2\). This means that</p>
<div>
$$
\begin{align*}
2 = a^2 + 5b^2.
\end{align*}
$$
</div>
<p>But there are no integer solutions to this. Therefore, \(2\) is irreducible in \(R = \mathbf{Z}[\sqrt{-2}]\). What about 2 being prime? Observe that</p>
<div>
$$
\begin{align*}
6 = 2(3) = (1+\sqrt{-5})(1-\sqrt{-5})
\end{align*}
$$
</div>
<p>We know that \(2 \ | \ 6\). But 2 doesn’t divide either of \((1 \pm \sqrt{-5})\) in \(R\). So by defintion, \(2\) is not prime. (recall that the def was that a prime must divide either \(a\) or \(b\)). This fails in this domain because in \(\mathbf{Z}\) prime factorization is unique but in this domain we see that we have two completely different factorization.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Principle Ideal Domain (PID)</b></h4>
<p>A new definition
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A domain \(R\) is a Principle Ideal Domain if every ideal is a principle ideal in \(R\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
Examples</p>
<ul>
	<li>\(R = K\) where \(K\) is a field. Recall that fields are domains and they have two ideals.</li>
	<li>\(R = \mathbf{Z}\). Recall that every ideal in \(\mathbf{Z}\) is principle. </li>
	<li>\(R = K[x]\) where \(K\) is a field</li>
</ul>
<p>Non-Examples</p>
<ul>
	<li>\(R = K[x,y]\). Polynomial rings in two variables are not PIDs. One example is that $$I = (x,y)$$ is not a principle ideal. (Exercise)</li>
	<li>\(\mathbf{Z}[x]\). \((z,x)\) also not a principle ideal. (Exercise)</li>
	<li>\(R = \mathbf{Z}[\sqrt{-5}]\) is not a principle domain</li>
</ul>
<p>This last example is a consequence of the following proposition. It contains the ideal \(I = (2, 1+\sqrt{-5})\) which is not principle. (complete proof in the lecture notes)
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
In a PID irreducible elements are the same as prime elements
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
\(\Rightarrow\): We know that prime elements are always irreducible. 
<br />
<br />
\(\Leftarrow:\): Suppose \(R\) is a PID and \(p \in R\) is irreducible. We want to show that \(p\) is prime. Since \(p\) is irreducible, then it’s non-zero. So now suppose \(p \ | \ ab\). We want to show that \(p \ | \ a\) or \(p \ | \ b\). So assume that \(p \nmid a\), we will show that \(p \ | \ b\).<br />
<br />
Now consider the ideal generated by the two elements \(p\) and \(a\) so \(I = (p,a)\). By assumption this ideal is principle. So it is also generated by a single element \(I = (c)\). We know that \(p \in I\). So \(p\) is a multiple of \(c\) so \(p = cd\) for some \(d \in R\). Since \(p\) is irreducible, then either \(c\) is a unit \(c \in R^{\times}\) or \(d\) is a unit, \(d \in R^{\times}\). 
<br />
<br />
\(d\) can’t be a unit. This is because \(p = cd\) and since \(d\) is a unit, then multiply both sides by the inverse of \(d\) to see that \(c = pd^{-1}\). But this means that \(c\) is a multiple of \(p\). So \(c \in (p)\). Thus, \((c)\) = \((p)\). (Side note: In general, \((p)=(c)\) if and only if \(p = cd\) for some unit \(d\)) Now, we know that \(p \nmid a\). But \(a \in (p,a) = (c)\). So \(a \in (p)\). This is a contradiction since \(p \nmid a\). Therefore, \(d\) can’t be a unit. Thus, \(c\) is a unit. But we know that \(I = (c)\) so \(I = R\). So \(1 \in (p,a)\). So</p>
<div>
$$
\begin{align*}
1 &amp;= px + ay \quad \text{ for some } x,y \in R \\
b &amp;= bpx + aby 
\end{align*}
$$
</div>
<p>We know that \(p \ | \ bpx\). We also know that \(p \ | \ ab\). Therefore, \(p \ | \ b\) as we wanted to show. \(\ \blacksquare\).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>The Set of Gaussian Integers is a PID</b></h4>
<p>One more example of PID. We want to show that the gaussian integers are a pid but to show this, we need the following proposition
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(u,v \in \mathbf{Z}[i]\) and \(v \neq 0\). Then there exists \(q, r \in \mathbf{Z}[i]\) such that 
$$
\begin{align*}
u = qv + r \quad \text{ and } \quad N(r) &lt; N(v)
\end{align*}
$$
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
The proof for this proposition is geometric. Take the complex plane and label the gaussian integers with black dots as shown below</p>

<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec38/complex.png" width="55%" class="center" /></p>

<p>So suppose \(v\) is the red dot above, then distance between \(v\) and the next closest Gaussian number is always less than or equal to \(\frac{\sqrt{2}}{2}\). This is because the diagonal between any two gaussian numbers is of length \(\sqrt{2}\). So any complex number is at most a distance of 1 away from any Gaussian number. 
<br />
<br />
So now take \(v\) and \(u\) and divide them \(\frac{u}{v}\). This is a complex number still. Now choose \(q \in \mathbf{Z}[i]\) that is the closest to \(\frac{u}{v}\). Observe that</p>
<div>
$$
\begin{align*}
\lVert \frac{u}{v} - q \rVert &amp;&lt; 1 \\
\lVert \frac{u}{v} - \frac{qv}{v} \rVert &amp;&lt; 1 \\
\lVert \frac{u - qv}{v} \rVert &amp;&lt; 1 \\
\frac{\lVert u - qv \rVert}{\lVert v\rVert} &amp;&lt; 1 \\
\lVert u - qv \rVert &amp;&lt; \lVert v\rVert \\
\lVert u - qv \rVert^2 &amp;&lt; \lVert v\rVert^2 \\
N(u - qv) &amp;&lt; N(v) \\
\end{align*}
$$
</div>
<p>So now set \(r = u - qv \in \mathbf{Z}[i]\). Thus, \(N(r) &lt; N(v)\). \(\ \blacksquare\). 
<br />
<br />
Notice here that we don’t have uniqueness statement about \(q\) and \(r\) like the division algorithm for integers. So now we can prove the following theorem about \(\mathbf{Z}[i]\)
<br />
<!-----------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
\(R = \mathbf{Z}[i] = \{a + bi \ | \ a,b \in \mathbf{Z}\} \) is a PID. In other words, Every ideal in the gaussian integers is a principle.
</div>
<!----------------------------------------------------------------------------->
<p><br />
<br />
<b>Proof</b>
<br />
We want to show that \(R\) is a principle ideal domain. By defintion, this means that every ideal is a principle ideal in \(R\). So let \(I \in \mathbf{Z}[i]\). We want to show that \(I\) is a principle ideal.
Use the previous proposition. If \(u, v \in \mathbf{Z}[i]\). If it’s the zero ideal, there is nothing to do. So if it’s a non-zero ideal, then it has a non-zero element. Choose an element \(v \in I/\{0\}\) in the ideal with minimal norm. We claim that \(I = (d)\). 
\((v) \subseteq I\): This is easy since \(v \in I\). <br />
\(I \subseteq (v)\): Suppose \(u \in I\), then by the previous proposition, \(u = qv + r\) where \(N(r) &lt; N(v)\). So \(r = u - qv\). \(u \in I\) and \(qv \in\). Then \(r \in\). But \(N(r) &lt; N(v)\) and we said that \(v\) is the element with minimum norm. So \(r = 0\). Therefore, \(u \in (v)\). So \(I = (d)\) and so \(R\) is a principle ideal domain. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[We’ll start by defining Quotient Rings Definition: Domain A domain \(R\) is a commutative ring with 1 such that \(1 \neq 0\). If \(a,b \in R/\{0\}\), then \(ab \in R/\{0\}\). So non-zero elements multiply to non-zero elements. In other words, \(ab = 0\) then either \(a = 0\) or \(b = 0\). Fact: Every field is a domain. Other examples: \(\mathbf{Z}\) and \(K[x]\) are domains. The Gaussian integers are a domain \(\mathbf{Z}[i] = \{a + bi \in \mathbf{C} \ | \ a, b \in \mathbf{Z}\). \(\mathbf{Z}_4\) is not a domain, \([2] \neq 0\) but \([2][2] = [4] = [0]]\). \(\mathbf{Q}/(f_1f_2)\) where \(\deg(f_i) \geq 1\) is not a domain. (Exercise) Fact: If \(K\) is a field and \(R \subseteq K\) is a subring such that \(1_K \in R\), then \(R\) is a domain Proposition Every domain \(R\) is (isomorphic) a subring of a field \(F = \text{Frac}(R)\) (field of fraction) So basically every domain can be enlarge to be a field. Proof Let \(X = \{(a,b) \ | \ a, b \in R, b \neq 0\}\). Define a relation on \(X\): $$ \begin{align*} (a,b) \sim (a',b') \quad \text{ iff } ab' = ba' \end{align*} $$ We claim that this relation is an equivalence relation. (Exercise, hard to prove but use that \(R\) is a domain Side note: domains have cancellations so if \(ab = bc\) and \(a \neq 0\), then \(b = c\).) Since we have an equivalence relation on a set \(X\), then define \(F: X/\sim\) to be the set of equivalence classes. Write \([\frac{a}{b}] \in F\) for the equivalence class of \((a,b)\). Now, define $$ \begin{align*} \big[\frac{a}{b}\big] + \big[\frac{a'}{b'}\big] &amp;= \big[\frac{ab'+ba'}{bb'}\big] \\ \big[\frac{a}{b}\big]\big[\frac{a'}{b'}\big] &amp;= \big[\frac{aa'}{bb'}\big] \end{align*} $$ Check that these operations are well defined and make \(F\) a field. Finally, define \(\varphi: R \rightarrow F\) by \(\varphi(a) = [\frac{a}{1}]\). Check that \(\varphi\) is an injective ring homomorphism. Examples Suppose \(R = \mathbf{Z}\), then \(\text{Frac}(\mathbf{Z}) \cong \mathbf{Q}\). Suppose \(R = K[x]\) the ring of polynomials over a field. Then \(\text{Frac}(K[x]) = K[x]\) is the field of rational polynomials. elements in \(\text{Frac}(K[x]) = K[x]\) are of the form \(\frac{f}{g}\). Element Types We want to discuss factorization in a domain but before doing so, we need to see the types of elements we can find in a domain. Zero: the element zero is in \(R\). Units: These are the elements that have a multiplicative inverse. Reducible: If \(a \in R\), \(a \neq 0\) and \(a \not\in R^{\times}\) (not a unit), then there exists \(b,c \in R\) such that \(a = bc\). (\(b\) and \(b\) must both be non-units!) Irreducible: Not a zero, not a unit and not reducible. This means \(a \in R\), \(a \not\in R^{\times}\) and if \(a = bc\), then either \(b \in R^{\times}\) or \(c \in R^{\times}\). Examples \(R = \mathbf{Z}\) Units: \(\mathbf{Z}^{\times} = \{-1, +1\}\) Reducible: \(\{\pm n, n \in \mathbf{N}, \text{composite}\}\) Irreducible: These are the elements that don't factor so \(\{\pm p, p \in \mathbf{N}, \text{prime}\}\) \(R = K\) where \(K\) is a field \(0 \in K\) Units: \(K^{\times} = K / \{0\}\) Reducible: none. Irreducible: none. \(R = K[x]\) where \(K\) is a field \(0 \in K[x]\) Units: these are polynomials of degree 0 so \(K^{\times}\) Reducible: polynomials that you can factor into smaller ones. \(f, \deg(f) \geq 1\) such that \(f = gh, 0 &lt; \deg(g), \deg(h) &lt; \deg(f)\) Irreducible: polynomials that you can't factor. \(f, \deg(f) \geq 1\) such that there is no \(g,h, \deg(h), \deg(g) &lt; \deg(f)\) such that \(f = gh\) \(R = \mathbf{C}[x]\) \(0 \in C[x]\) Units: \(C^{\times}\) Reducible: \(f, \deg(f) \geq 2\) Irreducible: \(f, \deg(f) = 1\) \(R = \mathbf{C}[x]\) \(0 \in R[x]\) Units: \(R^{\times}\) Irreducible: One form is \(ax + b, a \neq 0\) and another form is \(ax^2 + bx + c\) where \(a \neq 0, b^2 - 4ac &lt; 0\) Reducible: The rest of polynomials are reducible Warning: If we take a look at the polynomials over the rational numbers, we will find out that there are a lot more irreducible polynomials there. Note here that the ring of polynomials with rational coefficients is contained in the ring of polynomials with the real coefficients and that’s contained in the field of rational functions over \(\mathbf{R}\). In other words, \(\mathbf{Q}[x] \subseteq \mathbf{R}[x] \subseteq \mathbf{R}(x)\). Now, take \(x^p - 2\) where \(p \geq 2\), then \(x^p - 2\) is irreducible in \(Q[x]\), reducible in \(R[x]\). (The proof is not obvious). It is a unit in \(\mathbf{R}(x)\)! so it’s important to consider the context in which we’re in. Norm Functions Another Example is the Gaussian Integers: \(R = \mathbf{Z}[i] = \{a + bi \ | \ a, b \in \mathbf{Z}\} \subseteq \mathbf{C}\). So \(R\) is a subring of the complex numbers and it is a domain. Since it’s a domain, we want to categorize the elements in it. But to do so, we need another tool defined as follows Definition: Norm Functions The norm of \(a + bi\) is defined to be \(N(a + bi) = a^2 + b^2 = (a + bi)(a - bi) = \lVert a + bi \rVert^2 \) So this is a function defined on the complex numbers and therefore defined on the Gaussian integers. Some properties: If \(z \in \mathbf{Z}[i], N(z) \in \mathbf{Z}_{\geq 0}\) \(N(z) = 0\) if and only if \(z = 0\) If \(z, w \in \mathbf{Z}[i], N(zw) = N(z)N(w)\) If \(z \in \mathbf{Z}[i]\), then \(z \in \mathbf{Z}[i]^{\times}\) if and only if \(N(z) = 1\) Proof of (4): If \(z \in \mathbf{Z}[i]^{\times}\), then \(z\) is a unit and \(zz^{-1} = 1\). We know that \(z^{-1} \in \mathbf{Z}[i]\) so \(z^{-1}\) is a Gaussian integer. So $$ \begin{align*} 1 = N(1) = N(z)N(z^{-1}) \end{align*} $$ But \(N(z)\) and \(N(z^{-1})\) are positive integers by (1). Therefore \(N(z) = N(z^{-1}) = 1\). For the other direction when \(N(z) = 1\). Write \(z = a + bi\) where \(a, b \in \mathbf{Z}\). By definition $$ \begin{align*} 1 = N(z) = N(a + bi) = (a + bi)(a - bi) \end{align*} $$ Therefore, \((a + bi)^{-1} = (a - bi)\). In fact the units are just \(\mathbf{Z}^{-1}[i] = \{ \pm 1, \pm i\}\). Example 1 Example: \(2 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). So 2 is also a Gaussian integer since \(\mathbf{Z}\) is a subring of the Gaussian integers. \(2\) is a prime number so it’s irreducible as an integer. However, is it reducible as a Gaussian integer? Observe that $$ \begin{align*} 2 = (1 + i)(1 - i) \end{align*} $$ So it’s definitely reducible as a Gaussian integer. Example 2 Example: Take \(1 + i \in \mathbf{Z}[i]\). Is it reducible or irreducible in \(\mathbf{Z}[i]\)? It is in fact irreducible. We know this because \(N(1 + i) = 2\) and if there were factors \(1 + i = zw\), then $$ \begin{align*} N(1 + i) = N(z)N(w) = 2 \end{align*} $$ But the norm is a non-negative integer. So the only way to make this work is that either \(N(z) = 1\) or \(N(w) = 1\) so one of the factors is a unit. Thus, by definition, \(z\) is irreducible. Associate Elements Next, we have this definition for when two elements are associate when one element is a product of some unit times the other element. Definition \(a, b \in R\) are the same up-to-units or associate (we write \(a \sim b\)) if there exists an element \(u \in R^{\times}\) such that \(b = ua\). This is in fact an equivalence relation (Exercise) Example: In \(\mathbf{Z}\), associate classes are \(\{0\}\), \(\{\pm n\}, n &gt; 0\). Another example is \(K[x]\), \(f \sim g\) if \(g = fc\) for some \(c \in K/\{0\}\). Fact: If two elements are associate, then they are of the same type! Example 3 \(3 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). Is it reducible? It is irreducible in \(\mathbf{Z}\) since it is prime. In \(\mathbf{Z}[i]\), we know that \(N(3) = N(3 + 0i) = 9\). Suppose it was reducible. This means that there exists \(z,w \in \mathbf{Z}[i]\) $$ \begin{align*} 9 = N(3) = N(z)N(w) \end{align*} $$ To be reducible, neither \(z\) or \(w\) can be units so they can’t have a norm of 1. Therefore, we must have \(N(z) = N(w) = 3\). This a contradiction since we don’t have any Gaussian integers with norm 3 (square root of 3 from the origin). $$ \begin{align*} N(a + bi) = a^2 + b^2, \quad a^2, b^2 \in \{0,1,4,9,16,...\} \end{align*} $$ So it’s not possible to construct an element of the form \(a + bi\) in \(\mathbf{Z}[i]\) such that \(a^2 + b^2 = 3\). Example 4 \(4 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). Is it reducible? It is reducible in \(\mathbf{Z}\). In \(\mathbf{Z}[i]\), we know that \(4 = (2)(2)\) and \(2\) is not a unit in \(\mathbf{Z}[i]\). Not just that but we also saw that \(2\) can be factored using the previous example \(2 = (1 + i)(1 - i)\). Furthermore, we also have another way too to factor 4. Below are some of the ways $$ \begin{align*} 4 = 2(2) = (1 + i)^2(1 - i)^2 = -(1 + i)^4 \end{align*} $$ Example 5 \(5 \in \mathbf{Z} \subseteq \mathbf{Z}[i]\). Is it reducible in \(\mathbf{Z}[i]\)? It is reducible because $$ \begin{align*} 5 = (2 + i)(2 - i) \end{align*} $$ The factors themselves \((2+i)\) and \((2-i)\) are irreducible since the the norm \(N(2 + i) = 5\). Also note that \((2+i)\) and \((2-i)\) are not associate. When is \(p\) reducible in \(\mathbf{Z}[i]\)? We went through a few examples of doing this calculation but in fact we do have a proposition about this as follows Proposition If \(p \in \mathbf{N}\) is a prime number, then \(p\) is reducible in \(\mathbf{Z}[i]\) if and only if \(p = a^2 + b^2\) for some \(a,b \in \mathbf{Z}\) Proof \(\Leftarrow:\) Suppose that \(p = a^2 + b^2\). Then we can write $$ \begin{align*} p = (a - bi)(a + bi) \end{align*} $$ Recall that \(N(a + bi) = a^2 + b^2\) but that means \(N(a + bi) = p\) and \(p\) is prime so it’s not 1. So neither (a + bi) or (a - bi) is a unit. Therefore, \(p\) is reducible. \(\Rightarrow:\) Suppose that \(p\) is reducible so \(p = zw\). Therefore, $$ \begin{align*} N(p) = N(z)N(w) = p^2 \quad (\text{since } p \in \mathbf{Z}, N(p)=p^2) \end{align*} $$ But \(p\) is prime and so we must have \(N(z)=N(w)=p\). This means that there exists some \(a, b\) such that \(z = a + bi\) where \(N(z) = p\). This means $$ \begin{align*} N(z) = a^2 + b^2 = p. \end{align*} $$ So \(p = a^2 + b^2\) as we wanted to show. \(\ \blacksquare\) Examples The proof shows that for a prime to be a sum of squares is related to whether it factors as a Gaussian integer]]></summary></entry><entry><title type="html">Lecture 36: Homomorphism Theorem and Isomorphism Theorem</title><link href="http://localhost:4000/jekyll/update/2025/02/28/math417-36-ring-homomorphisms-isomorphisms.html" rel="alternate" type="text/html" title="Lecture 36: Homomorphism Theorem and Isomorphism Theorem" /><published>2025-02-28T00:01:36-08:00</published><updated>2025-02-28T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/28/math417-36-ring-homomorphisms-isomorphisms</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/28/math417-36-ring-homomorphisms-isomorphisms.html"><![CDATA[<p>We’ll start by defining Quotient Rings
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Quotient Ring
</div>
<div class="mintbodydiv">
Let \(R\) be a ring and \(I\) be an ideal in \(R\). Then let the quotient ring \(R/I\)
$$
\begin{align*}
R/I = \{a + I \ | \ a + R\}
\end{align*}
$$
be the set of all \(I\)-cosets in \(R\) with operations:
<ol>
	<li>Addition: \((a + I) + (b + I) = (a + b) + I\).</li>
	<li>Multiplication: \((a + I) + (b + I) = (ab) + I\).</li>
</ol>
</div>
<!----------------------------------------------------------------------------->
<p><br />
Note that there are other notations used for \(I + a\). One notation is \([a]\) or \(\bar{a}\).
<br />
<br />
The claim is that these operations are well defined and will make the quotient set with the operations defined a ring. For addition, it’s already part of how we defined quotient groups? For multiplication, we need to show that if \(a + I = a' + I\) and \(b + I = b' + I\). Then</p>
<div>
$$
\begin{align*}
ab + I = a'b' + 1
\end{align*}
$$
</div>
<p>To see this, write \(a' = a + u\) and \(b' = b + v\) for some \(u, v \in I\). Then</p>
<div>
$$
\begin{align*}
a'b' &amp;= (a + u)(b + v) \\
     &amp;= ab + av + ub + uv
\end{align*}
$$
</div>
<p>\(av + ub + uv\) is in \(I\) since \(I\) is an ideal. Therefore, \(a'b' + (av+ub+uv)\) and \(ab + I\) represent the same ideal. 
<br />
<br />
Next, we need to show that \(R/I\) is an abelian group with addition. And then we need to show that multiplication is associative and distributes over addition. (exercise)
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Quotient Homomorphism</b></h4>

<div class="mintheaderdiv">
Definition: Quotient Homomorphism
</div>
<div class="mintbodydiv">
Let \(R\) be a ring and \(I\) be an ideal in \(R\). Define
$$
\begin{align*}
\pi: R &amp;\rightarrow R/I \\
     \pi(a) &amp;= a + I
\end{align*}
$$
</div>
<!------------------------------------------------------------------------->
<p><br />
So just send any element to its coset. We already know this makes a group homomorphism for quotient groups. It also makes a ring homomorphism. We just need to check. It is also surjective because every coset comes from some element in \(I\). The kernel of the homomorphism \(\ker(\pi) = I\).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 1</b></h4>
<p>Take \(R = \mathbf{Z}\) and take \(I\) to be a principle ideal generated by some element \(d\) so \(I = (d) = \mathbf{Z}d\). Then</p>
<div>
$$
\begin{align*}
R/I = \mathbf{Z}/\mathbf{Z}d = \mathbf{Z}_d
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 2</b></h4>
<p>Take the ring of polynomials \(R[x]\). If we quotient this ring by the principle ideal generated by \((x^2 + 1)\), then we get the ring of complex numbers. \(R[x]/(x^2+1) \cong \mathbf{C}\)
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Quotient Rings of Polynomial Rings</b></h4>
<p>Let \(K\) be a field. Let \(R = K[x]\) be the ring of polynomials over the field \(K\) and let \(I \subseteq R\). From this, form the quotient ring \(S = K[x]/I\).  Notice here that since the ideal is in a ring over a field, then we know every ideal is principle. So \(I\) is a principle ideal generated by some polynomial and we can write \(I = (f)\) for some \(f \in R\). 
<br />
<br />
For example, \(R/(0) \cong R\). If \(I\) is not \(\{0\}\), then choose \(f\) to be monic of minimal degree. Now write</p>
<div>
$$
\begin{align*}
f = x^n + a_{n-1}x + ... + a_0, a_0,...,a_{n-1} \in K
\end{align*}
$$
</div>
<p>Then \(S = K[x] /(f)\). We have the following claim based in this
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Every element in \(S\) has the form \(r + I\) for some unique \(r \in K[x]\) such that \(\deg(r) &lt; n\). 
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
Use division with remainder. If \(g + I \in S\) where \(g \in K[x]\), then there exists unique \(q, r \in K[x]\) such that \(g = qf + r\) where \(\deg(r) &lt; n = \deg(f)\). This means we can write \(g - r = qf\). We know that \(qf \in I\) since it’s a multiple of \(f\). Since \(g - r = qf\), then \(g-r\) is also in \(I\). This implies that \(g\) and \(r\) are in the same \(I\)-coset. Therefore \(g+I = r+I\). \(\blacksquare\).
<br />
<br />
\(r + I\) is the canonical form of an element in \(S = K[x] / (f)\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Suppose \(K = \mathbf{Q}\) be the rationals ring, \(S = \mathbf{Q}[x]/(f)\) be the quotient ring and let \(f = x^2 - 2\) so \(I = (f)\) is the ideal generated by this polynomial \(f=x^2-2\). 
<br />
<br />
Using the previous result, we know that Every element of \(S\) can be written as \(r + I\) for a unique \(r \in Q[x]\) such that \(\deg(r) &lt; \deg(f)=2\). Therefore, we can write \(r + I\) as</p>
<div>
$$
\begin{align*}
(a + bx) + I = a + b\bar{x} \quad a,b \in \mathbf{Q}
\end{align*}
$$
</div>
<p>This notation is a shorthand for: given \(a \in \mathbf{Q}\), then write \(a\) or \(\bar{a}\) instead of writing \(a + I \in S\)  where \(a+I\) is the coset of constant polynomials in \(S\). Also write \(\bar{x}\) for the element \(x + I\). So, then</p>
<div>
$$
\begin{align*}
(a + b\bar{x}) + (a' + b'\bar{x}) &amp;= (a+a') + (b+b')\bar{x} \\
(a + b\bar{x}) (a' + b'\bar{x}) &amp;= aa' + ab'\bar{x} + ba'\bar{x} + bb'\bar{x}^2
\end{align*}
$$
</div>
<p>but now we have \(\bar{x}^2\). That’s because we still need to divide by \(f\). If we divide \(\bar{x}^2\) by \(x^2 - 2\), the remainder is 2. So \(\bar{x}^2\) is really 2 in the ring \(R/(f)\). Then we can simplify this to</p>
<div>
$$
\begin{align*}
(a + b\bar{x}) (a' + b'\bar{x}) &amp;= aa' + ab'\bar{x} + ba'\bar{x} + 2bb' \\
                                &amp;= (aa' + 2bb') +(ab'+ba')\bar{x}
\end{align*}
$$
</div>
<p>Remark: This quotient ring \(S\) is isomorphic to \(\mathbf{Q}(\sqrt{2})\) which is a subring of \(\mathbf{R}\). \(\mathbf{Q}(\sqrt{2})\) is the ring</p>
<div>
$$
\begin{align*}
\{a+b\sqrt{2} \ | \ a,b \in \mathbf{Q}\}
\end{align*}
$$
</div>
<p>The isomorphism between these rings is</p>
<div>
$$
\begin{align*}
a+b\bar{x} \rightarrow a + b\sqrt{2}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Homomorphism Theorem</b></h4>
<p>We start by a recipe to form a new homomorphism from a quotient ring.
<br />
<!-------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Homomorphism Theorem
</div>
<div class="yellowbodydiv">
Let \(\varphi: R \rightarrow S\) be a ring homomorphism and \(I \subseteq R\) be an ideal. If \(I \subseteq \ker(\varphi)\) (ie. \(\varphi(I) = \{0\}\)), then there exists a ring homomorphism \(\bar{\varphi}: R/I \rightarrow S\). Such that \(\bar{\varphi}(a + I) = \varphi(a)\)
</div>
<!------------------------------------------------------------------------->
<p><br />
To prove this we need to show that the new homomorphism \(\bar{\phi}\) is well defined and then we need to show that it’s a ring homomorphism. And then we have the isomorphism theorem as follows
<br />
<!-------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Isomorphism Theorem
</div>
<div class="yellowbodydiv">
Let \(\varphi: R \rightarrow S\) be a <b>surjective</b> ring homomorphism and \(I \subseteq R\) be an ideal. If \(I = \ker(\varphi)\), then we have an isomorphism of rings 
$$
\begin{align*}
\bar{\varphi}: R/I &amp;\rightarrow S \\ 
\bar{\varphi}(a + I) &amp;= \varphi(a)
\end{align*}
$$
</div>
<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 1</b></h4>
<p>Let \(R = \mathbf{Q}[x]\) and \(S = \mathbf{R}\). Since we want to build a homomorphism from a polynomial ring, then we should always think of the substitution principle. Recall that the substitution principle says that given that we have a homomorphism (in this case let this homomorphism be the identity function), then we can create the following evaluation homomorphism</p>
<div>
$$
\begin{align*}
\varphi: \mathbf{Q}[x] &amp;\rightarrow \mathbf{R} \\ 
\varphi(a) &amp;= a \quad \text{if } a \in \mathbf{Q} \subseteq \mathbf{Q}[x] \\
\varphi(x) &amp;= \sqrt{2} \\
\end{align*}
$$
</div>
<p>So in this case, it’s just an evaluation. So, given some polynomial \(f\), then</p>
<div>
$$
\begin{align*}
\varphi: \mathbf{Q}[x] &amp;\rightarrow \mathbf{R} \\ 
\phi(f) &amp;= f(\sqrt{2})
\end{align*}
$$
</div>
<p>What is the kernel of this homomorphism?</p>
<div>
$$
\begin{align*}
I = \ker(\varphi) &amp;= \{ f \in \mathbf{Q}[x] \ | \ \varphi(f) = 0 \} \\
 &amp;= \{ f \in \mathbf{Q}[x] \ | \ f(\sqrt{2}) = 0 \}
\end{align*}
$$
</div>
<p>So it’s any polynomial that has \(\sqrt{2}\) as a root. Since \(\mathbf{Q}\) is a field, then we know that the kernel is principle. So it’s generated by a single monic polynomial of minimal degree. First of all, this kernel isn’t trivial. For example \(x^2 - 2\) has a \(\sqrt{2}\) as a root of degree 2. If we know that we don’t have constant polynomials or polynomials of degree 1, then we know \(x^2 - 2\) is a generator for the group. Constant non-zero polynomials don’t have roots. Linear polynomials can’t have \(\sqrt{2}\) as a root. The roots will be rationals since the coefficients are rational.
<br />
<br />
So now we have a homomorphism \(\varphi\) from \(\mathbf{Q}[x]\) to \(\mathbf{R}\). Therefore, we can apply the homomorphism theorem to get a new homomorphism (quotient homomorphism) from \(\mathbf{Q}[x]\) to \(\mathbf{Q}[x]/(x^2-2)\).</p>
<div>
$$
\begin{align*}
\pi: \mathbf{Q}[x] &amp;\rightarrow \mathbf{Q}[x]/(x^2-2) \\ 
\phi(f) &amp;= f + (x^2 - 2)
\end{align*}
$$
</div>
<p>The homomorphism takes a polynomial \(f\) in \(\mathbf{Q}[x]\) to its coset.
<br />
<br />
Notice now that we have a homomorphism \(\varphi: \mathbf{Q}[x] \rightarrow \mathbf{R}\) and we have the canonical homomorphism \(\pi: \mathbf{Q}[x] \rightarrow \mathbf{Q}[x]/(x^2-2)\). Before we can apply the isomorphism theorem, we have one issue which is that \(\varphi\) is not surjective. We can fix this by restricting the target to only the image of \(\varphi\) so</p>
<div>
$$
\begin{align*}
\varphi': \mathbf{Q}[x] &amp;\rightarrow \varphi(\mathbf{Q}[x]) \\ 
f(x) &amp;\rightarrow f(\sqrt{2}) \\
\end{align*}
$$
</div>
<p>So now we have a surjective homomorphism where the kernel is \(I = (x^2 - 2)\) and we formed the quotient ring \(\mathbf{Q}[x]/(x^2-2)\). Therefore, we can now apply the isomorphism to conclude that \(\mathbf{Q}[x]/(x^2-2)\) is isomorphic to \(\varphi(\mathbf{Q}[x])\). Moreover, we have an isomorphism defined by</p>
<div>
$$
\begin{align*}
\bar{\varphi}: \mathbf{Q}[x]/(x^2-2) &amp;\rightarrow \varphi(\mathbf{Q}[x]) \\ 
f + (x^2 - 2) &amp;\rightarrow \varphi(f) = f(\sqrt{2})
\end{align*}
$$
</div>
<p>Note that \(\varphi(\mathbf{Q}[x])\) are all the real numbers we can get by plugging in \(\sqrt{2}\) into polynomials with rational coefficients. So</p>
<div>
$$
\begin{align*}
f(x) &amp;= a_0 + a_1x + ... + a_nx^n, \quad a_i \in \mathbf{Q} \\
f(\sqrt{2}) &amp;= a_0 + a_1(\sqrt{2}) + ... + a_n(\sqrt{2})^n, \quad a_i \in \mathbf{Q}
\end{align*}
$$
</div>
<p>But \((\sqrt{2}) = 2, (\sqrt{2})^3 = 2\sqrt{2}\) and in general \((\sqrt{2})^2k = 2^k\) while \((\sqrt{2})^{2k+1} = 2^k\sqrt{2}\). So any \(f(\sqrt{2})\) simplifies to \(a + b\sqrt{2}\). Therefore</p>
<div>
$$
\begin{align*}
\varphi(\mathbf{Q}) = \{ a + b\sqrt{2} \ | \ a,b \in \mathbf{Q} \}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 2</b></h4>
<p>Suppose we have a homomorphism which is just the identity function \(id\) from \(\mathbf{R} \rightarrow \mathbf{R}\). Based on this create the evaluation homomorphism</p>
<div>
$$
\begin{align*}
\varphi: \mathbf{R}[x] &amp;\rightarrow \mathbf{C} \\ 
\varphi(a) &amp;\rightarrow a \\
\varphi(x) &amp;\rightarrow i
\end{align*}
$$
</div>
<p>This homomorphism is in fact surjective. The kernel of this homomorphism is generated by \((x^2+1)\). Therefore,</p>
<div>
$$
\begin{align*}
\mathbf{R}[x]/(x^2+1) \cong \mathbf{C}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example 3</b></h4>
<p>This take, let’s take the rational numbers instead so</p>
<div>
$$
\begin{align*}
\varphi: \mathbf{Q}[x] &amp;\rightarrow \mathbf{R} \\ 
\varphi(a) &amp;\rightarrow a \\
\varphi(x) &amp;\rightarrow \sqrt[3]{2}
\end{align*}
$$
</div>
<p>The kernel of this homomorphism is generated by \((x^3-2)\). The image of this homomorphism is a subset of \(\mathbf{R}\).</p>
<div>
$$
\begin{align*}
\mathbf{Q}[x]/(x^3-2) \cong \varphi(\mathbf{Q}[x]) \subseteq \mathbf{R}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[We’ll start by defining Quotient Rings Definition: Quotient Ring Let \(R\) be a ring and \(I\) be an ideal in \(R\). Then let the quotient ring \(R/I\) $$ \begin{align*} R/I = \{a + I \ | \ a + R\} \end{align*} $$ be the set of all \(I\)-cosets in \(R\) with operations: Addition: \((a + I) + (b + I) = (a + b) + I\). Multiplication: \((a + I) + (b + I) = (ab) + I\). Note that there are other notations used for \(I + a\). One notation is \([a]\) or \(\bar{a}\). The claim is that these operations are well defined and will make the quotient set with the operations defined a ring. For addition, it’s already part of how we defined quotient groups? For multiplication, we need to show that if \(a + I = a' + I\) and \(b + I = b' + I\). Then $$ \begin{align*} ab + I = a'b' + 1 \end{align*} $$ To see this, write \(a' = a + u\) and \(b' = b + v\) for some \(u, v \in I\). Then $$ \begin{align*} a'b' &amp;= (a + u)(b + v) \\ &amp;= ab + av + ub + uv \end{align*} $$ \(av + ub + uv\) is in \(I\) since \(I\) is an ideal. Therefore, \(a'b' + (av+ub+uv)\) and \(ab + I\) represent the same ideal. Next, we need to show that \(R/I\) is an abelian group with addition. And then we need to show that multiplication is associative and distributes over addition. (exercise) Quotient Homomorphism]]></summary></entry><entry><title type="html">Lecture 35: Principal Ideal</title><link href="http://localhost:4000/jekyll/update/2025/02/27/math417-35-principal-ideal.html" rel="alternate" type="text/html" title="Lecture 35: Principal Ideal" /><published>2025-02-27T00:01:36-08:00</published><updated>2025-02-27T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/27/math417-35-principal-ideal</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/27/math417-35-principal-ideal.html"><![CDATA[<p>Last time we introduced the notion of an ideal in a ring. Stating it again
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Ideal
</div>
<div class="mintbodydiv">
An ideal in \(R\) is a subset \(I \subseteq R\) such that
<ol>
	<li>\(I\) is a subgroup of the abelian group with addition \((R, +)\). So the ideal must have \(0 \in I\), closed under addition, additive inverses are in \(I\) as well.</li>
	<li>If \(a \in I, r \in R\), then \(ra, ar \in I\) so it is also closed under multiplication.</li>
</ol>
</div>
<!----------------------------------------------------------------------------->
<p><br />
We said that usually we refer to this definition as the “Two sided ideal” since other variants can exists (left and right ideals).
<br />
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(\{I_{\alpha}\}\) is a collection of ideals, then \(I = \bigcap_{\alpha} I_{\alpha}\) is an ideal. 
</div>
<p><br />
As a consequence of this, we have the following defintion
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Ideal Generated by \(S\)
</div>
<div class="mintbodydiv">
Given a subset \(S \subseteq R\) ring, define 
$$
\begin{align*}
(S) = \bigcap_{\text{all ideas such that }S \subseteq I} I
\end{align*}
$$
\((S)\) is an Ideal in \(R\) generated by \(S\). It is in fact the smallest Ideal containing the subset \(S\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
It is the smallest, since by definition for any \(I \subseteq R\), \(S\) is contained in \(I\), so \((S)\) is also in \(I\). This is a nice formal definition but it’s hard to use. An explicit description of the Ideal is as follows
<br />
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(R\) is a ring with 1 and \(S \subseteq R\) then,
$$
\begin{align*}
(S) = \{0\} \cup \{a_1s_1b_1 + ... + a_ks_kb_k \ | \ k \geq 1, s_1,...s_k \in S, a_i,b_i \in R\}
\end{align*}
$$
</div>
<!----------------------------------------------------------------------------->
<p><br />
The elements are of the form \(a_is_ib_i\) since by definition, if an element \(s_i\) is in \(I\), then for any \(a_i \in R\), \(a_is_i \in I\) and for any \(b_i \in R\), \(s_ib_i \in R\). So we have \(a_is_ib_i\) to account for all possible products.
<br />
<br />
<b>Proof</b>
<br />
Let \(T = \{a_1s_2b_1 + ... + a_ks_kb_k \ | \ k \geq 1, s_1,...s_k \in S, a_i,b_i \in R\}\). Then we need to show</p>
<ol>
<li>Step (1) is showing that \(T\) is an Ideal where \(S \subseteq T\).</li>
<li>Step (2) is if any \(I \subseteq R\) is any idea such that \(S \subseteq I\), then \(T \subseteq I\).</li>
</ol>
<p>(1) and (2) Together imply that \(T = (S)\). <br />
[TODO: Write full proof]
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Principle Ideal</b></h4>
<p>A special case of the above definition is when \(R\) is commutative. If it is, then the definition simplifies to</p>
<div>
$$
\begin{align*}
(S) = \{0\} \cup \{a_1s_2 + ... + a_ks_k \ | \ k \geq 1, s_1,...s_k \in S, a_i \in R\}
\end{align*}
$$
</div>
<p>We don’t need to multiply on both the left and right since \(a_1s_2 = s_2a_1\) so we get to have all products still with a simpler defintion.
<br />
<br />
Another special case is the Principle Ideal.
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Principle Ideal
</div>
<div class="mintbodydiv">
A Principle Ideal \(I\) is an ideal such that \(I = (r)\) for a single \(r = R\) so
$$
\begin{align*}
(r) = \{a_1rb_1 + ... + a_krb_k \ | \  a_i,b_i \in R\}
\end{align*}
$$
</div>
<p><br />
Note that if \(R\) is a commutative ring with identity then</p>
<div>
$$
\begin{align*}
(r) &amp;= \{a_1r + ... + a_kr \ | \  a_1,...a_k \in R\} \\
    &amp;= \{(a_1 + ... + a_k)r \ | \  a_1,...a_k \in R\} \\
	&amp;= \{ ar \ | \ a \in R \} \quad \text{(because $a_1+...+a_k \in R$)}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<p>Example 1: If \(K\) is a field. The only ideals are \(\{0\}\) and \(K\). \(\{0\}\) is generated by \((0)\) and \(K\) is generated by \((1)\). The idea generated by 1 is always the whole ring.
<br />
<br />
Example 2: Take \(R = \mathbf{Z}\). All ideals are of the form \((d) = \mathbf{Z}d\) for some \(d \geq 0\). In fact, all ideals are principle. Why? 
<br />
<br />
<b>Proof</b>
<br />
We know that for any ideal, it is a subgroup (with addition) of \(R=\mathbf{Z}\) so \(I \leq \mathbf{Z}\). If \(I = \{0\}\), then we’re done since \(\{0\}\) is a principle ideal generated by \((0)\). Suppose it is not so \(I \neq \{0\}\), then there exists a non-zero element in \(I\). Choose \(d \in I \cap \mathbf{Z}d\) to be the smallest positive element. 
<br />
<br />
Claim: \(I = \mathbf{Z}d\). We can show this by:
<br />
<br />
\(\mathbf{Z}d \subseteq I\) (easy): Since \(d \in I\), then any multiple of \(d\) is in \(I\) so \(\mathbf{Z}d \subseteq I\).
<br />
\(I \subseteq \mathbf{Z}d\) (hard): Consider any \(a \in I\). Use division with remainder to see that \(a = qd + r\). \(r \in \mathbf{Z}\) where \(0 \leq r &lt; d\). So \(r = a - qd\). \(r\) is in \(I\) because \(a \in I\) and \(qd \in I\). But \(d\) is the smallest element in \(I\). So \(r\) must be zero. Therefore, \(a = qd\) so \(a \in \mathbf{Z}d\). So \(I \in \mathbf{Z}d\). \(\blacksquare\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>More Propositions</b></h4>
<p>We have more propositions about the principle ideal. One is the following
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Suppose that \(K\) is is a field and \(R = K[x]\). Every ideal in \(R\) is principle. In fact, if \(I \subseteq R\), then there exists a unique \(f\) such that \((f) = I\) and either \(f = 0\) or \(f\) is monic.
</div>
<!----------------------------------------------------------------------------->
<p><br />
A monic polynomial is \(f = a_nx^n + a_{n-1}x^{n-1} + ... + a_0\) where \(a_n = 1\).
<br />
<br />
<b>Proof</b>
<br />
If \(I \subseteq K[x]\) and \(I\) is an ideal. Then if \(I = \{0\}\), then \(I\) is generated by \(0\) so \(I = (0)\). Now, suppose that \(I \neq \{0\}\). Then, pick an element \(f \in I/\{0\}\) of minimal degree. We can choose</p>
<div>
$$
\begin{align*}
f = a_nx^n +... +a_0
\end{align*}
$$
</div>
<p>to be monic. If it’s not monic, then use \(f' = a_n^{-1}f\). This is fine because \(a_n\) is a unit in \(K\) and has an inverse. Both \(f\) and \(f'\) have the same degree. 
<br />
<br />
Note: This polynomial of minimal degree is unique. Why? Suppose \(f, g \in I/\{0\}\) and \(f\) and \(g\) are monic of the same minimal degree. Then their difference is in the ideal so \(f-g \in I\). (side note: reminder for any two polynomials in \(I\), their difference is in \(I\) since \(I\) is closed under addition/multiplication). In fact, since \(f\) and \(g\) are monic, then their leading terms are 1 so when we take the difference, this new polynomial \(f-g\) must have degree lower than \(f\) and \(g\). But this is a contradiction since we said that \(f\) and \(g\) are both of minimal degree. Thus, \(f - g = 0\) and \(f = g\). So the monic polynomial of minimal degree in \(I\) is unique. (Another side note: This is not true inside all of \(K[x]\).)
<br />
<br />
So now the claim is that \(I = (f)\) so \(I\) is generated by this minimal monic polynomial. <br />
\((f) \subseteq I\) (easy): This is immediate since \(f\) is in \(I\) so all multiplies of \(f\) are in \(I\).<br /><br />
\(I \subseteq (f)\) (hard): We know \((f) = \{fg \ | \ g \in K[x]\}\). So suppose that \(p \in I\). Then use division with remainder \((p \div f)\) to get \(p = qf + r\) for some polynomials \(q, r \in K[x]\) with \(\deg(r) &lt; \deg(f)\). So now \(r = p - qf\). We know \(p \in I\) and \(qf \in I\) since \(f \in I\). So \(r\) must be in \(I\). But that’s impossible since we said that \(f\) has the smallest degree in \(I\) so \(r = 0\). Therefore, \(p = qf\) is in \((f)\) as we wanted to show. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Suppose that \(K\) is a field with \(c \in K\). Consider the evaluation homomorphism of rings where when \(r \in K \subseteq K[x]\), then \(ev_c(r) = r\)</p>
<div>
$$
\begin{align*}
ev_c: K[x] &amp;\rightarrow K \\
      ev_c(f) &amp;= f(c)
\end{align*}
$$
</div>
<p>The kernel is an ideal. \(\ker(ev_c) = I\). By definition</p>
<div>
$$
\begin{align*}
\ker(ev_c) = \{f(x) \in K[x] \ | \ f(c) = 0\}.
\end{align*}
$$
</div>
<p>So it’s the set of polynomials that vanish at \(c\) or have \(c\) as a root. But since \(K\) is a field, then \(I\) is a principle ideal so it’s generated by some unique monic polynomial. One monic polynomial that satisfies this is \(x - c\). So \(\ker(ev_c) = (x-c)\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Consequences</b></h4>
<!----------------------------------------------------------------------------->
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Suppose that \(K\) is is a field, then every non-zero polynomial \(f \in K[x]\) has only finitely many roots in \(K\) in \(R\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
If \(c \in K\) and \(f(c) = 0\), then \(f\) is generated by \((x - c)\). The ideal generated by \((x-c)\) is the set of multiples of this generator so</p>
<div>
$$
\begin{align*}
I = \{ (x-c)g \ | \ g \in K[x]\}.
\end{align*}
$$
</div>
<p>So \(f\) must be of the from \((x-c)g\) for some polynomial \(g \in K[x]\) and if \(c\) is a root, then we can factor off the linear term \((x - c)\). Inductively, we can iterate this process on \(g\) and in each iteration notice that the degree of the polynomial goes down by one until we reach the form</p>
<div>
$$
\begin{align*}
f = (x - c_1) (x - c_2)...(x - c_k)g', \quad c_1,...,c_k \in K
\end{align*}
$$
</div>
<p>where \(g' \in K[x]\) is a polynomial with no roots in \(K\). Now, we can see that we found the roots \(c_1,c_2,...,c_k \in K\) but \(g\) has no roots in \(K\) (otherwise, we would’ve kept factoring). The degree of \(f\) is</p>
<div>
$$
\begin{align*}
\deg(f) &amp;= \deg((x - c_1) (x - c_2)...(x - c_k)g') \\
n &amp;= k + \deg(g')
\end{align*}
$$
</div>
<p>So \(k\) at most \(n\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Let \(K = \mathbf{R} \subseteq \mathbf{C}\) be a subring. Define the following function using the substitution principle</p>
<div>
$$
\begin{align*}
ev_i : \mathbf{R}[x] &amp;\rightarrow \mathbf{C} \\
               ev_i(r) &amp;= r \\
			   rv_i(x) &amp;= i.
\end{align*}
$$
</div>
<p>In other words, \(ev_i(f) = f(i) \in \mathbf{C}\). So it’s like plugging in \(i\) in the function. What is the kernel? We know the kernel is an ideal that is generated by a single monic polynomial. In the previous example, we were evaluating at \(c\) where \(c \in K\). But now, \(i\) is not in the field \(K\). The question is now: Do we know a monic polynomial that has \(i\) as a root? It is \(x^2 + 1\) so \(I = \ker(ev_i) = (x^2 + 1)\).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Last time we introduced the notion of an ideal in a ring. Stating it again Definition: Ideal An ideal in \(R\) is a subset \(I \subseteq R\) such that \(I\) is a subgroup of the abelian group with addition \((R, +)\). So the ideal must have \(0 \in I\), closed under addition, additive inverses are in \(I\) as well. If \(a \in I, r \in R\), then \(ra, ar \in I\) so it is also closed under multiplication. We said that usually we refer to this definition as the “Two sided ideal” since other variants can exists (left and right ideals). Proposition If \(\{I_{\alpha}\}\) is a collection of ideals, then \(I = \bigcap_{\alpha} I_{\alpha}\) is an ideal. As a consequence of this, we have the following defintion Definition: Ideal Generated by \(S\) Given a subset \(S \subseteq R\) ring, define $$ \begin{align*} (S) = \bigcap_{\text{all ideas such that }S \subseteq I} I \end{align*} $$ \((S)\) is an Ideal in \(R\) generated by \(S\). It is in fact the smallest Ideal containing the subset \(S\). It is the smallest, since by definition for any \(I \subseteq R\), \(S\) is contained in \(I\), so \((S)\) is also in \(I\). This is a nice formal definition but it’s hard to use. An explicit description of the Ideal is as follows Proposition If \(R\) is a ring with 1 and \(S \subseteq R\) then, $$ \begin{align*} (S) = \{0\} \cup \{a_1s_1b_1 + ... + a_ks_kb_k \ | \ k \geq 1, s_1,...s_k \in S, a_i,b_i \in R\} \end{align*} $$ The elements are of the form \(a_is_ib_i\) since by definition, if an element \(s_i\) is in \(I\), then for any \(a_i \in R\), \(a_is_i \in I\) and for any \(b_i \in R\), \(s_ib_i \in R\). So we have \(a_is_ib_i\) to account for all possible products. Proof Let \(T = \{a_1s_2b_1 + ... + a_ks_kb_k \ | \ k \geq 1, s_1,...s_k \in S, a_i,b_i \in R\}\). Then we need to show Step (1) is showing that \(T\) is an Ideal where \(S \subseteq T\). Step (2) is if any \(I \subseteq R\) is any idea such that \(S \subseteq I\), then \(T \subseteq I\). (1) and (2) Together imply that \(T = (S)\). [TODO: Write full proof] Principle Ideal A special case of the above definition is when \(R\) is commutative. If it is, then the definition simplifies to $$ \begin{align*} (S) = \{0\} \cup \{a_1s_2 + ... + a_ks_k \ | \ k \geq 1, s_1,...s_k \in S, a_i \in R\} \end{align*} $$ We don’t need to multiply on both the left and right since \(a_1s_2 = s_2a_1\) so we get to have all products still with a simpler defintion. Another special case is the Principle Ideal. Definition: Principle Ideal A Principle Ideal \(I\) is an ideal such that \(I = (r)\) for a single \(r = R\) so $$ \begin{align*} (r) = \{a_1rb_1 + ... + a_krb_k \ | \ a_i,b_i \in R\} \end{align*} $$ Note that if \(R\) is a commutative ring with identity then $$ \begin{align*} (r) &amp;= \{a_1r + ... + a_kr \ | \ a_1,...a_k \in R\} \\ &amp;= \{(a_1 + ... + a_k)r \ | \ a_1,...a_k \in R\} \\ &amp;= \{ ar \ | \ a \in R \} \quad \text{(because $a_1+...+a_k \in R$)} \end{align*} $$ Examples Example 1: If \(K\) is a field. The only ideals are \(\{0\}\) and \(K\). \(\{0\}\) is generated by \((0)\) and \(K\) is generated by \((1)\). The idea generated by 1 is always the whole ring. Example 2: Take \(R = \mathbf{Z}\). All ideals are of the form \((d) = \mathbf{Z}d\) for some \(d \geq 0\). In fact, all ideals are principle. Why? Proof We know that for any ideal, it is a subgroup (with addition) of \(R=\mathbf{Z}\) so \(I \leq \mathbf{Z}\). If \(I = \{0\}\), then we’re done since \(\{0\}\) is a principle ideal generated by \((0)\). Suppose it is not so \(I \neq \{0\}\), then there exists a non-zero element in \(I\). Choose \(d \in I \cap \mathbf{Z}d\) to be the smallest positive element. Claim: \(I = \mathbf{Z}d\). We can show this by: \(\mathbf{Z}d \subseteq I\) (easy): Since \(d \in I\), then any multiple of \(d\) is in \(I\) so \(\mathbf{Z}d \subseteq I\). \(I \subseteq \mathbf{Z}d\) (hard): Consider any \(a \in I\). Use division with remainder to see that \(a = qd + r\). \(r \in \mathbf{Z}\) where \(0 \leq r &lt; d\). So \(r = a - qd\). \(r\) is in \(I\) because \(a \in I\) and \(qd \in I\). But \(d\) is the smallest element in \(I\). So \(r\) must be zero. Therefore, \(a = qd\) so \(a \in \mathbf{Z}d\). So \(I \in \mathbf{Z}d\). \(\blacksquare\). More Propositions We have more propositions about the principle ideal. One is the following Proposition Suppose that \(K\) is is a field and \(R = K[x]\). Every ideal in \(R\) is principle. In fact, if \(I \subseteq R\), then there exists a unique \(f\) such that \((f) = I\) and either \(f = 0\) or \(f\) is monic. A monic polynomial is \(f = a_nx^n + a_{n-1}x^{n-1} + ... + a_0\) where \(a_n = 1\). Proof If \(I \subseteq K[x]\) and \(I\) is an ideal. Then if \(I = \{0\}\), then \(I\) is generated by \(0\) so \(I = (0)\). Now, suppose that \(I \neq \{0\}\). Then, pick an element \(f \in I/\{0\}\) of minimal degree. We can choose $$ \begin{align*} f = a_nx^n +... +a_0 \end{align*} $$ to be monic. If it’s not monic, then use \(f' = a_n^{-1}f\). This is fine because \(a_n\) is a unit in \(K\) and has an inverse. Both \(f\) and \(f'\) have the same degree. Note: This polynomial of minimal degree is unique. Why? Suppose \(f, g \in I/\{0\}\) and \(f\) and \(g\) are monic of the same minimal degree. Then their difference is in the ideal so \(f-g \in I\). (side note: reminder for any two polynomials in \(I\), their difference is in \(I\) since \(I\) is closed under addition/multiplication). In fact, since \(f\) and \(g\) are monic, then their leading terms are 1 so when we take the difference, this new polynomial \(f-g\) must have degree lower than \(f\) and \(g\). But this is a contradiction since we said that \(f\) and \(g\) are both of minimal degree. Thus, \(f - g = 0\) and \(f = g\). So the monic polynomial of minimal degree in \(I\) is unique. (Another side note: This is not true inside all of \(K[x]\).) So now the claim is that \(I = (f)\) so \(I\) is generated by this minimal monic polynomial. \((f) \subseteq I\) (easy): This is immediate since \(f\) is in \(I\) so all multiplies of \(f\) are in \(I\). \(I \subseteq (f)\) (hard): We know \((f) = \{fg \ | \ g \in K[x]\}\). So suppose that \(p \in I\). Then use division with remainder \((p \div f)\) to get \(p = qf + r\) for some polynomials \(q, r \in K[x]\) with \(\deg(r) &lt; \deg(f)\). So now \(r = p - qf\). We know \(p \in I\) and \(qf \in I\) since \(f \in I\). So \(r\) must be in \(I\). But that’s impossible since we said that \(f\) has the smallest degree in \(I\) so \(r = 0\). Therefore, \(p = qf\) is in \((f)\) as we wanted to show. \(\ \blacksquare\) Example Suppose that \(K\) is a field with \(c \in K\). Consider the evaluation homomorphism of rings where when \(r \in K \subseteq K[x]\), then \(ev_c(r) = r\) $$ \begin{align*} ev_c: K[x] &amp;\rightarrow K \\ ev_c(f) &amp;= f(c) \end{align*} $$ The kernel is an ideal. \(\ker(ev_c) = I\). By definition $$ \begin{align*} \ker(ev_c) = \{f(x) \in K[x] \ | \ f(c) = 0\}. \end{align*} $$ So it’s the set of polynomials that vanish at \(c\) or have \(c\) as a root. But since \(K\) is a field, then \(I\) is a principle ideal so it’s generated by some unique monic polynomial. One monic polynomial that satisfies this is \(x - c\). So \(\ker(ev_c) = (x-c)\). Consequences Proposition Suppose that \(K\) is is a field, then every non-zero polynomial \(f \in K[x]\) has only finitely many roots in \(K\) in \(R\). Proof If \(c \in K\) and \(f(c) = 0\), then \(f\) is generated by \((x - c)\). The ideal generated by \((x-c)\) is the set of multiples of this generator so $$ \begin{align*} I = \{ (x-c)g \ | \ g \in K[x]\}. \end{align*} $$ So \(f\) must be of the from \((x-c)g\) for some polynomial \(g \in K[x]\) and if \(c\) is a root, then we can factor off the linear term \((x - c)\). Inductively, we can iterate this process on \(g\) and in each iteration notice that the degree of the polynomial goes down by one until we reach the form $$ \begin{align*} f = (x - c_1) (x - c_2)...(x - c_k)g', \quad c_1,...,c_k \in K \end{align*} $$ where \(g' \in K[x]\) is a polynomial with no roots in \(K\). Now, we can see that we found the roots \(c_1,c_2,...,c_k \in K\) but \(g\) has no roots in \(K\) (otherwise, we would’ve kept factoring). The degree of \(f\) is $$ \begin{align*} \deg(f) &amp;= \deg((x - c_1) (x - c_2)...(x - c_k)g') \\ n &amp;= k + \deg(g') \end{align*} $$ So \(k\) at most \(n\). Example Let \(K = \mathbf{R} \subseteq \mathbf{C}\) be a subring. Define the following function using the substitution principle $$ \begin{align*} ev_i : \mathbf{R}[x] &amp;\rightarrow \mathbf{C} \\ ev_i(r) &amp;= r \\ rv_i(x) &amp;= i. \end{align*} $$ In other words, \(ev_i(f) = f(i) \in \mathbf{C}\). So it’s like plugging in \(i\) in the function. What is the kernel? We know the kernel is an ideal that is generated by a single monic polynomial. In the previous example, we were evaluating at \(c\) where \(c \in K\). But now, \(i\) is not in the field \(K\). The question is now: Do we know a monic polynomial that has \(i\) as a root? It is \(x^2 + 1\) so \(I = \ker(ev_i) = (x^2 + 1)\). References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 34: Homomorphisms of Rings and the Substitution Principle</title><link href="http://localhost:4000/jekyll/update/2025/02/26/math417-34-homomorphisms-rings.html" rel="alternate" type="text/html" title="Lecture 34: Homomorphisms of Rings and the Substitution Principle" /><published>2025-02-26T00:01:36-08:00</published><updated>2025-02-26T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/26/math417-34-homomorphisms-rings</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/26/math417-34-homomorphisms-rings.html"><![CDATA[<p>Last time we introduced polynomial rings. Given a commutative ring with 1, then \(R[x]\) is a commutative polynomial ring with 1 and coefficients in \(R\). Today, we will introduce a few more definitions
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Homomorphisms of Rings
</div>
<div class="mintbodydiv">
Let \(R\) and \(S\) be rings. A homomorphism \(\varphi: R \rightarrow S\) is a function such that
<ol>
	<li>\(\varphi: (R_1, +) \rightarrow (S, +)\) is a homomorphism of groups (ie: \(\varphi(a + b) = \varphi(a) + \varphi(b)\)</li>
	<li>\(\varphi(a,b) = \varphi(a)\varphi(b)\) for all \(a,b \in R\)</li>
</ol>
</div>
<!--------------------------------------------------------------------------->
<p><br />
Remark: If \(R\) and \(S\) have a multiplication identity, \(\varphi\) can fail to take 1 to 1. So \(\varphi(1)\) could be something other than 1. Unlike for zero, where zero needs to go zero. This is because rings are required to have an additive inverses and because we have additive inverses, then zero will be mapped to zero. But we don’t necessarily have multiplicative inverses for all elements (that’s a field). So 1 won’t necessarily get mapped to 1. Based on this define
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Homomorphisms of Rings
</div>
<div class="mintbodydiv">
Let \(R\) and \(S\) be rings. A unital homomorphism is a ring homomorphism such that also \(\varphi(1_R) = 1_S\)
</div>
<p><br /></p>
<h4><b>Example 1</b></h4>
<p>Let \(\pi: \mathbf{Z} \rightarrow \mathbf{Z}_n\) where \(\pi(a) = [a]_n\). Then \(\pi\) is a unital homomorphism of rings.
<br />
<br /></p>
<h4><b>Example 2</b></h4>
<p>If \(R\) is any ring with 1. Define \(\varphi \mathbf{Z} \rightarrow R\) by \(\varphi(n) = n1_R\). \(\varphi\) is a unital ring homomorphism. For example</p>
<div>
$$
\begin{align*}
\varphi(2) &amp;= 1_R + 1_R \\
\varphi(3) &amp;= 1_R + 1_R + 1_R \\
\varphi(2)\varphi(3) &amp;= (1_R + 1_R)(1_R + 1_R + 1_R) = \varphi(6).
\end{align*}
$$
</div>
<p><br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Isomorphism of Rings</b></h4>
<p>More simple definitions:
<br /></p>
<div class="mintheaderdiv">
Definition: Isomorphism of Rings
</div>
<div class="mintbodydiv">
Let \(R\) and \(S\) be rings. An Isomorphism of rings is a homomorphism of rings which is also a bijection.
</div>
<p><br />
Since an isomorphism is a bijection, this means that we have an inverse function \(\varphi^{-1}: S \rightarrow R\) that is also an isomorphism of rings
<!------------------------------------------------------------------------->
<br /></p>
<div class="mintheaderdiv">
Definition: Automorphism of Rings
</div>
<div class="mintbodydiv">
Let \(R\) be a ring. An Automorphism \(\varphi: R \rightarrow R\) is an isomorphism of the ring to itself.
</div>
<p><br />
<!------------------------------------------------------------------------->
For example, take the set of matrices such that</p>
<div>
$$
\begin{align*}
S = \big\{ \begin{pmatrix} a &amp; -b \\ b &amp; a \end{pmatrix} \big\} 
\subseteq \text{Mat}_{2\times 2}(\mathbf{R})
\end{align*}
$$
</div>
<p>with \(a, b \in \mathbf{R}\). \(S\) is a subring. We have an isomorphism of rings between \(S\) and the complex numbers as follows</p>
<div>
$$
\begin{align*}
\varphi: \mathbf{C} &amp;\rightarrow S \\
         a + bi &amp;\rightarrow \begin{pmatrix} a &amp; -b \\ b &amp; a \end{pmatrix}
\end{align*}
$$
</div>
<p>Another example is \(\varphi: \mathbf{C} \rightarrow \mathbf{C}\) where \(\varphi(z) = \bar{z}\). So \(\varphi(a+bi) = a - bi\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Substitution Principle</b></h4>
<p>The substitution principle is a method for constructing any ring homomorphism where the domain is a polynomial ring
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition: Substitution Principle
</div>
<div class="peachbodydiv">
Let \(R\) and \(S\) be commutative rings with identity. Given that
<ol> 
	<li>\(\varphi: R \rightarrow S\) is a unital homomorphism</li>
	<li>\(c \in S\)</li>
</ol>
Then there exists a unique ring homomorphism
$$
\begin{align*}
\varphi_c: R[x] \rightarrow S
\end{align*}
$$
such that
<ol> 
	<li>\(\varphi_c(r) = \varphi(r)\)</li>
	<li>\(\varphi_c(x) = c\)</li>
</ol>
Furthermore, if \(f = \sum_{k=0}^n a_kx^k \in R[x], a_k \in R\). Then
$$
\begin{align*}
\varphi_c(f): \sum_{k=0}^n \varphi(a_k) c^k
\end{align*}
$$
</div>
<p><br />
<!---------------------------------------------------------------------->
This means given some unital homomorphism between the two rings. Then</p>
<ul>
<li>If we know how the homomorphism act on constant polynomials (so these are the elements in \(R\) which will be the constant polynomials in \(R[x]\)</li> 
<li>And if we know how it acts on \(x\) (we're sending it to \(c\))</li>
</ul>
<p>Then we will get this new homomorphism \(\varphi_c\) and we will know how it acts on all the other polynomials using \(\varphi_c(f): \sum_{k=0}^n \varphi(a_k) c^k\).
<br />
<br />
But now you might ask that it’s kind of like evaluating the polynomial at \(c\)?? This is true for a special case when \(\phi\) is the identity function. So when \(R = S\) and \(\phi:R \rightarrow R\) is just the identity. Then, given any \(c\), we will see that</p>
<div>
$$
\begin{align*}
\phi_c(f) = ev_c(f) = \sum_{k=0}^n a_k c^k \in R \quad \text{ev for evaluation}
\end{align*}
$$
</div>
<p>which is basically like plugging in \(c\) for \(x\) so \(f(c)\). However, this \(ev_c: R[x] \rightarrow R\) is actually a ring homomorphism. This ring homomorphism has the following properties.</p>
<ol>
	<li>\(ev_c(r) = r\) if \(r \in R \subseteq R(x)\)</li>
	<li>\(ev_(f+g) = ev_c(f) + ev_c(g)\). This is equivalent to us doing \((f+g)(c) = f(c)+f(g)\)</li>
	<li>\(ev_c(fg) = ev_c(f)ev_c(g)\). This is equivalent to us doing \((fg)(c) = f(c)g(c)\)</li>
</ol>
<p>So again, if we have a unital homomorphism and we have those two conditions where we know what it does to \(c\) and we know what it does to constant polynomials. Then that formula must work. It’s the only way. But then we need to check that this formula is actually a ring homomorphism (Excercise)
<br />
<br />
Observation: \(R\) is a commutative ring with 1. Any polynomial \(f \in R[x]\) gives a function</p>
<div>
$$
\begin{align*}
func_c: R &amp;\rightarrow R \\
c &amp;\rightarrow ev_c(f) = "f(c)"
\end{align*}
$$
</div>
<p>Warning: We can have \(f \neq g\) but \(func_f = func_g\)!.
<br />
Example 1: Let \(R = \mathbf{Z}_p\) where \(p\) is prime. Then</p>
<div>
$$
\begin{align*}
f &amp;= x \in \mathbf{Z}_p[x] \implies func_f = id: \mathbf{Z}_p \rightarrow \mathbf{Z}_p \\
g &amp;= x^p \in \mathbf{R}_p[x] \implies func_g(c) = c^p: \mathbf{Z}_p \rightarrow \mathbf{Z}_p 
\end{align*}
$$
</div>
<p>These are two different polynomials but they are the same function because due to Fermat’s little theorem. \(c^p \equiv c (\bmod p)\) so \(c^p = c\) in \(\mathbf{Z}_p\).
<br />
<br />
Example 2: Let \(h = g-f \in \mathbf{Z}_p\) so \(h = x^p - x\) and \(func_h = 0\) for any \(x \in \mathbf{Z}_p\). So any element in \(\mathbf{Z}_p\) is a root of \(h(x)\) and \(h(x)\) has at least \(p\) roots in \(\mathbf{Z}_p\). In otherwords, we have a polynomial where any element we input, we get zero and so we can’t distinguish it as a function from the zero function.</p>
<ul>
<li>So as a polynomial, $$h(x) = x - x^p$$ is not the zero polynomial. Its coefficients are not all zero. </li>
<li>But as a function, it is the zero function. It evalutes to zero for any input in \(\mathbf{Z}_p\)</li>
</ul>
<p>This happens because we’re in \(\mathbf{Z}_p\). If we’re in an inifinite field, then when \(f \neq g\), we will always get \(func_g \neq func_f\). Also in general, polynomials give us functions but they are not exactly functions!
<br />
<br />
Side study note: A polynomial belongs to the ring \(R[x]\). A function is a mapping from \(R\) to \(R\). It assigns to each input \(r\) in \(R\), another value \(f(r)\) in \(R\). The function lives in the set of functions from \(R\) to \(R\). If \(R\) is finite, two different polynomials in \(R[x]\) may define the same function! So \(x^2\) and \(x\), will define the same function from \(\mathbf{Z}_2 \rightarrow \mathbf{Z}_2\). If \(R\) was an infinite field, then each distinct polynmoial will give a distinct function.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Ideals</b></h4>
<p>So far, we’ve seen groups, subgroups and normal subgroups. Normal subgroups were special since they show up as kernels of homomorphism and we can form quotient groups using them. 
<br />
<br />
Similarly, we have rings and subrings. And we also have ideals. Ideals show up as kernels of ring homomorphisms similar to nomral groups. And we can also form quotient rings using them. 
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition: Ideal
</div>
<div class="mintbodydiv">
An ideal in \(R\) is a subset \(I \subseteq R\) such that
<ol>
	<li>\(I\) is a subgroup of the abelian group with addition \((R, +)\). So the ideal must have \(0 \in I\), closed under addition, additive inverses are in \(I\) as well.</li>
	<li>If \(a \in I, r \in R\), then \(ra, ar \in I\) so it is also closed under multiplication.</li>
</ol>
</div>
<!----------------------------------------------------------------------------->
<p><br />
So it’s not just a subring. It’s more special because of the closure under the product. Warning: This definition is also reffered as a “Two Sided Ideal”. Because we do have another variant where we only require half the second condition (left and right ideals).
<br />
<br />
Example: In any ring \(R\), \(\{0\}\) and \(R\) are both ideas in \(R\). \(\{0\}\) is usually called the trivial ideal. \(R\) is called the unit ideal.
<br />
<br />
Observation: If \(R\) is a ring with 1 and \(I \subseteq R\) is an ideal. Then, if \(1 \in I\), then \(I = R\). Why? The ideal must be closed under multiplication so if the ideal contains 1, then it contains every element in \(R\). 
<br />
<br />
Observation: If \(I\) contains a unit \(u\), then \(I = R\). This is because if \(u \in I\), then \(u^{-1}u = 1 \in I\). so \(1 \in I\) and therefore, every element is in \(I\). So \(I = R\). 
<br />
<br />
Example: If \(K\) is a field, then we have exactly two ideals \(K\) and \(\{0\}\). Because fields have only units in them. 
<br />
<br />
Example: If \(K\) is a field and \(n \geq 1\), then \(S = \text{Mat}_{n \times n}(K)\) has two ideals: \(\{0\}\) and \(S\) (not trivial but not hard to prove).
<br />
<br />
Example: If \(R = \mathbf{Z}\), the ideals in \(\mathbf{Z}\) all have form \(\{\mathbf{Z}_n = \{an \ | \ a \in \mathbf{Z}\}\). 
<br />
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
If \(\varphi: R \rightarrow S\) is a ring homomorphism. Its kernel is 
$$
\begin{align*}
\ker(\varphi) = \{r \in R \ | \ \varphi(r) = 0\}
\end{align*}
$$
</div>
<p><br />
Fact: \(\ker(\varphi)\) is an ideal in \(R\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Last time we introduced polynomial rings. Given a commutative ring with 1, then \(R[x]\) is a commutative polynomial ring with 1 and coefficients in \(R\). Today, we will introduce a few more definitions Definition: Homomorphisms of Rings Let \(R\) and \(S\) be rings. A homomorphism \(\varphi: R \rightarrow S\) is a function such that \(\varphi: (R_1, +) \rightarrow (S, +)\) is a homomorphism of groups (ie: \(\varphi(a + b) = \varphi(a) + \varphi(b)\) \(\varphi(a,b) = \varphi(a)\varphi(b)\) for all \(a,b \in R\) Remark: If \(R\) and \(S\) have a multiplication identity, \(\varphi\) can fail to take 1 to 1. So \(\varphi(1)\) could be something other than 1. Unlike for zero, where zero needs to go zero. This is because rings are required to have an additive inverses and because we have additive inverses, then zero will be mapped to zero. But we don’t necessarily have multiplicative inverses for all elements (that’s a field). So 1 won’t necessarily get mapped to 1. Based on this define Definition: Homomorphisms of Rings Let \(R\) and \(S\) be rings. A unital homomorphism is a ring homomorphism such that also \(\varphi(1_R) = 1_S\) Example 1 Let \(\pi: \mathbf{Z} \rightarrow \mathbf{Z}_n\) where \(\pi(a) = [a]_n\). Then \(\pi\) is a unital homomorphism of rings. Example 2 If \(R\) is any ring with 1. Define \(\varphi \mathbf{Z} \rightarrow R\) by \(\varphi(n) = n1_R\). \(\varphi\) is a unital ring homomorphism. For example $$ \begin{align*} \varphi(2) &amp;= 1_R + 1_R \\ \varphi(3) &amp;= 1_R + 1_R + 1_R \\ \varphi(2)\varphi(3) &amp;= (1_R + 1_R)(1_R + 1_R + 1_R) = \varphi(6). \end{align*} $$ Isomorphism of Rings More simple definitions: Definition: Isomorphism of Rings Let \(R\) and \(S\) be rings. An Isomorphism of rings is a homomorphism of rings which is also a bijection. Since an isomorphism is a bijection, this means that we have an inverse function \(\varphi^{-1}: S \rightarrow R\) that is also an isomorphism of rings Definition: Automorphism of Rings Let \(R\) be a ring. An Automorphism \(\varphi: R \rightarrow R\) is an isomorphism of the ring to itself. For example, take the set of matrices such that $$ \begin{align*} S = \big\{ \begin{pmatrix} a &amp; -b \\ b &amp; a \end{pmatrix} \big\} \subseteq \text{Mat}_{2\times 2}(\mathbf{R}) \end{align*} $$ with \(a, b \in \mathbf{R}\). \(S\) is a subring. We have an isomorphism of rings between \(S\) and the complex numbers as follows $$ \begin{align*} \varphi: \mathbf{C} &amp;\rightarrow S \\ a + bi &amp;\rightarrow \begin{pmatrix} a &amp; -b \\ b &amp; a \end{pmatrix} \end{align*} $$ Another example is \(\varphi: \mathbf{C} \rightarrow \mathbf{C}\) where \(\varphi(z) = \bar{z}\). So \(\varphi(a+bi) = a - bi\). Substitution Principle The substitution principle is a method for constructing any ring homomorphism where the domain is a polynomial ring Proposition: Substitution Principle Let \(R\) and \(S\) be commutative rings with identity. Given that \(\varphi: R \rightarrow S\) is a unital homomorphism \(c \in S\) Then there exists a unique ring homomorphism $$ \begin{align*} \varphi_c: R[x] \rightarrow S \end{align*} $$ such that \(\varphi_c(r) = \varphi(r)\) \(\varphi_c(x) = c\) Furthermore, if \(f = \sum_{k=0}^n a_kx^k \in R[x], a_k \in R\). Then $$ \begin{align*} \varphi_c(f): \sum_{k=0}^n \varphi(a_k) c^k \end{align*} $$ This means given some unital homomorphism between the two rings. Then If we know how the homomorphism act on constant polynomials (so these are the elements in \(R\) which will be the constant polynomials in \(R[x]\) And if we know how it acts on \(x\) (we're sending it to \(c\)) Then we will get this new homomorphism \(\varphi_c\) and we will know how it acts on all the other polynomials using \(\varphi_c(f): \sum_{k=0}^n \varphi(a_k) c^k\). But now you might ask that it’s kind of like evaluating the polynomial at \(c\)?? This is true for a special case when \(\phi\) is the identity function. So when \(R = S\) and \(\phi:R \rightarrow R\) is just the identity. Then, given any \(c\), we will see that $$ \begin{align*} \phi_c(f) = ev_c(f) = \sum_{k=0}^n a_k c^k \in R \quad \text{ev for evaluation} \end{align*} $$ which is basically like plugging in \(c\) for \(x\) so \(f(c)\). However, this \(ev_c: R[x] \rightarrow R\) is actually a ring homomorphism. This ring homomorphism has the following properties. \(ev_c(r) = r\) if \(r \in R \subseteq R(x)\) \(ev_(f+g) = ev_c(f) + ev_c(g)\). This is equivalent to us doing \((f+g)(c) = f(c)+f(g)\) \(ev_c(fg) = ev_c(f)ev_c(g)\). This is equivalent to us doing \((fg)(c) = f(c)g(c)\) So again, if we have a unital homomorphism and we have those two conditions where we know what it does to \(c\) and we know what it does to constant polynomials. Then that formula must work. It’s the only way. But then we need to check that this formula is actually a ring homomorphism (Excercise) Observation: \(R\) is a commutative ring with 1. Any polynomial \(f \in R[x]\) gives a function $$ \begin{align*} func_c: R &amp;\rightarrow R \\ c &amp;\rightarrow ev_c(f) = "f(c)" \end{align*} $$ Warning: We can have \(f \neq g\) but \(func_f = func_g\)!. Example 1: Let \(R = \mathbf{Z}_p\) where \(p\) is prime. Then $$ \begin{align*} f &amp;= x \in \mathbf{Z}_p[x] \implies func_f = id: \mathbf{Z}_p \rightarrow \mathbf{Z}_p \\ g &amp;= x^p \in \mathbf{R}_p[x] \implies func_g(c) = c^p: \mathbf{Z}_p \rightarrow \mathbf{Z}_p \end{align*} $$ These are two different polynomials but they are the same function because due to Fermat’s little theorem. \(c^p \equiv c (\bmod p)\) so \(c^p = c\) in \(\mathbf{Z}_p\). Example 2: Let \(h = g-f \in \mathbf{Z}_p\) so \(h = x^p - x\) and \(func_h = 0\) for any \(x \in \mathbf{Z}_p\). So any element in \(\mathbf{Z}_p\) is a root of \(h(x)\) and \(h(x)\) has at least \(p\) roots in \(\mathbf{Z}_p\). In otherwords, we have a polynomial where any element we input, we get zero and so we can’t distinguish it as a function from the zero function. So as a polynomial, $$h(x) = x - x^p$$ is not the zero polynomial. Its coefficients are not all zero. But as a function, it is the zero function. It evalutes to zero for any input in \(\mathbf{Z}_p\) This happens because we’re in \(\mathbf{Z}_p\). If we’re in an inifinite field, then when \(f \neq g\), we will always get \(func_g \neq func_f\). Also in general, polynomials give us functions but they are not exactly functions! Side study note: A polynomial belongs to the ring \(R[x]\). A function is a mapping from \(R\) to \(R\). It assigns to each input \(r\) in \(R\), another value \(f(r)\) in \(R\). The function lives in the set of functions from \(R\) to \(R\). If \(R\) is finite, two different polynomials in \(R[x]\) may define the same function! So \(x^2\) and \(x\), will define the same function from \(\mathbf{Z}_2 \rightarrow \mathbf{Z}_2\). If \(R\) was an infinite field, then each distinct polynmoial will give a distinct function. Ideals So far, we’ve seen groups, subgroups and normal subgroups. Normal subgroups were special since they show up as kernels of homomorphism and we can form quotient groups using them. Similarly, we have rings and subrings. And we also have ideals. Ideals show up as kernels of ring homomorphisms similar to nomral groups. And we can also form quotient rings using them. Definition: Ideal An ideal in \(R\) is a subset \(I \subseteq R\) such that \(I\) is a subgroup of the abelian group with addition \((R, +)\). So the ideal must have \(0 \in I\), closed under addition, additive inverses are in \(I\) as well. If \(a \in I, r \in R\), then \(ra, ar \in I\) so it is also closed under multiplication. So it’s not just a subring. It’s more special because of the closure under the product. Warning: This definition is also reffered as a “Two Sided Ideal”. Because we do have another variant where we only require half the second condition (left and right ideals). Example: In any ring \(R\), \(\{0\}\) and \(R\) are both ideas in \(R\). \(\{0\}\) is usually called the trivial ideal. \(R\) is called the unit ideal. Observation: If \(R\) is a ring with 1 and \(I \subseteq R\) is an ideal. Then, if \(1 \in I\), then \(I = R\). Why? The ideal must be closed under multiplication so if the ideal contains 1, then it contains every element in \(R\). Observation: If \(I\) contains a unit \(u\), then \(I = R\). This is because if \(u \in I\), then \(u^{-1}u = 1 \in I\). so \(1 \in I\) and therefore, every element is in \(I\). So \(I = R\). Example: If \(K\) is a field, then we have exactly two ideals \(K\) and \(\{0\}\). Because fields have only units in them. Example: If \(K\) is a field and \(n \geq 1\), then \(S = \text{Mat}_{n \times n}(K)\) has two ideals: \(\{0\}\) and \(S\) (not trivial but not hard to prove). Example: If \(R = \mathbf{Z}\), the ideals in \(\mathbf{Z}\) all have form \(\{\mathbf{Z}_n = \{an \ | \ a \in \mathbf{Z}\}\). Definition If \(\varphi: R \rightarrow S\) is a ring homomorphism. Its kernel is $$ \begin{align*} \ker(\varphi) = \{r \in R \ | \ \varphi(r) = 0\} \end{align*} $$ Fact: \(\ker(\varphi)\) is an ideal in \(R\). References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 33: Polynomial Rings</title><link href="http://localhost:4000/jekyll/update/2025/02/25/math417-33-polynomial-rings.html" rel="alternate" type="text/html" title="Lecture 33: Polynomial Rings" /><published>2025-02-25T00:01:36-08:00</published><updated>2025-02-25T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/25/math417-33-polynomial-rings</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/25/math417-33-polynomial-rings.html"><![CDATA[<p>We’ve introduced rings last lecture and we said that rings can be commutative, contain a multiplicative identity or can also be a field. We saw the subset that includes elements with multiplicative inverses that’s also a group. This is the Units group or \(R^{\times}\) which contains an element in \(R\) such that it has a multiplication inverse. We also saw an example of a ring which is</p>
<div>
$$
\begin{align*}
R[i] = \{\text{Formal expressions } a+bi, a, b \in R \}, \quad i^2 = -1
\end{align*}
$$
</div>

<!----------------------------------------------------------------------------->
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Given a commutative ring with 1. Define \(R[x]\) to be the set of "Formal Expression"
$$
\begin{align*}
f = \sum_{k = 0}^n a_kx^k = a_0 + a_1x + ... + a_nx^n \quad a_0,...a_n \in R, \quad x \text{ new symbol}
\end{align*}
$$
</div>
<!--------------------------------------------------------------------------->
<p><br />
Warning: We want to think of \(3 + 4x + 17x^2 + 0x^3 = 3 + 4x + 17x^2\). So if terms has a zero, then we can take it out. 
<br />
We really identify an \(f \in R[x]\) with an infinite sequence \((a_k)_{k \geq 0} = (a_0,a_1,a_2,...)\) where each \(a_i \in R\) and because this polynomial is finite and we want an infinite sequence, we’ll say that there exists an \(n\) such that \(a_i = 0\) for all \(i &gt; n\). So after some point \(n\), all the terms will be zero after.
<br />
<br />
The claim is that \(R[x]\) is a commutative ring with 1. So we need to define multiplication and addition. Therefore, let \(f = \sum_i a_ix^i, g = \sum_j b_jx^j\) where \(a_i,b_j \in R\). Then</p>
<div>
$$
\begin{align*}
f + g := \sum_k (a_k + b_k)x^k \\
fg := \sum_k (\sum_{i = 0}^k a_ib_{k-i})x^k
\end{align*}
$$
</div>
<!--------------------------------------------------------------------------->
<p>The identity element is an example of a constant polynomial. A constant polynomial is \(f \in R[i]\) where \(f = \sum_ka_k x^k\) such that \(a_k = 0\) for all \(k \geq 1\) So \(f = a_0\).
<br />
<br />
Let \(C \subseteq R[i]\) be the subset of constant. Then \(C\) is a subring. Define a bijection from</p>
<div>
$$
\begin{align*}
\lambda: R &amp;\rightarrow C \\
         a &amp;\rightarrow \text{constant polynomial $a$}
\end{align*}
$$
</div>
<p>This bijection is in fact an isomorphism of rings between \(R\) and \(C\). 
<br />
<br />
Convention: We identify an element \(a\) in the original ring \(R\) with the corresponding constant polynomial in \(R[x]\). So we can think of \(R\) as a subring of \(R[x]\). 
<br />
<br />
Remark: In a similar way, we can form \(R[x,y]\) or \(R[x_1,...,x_n]\) (polynomial ring of several variables). In fact, \(R[x,y] = (R[x])[y]\).
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------></p>
<h4><b>The Degree of a Polynomial</b></h4>
<p>We now want to focus on a special case of a polynomial ring where the coefficient ring is actually a field. So let \(R = K\) be a field and let</p>
<div>
$$
\begin{align*}
f = \sum_k a_kx^k \in K[x], a_k \in K
\end{align*}
$$
</div>
<p>Then, the degree of \(f\), \(\deg(f)\) is the largest integer \(n\) such that \(a_n \neq 0\). For example if</p>
<div>
$$
\begin{align*}
f = 7x^3 + \frac{1}{2}x - 17
\end{align*}
$$
</div>
<p>Then, \(\deg(f) = 3\). Warning: if</p>
<div>
$$
\begin{align*}
f = \sum_{k=0}^{n} a_kx^k \in K[x]
\end{align*}
$$
</div>
<p>Then, we only know that \(\deg(f) \leq n\).
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>The Degree of the Zero Polynomial</b></h4>
<p>If \(f\) is a constant polynomial, what is the degree of \(f\)? We defined the degree as the largest \(n\) such that \(a_n \neq 0\). In a constant polynomial, all the terms are zero except for \(a_0\). If the constant is non-zero, then the degree is zero. But if the polynomial is zero itself so \(f = 0\), then now all the coefficients \(a_i\)’s are zero so in this case the degree is undefined but we’re going to let the degree in this case be \(-\infty\). So deg\((f)=0\) if and only if \(f = 0\). 
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>The Degree of a Polynomial when the Coefficient Ring is a Field</b></h4>
<p>Next, we’re going to prove a proposition where we will see why we needed the coefficient ring to be a field.
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(K\) is a field and \(f,g \in K[x]\). Then
<ol> 
	<li>\(\text{deg}(fg) = \text{deg}(f) + \text{deg}(g)\)</li>
	<li>\(\text{deg}(f+g) \leq \max\{\text{deg}(f), \text{deg}(g)\}\)</li>
</ol>
</div>
<!------------------------------------------------------------------------>
<p><br />
Convention:</p>
<ul>
	<li>\(-\infty + \text{ anything } = -\infty\)</li>
	<li>\(-\infty \leq \text{ anything }\)</li>
</ul>
<p><b>Proof of (1)</b>
<br />
Let \(f = a_0 + a_1x + ... + a_mx^m\) and \(g = b_0 + b_1x + ... + b_nx^n\). Then</p>
<div>
$$
\begin{align*}
fg &amp;= a_0b_0 + (a_1b_0+a_0b_1)x + ... + (a_ma_n)x^{m+n} \\
\end{align*}
$$
</div>
<p>and if \(a_m \neq 0\) and \(b_n \neq 0\), then \(a_mb_n \neq 0\). This is because \(K\) is a field so if \(a,b \in K\) and \(a \neq 0\), \(b \neq 0\), then \(ab \neq 0\). (because \(K^{\times} = K\{0\}\)). 
<br />
<br /></p>
<hr />

<p><br />
Non-example: Take \(R = \mathbf{Z}_4 = \{0,1,2,3\}\). \(\mathbf{Z}_4\) is not a field since element 2 doesn’t have an inverse in \(\mathbf{Z}_4\). Note that only elements 1 and 3 have inverses. (\(3*3 = 1\) and \(1*1 = 1\) in \(\mathbf{Z}_4\). Now consider \(\mathbf{Z}_4[x]\) and let \(f = 1 + 2x \in \mathbf{Z}_4[x]\). Observe that</p>
<div>
$$
\begin{align*}
ff = f^2 = (1 + 2x)^2 = 1 + 2x + 2x + (2x)(2x) = 1 + 4x + 4x^2 = 1
\end{align*}
$$
</div>
<p>The proposition says the degree of \(fg\) should be \(1+1=2\) but here so the degree of \(f^2\) is zero. So we’re failing here because we’re not working in a field. Note that this shows that \(f \in \mathbf{Z_4}[x]^{\times}\) is a unit and it’s multiplicative inverse is itself.  Here is a consequence of the proposition:
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Corollary
</div>
<div class="peachbodydiv">
If \(K\) is a field, then the units in the polynomial ring \(K[x]\) are exactly the elements of \(K^{\times}\). In other words, \(K[x]^{\times} = K^{\times}\).
</div>
<!------------------------------------------------------------------------>
<p><br />
So if \(K\) is a field, then all the units in the ring \(K[x]\) will be the nonzero constant polynomials. Those units are called \(K[x]^{\times}\). They form the multiplicative group of the ring \(K[x]\). Reminder: \(K\) is a field so every element except zero has a multiplicative inverse. \(K^{\times}\) is not a field, it is a group \((K^{\times},\cdot)\) that excludes zero so every single element has a multiplicative inverse. 
<br />
<br />
<b>Proof</b>
<br />
One direction: If we have a constant non-zero polynomial and we’re working in a field, then it has an inverse that’s also a constant polynomial.
<br />
Other direction: If we have two polynomials \(f,g\) such that \(fg = 1\), then computing the degree of both sides we see that</p>
<div>
$$
\begin{align*}
\deg(f,g) &amp;= \deg(1) \\
\deg(f) + \deg(g) &amp;= 0 \\
\deg(f) &amp;= -\deg(g).
\end{align*}
$$
</div>
<p>But the only solution is that \(\deg(f) = \deg(g) = 0\). So the units always have to be constant.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Division Algorithm for \(K[x]\)</b></h4>
<!------------------------------------------------------------------------>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(K\) be a field. Let \(p, d \in K[x]\) where \(\deg(d) \geq 0\) so \(d\) is not a constant polynomial. Then there exists unique \(q,r \in K[x]\) such that
<ol>
	<li>\(p = qd + r\)</li>
	<li>\(\deg(r) &lt; \deg(d)\)</li>
</ol>
</div>
<!------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
Let</p>
<div>
$$
\begin{align*}
p &amp;= \sum_i a_ix^i \text{ with } \deg(p)=m, \ \text{ so } \ a_m \neq 0, a_k &gt; 0 \text{ if } k &gt; m\\
d &amp;= \sum_j b_ix^j, \text{ with } \deg(d)=n \geq 0, \ \text{ so } \ b_n \neq 0, b_k &gt; 0 \text{ if } k &gt; n
\end{align*}
$$
</div>
<p>First, show that if \(m &gt; n\) so the degree of \(p\) is greater than the degree of \(d\), then there exists a monomial \(cx^k\) such that</p>
<ol>
	<li>\(p = (cx^k)d + p'\)</li>
	<li>\(\deg(p') &lt; m = \deg(p)\)</li>
</ol>
<p>So we can in a sense subtract that extra monomial where its degree is less than \(m\). Now, re-write both polynomials such that highest term is in the front</p>
<div>
$$
\begin{align*}
p &amp;= a_mx^m + \text{ lower polynomial } \\
d &amp;= b_nx^n + \text{ lower polynomial }
\end{align*}
$$
</div>
<p>Let \(c = a_mb_n^{-1} = \frac{a_m}{b_n}\). This is fine becasuse \(b_n \neq 0\). Let \(k = m - n\). Then</p>
<div>
$$
\begin{align*}
p' &amp;= p - (cx^k)d = (a_mx^m + \text{ lower polynomial }) - (a_nb_n^{-1}x^{m-n})(b_nx^n + \text{ lower polynomial }) \\
&amp;= (a_mx^m - a_nx^m) \text{ lower polynomial }) \\
&amp;= \text{ lower polynomial }
\end{align*}
$$
</div>
<p>Therefore, \(\deg(p') &lt; m\). 
<br />
<br />
To prove the proposition, we use induction on \(m = \deg(p)\). <br />
If \(m &lt; n = \deg(d)\), let \(q = 0, r = p\) so that \(p = 0d + r\). Therefore, \(\deg(r) = \deg(p) &lt; n\). 
<br />
<br />
If \(m \geq n\), use induction. I can write \(p = (cx^k)d + p'\) where \(\deg(p') &lt; m\). By induction, there exists a \(q'\) such that \(q'd + r\) where \(\deg(r) &lt; n\) so</p>
<div>
$$
\begin{align*}
p &amp;= (cx^k + p')d + r.
\end{align*}
$$
</div>
<p>[TODO: This proof is unclear and a mess … ]
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[We’ve introduced rings last lecture and we said that rings can be commutative, contain a multiplicative identity or can also be a field. We saw the subset that includes elements with multiplicative inverses that’s also a group. This is the Units group or \(R^{\times}\) which contains an element in \(R\) such that it has a multiplication inverse. We also saw an example of a ring which is $$ \begin{align*} R[i] = \{\text{Formal expressions } a+bi, a, b \in R \}, \quad i^2 = -1 \end{align*} $$]]></summary></entry><entry><title type="html">Lecture 32: Rings</title><link href="http://localhost:4000/jekyll/update/2025/02/24/math417-32-rings.html" rel="alternate" type="text/html" title="Lecture 32: Rings" /><published>2025-02-24T00:01:36-08:00</published><updated>2025-02-24T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/24/math417-32-rings</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/24/math417-32-rings.html"><![CDATA[<p>Let \(G\) be a group that acts on \(X\). Define
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A Ring: \(R, +, \cdot\) is a \(R\)-set with \(+, \cdot\) operations on \(R\) such that
<ul>
	<li>\(R, +\) is an abelian group with \(0\) as the identity and \(-a\) as the inverse of \(a \in R\).</li>
	<li>Multiplication is associative so \((ab)c = a(bc)\) for all \(a,b,c \in R\).</li>
	<li>Distributive Law: \((a + b)c = (ac) + (bc)\) and \((a(b + c) = (ab) + (ac)\).</li>
</ul>
</div>
<!----------------------------------------------------------------------------->
<p><br />
Warning: we don’t know if \(a + b \cdot c\) should be \((a + b) \cdot c\) or \(a + (b \cdot c)\). The convention is to use the second (operator precedence).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>More Terminology</b></h4>
<ul>
	<li><b>Ring with identity</b>: This means a rin with a multiplicative identity since a ring always has an additive identity but not necessarily a multiplicative identity. This is a ring \(R\) such that \(\exists 1 \in R\) so that \(1a = a1 = a\) for all \(a \in R\).</li>
	<!----->
	<li><b>Commutative Ring</b>: A ring \(R\) such that \(ab = ba\) for all \(a, b \in R\).</li>
	<!---->
	<li>If \(R\) has a multiplicative identity, then \(a \in R\) is a unit if there exists a \(b\) in \(R\) such that \(ab = 1 = ba\). We call \(b\) an inverse of \(a\) and write \(b = a^{-1}\). (So a unit is an element with a multiplicative inverse)</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Basic Facts in a Ring</b></h4>
<ol>
	<li>\(a0 = 0 = 0a\) for all \(a \in R\). To show this, use the distributive law to see that
		<div>
		$$
		\begin{align*}
		0a = (0 + 0)a = 0a + 0a. 
		\end{align*}
		$$
		</div>
	But \(R\) is abelian with respect to addition so we can cancel \(0a\) from both sides to see that \(0 = 0a\).</li>
	<!----->
	<li>If \(1 \in R\), then \(-a = (-1)a\). So this says the additive inverse is -1 multiplied by \(a\). To see why, observe that
		<div>
		$$
		\begin{align*}
		(1 + (-1))a &amp;= 1a + (-1)a \\
		     0a &amp;= 0.
		\end{align*}
		$$
		</div>
	  </li>
	  <!----->
	  <li>The multiplicative identity is unique if it exists.</li>
	  <!----->
	  <li>If \(1 \in R\) and \(a\) is unit in \(R\), then it has a unique inverse</li>
	  <!----->
	  <li>If \(1 \in R\), then define \((R^{\times},\cdot)\) as the set of units in \(R\) so \((R^{\times},\cdot) = \{\text{units }a \in R\}\). So this is set of the elements that have a multiplicative inverse. This set with the multiplication operation is a group. As a consequence, if \(a\) and \(b\) are units, then their product is in \(R^{\times}\). In fact, \((ab)^{-1} = b^{-1}a^{-1}\).</li>	  
</ol>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>The Zero Ring</b></h4>
<p>This is a ring \(R\) with element \(R = \{0\}\). \(0 + 0 = 0\) and \(0 \cdot 0 = 0\). This is a commutative ring with identity. The multiplicative identity is \(1 = 0\) in this ring. In fact, If \(R\) is a ring with 1, then \(1 = 0\) if and only if \(R = \{0\}\). Sometimes this ring is excluded from the definition of rings …
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Fields</b></h4>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A Field is a commutative ring with 1 such that every nonzero element is a unit and \(1 \neq 0\).
</div>
<p><br />
So we’re excluding the zero ring here.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<ul>
	<li>\(\mathbf{Z}\) with addition and multiplication is a commutative ring with identity.</li>
	<!----->
	<li>\(\mathbf{Z}2 = \{2n \ | \ n \in \mathbf{Z}\}\) is a commutative ring but it doesn't have the identity \(1 \not\in \mathbf{Z}2\).</li>
	<!---->
	<li>\(\mathbf{Q}, \mathbf{R}, \mathbf{C}\) are all fields.</li>
	<!---->
	<li>For \(n \geq 1\), \(\mathbf{Z}_n\) is a commutative ring with \(1 = [1]_n\). It is a field if and only if \(n\) is a prime.</li>
	<!---->
	<li>Let \(R\) be any ring. Then \(S = \text{Mat}_{n \times n}(R)\) the set of matrices with entries in \(R\) is 
	also a ring with matrix addition/multiplication.</li>
	    <ul>
	    <li>If \(1 \in R\) so \(R\) includes the multiplicative identity. Then, \(I \in S\).</li>
	    <li>If \(R\) is commutative. Then, \(S\) might not be commutative.</li>
	   </ul>
	<!---->
	<li>Rings of functions: if \(X\) is an arbitrary set and \(R\) is an arbitrary function, then \(F(X,R) = \{ \text{ all functions } \ | \ f: X \rightarrow R \ \}\) is a ring via a pointwise operation. What's a pointwise operation? Given two different functions \(f, g: X \rightarrow R\), then define 
		<div>
		$$
		\begin{align*}
		(f + g)(x) &amp;:= f(x) + g(x) \\
		(fg)(x) &amp;:= f(x)g(x) \quad \text{ for } x \in X
		\end{align*}
		$$
		</div>
	As long as the target is a ring this works. No restriction on \(X\).
	</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Subrings</b></h4>
<p>A subring \(S\) of ring \(R\) is a subset, which is a ring via operation inherited from \(R\). This implies that if \(a, b \in S\), then \(a + b, ab \in S\). To show \(S\) is a subring, we have the following proposition
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
\(R\) ring, a subset \(S \subseteq R\) is a subring if and only if
<ul>
	<li>\(0 \in S\) or \(S \neq \emptyset\).</li>
	<li>if \(a,b \in S\), then \(a + b, ab \in S\).</li>
	<li>If \(s \in S\) then \(-a \in S\).</li>
</ul>
</div>
<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<ul>
	<li>\(\mathbf{Z}\) is a ring and \(\mathbf{Z}2\) is a subring.</li>
	<!----->
	<li>\(\mathbf{Z} \subseteq \mathbf{Q} \subseteq \mathbf{R} \subseteq \mathbf{C}\) are subrings.</li>
	<!----->
	<li> \(R = \text{Mat}_{n \times n}(\mathbf{R})\) be the ring of 2 by 2 matrices with entries in \(\mathbf{R}\). Then, \(S = \big\{ \begin{pmatrix}a &amp; -b \\ b &amp; a \end{pmatrix} \big\}, a, b \in R\) is a subring. In fact, \(S \cong \mathbf{C}\) as rings</li>
</ul>
<p>Warning: we can have a subring \(S \subseteq R\) such that \(1_S \in S\) and \(1_R \in R\) but \(1_S \neq 1_S\).
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Complex Numbers</b></h4>
<p>One way to describe the complex numbers is to say that the elements of \(\mathbf{C}\) are “formal expressions” \(a + bi\) where \(a, b \in \mathbf{R}\) and \(i\) is a new symbol. We add in the usual way and when we multiply, we use the identity \(i^2 = -1\). 
<br />
<br />
Another way to describe the complex numbers is to say that the elements of \(C\) are vectors \((a,b)\) in \(\mathbf{R}^2\) where we have a special notation for \(1 = (1, 0)\) and \(i = (0, 1)\). Now, define \(+\) by vector addition and define \(\cdot\) by</p>
<div>
$$
\begin{align*}
(a, b) \cdot (a', b') = (aa' - bb', ab' + ba')
\end{align*}
$$
</div>
<p>In terms of the older notation where \((a,b) = a+bi\), it is</p>
<div>
$$
\begin{align*}
(a + bi)(a' + b'i) = (aa' - bb') + (ab' + ba')i
\end{align*}
$$
</div>
<p>\(\mathbf{C}\) is a commutative ring with 1. In fact, \(\mathbf{C}\) is a field. Why? because we have straight forward formula to finding the inverse. First observe what happens when we multiply by the complex conjugate</p>
<div>
$$
\begin{align*}
(a + bi)(a' - b'i) = (a^2 + b^2) + 0i.
\end{align*}
$$
</div>
<p>Fact: if \(a, b \in \mathbf{R}\) and \((a,b) \neq (0,0)\), then \(a^2 + b^2 &gt; 0\). From this we get the inverse formula</p>
<div>
$$
\begin{align*}
\frac{a}{a^2+b^2} + \frac{-b}{a^2+b^2}i = (a + bi)^{-1} 
\end{align*}
$$
</div>
<p>So every non-zero element has a multiplicative inverse and so it’s a field because we have this formula.
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Let \(R = \mathbf{Z}_3[i]\) is ring. This is the set of formal expressions \(a + bi\) where \(a, b \in \mathbf{Z}_3\). \(i\) is a symbol such that \(i^2 = [-1]_3 = -1\).
<br />
<br />
We can check very easily that \(R\) is a commutative ring with identity. Is \(R\) a field? It’s obvious but the answer is yes. So for any \(a, b \in \mathbf{Z}_3\) where \((a,b) \neq (0,0)\), then \(a^2 + b^2 \neq 0\). Why? observe that, \(0^2 = 0\), \(1^2 = 1\) but \(2^2 = 1\) in \(\mathbf{Z}_3\). So the only way to get \(a^2 + b^2 = 0\) is to have \(a = b = 0\). The formula for a multiplicative inverse is</p>
<div>
$$
\begin{align*}
(a + bi)^{-1} = \frac{a}{a^2+b^2} + \frac{-b}{a^2+b^2}i 
\end{align*}
$$
</div>
<p>Therefore, \(\mathbf{Z}_3[i]\) is a field with 9 elements. Call this \(\mathbf{F}_9\).
<br />
<br />
What about \(\mathbf{Z}_5[i]\)? is it a field? No. Because \((2 + i)\) doesn’t have a multiplicative in \(\mathbf{Z}_5[i]\). To see this, observe that</p>
<div>
$$
\begin{align*}
(2 + i) \cdot (2 - i) = 2^2 + i^2 + 5 = 0 
\end{align*}
$$
</div>
<p><br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Let \(G\) be a group that acts on \(X\). Define Definition A Ring: \(R, +, \cdot\) is a \(R\)-set with \(+, \cdot\) operations on \(R\) such that \(R, +\) is an abelian group with \(0\) as the identity and \(-a\) as the inverse of \(a \in R\). Multiplication is associative so \((ab)c = a(bc)\) for all \(a,b,c \in R\). Distributive Law: \((a + b)c = (ac) + (bc)\) and \((a(b + c) = (ab) + (ac)\). Warning: we don’t know if \(a + b \cdot c\) should be \((a + b) \cdot c\) or \(a + (b \cdot c)\). The convention is to use the second (operator precedence). More Terminology Ring with identity: This means a rin with a multiplicative identity since a ring always has an additive identity but not necessarily a multiplicative identity. This is a ring \(R\) such that \(\exists 1 \in R\) so that \(1a = a1 = a\) for all \(a \in R\). Commutative Ring: A ring \(R\) such that \(ab = ba\) for all \(a, b \in R\). If \(R\) has a multiplicative identity, then \(a \in R\) is a unit if there exists a \(b\) in \(R\) such that \(ab = 1 = ba\). We call \(b\) an inverse of \(a\) and write \(b = a^{-1}\). (So a unit is an element with a multiplicative inverse) Basic Facts in a Ring \(a0 = 0 = 0a\) for all \(a \in R\). To show this, use the distributive law to see that $$ \begin{align*} 0a = (0 + 0)a = 0a + 0a. \end{align*} $$ But \(R\) is abelian with respect to addition so we can cancel \(0a\) from both sides to see that \(0 = 0a\). If \(1 \in R\), then \(-a = (-1)a\). So this says the additive inverse is -1 multiplied by \(a\). To see why, observe that $$ \begin{align*} (1 + (-1))a &amp;= 1a + (-1)a \\ 0a &amp;= 0. \end{align*} $$ The multiplicative identity is unique if it exists. If \(1 \in R\) and \(a\) is unit in \(R\), then it has a unique inverse If \(1 \in R\), then define \((R^{\times},\cdot)\) as the set of units in \(R\) so \((R^{\times},\cdot) = \{\text{units }a \in R\}\). So this is set of the elements that have a multiplicative inverse. This set with the multiplication operation is a group. As a consequence, if \(a\) and \(b\) are units, then their product is in \(R^{\times}\). In fact, \((ab)^{-1} = b^{-1}a^{-1}\). The Zero Ring This is a ring \(R\) with element \(R = \{0\}\). \(0 + 0 = 0\) and \(0 \cdot 0 = 0\). This is a commutative ring with identity. The multiplicative identity is \(1 = 0\) in this ring. In fact, If \(R\) is a ring with 1, then \(1 = 0\) if and only if \(R = \{0\}\). Sometimes this ring is excluded from the definition of rings … Fields Definition A Field is a commutative ring with 1 such that every nonzero element is a unit and \(1 \neq 0\). So we’re excluding the zero ring here. Examples \(\mathbf{Z}\) with addition and multiplication is a commutative ring with identity. \(\mathbf{Z}2 = \{2n \ | \ n \in \mathbf{Z}\}\) is a commutative ring but it doesn't have the identity \(1 \not\in \mathbf{Z}2\). \(\mathbf{Q}, \mathbf{R}, \mathbf{C}\) are all fields. For \(n \geq 1\), \(\mathbf{Z}_n\) is a commutative ring with \(1 = [1]_n\). It is a field if and only if \(n\) is a prime. Let \(R\) be any ring. Then \(S = \text{Mat}_{n \times n}(R)\) the set of matrices with entries in \(R\) is also a ring with matrix addition/multiplication. If \(1 \in R\) so \(R\) includes the multiplicative identity. Then, \(I \in S\). If \(R\) is commutative. Then, \(S\) might not be commutative. Rings of functions: if \(X\) is an arbitrary set and \(R\) is an arbitrary function, then \(F(X,R) = \{ \text{ all functions } \ | \ f: X \rightarrow R \ \}\) is a ring via a pointwise operation. What's a pointwise operation? Given two different functions \(f, g: X \rightarrow R\), then define $$ \begin{align*} (f + g)(x) &amp;:= f(x) + g(x) \\ (fg)(x) &amp;:= f(x)g(x) \quad \text{ for } x \in X \end{align*} $$ As long as the target is a ring this works. No restriction on \(X\). Subrings A subring \(S\) of ring \(R\) is a subset, which is a ring via operation inherited from \(R\). This implies that if \(a, b \in S\), then \(a + b, ab \in S\). To show \(S\) is a subring, we have the following proposition Proposition \(R\) ring, a subset \(S \subseteq R\) is a subring if and only if \(0 \in S\) or \(S \neq \emptyset\). if \(a,b \in S\), then \(a + b, ab \in S\). If \(s \in S\) then \(-a \in S\). Examples \(\mathbf{Z}\) is a ring and \(\mathbf{Z}2\) is a subring. \(\mathbf{Z} \subseteq \mathbf{Q} \subseteq \mathbf{R} \subseteq \mathbf{C}\) are subrings. \(R = \text{Mat}_{n \times n}(\mathbf{R})\) be the ring of 2 by 2 matrices with entries in \(\mathbf{R}\). Then, \(S = \big\{ \begin{pmatrix}a &amp; -b \\ b &amp; a \end{pmatrix} \big\}, a, b \in R\) is a subring. In fact, \(S \cong \mathbf{C}\) as rings Warning: we can have a subring \(S \subseteq R\) such that \(1_S \in S\) and \(1_R \in R\) but \(1_S \neq 1_S\). Complex Numbers One way to describe the complex numbers is to say that the elements of \(\mathbf{C}\) are “formal expressions” \(a + bi\) where \(a, b \in \mathbf{R}\) and \(i\) is a new symbol. We add in the usual way and when we multiply, we use the identity \(i^2 = -1\). Another way to describe the complex numbers is to say that the elements of \(C\) are vectors \((a,b)\) in \(\mathbf{R}^2\) where we have a special notation for \(1 = (1, 0)\) and \(i = (0, 1)\). Now, define \(+\) by vector addition and define \(\cdot\) by $$ \begin{align*} (a, b) \cdot (a', b') = (aa' - bb', ab' + ba') \end{align*} $$ In terms of the older notation where \((a,b) = a+bi\), it is $$ \begin{align*} (a + bi)(a' + b'i) = (aa' - bb') + (ab' + ba')i \end{align*} $$ \(\mathbf{C}\) is a commutative ring with 1. In fact, \(\mathbf{C}\) is a field. Why? because we have straight forward formula to finding the inverse. First observe what happens when we multiply by the complex conjugate $$ \begin{align*} (a + bi)(a' - b'i) = (a^2 + b^2) + 0i. \end{align*} $$ Fact: if \(a, b \in \mathbf{R}\) and \((a,b) \neq (0,0)\), then \(a^2 + b^2 &gt; 0\). From this we get the inverse formula $$ \begin{align*} \frac{a}{a^2+b^2} + \frac{-b}{a^2+b^2}i = (a + bi)^{-1} \end{align*} $$ So every non-zero element has a multiplicative inverse and so it’s a field because we have this formula. Example Let \(R = \mathbf{Z}_3[i]\) is ring. This is the set of formal expressions \(a + bi\) where \(a, b \in \mathbf{Z}_3\). \(i\) is a symbol such that \(i^2 = [-1]_3 = -1\). We can check very easily that \(R\) is a commutative ring with identity. Is \(R\) a field? It’s obvious but the answer is yes. So for any \(a, b \in \mathbf{Z}_3\) where \((a,b) \neq (0,0)\), then \(a^2 + b^2 \neq 0\). Why? observe that, \(0^2 = 0\), \(1^2 = 1\) but \(2^2 = 1\) in \(\mathbf{Z}_3\). So the only way to get \(a^2 + b^2 = 0\) is to have \(a = b = 0\). The formula for a multiplicative inverse is $$ \begin{align*} (a + bi)^{-1} = \frac{a}{a^2+b^2} + \frac{-b}{a^2+b^2}i \end{align*} $$ Therefore, \(\mathbf{Z}_3[i]\) is a field with 9 elements. Call this \(\mathbf{F}_9\). What about \(\mathbf{Z}_5[i]\)? is it a field? No. Because \((2 + i)\) doesn’t have a multiplicative in \(\mathbf{Z}_5[i]\). To see this, observe that $$ \begin{align*} (2 + i) \cdot (2 - i) = 2^2 + i^2 + 5 = 0 \end{align*} $$ References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 31: Fixed Point Theorem and Cauchy Theorem</title><link href="http://localhost:4000/jekyll/update/2025/02/23/math417-31-fixed-point-theorem-cauchy-theorem.html" rel="alternate" type="text/html" title="Lecture 31: Fixed Point Theorem and Cauchy Theorem" /><published>2025-02-23T00:01:36-08:00</published><updated>2025-02-23T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/23/math417-31-fixed-point-theorem-cauchy-theorem</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/23/math417-31-fixed-point-theorem-cauchy-theorem.html"><![CDATA[<p>Let \(G\) be a group that acts on \(X\). Define
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Define \(X^G = \{x \in X \ | \ gx = x \text{ for all } g \in G\} \subseteq X \). This set is called the Fixed Point set of the action. 
</div>
<!----------------------------------------------------------------------------->
<p><br />
Compare this to the definition for any \(g \in G\), then.</p>
<div>
$$
\begin{align*}
\text{Fix}(g) = \{x \in X \ | \ gx = x\}
\end{align*}
$$
</div>
<p>So this is the set of elements fixed by \(g\) but what we defined above is the set of elements in \(X\) such that they’re always fixed by any \(g\). This means that we can re-write the definition to</p>
<div>
$$
\begin{align*}
X^G = \bigcap_{g \in G}\text{Fix}(g)
\end{align*}
$$
</div>
<!----------------------------------------------------------------------------->
<p>We can also describe this set another way. Recall that an element \(x\) is fixed by every element \(g \in G\) if and only if its orbit contains only the element \(x\) itself. So now we can re-write the definition to be</p>
<div>
$$
\begin{align*}
X^G = \{x \in X \ | \ O(x) = \{x\} \}
\end{align*}
$$
</div>
<!----------------------------------------------------------------------------->
<p>Recall now that \(\text{Stab}(x) = \{g \in G \ | \ gx = x\}\). So we can re-write this definition to say</p>
<div>
$$
\begin{align*}
X^G = \{x \in X \ | \ \text{Stab}(x) = G \}
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Fixed Point Theorem</b></h4>
<p>We’ll study one theorem about this. But first define
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Let \(p\) be a prime number. A \(p\)-group is a group of order \(p^k\) for some \(k \geq 1\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
For example \(\mathbf{Z}_{p^k}\) is a \(p\)-group. The cyclic group like \(\mathbf{Z}_{p^i} \times \mathbf{Z}_{p^j}\) is another \(p\)-group. Or the dihedral group \(D_{2^k}\) which has order \(2^{k+1}\) so this is a 2-group.
<br />
<!-----------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
Let \(G\) be \(p\)-group which acts on a finite set \(X\). Then \(|X^G| \equiv |X| (\bmod p)\)
</div>
<!----------------------------------------------------------------------------->
<p><br /></p>
<p>Proof</p>
<p>The idea is that since \(G\) acts on \(X\), then it partitions \(X\) into non-empty disjoint orbits. So we can write \(O_1,O_2,...O_r\) for the orbits of the action. Then</p>
<div>
$$
\begin{align*}
|X| = |O_1| + |O_2| + ... + |O_r|
\end{align*}
$$
</div>
<p>But we know that \(|G|=p^k\) and we also know that any orbit size must divide the group order. Therefore, \(|O_i| \in \{1,p,p^2,...p^k\}\). Break the orbits into two types. Let</p>
<div>
$$
\begin{align*}
O_1, O_2, ..., O_d
\end{align*}
$$
</div>
<p>be orbits of size 1 and let</p>
<div>
$$
\begin{align*}
O_{d+1}, O_{d+2}, ..., O_r
\end{align*}
$$
</div>
<p>be orbits of sizes \(p,p^2,...,p^k\) (so not 1). Then</p>
<div>
$$
\begin{align*}
|X| = (|O_1| + |O_2| + ... + |O_d|) + (|O_{d+1}| + |O_{d+2}| + ... + |O_{r}|)
\end{align*}
$$
</div>
<p>where \(|O_1| + |O_2| + ... + |O_d|=d\). More precisely, \(d\) is the number of elements that are in orbits of size 1. By definition, this is the fixed set of the action so \(|X^G| = d\). Furthermore, \(|O_{d+1}| + |O_{d+2}| + ... + |O_{r}|\) is a sum of terms \(p^i\). So this sum is divisible by \(p\). Therefore, it’s a multiple \(p\). More precisely, \(d\) is the number of elements that are in orbits of size 1. By definition, this is the fixed set of the action so \(|X^G| = d\). Thus</p>
<div>
$$
\begin{align*}
|X| &amp;= d + kp \\
|X| - d &amp;= kp \\
\end{align*}
$$
</div>
<p>Therefore,</p>
<div>
$$
\begin{align*}
|X| &amp;\equiv d (\bmod p) \\
|X| &amp;\equiv |X^G| (\bmod p) 
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Application of the Fixed Point Theorem</b></h4>
<p>Here are some application of this theorem
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(G\) be \(p\)-group. Then the center of the group \(Z(G) = \{ g \in G \ | \ gh = hg \text{ for all } h \in H\}\) is non-trivial so \(Z(G) \neq \{e\}\).
</div>
<!----------------------------------------------------------------------------->
<p><br /></p>
<p>Proof</p>
<p>Let \(G\) acts on \(X = G\) itself by conjugation. So we have \(c: G \rightarrow Sym(X)\). The fixed points of this action are</p>
<div>
$$
\begin{align*}
X^G &amp;= \{x \in X \ | \ gx = x \text{ for all } g \in G\} \\
 &amp;= \{x \in X \ | \ c(g)(x) = x \text{ for all } g \in G\} \quad \text{(the action is the conjugation action)} \\
&amp;= \{x \in X \ | gxg^{-1} = x \text{ for all } g \in G\} \\
&amp;= \{x \in X \ | gx = xg \text{ for all } g \in G\} 
\end{align*}
$$
</div>
<p>So in the conjugation action, the fixed point set is the center of the set. By the previous theorem we know that</p>
<div>
$$
\begin{align*}
|X^G| &amp;\equiv |X| (\bmod p) \\
|X^G| &amp;\equiv p^k (\bmod p) \quad \text{(order of $|G|$ is $p^k$)} \\
|X^G| &amp;\equiv 0 (\bmod p)  \quad \text{because ($p^k \equiv 0 (\bmod p)$)}\\
|Z(G)| &amp;\equiv 0 (\bmod p)  \quad \text{(we just showed this)}\\
\end{align*}
$$
</div>
<p>Therefore, \(Z(G) - 0 = pm\) for some \(m \in Z\). This means that \(p \ | \ Z(G)\). But \(Z(G)\) is a subgroup so it includes at least the identity element. So its size is at least 1. Therefore, \(|Z(G)| \geq p \geq 2\). So we must have at least one non-trivial element in the center. \(\ \blacksquare\)
<br />
<br />
So again, \(p-\)groups will always have a non-trivial center. Next, we have a corollary of this
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(p\) be a prime number. Then every group of order \(p^2\) is abelian.
</div>
<!----------------------------------------------------------------------------->
<p><br />
Using this, we can now use the elementary divisor theorem to classify these groups. In fact, \(G\) of order (p^2) is isomorphic to either \(\mathbf{Z}_{p^2}\) or \(\mathbf{Z}_p \times \mathbf{Z}_p\). 
<br />
<br />
<b>Proof</b>
Let \(|G| = p^2\). By the proposition, \(Z(G)\) is not trivial. But we also know that it is a subgroup. So its order must divide the order of the group. So its order must either be \(p\) or \(p^2\). If the order is \(p^2\), then every element commute with every other element so \(G\) must be abelian. 
<br />
<br />
When \(|Z(G)| = p\), recall that \(Z(G)\) is a normal subgroup in \(G\). Therefore, we can form the quotient group \(G/Z(G)\). The order of this quotient group is \(p^2/p = p\). But we also know that every group of prime order is cyclic so \(G/Z(G)\) is cyclic (any group of prime order is cyclic). By Homework 8, if we have a group \(G\) where its quotient group mod its center is cyclic (\(G/Z(G)\)), then \(G\) is abelian. So \(G\) is abelian in this case too. \(\ \blacksquare\). 
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Cauchy Theorem</b></h4>
<p>There is one more application of the fixed point theorem. 
<br />
<!-----------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
Let \(G\) be a finite group. If \(p\) is a prime number that divides \(|G|\), then \(G\) must have element of order \(p\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
A special case of this is the even-order theorem. As a reminder, let’s revisit this proof in terms of group actions before proving the actual theorem. 
<br />
<br />
<b>Proof (Even Order Theorem)</b>
<br />
Let \(|G| = n\) where \(n\) is even. Let \(C = \langle \varphi \rangle = \{e, \varphi\}\) be a cyclic group of order 2. Let \(C\) act on the set \(X = C\) which is the group itself. We know the identity elements acts as the identity function on \(X\). So we only have to define the action for \(\varphi\). So let’s define what \(\varphi(g)\) is for every element of the group. Let \(\varphi(g)\) be</p>
<div>
$$
\begin{align*}
\varphi(g) = g^{-1} \quad \text{for } g \in G
\end{align*}
$$
</div>
<p>This is in fact is a bijection. Note here, \(\varphi \circ \varphi = id\) so composing the action \(\varphi\) with itself gives us back the identity function. Now, \(C\) is a 2-group since its of order 2. So we can apply the fixed point theorem which states that</p>
<div>
$$
\begin{align*}
|X^C| &amp;\equiv |X| (\bmod 2) \\
|X^C| &amp;\equiv 2 (\bmod 2) \quad \text{(We know $|X| = 2$)}\\
|X^C| &amp;\equiv 0 (\bmod 2)
\end{align*}
$$
</div>
<p>So \(|X^C|\) must be even. \(X^C\) is the set of elements that are fixed by the action \(\varphi\) so</p>
<div>
$$
\begin{align*}
X^C &amp;= \{x \in X \ | \ \varphi(x) = x\} \\
    &amp;= \{x \in X \ | \ x^{-1} = x\} \\
	&amp;= \{x \in X \ | \ x^2 = e\}.
\end{align*}
$$
</div>
<p>So this group has an even number of elements and must at least include the identity element. Therefore, it must have at least one more non-trivial element of order 2. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------->
<b>Proof (Cauchy’s Theorem)</b>
<br />
Let \(G\) be a group of order \(n\). Suppose \(p\) is a prime number such that \(p \ | \ n\). Let \(C = \langle \varphi \rangle\) be a cyclic group of order \(p\). Let \(X\) be the set</p>
<div>
$$
\begin{align*}
X = \{(a_1,...,a_p) \in G^p \ | \ a_1,...a_p \in G, a_1a_2...a_p = e\}
\end{align*}
$$
</div>
<p>So it’s the set of all \(p\) tuples such that when we multiply any tuple’s elements, we get the identity. But we can re-write this as</p>
<div>
$$
\begin{align*}
a_p =  (a_1,a_2...a_{p-1})^{-1}
\end{align*}
$$
</div>
<p>So the last element \(a_p\) is the inverse of the previous elements all multiplied. So for any \(g\) to be in \(G^p\), we can pick \(p-1\) elements from \(G\) and then form the last element by taking their product and taking the inverse of that product. 
<br />
<br />
What is \(|X|\)? we have \(n\) choices for the first \(p-1\) elements but only 1 choice for the last element. This implies that \(|X| = n^{p-1}\). Moreover, by assumption we know that \(p\) divides \(|G|=n\). So \(n = pk\) for some \(k\). So we can write \(|X| = (pk)^{p-1}\). But \(p\) is prime so it’s at least 2. Therefore, \(p\) must divide \(|X|\) as well.
<br />
<br />
Now, let \(C\) act on \(X\). Define</p>
<div>
$$
\begin{align*}
\varphi \cdot (a_1,a_2,...,a_{p-1},a_p) = (a_p,a_1,...,a_{p-1})
\end{align*}
$$
</div>
<p>So the action permutes the elements cyclicly. We need to verify that the product is in \(X\). This means if we multiply the first \(p-1\) elements and take their inverse, we should get the last element. To show this notice that \((a_1,a_2,...,a_{p-1},a_p)\) is in \(X\) by assumption so we know that the product of the elements is \(e\). Now conjugate this product by \(a^{p}\) to see that</p>
<div>
$$
\begin{align*}
(a_1a_2...a_{p-1}a_p) &amp;= e \\
a_p(a_1a_2...a_{p-1}a_p)a_p^{-1} &amp;= a_pea_p^{-1} \\
a_pa_1a_2...a_{p-1} &amp;= e.
\end{align*}
$$
</div>
<p>So we can see that \(a_pa_1a_2...a_{p-1} \in X\) which is what we wanted to show. Additionally, if we apply \(\varphi\) \(p\) times, we will see that \(\varphi \circ \varphi \circ ... \varphi = id\) it will take us to the identity function or action. So this action or permutation has order \(p\). 
<br />
<br />
So now we have \(|G| = n\) and \(|X| = n^{p-1}\). We know \(p\) divides both. We can apply the fixed point theorem but what is \(X^C\)? By definition, it’s the set of elements fixed by any \(g \in \langle \varphi \rangle\). But since \(\langle \varphi \rangle\) is cyclic, then if an element gets fixed by \(\varphi\), it get fixed by any power of \(\varphi\). Therefore</p>
<div>
$$
\begin{align*}
X^C &amp;= \{x \in X \ | \ \varphi(x) = x\} \\
    &amp;= \{(a_1,...,a_p) \in G \ | \ a_1...a_p = e \text{ and } \varphi \cdot (a_1,...,a_p) = (a_1,...,a_p)\} \\
    &amp;= \{(a_1,...,a_p) \in G \ | \ a_1...a_p = e \text{ and }  (a_p,a_1...,a_{p-1}) = (a_1,a_2...,a_p)\}.
\end{align*}
$$
</div>
<p>This last condition says that \(a_p=a_1\), \(a_1=a_2\), … \(a_{p-1}=a_p\). This means that all the elements are the same. So we can write \(X^C\) as</p>
<div>
$$
\begin{align*}
X^C &amp;= \{ (a,a...,a) \ | \ a \in G, aa...a = a^p = e\}.
\end{align*}
$$
</div>
<p>Therefore, the size of this set, is the number of elements in \(G\) which have order \(p\). So</p>
<div>
$$
\begin{align*}
|X^C| &amp;= |\{ a \in G \ | \ a^p = e\}|.
\end{align*}
$$
</div>
<p>So \(X^C\) is the set of all elements such that \(a^p = e\). But we know that \(e^p = e\) so it must contain at least the identity element. Moreover, by the Fixed Point Theorem,</p>
<div>
$$
\begin{align*}
|X^C| &amp;\equiv |X| (\bmod p) \\
|X^C| &amp;\equiv 0 (\bmod p) \quad \text{(because $p \ | \ |X|$)}
\end{align*}
$$
</div>
<p>So \(|X^C|\) must be divisible by \(p\) and since \(|X^C| \geq 1\), then \(|X^C| \geq p\). But this means that \(G\) has at least one non-trivial element of order \(p\). \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Classification of Groups of Order 6</b></h4>
<p>We’ve seen before \(\mathbf{Z}_6 \cong \mathbf{Z}_2 \times \mathbf{Z}_3\) and we’ve also seen \(D_3 \cong S_3\). 
<br />
<br />
Suppose \(|G| = 6 = 2(3)\). These are prime factors, so we can use Cauchy’s Theorem twice to conclude that we must have an element of order 2 and another element of order 3. So let</p>
<div>
$$
\begin{align*}
A &amp;= \langle a \rangle \text{ where $|A| = 2$ } \\
N &amp;= \langle 3 \rangle \text{ where $|N| = 3$}
\end{align*}
$$
</div>
<p>This implies that</p>
<div>
$$
\begin{align*}
[G:N] = \frac{|G|}{|N|} = \frac{6}{3} = 2.
\end{align*}
$$
</div>
<p>But we’ve seen in one of the homeworks, that this implies that \(N\) is normal. We also know the following facts</p>
<ul>
	<li>\(N \cap A = \{e\}\) since elements of \(N\) have order 1 or 3 and elements of \(A\) have orders 1 and 2</li>
	<li>\(NA\) is a subgroup of \(G\) because one of the groups is normal by Corollary (26.4).</li>
	<li>By the Diamond Isomorphism Theorem, \(A/A \cap N \cong NA/N\). But since \(A \cap N = \{e\}\). Then \(A \cong NA/N\). This means that \(|NA|/|N| = |A|\). So \(|NA| = |A||N| = 6\)</li>
	<li>Since \(NA\) is a subgroup of size 6, then it's \(G\) so \(NA = G\)</li>
</ul>
<p>So we know 4 important things</p>
<ul>
	<li>\(A\) is a subgroup of \(G\).</li>
	<li>\(N\) is a normal subgroup of \(G\).</li>
	<li>\(G = NA\).</li>
	<li>\(A \cap N = \{e\}\).</li>
</ul>
<p>These are the 4 conditions so we can apply the the recognization theorem to conclude that there exists a homomorphism \(\gamma: A \rightarrow \text{Aut}(N)\) such that there is an isomorphism of groups</p>
<div>
$$
\begin{align*}
N \rtimes_{\gamma} A \cong G
\end{align*}
$$
</div>
<p>\(A\) is of order 2 so it must be isomorphic to \(\mathbf{Z}_2\). \(N\) is of order 3 so it’s isomorphic to \(\mathbf{Z}_3\). We know that \(\text{Aut}(\mathbf{Z}_3) \cong \Phi(3)\) But \(\Phi(3)\) is of order 2 so it’s isomorphic to \(\mathbf{Z}_2\). So how many homomorphisms can we have from \(A\) to \(\text{Aut}(N)\) if both groups are cyclic of order 2? There are only two choices.</p>
<ul>
	<li>The trivial homomorphism gives us the product group \(\mathbf{Z}_2 \times \mathbf{Z}_3\)</li>
	<li>The non-trivial homomorphism gives us the dihedral group \(D_3\).</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Study Notes on \(D_3\)</b></h4>
<p>How does the non-trivial homomorphism gives us the dihedral group? how does this happen? We have</p>
<ul>
	<li>\(N = \langle n \rangle \cong \mathbf{Z}_3\) where \(n^3 = e\).</li>
	<li>\(A = \langle a \rangle \cong \mathbf{Z}_2\) where \(a^2 = e\)</li>
</ul>
<p>Define</p>
<div>
	$$
	\begin{align*}
	\gamma: A &amp;\rightarrow \text{Aut}(\mathbf{Z}_3) \\
	\gamma(a) &amp;= \alpha \text{ where } \alpha(n) = n^{-1} \\
	\gamma(a)(n) &amp;= n^{-1}
	\end{align*}
	$$
</div>
<p>So the element \(a \in A\) acts on \(n \in N\) by inverting it. Observe that \(a^2 = e\) and \(\alpha^2 = (n^{-1})^{-1} = \text{id}\) so \(\gamma(\alpha^2) = \gamma(\alpha)^2\). So now multiplication in semi-direct groups is defined as</p>
<div>
	$$
	\begin{align*}
	(n^i, a^j)(n^k, a^l) = (n^i \cdot \gamma_{a^j}(n^k), a^{j}a^{j})
	\end{align*}
	$$
</div>
<p>\(a\) has order 2 so \(\gamma_{a^j}(n^k)\) is defined as</p>
<ul>
	<li>When \(j = 0\), then \(a^0 = 0\), then \(\gamma_{e} = id\).</li>
	<li>When \(j = 1\), then \(a^1 = a\), then \(\gamma_{a} = \alpha\) where \(\alpha(n) = n^{-k}\).</li>
</ul>
<p>So now if we apply the semidirect product multiplication, using the homomorphism we defined, we will see that for any \(a\), that we get the relationship \(ana^{-1} = n^{-1}\). 
<br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Classification of Groups of Order \(2p\)</b></h4>
<p>where \(p\) is an odd prime. We know two groups \(\mathbf{Z}_{2p} =\mathbf{Z}_{2} \times \mathbf{Z}_{p}\) and \(D_p\). 
<br />
<br />
Let \(|G| = 2p\). By Cauchy, \(2\) divides \(|G|\). Therefore, we have an element of order \(2\). From this, we get \(A = \langle a \rangle\) where \(|A| = 2\). We also have an element of order \(p\). From this we get \(N = \langle N \rangle\). Again, we will see that</p>
<div>
$$
\begin{align*}
[G:N] = \frac{|G|}{|N|} = \frac{2p}{p} = 2.
\end{align*}
$$
</div>
<p>Therefore \(N\) is normal. With a similar argument to the previous example. We will see that</p>
<ul>
	<li>\(A\) is a subgroup of \(G\).</li>
	<li>\(N\) is a normal subgroup of \(G\).</li>
	<li>\(G = NA\).</li>
	<li>\(A \cap N = \{e\}\).</li>
</ul>
<p>So we can use the recognization theorem again to conclude that there exists a homomorphism \(\gamma: A \rightarrow \text{Aut}(N)\) such that there is an isomorphism of groups</p>
<div>
$$
\begin{align*}
N \rtimes_{\gamma} A \cong G
\end{align*}
$$
</div>
<p>\(A\) is of order 2 so it must be isomorphic to \(\mathbf{Z}_2\). \(N\) is of order \(p\) so it’s isomorphic to \(\mathbf{Z}_p\) (cyclic). We know that \(\text{Aut}(\mathbf{Z}_p) \cong \Phi(p)\) where \(\Phi(p)\) is of order \(p-1\). So how many homomorphisms can we have from \(A\) to \(\text{Aut}(N)\).</p>
<ul>
	<li>The trivial homomorphism gives us the product group \(\mathbf{Z}_2 \times \mathbf{Z}_p\)</li>
	<li>The non-trivial homomorphism gives us the dihedral group \(D_p\).</li>
</ul>
<p><br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>Classification of Groups of Order \(pq\)</b></h4>
<p>\(p\) and \(q\) are distinct primes where \(p &gt; q\). So again we have \(|G|=pq\). By Cauchy, we have two cyclic subgroups such that</p>
<div>
$$
\begin{align*}
A &amp;= \langle a \rangle \text{ where $|A| = q$ } \\
N &amp;= \langle b \rangle \text{ where $|N| = p$}
\end{align*}
$$
</div>
<p>This implies that</p>
<div>
$$
\begin{align*}
[G:N] = \frac{|G|}{|N|} = q.
\end{align*}
$$
</div>
<p>\(q\) is the smallest prime dividing the order of \(|G|\). By some homework assignment that said that if we have a subgroup of order “the smallest prime dividing the order”, then this subgroup is normal. So now again,</p>
<ul>
	<li>\(A\) is a subgroup of \(G\).</li>
	<li>\(N\) is a normal subgroup of \(G\).</li>
	<li>\(G = NA\).</li>
	<li>\(A \cap N = \{e\}\) because \(p \neq q\).</li>
</ul>
<p>So we can use the recognization theorem AGAIN to conclude that there exists a homomorphism \(\gamma: A \rightarrow \text{Aut}(N)\) such that there is an isomorphism of groups</p>
<div>
$$
\begin{align*}
N \rtimes_{\gamma} A \cong G
\end{align*}
$$
</div>
<p>Where</p>
<div>
	$$
	\begin{align*}
	\gamma: A &amp;\rightarrow \text{Aut}(N) \\
	\gamma: \mathbf{Z}_p &amp;\rightarrow \Phi(p)
	\end{align*}
	$$
</div>
<p>There are two cases:</p>
<ul>
	<li>\(q \ \not\mid \ (p-1)\): In this case, the generator of the group \(A\)'s \(q\)th power has to go to the identity because \(q\) doesn't divide \(p - 1\) which is the order of \(\Phi(p)\). The only possible \(\gamma\) is \(\gamma(a) = e\) so send everything to the identity and we get the direct product \(\mathbf{Z}_p \times \mathbf{Z}_q\).</li>
	<li>\(q \ | \ (p-1)\): So we get the non-trivial homomorphism \(\gamma\). Because \(q \ (p-1)\) which is the order of \(\Phi(p-1)\), then by Cauchy there exists an element of order \(q\) in \(\Phi(p-1)\). So \(\mathbf{Z}_{pq}\) and another non abelian group.</li>
</ul>
<p><br />
<br /></p>
<hr />

<p><br />
<!-------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Let \(G\) be a group that acts on \(X\). Define Definition Define \(X^G = \{x \in X \ | \ gx = x \text{ for all } g \in G\} \subseteq X \). This set is called the Fixed Point set of the action. Compare this to the definition for any \(g \in G\), then. $$ \begin{align*} \text{Fix}(g) = \{x \in X \ | \ gx = x\} \end{align*} $$ So this is the set of elements fixed by \(g\) but what we defined above is the set of elements in \(X\) such that they’re always fixed by any \(g\). This means that we can re-write the definition to $$ \begin{align*} X^G = \bigcap_{g \in G}\text{Fix}(g) \end{align*} $$ We can also describe this set another way. Recall that an element \(x\) is fixed by every element \(g \in G\) if and only if its orbit contains only the element \(x\) itself. So now we can re-write the definition to be $$ \begin{align*} X^G = \{x \in X \ | \ O(x) = \{x\} \} \end{align*} $$ Recall now that \(\text{Stab}(x) = \{g \in G \ | \ gx = x\}\). So we can re-write this definition to say $$ \begin{align*} X^G = \{x \in X \ | \ \text{Stab}(x) = G \} \end{align*} $$ Fixed Point Theorem We’ll study one theorem about this. But first define Definition Let \(p\) be a prime number. A \(p\)-group is a group of order \(p^k\) for some \(k \geq 1\). For example \(\mathbf{Z}_{p^k}\) is a \(p\)-group. The cyclic group like \(\mathbf{Z}_{p^i} \times \mathbf{Z}_{p^j}\) is another \(p\)-group. Or the dihedral group \(D_{2^k}\) which has order \(2^{k+1}\) so this is a 2-group. Theorem Let \(G\) be \(p\)-group which acts on a finite set \(X\). Then \(|X^G| \equiv |X| (\bmod p)\) Proof The idea is that since \(G\) acts on \(X\), then it partitions \(X\) into non-empty disjoint orbits. So we can write \(O_1,O_2,...O_r\) for the orbits of the action. Then $$ \begin{align*} |X| = |O_1| + |O_2| + ... + |O_r| \end{align*} $$ But we know that \(|G|=p^k\) and we also know that any orbit size must divide the group order. Therefore, \(|O_i| \in \{1,p,p^2,...p^k\}\). Break the orbits into two types. Let $$ \begin{align*} O_1, O_2, ..., O_d \end{align*} $$ be orbits of size 1 and let $$ \begin{align*} O_{d+1}, O_{d+2}, ..., O_r \end{align*} $$ be orbits of sizes \(p,p^2,...,p^k\) (so not 1). Then $$ \begin{align*} |X| = (|O_1| + |O_2| + ... + |O_d|) + (|O_{d+1}| + |O_{d+2}| + ... + |O_{r}|) \end{align*} $$ where \(|O_1| + |O_2| + ... + |O_d|=d\). More precisely, \(d\) is the number of elements that are in orbits of size 1. By definition, this is the fixed set of the action so \(|X^G| = d\). Furthermore, \(|O_{d+1}| + |O_{d+2}| + ... + |O_{r}|\) is a sum of terms \(p^i\). So this sum is divisible by \(p\). Therefore, it’s a multiple \(p\). More precisely, \(d\) is the number of elements that are in orbits of size 1. By definition, this is the fixed set of the action so \(|X^G| = d\). Thus $$ \begin{align*} |X| &amp;= d + kp \\ |X| - d &amp;= kp \\ \end{align*} $$ Therefore, $$ \begin{align*} |X| &amp;\equiv d (\bmod p) \\ |X| &amp;\equiv |X^G| (\bmod p) \end{align*} $$ Application of the Fixed Point Theorem Here are some application of this theorem Proposition Let \(G\) be \(p\)-group. Then the center of the group \(Z(G) = \{ g \in G \ | \ gh = hg \text{ for all } h \in H\}\) is non-trivial so \(Z(G) \neq \{e\}\). Proof Let \(G\) acts on \(X = G\) itself by conjugation. So we have \(c: G \rightarrow Sym(X)\). The fixed points of this action are $$ \begin{align*} X^G &amp;= \{x \in X \ | \ gx = x \text{ for all } g \in G\} \\ &amp;= \{x \in X \ | \ c(g)(x) = x \text{ for all } g \in G\} \quad \text{(the action is the conjugation action)} \\ &amp;= \{x \in X \ | gxg^{-1} = x \text{ for all } g \in G\} \\ &amp;= \{x \in X \ | gx = xg \text{ for all } g \in G\} \end{align*} $$ So in the conjugation action, the fixed point set is the center of the set. By the previous theorem we know that $$ \begin{align*} |X^G| &amp;\equiv |X| (\bmod p) \\ |X^G| &amp;\equiv p^k (\bmod p) \quad \text{(order of $|G|$ is $p^k$)} \\ |X^G| &amp;\equiv 0 (\bmod p) \quad \text{because ($p^k \equiv 0 (\bmod p)$)}\\ |Z(G)| &amp;\equiv 0 (\bmod p) \quad \text{(we just showed this)}\\ \end{align*} $$ Therefore, \(Z(G) - 0 = pm\) for some \(m \in Z\). This means that \(p \ | \ Z(G)\). But \(Z(G)\) is a subgroup so it includes at least the identity element. So its size is at least 1. Therefore, \(|Z(G)| \geq p \geq 2\). So we must have at least one non-trivial element in the center. \(\ \blacksquare\) So again, \(p-\)groups will always have a non-trivial center. Next, we have a corollary of this Proposition Let \(p\) be a prime number. Then every group of order \(p^2\) is abelian. Using this, we can now use the elementary divisor theorem to classify these groups. In fact, \(G\) of order (p^2) is isomorphic to either \(\mathbf{Z}_{p^2}\) or \(\mathbf{Z}_p \times \mathbf{Z}_p\). Proof Let \(|G| = p^2\). By the proposition, \(Z(G)\) is not trivial. But we also know that it is a subgroup. So its order must divide the order of the group. So its order must either be \(p\) or \(p^2\). If the order is \(p^2\), then every element commute with every other element so \(G\) must be abelian. When \(|Z(G)| = p\), recall that \(Z(G)\) is a normal subgroup in \(G\). Therefore, we can form the quotient group \(G/Z(G)\). The order of this quotient group is \(p^2/p = p\). But we also know that every group of prime order is cyclic so \(G/Z(G)\) is cyclic (any group of prime order is cyclic). By Homework 8, if we have a group \(G\) where its quotient group mod its center is cyclic (\(G/Z(G)\)), then \(G\) is abelian. So \(G\) is abelian in this case too. \(\ \blacksquare\). Cauchy Theorem There is one more application of the fixed point theorem. Theorem Let \(G\) be a finite group. If \(p\) is a prime number that divides \(|G|\), then \(G\) must have element of order \(p\). A special case of this is the even-order theorem. As a reminder, let’s revisit this proof in terms of group actions before proving the actual theorem. Proof (Even Order Theorem) Let \(|G| = n\) where \(n\) is even. Let \(C = \langle \varphi \rangle = \{e, \varphi\}\) be a cyclic group of order 2. Let \(C\) act on the set \(X = C\) which is the group itself. We know the identity elements acts as the identity function on \(X\). So we only have to define the action for \(\varphi\). So let’s define what \(\varphi(g)\) is for every element of the group. Let \(\varphi(g)\) be $$ \begin{align*} \varphi(g) = g^{-1} \quad \text{for } g \in G \end{align*} $$ This is in fact is a bijection. Note here, \(\varphi \circ \varphi = id\) so composing the action \(\varphi\) with itself gives us back the identity function. Now, \(C\) is a 2-group since its of order 2. So we can apply the fixed point theorem which states that $$ \begin{align*} |X^C| &amp;\equiv |X| (\bmod 2) \\ |X^C| &amp;\equiv 2 (\bmod 2) \quad \text{(We know $|X| = 2$)}\\ |X^C| &amp;\equiv 0 (\bmod 2) \end{align*} $$ So \(|X^C|\) must be even. \(X^C\) is the set of elements that are fixed by the action \(\varphi\) so $$ \begin{align*} X^C &amp;= \{x \in X \ | \ \varphi(x) = x\} \\ &amp;= \{x \in X \ | \ x^{-1} = x\} \\ &amp;= \{x \in X \ | \ x^2 = e\}. \end{align*} $$ So this group has an even number of elements and must at least include the identity element. Therefore, it must have at least one more non-trivial element of order 2. \(\ \blacksquare\) Proof (Cauchy’s Theorem) Let \(G\) be a group of order \(n\). Suppose \(p\) is a prime number such that \(p \ | \ n\). Let \(C = \langle \varphi \rangle\) be a cyclic group of order \(p\). Let \(X\) be the set $$ \begin{align*} X = \{(a_1,...,a_p) \in G^p \ | \ a_1,...a_p \in G, a_1a_2...a_p = e\} \end{align*} $$ So it’s the set of all \(p\) tuples such that when we multiply any tuple’s elements, we get the identity. But we can re-write this as $$ \begin{align*} a_p = (a_1,a_2...a_{p-1})^{-1} \end{align*} $$ So the last element \(a_p\) is the inverse of the previous elements all multiplied. So for any \(g\) to be in \(G^p\), we can pick \(p-1\) elements from \(G\) and then form the last element by taking their product and taking the inverse of that product. What is \(|X|\)? we have \(n\) choices for the first \(p-1\) elements but only 1 choice for the last element. This implies that \(|X| = n^{p-1}\). Moreover, by assumption we know that \(p\) divides \(|G|=n\). So \(n = pk\) for some \(k\). So we can write \(|X| = (pk)^{p-1}\). But \(p\) is prime so it’s at least 2. Therefore, \(p\) must divide \(|X|\) as well. Now, let \(C\) act on \(X\). Define $$ \begin{align*} \varphi \cdot (a_1,a_2,...,a_{p-1},a_p) = (a_p,a_1,...,a_{p-1}) \end{align*} $$ So the action permutes the elements cyclicly. We need to verify that the product is in \(X\). This means if we multiply the first \(p-1\) elements and take their inverse, we should get the last element. To show this notice that \((a_1,a_2,...,a_{p-1},a_p)\) is in \(X\) by assumption so we know that the product of the elements is \(e\). Now conjugate this product by \(a^{p}\) to see that $$ \begin{align*} (a_1a_2...a_{p-1}a_p) &amp;= e \\ a_p(a_1a_2...a_{p-1}a_p)a_p^{-1} &amp;= a_pea_p^{-1} \\ a_pa_1a_2...a_{p-1} &amp;= e. \end{align*} $$ So we can see that \(a_pa_1a_2...a_{p-1} \in X\) which is what we wanted to show. Additionally, if we apply \(\varphi\) \(p\) times, we will see that \(\varphi \circ \varphi \circ ... \varphi = id\) it will take us to the identity function or action. So this action or permutation has order \(p\). So now we have \(|G| = n\) and \(|X| = n^{p-1}\). We know \(p\) divides both. We can apply the fixed point theorem but what is \(X^C\)? By definition, it’s the set of elements fixed by any \(g \in \langle \varphi \rangle\). But since \(\langle \varphi \rangle\) is cyclic, then if an element gets fixed by \(\varphi\), it get fixed by any power of \(\varphi\). Therefore $$ \begin{align*} X^C &amp;= \{x \in X \ | \ \varphi(x) = x\} \\ &amp;= \{(a_1,...,a_p) \in G \ | \ a_1...a_p = e \text{ and } \varphi \cdot (a_1,...,a_p) = (a_1,...,a_p)\} \\ &amp;= \{(a_1,...,a_p) \in G \ | \ a_1...a_p = e \text{ and } (a_p,a_1...,a_{p-1}) = (a_1,a_2...,a_p)\}. \end{align*} $$ This last condition says that \(a_p=a_1\), \(a_1=a_2\), … \(a_{p-1}=a_p\). This means that all the elements are the same. So we can write \(X^C\) as $$ \begin{align*} X^C &amp;= \{ (a,a...,a) \ | \ a \in G, aa...a = a^p = e\}. \end{align*} $$ Therefore, the size of this set, is the number of elements in \(G\) which have order \(p\). So $$ \begin{align*} |X^C| &amp;= |\{ a \in G \ | \ a^p = e\}|. \end{align*} $$ So \(X^C\) is the set of all elements such that \(a^p = e\). But we know that \(e^p = e\) so it must contain at least the identity element. Moreover, by the Fixed Point Theorem, $$ \begin{align*} |X^C| &amp;\equiv |X| (\bmod p) \\ |X^C| &amp;\equiv 0 (\bmod p) \quad \text{(because $p \ | \ |X|$)} \end{align*} $$ So \(|X^C|\) must be divisible by \(p\) and since \(|X^C| \geq 1\), then \(|X^C| \geq p\). But this means that \(G\) has at least one non-trivial element of order \(p\). \(\ \blacksquare\) Classification of Groups of Order 6 We’ve seen before \(\mathbf{Z}_6 \cong \mathbf{Z}_2 \times \mathbf{Z}_3\) and we’ve also seen \(D_3 \cong S_3\). Suppose \(|G| = 6 = 2(3)\). These are prime factors, so we can use Cauchy’s Theorem twice to conclude that we must have an element of order 2 and another element of order 3. So let $$ \begin{align*} A &amp;= \langle a \rangle \text{ where $|A| = 2$ } \\ N &amp;= \langle 3 \rangle \text{ where $|N| = 3$} \end{align*} $$ This implies that $$ \begin{align*} [G:N] = \frac{|G|}{|N|} = \frac{6}{3} = 2. \end{align*} $$ But we’ve seen in one of the homeworks, that this implies that \(N\) is normal. We also know the following facts \(N \cap A = \{e\}\) since elements of \(N\) have order 1 or 3 and elements of \(A\) have orders 1 and 2 \(NA\) is a subgroup of \(G\) because one of the groups is normal by Corollary (26.4). By the Diamond Isomorphism Theorem, \(A/A \cap N \cong NA/N\). But since \(A \cap N = \{e\}\). Then \(A \cong NA/N\). This means that \(|NA|/|N| = |A|\). So \(|NA| = |A||N| = 6\) Since \(NA\) is a subgroup of size 6, then it's \(G\) so \(NA = G\) So we know 4 important things \(A\) is a subgroup of \(G\). \(N\) is a normal subgroup of \(G\). \(G = NA\). \(A \cap N = \{e\}\). These are the 4 conditions so we can apply the the recognization theorem to conclude that there exists a homomorphism \(\gamma: A \rightarrow \text{Aut}(N)\) such that there is an isomorphism of groups $$ \begin{align*} N \rtimes_{\gamma} A \cong G \end{align*} $$ \(A\) is of order 2 so it must be isomorphic to \(\mathbf{Z}_2\). \(N\) is of order 3 so it’s isomorphic to \(\mathbf{Z}_3\). We know that \(\text{Aut}(\mathbf{Z}_3) \cong \Phi(3)\) But \(\Phi(3)\) is of order 2 so it’s isomorphic to \(\mathbf{Z}_2\). So how many homomorphisms can we have from \(A\) to \(\text{Aut}(N)\) if both groups are cyclic of order 2? There are only two choices. The trivial homomorphism gives us the product group \(\mathbf{Z}_2 \times \mathbf{Z}_3\) The non-trivial homomorphism gives us the dihedral group \(D_3\). Study Notes on \(D_3\) How does the non-trivial homomorphism gives us the dihedral group? how does this happen? We have \(N = \langle n \rangle \cong \mathbf{Z}_3\) where \(n^3 = e\). \(A = \langle a \rangle \cong \mathbf{Z}_2\) where \(a^2 = e\) Define $$ \begin{align*} \gamma: A &amp;\rightarrow \text{Aut}(\mathbf{Z}_3) \\ \gamma(a) &amp;= \alpha \text{ where } \alpha(n) = n^{-1} \\ \gamma(a)(n) &amp;= n^{-1} \end{align*} $$ So the element \(a \in A\) acts on \(n \in N\) by inverting it. Observe that \(a^2 = e\) and \(\alpha^2 = (n^{-1})^{-1} = \text{id}\) so \(\gamma(\alpha^2) = \gamma(\alpha)^2\). So now multiplication in semi-direct groups is defined as $$ \begin{align*} (n^i, a^j)(n^k, a^l) = (n^i \cdot \gamma_{a^j}(n^k), a^{j}a^{j}) \end{align*} $$ \(a\) has order 2 so \(\gamma_{a^j}(n^k)\) is defined as When \(j = 0\), then \(a^0 = 0\), then \(\gamma_{e} = id\). When \(j = 1\), then \(a^1 = a\), then \(\gamma_{a} = \alpha\) where \(\alpha(n) = n^{-k}\). So now if we apply the semidirect product multiplication, using the homomorphism we defined, we will see that for any \(a\), that we get the relationship \(ana^{-1} = n^{-1}\). Classification of Groups of Order \(2p\) where \(p\) is an odd prime. We know two groups \(\mathbf{Z}_{2p} =\mathbf{Z}_{2} \times \mathbf{Z}_{p}\) and \(D_p\). Let \(|G| = 2p\). By Cauchy, \(2\) divides \(|G|\). Therefore, we have an element of order \(2\). From this, we get \(A = \langle a \rangle\) where \(|A| = 2\). We also have an element of order \(p\). From this we get \(N = \langle N \rangle\). Again, we will see that $$ \begin{align*} [G:N] = \frac{|G|}{|N|} = \frac{2p}{p} = 2. \end{align*} $$ Therefore \(N\) is normal. With a similar argument to the previous example. We will see that \(A\) is a subgroup of \(G\). \(N\) is a normal subgroup of \(G\). \(G = NA\). \(A \cap N = \{e\}\). So we can use the recognization theorem again to conclude that there exists a homomorphism \(\gamma: A \rightarrow \text{Aut}(N)\) such that there is an isomorphism of groups $$ \begin{align*} N \rtimes_{\gamma} A \cong G \end{align*} $$ \(A\) is of order 2 so it must be isomorphic to \(\mathbf{Z}_2\). \(N\) is of order \(p\) so it’s isomorphic to \(\mathbf{Z}_p\) (cyclic). We know that \(\text{Aut}(\mathbf{Z}_p) \cong \Phi(p)\) where \(\Phi(p)\) is of order \(p-1\). So how many homomorphisms can we have from \(A\) to \(\text{Aut}(N)\). The trivial homomorphism gives us the product group \(\mathbf{Z}_2 \times \mathbf{Z}_p\) The non-trivial homomorphism gives us the dihedral group \(D_p\). Classification of Groups of Order \(pq\) \(p\) and \(q\) are distinct primes where \(p &gt; q\). So again we have \(|G|=pq\). By Cauchy, we have two cyclic subgroups such that $$ \begin{align*} A &amp;= \langle a \rangle \text{ where $|A| = q$ } \\ N &amp;= \langle b \rangle \text{ where $|N| = p$} \end{align*} $$ This implies that $$ \begin{align*} [G:N] = \frac{|G|}{|N|} = q. \end{align*} $$ \(q\) is the smallest prime dividing the order of \(|G|\). By some homework assignment that said that if we have a subgroup of order “the smallest prime dividing the order”, then this subgroup is normal. So now again, \(A\) is a subgroup of \(G\). \(N\) is a normal subgroup of \(G\). \(G = NA\). \(A \cap N = \{e\}\) because \(p \neq q\). So we can use the recognization theorem AGAIN to conclude that there exists a homomorphism \(\gamma: A \rightarrow \text{Aut}(N)\) such that there is an isomorphism of groups $$ \begin{align*} N \rtimes_{\gamma} A \cong G \end{align*} $$ Where $$ \begin{align*} \gamma: A &amp;\rightarrow \text{Aut}(N) \\ \gamma: \mathbf{Z}_p &amp;\rightarrow \Phi(p) \end{align*} $$ There are two cases: \(q \ \not\mid \ (p-1)\): In this case, the generator of the group \(A\)'s \(q\)th power has to go to the identity because \(q\) doesn't divide \(p - 1\) which is the order of \(\Phi(p)\). The only possible \(\gamma\) is \(\gamma(a) = e\) so send everything to the identity and we get the direct product \(\mathbf{Z}_p \times \mathbf{Z}_q\). \(q \ | \ (p-1)\): So we get the non-trivial homomorphism \(\gamma\). Because \(q \ (p-1)\) which is the order of \(\Phi(p-1)\), then by Cauchy there exists an element of order \(q\) in \(\Phi(p-1)\). So \(\mathbf{Z}_{pq}\) and another non abelian group. References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry></feed>
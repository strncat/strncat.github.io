<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="nemo&apos;s notebook" />
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">nemo&#39;s notebook</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
  
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Lecture 31/32: Orthonormal Sets, Gram Schmidt and Vector Decomposition</h1>
    <!--
    <p class="post-meta">
      <time class="dt-published" datetime="2024-09-01T01:01:36-07:00" itemprop="datePublished">Sep 1, 2024
      </time></p>
     -->
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div class="bdiv">
Definition
</div>
<div class="bbdiv">
<ul>
	<li>\(x, y \in V\) are orthogonal (perpendicular) if \(\langle x, y \rangle = 0\)</li>
	<li>\(S \in V\) is orthogonal if for any \(x, y\) distinct in \(S\), \(\langle x, y \rangle = 0\)</li>
	<li>\(S \subset V\) is orthonormal if it is orthogonal and for each \(x \in S, \Vert x \Vert = 1\)</li>
</ul>
</div>
<p><br />
Remark: \(x \in V\) is a unit vector if \(\Vert x \Vert = 1\). If \(x \neq \bar{0}_V\), then \(\frac{x}{\Vert x \Vert}\) is a unit vector. This process is normalization.
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 1</b></h4>
<div> 
$$
\begin{align*}
V = C^0([0,1]), \langle f,g \rangle = \int_0^1 f(t)g(t)dt
\end{align*}
$$
</div>
<p>Show \(\sin(2\pi t)\) and \(\cos(2\pi t)\) are orthogonal. To do this, we’ll compute their inner product.</p>
<div> 
$$
\begin{align*}
\langle \sin(2\pi t), \cos(2\pi t) \rangle &amp;= \int_0^1 \sin(2\pi t) \cos(2\pi t) \\
                                           &amp;= \frac{\sin^2 2 \pi t}{4\pi} \Big|^1_0 = 0
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 2</b></h4>
<p>The standard basis \(\beta = \{e_1, e_2, ..., e_n \}\) of \(\mathbf{R}^n\) is an orthonormal subset. For every distinct two vectors in \(\beta\), their inner product is zero. Moreover, for any vector \(e_i \in \beta\), \(\langle e_i, e_i \rangle = 1\). In general,</p>
<div> 
$$
\begin{align*}
\langle e_i, e_j \rangle &amp;= \delta_{ij} = \begin{cases} 1 \quad \text{if } i = j \\ 0 \quad \text{if } i \neq j\end{cases}\\
\end{align*}
$$
</div>
<p>In general, if \(\{v_1,...,v_k\}\) is orthonormal, then \(\langle v_i, v_j \rangle = \delta_{ij}\). The next theorem tells us why orthonormal sets are useful.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="purdiv">
Theorem (Corollary 1 of Theorem 6.3 in the book)
</div>
<div class="purbdiv">
Suppose \(S = \{v_1,...,v_k\} \subseteq V\) is orthonormal. If \(y \in span(S)\), then
$$
\begin{align*}
y = \sum_{j=1}^k \langle y, v_j \rangle v_j
\end{align*}
$$
</div>
<p><br />
So we don’t need to solve a system of linear equations to figure out the coefficients if \(y\) written with respect to \(S\). 
<br />
<br />
<!------------------------------------------------------------------------------------>
<b>Proof</b>:
<br />
<br />
We know that \(y \in span(S)\) Therefore, we can write \(y\) as</p>
<div>
$$
\begin{align*}
y = \sum_{j=1}^k a_j v_j
\end{align*}
$$
</div>
<p>for scalars \(a_1,...,a_k\). We also know that the \(S\) is an orthonormal set. Taking the inner product of both sides with respect to one vector from \(S\), we see that</p>
<div>
$$
\begin{align*}
\langle y, v_i \rangle &amp;= \langle \sum_{j=1}^k a_j v_j, v_i \rangle \text{ for all $i = 1,...,k$} \\
 &amp;= \sum_{j=1}^k a_j \langle v_j, v_i \rangle \text{ (the inner product is linear in its first argument)} \\
 &amp;= \sum_{j=1}^k a_j \delta_{ij} \\
 &amp;= a_i \text{ ($\delta_{ij}$ is 1 only for $i = j$)}
\end{align*}
$$
</div>
<p>Therefore,</p>
<div>
$$
\begin{align*}
y = \sum_{j=1}^k \langle y, v_j \rangle v_j. \quad \blacksquare
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------>
What about orthogonal subsets, can we say anything about them? Yes!
<br />
<br /></p>
<div class="purdiv">
Corollary 1 (Theorem 6.3 in the book)
</div>
<div class="purbdiv">
If \(S = \{v_1,...,v_k\} \subseteq V\) is orthogonal and \(\bar{0} \notin S\). If \(y \in span(S)\), then
$$
\begin{align*}
y = \sum_{j=1}^k \frac{\langle y, v_j \rangle}{\Vert v_j \Vert^2 } v_j
\end{align*}
$$
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>:
<br />
<br />
If \(S = \{v_1,...,v_k\}\) is orthogonal. We can turn this set into an orthonormal set by normalizing the set so</p>
<div>
$$
\begin{align*}
\{\frac{v_1}{\Vert v_1 \Vert^2},...,\frac{v_k}{\Vert v_k \Vert^2}\}
\end{align*}
$$
</div>
<p>By the previous theorem, then</p>
<div>
$$
\begin{align*}
y &amp;= \sum_{j=1}^k \langle y, \frac{v_j}{\Vert v_j \Vert }\rangle \frac{v_j}{\Vert v_j \Vert}  \\
  &amp;= \sum_{j=1}^k \frac{\langle y, v_j \rangle}{\Vert v_j \Vert^2 } v_j. \quad \blacksquare
\end{align*}
$$
</div>
<!--------------------------------------------------------------------------------->
<div class="purdiv">
Corollary 2
</div>
<div class="purbdiv">
If \(S = \{v_1,...,v_k\} \subseteq V\) is orthogonal and \(\bar{0} \notin S\), then \(S\) is linearly independent. 
</div>
<p><br />
<br />
<b>Proof:</b>
To see that it’s linearly independent, then the only solution to the equation</p>
<div>
	$$
	\begin{align*}
	a_1v_1 + ... + a_kv_k = \bar{0}_V
	\end{align*}
	$$
</div>
<p>is the trivial solution. But by corollary 1, if \(\bar{0}_V \in span(S)\), then we know the coefficients when it’s written relative to (S). Specifically the \(j\)’s coefficient is</p>
<div>
	$$
	\begin{align*}
	a_j = \frac{\langle \bar{0}_V, v_j \rangle}{\Vert v_j \Vert^2} = 0. \quad \blacksquare
	\end{align*}
	$$
</div>
<p><br />
<!---------------------------------------------------------------------------------></p>
<div class="purdiv">
Theorem
</div>
<div class="purbdiv">
If \(V\) is finite dimensional inner product space, then it has an orthonormal basis.
</div>
<p><br />
<br />
This will follow from the procedure we will study next …
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Gram-Schmidt Process</b></h4>
<div class="purdiv">
Theorem
</div>
<div class="purbdiv">
Let \(\{w_1,...,w_k\}\) be a linearly independent subset of \(V\). Set 
	$$
	\begin{align*}
	u_1 &amp;= \frac{w_1}{\Vert w_1 \Vert} \\
	u_2 &amp;= \frac{w_2 - \langle w_2, u_1 \rangle}{\Vert w_2 - \langle w_2, u_1 \rangle \Vert} \\
	&amp;\vdots \\
	u_k &amp;= \frac{w_k - \sum_{j=1}^{k-1} \langle w_k, u_j \rangle u_j}{\Vert w_k - \sum_{j=1}^{k-1} \langle w_k, u_j \rangle u_j \Vert}
	\end{align*}
	$$
Then \(\{u_1,...,u_k\}\) is orthonormal and has same span as \(\{w_1,...,w_k\}\).
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<b>Proof</b>
<br />
<br />
The basic idea of the proof (by induction) is that given \(\{w_1,...,w_k\}\) is linearly independent and given than \(\{u_1, u_2\}\) is orthonormal with the same span as \(\{w_1, w_2\}\), we want \(u_3\) such that \(\{u_1, u_2, u_3\}\) is orthonormal and \(span(\{u_1, u_2, u_3\}) = span(\{w_1,w_2,w_3\})\)
<br />
<br />
To show that the two spans are the same, it suffices to show that \(w_3 \in span(\{u_1, u_2, u_3\})\). In this case, we know by the theorem above what the coefficients should be:</p>
<div>
	$$
	\begin{align*}
	w_3 = \langle w_3, u_1 \rangle u_1 + \langle w_3, u_2 \rangle u_2 + \langle w_3, u_3 \rangle u_3
	\end{align*}
	$$
</div>
<p>Therefore, we can use the above equation to solve for \(u_3\). But we don’t want to divide by \(\langle w_3, u_3 \rangle\) since we’re trying to solve for \(u_3\) so we can think of this term as a constant we’re multiplying with:</p>
<div>
	$$
	\begin{align*}
	u_3 = c( w_3 - \langle w_3, u_1 \rangle u_1 - \langle w_3, u_2 \rangle u_2  )
	\end{align*}
	$$
</div>
<p>But we know we want \(u_3\) to be a unit vector. So we can just divide by the length of it.</p>
<div>
	$$
	\begin{align*}
	u_3 = \frac{w_3 - \langle w_3, u_1 \rangle u_1 - \langle w_3, u_2 \rangle u_2}{w_3 - \langle w_3, u_1 \rangle u_1 - \langle w_3, u_2 \rangle u_2 \Vert}
	\end{align*}
	$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 3</b></h4>
<p>Find an orthonormal basis for \(P_2 \in C^0([-1, 1])\). equipped with</p>
<div>
	$$
	\begin{align*}
	\langle f, g \rangle = \int_{-1}^{1} f(x)g(x) dx
	\end{align*}
	$$
</div>
<p>Choose \(\{1, x, x^2\}\). Apply Gram-Schmidt. So</p>
<div>
	$$
	\begin{align*}
	\Vert 1\Vert^2 &amp;= \langle 1, 1 \rangle = \int_{-1}^{1} 1dx = 2 \\
	u_1 &amp;= \frac{1}{\Vert 1\Vert} = \frac{1}{\sqrt{2}}
	\end{align*}
	$$
</div>
<p>Next, we’ll find \(u_2\)</p>
<div>
	$$
	\begin{align*}
	\Vert w_2 \Vert^2 &amp;= \langle x, x \rangle = \int_{-1}^{1} x^2 dx = \frac{x^2}{3} \Big|^1_{-1} = \frac{2}{3} \\
	\langle w_2, u_1 \rangle &amp;=  \int_{-1}^{1} x\frac{1}{\sqrt{2}} dx = 0 \\
	u_2 &amp;= \frac{w_2 - \langle w_2, u_1 \rangle u_1}{\Vert w_2 - \langle w_2, u_1 \rangle u_1 \Vert} = \frac{\sqrt{3}}{\sqrt{2}}x
	\end{align*}
	$$
</div>
<p>And finally \(u_3\)</p>
<div>
	$$
	\begin{align*}
	u_3 &amp;= \frac{w_3 - \langle w_3, u_2 \rangle u_2 - \langle w_3, u_1 \rangle u_1}{\Vert w_3 - \langle w_3, u_2 \rangle u_2 - \langle w_3, u_1 \rangle u_1 \Vert}
	\\
	&amp;= \sqrt{\frac{5}{8}}(3x^2 - 1)
	\end{align*}
	$$
</div>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Fourier coefficients</b></h4>
<p>The coefficients with respect to an orthonormal spanning set that we studied last time have a special name:
<br /></p>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Let \(S \subseteq V\) be an (possibly infinite) orthonormal subset. The scalars \(\langle x, u\rangle\) for \(u \in S\) are called the Fourier coefficients of \(x\) with respect to \(S\).
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 1</b></h4>
<div> 
$$
\begin{align*}
V &amp;= C^0([-1,1]), \langle f,g \rangle = \int_{-1}^1 f(t)g(t)dt \\
S &amp;= \big\{\frac{1}{\sqrt{2}}\big\} \cup \{\sin n \pi t\}_{n=1}^{\infty} \cup \{\cos n \pi t \}_{n=1}^{\infty}
\end{align*}
$$
</div>
<p>We can easily check that \(S\) is an orthonormal set. Each of the two vectors is orthogonal to each other and each vector is of unit length. Find the Fourier coefficients of \(f = |t| \in C^0([-1,1])\)</p>
<div> 
$$
\begin{align*}
\langle f, \frac{1}{\sqrt{2}} \rangle &amp;= \int_{-1}^1 \frac{1}{\sqrt{2}} |t| dt = \frac{1}{\sqrt{2}} \\
\langle f, \sin n \pi t \rangle &amp;= \int_{-1}^1 \sin n \pi t |t| dt = 0 \\
\langle f, \cos n \pi t \rangle &amp;= \int_{-1}^1 \cos n \pi t |t| dt = 
\begin{cases} 0 \quad \ \ \quad \text{if $n$ even } \\ \frac{-4}{(n\pi)^2} \quad \text{if $n$ odd } \end{cases}
\end{align*}
$$
</div>
<p>When \(S = \{u_1,...,u_k\}\) is finite, then we can write</p>
<div> 
$$
\begin{align*}
x = \sum_{j=1}^{k} \langle x, u_j \rangle u_j
\end{align*}
$$
</div>
<p>But now in the infinite case, Is</p>
<div> 
$$
\begin{align*}
|t| = \frac{1}{2} = \sum_{n\text{ odd}} \frac{-4}{(n\pi)^2} \cos n \pi t
\end{align*}
$$
</div>
<p>Yes it is true but this is an infinite sum that converges to a number that is the absolute value of \(t\). This is basically the beginning of studying Fourier Analysis where any sufficiently nice function can be written as an infinite sum of sines and cosines. 
<br />
<br />
But one thing we know here is that \(S\) is not a basis for \(C^0[-1,1]\). \(|t| \neq\) finite set of elements of \(S\).
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li>Math416 by Ely Kerman</li>
</ul>


  </div><div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = /jekyll/update/2024/09/01/lec31-orthonormal-orthogonal-sets.html;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier =  /jekyll/update/2024/09/01/lec31-orthonormal-orthogonal-sets; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://strncat-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a class="u-url" href="/jekyll/update/2024/09/01/lec31-orthonormal-orthogonal-sets.html" hidden></a>
</article>
		 
      </div>
    </main>

    <!--<footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">nemo&#39;s notebook</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">nemo&#39;s notebook</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>personal study notes</p>
      </div>
    </div>

  </div>

</footer>
-->

	
  </body>

</html>

<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" href="/assets/main.css">
  
  <!-- <link rel="stylesheet" href="/assets/tufte.css"> -->

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not--><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="strncat&apos;s notebook" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>


</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">strncat&#39;s notebook</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">about</a></div>
      </nav></div>
  
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Random Variables</h1>
    <!--
    <p class="post-meta">
      <time class="dt-published" datetime="2019-07-26T07:01:36-07:00" itemprop="datePublished">Jul 26, 2019
      </time></p>
     -->
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h4><b>What is a Random Variable?</b></h4>
<p>A random variable is a real-valued function defined on a sample space. Why define a random variable? sometimes instead of being interested in the individual outcomes of an experiment, we are interested in some groups of the outcomes or more formally some <b>function of the outcome</b>. 
<br />
<br />
<b>Example 1:</b>
<br /> 
Suppose we’re interested in <i>counting</i> the number of heads in \(5\) trials of flipping a coin. We can define a random variable \(Y\) to represent the number of heads in 5 trials. Using \(Y\), we can now refer to the probability of seeing two heads in 5 trials as \(P(Y=2)\). This is much simpler that listing the exact outcomes that we’re interested in. (\(\{H,H,T,T,T\},\{H,T,H,T,T\},...\}\)).
<br />
<br />
<b>Example 2:</b>
<br /> 
Suppose we roll two dice and we’re interested in the sum of the two dice. We define a random variable \(X\) to be the sum of two dice (function of outcomes). We can now refer to the probability that the sum of the dice is 7 as \(P(X=7)\). This is much simpler that saying that we want the probability of seeing any of these outcomes: \((3,4),(4,3),(2,5),(5,2),(1,6),(6,1)\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Discrete Random Variables</b></h4>
<p>If our random variable takes on countable values \(x_1, x_2, x_3,...,x_n\), we call it a discrete random variable. 
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Probability Mass Function</b></h4>
<p>Suppose we have a random variable \(X\) that takes on a discrete values in \(R_X = \{k_1, k_2,...,k_n\}\). Define the probability mass function \(p_X(k)\) to be the probability that \(X\) takes on a particular value \(k\). In other words, the PMF is defined as</p>
<div center="">
$$
\begin{align*}
p_X(k) = P(X = k)
\end{align*}
$$
</div>
<p>Furthermore, the PMF of \(X\) satisfies</p>
<div center="">
$$
\begin{align*}
\sum_{i=1}^{\infty} p_X(k_i) = 1
\end{align*}
$$
</div>
<p>This also means that for any value \(k\) that is not in \(R_X\), we have \(p_X(k) = 0\),</p>
<div center="">
$$
\begin{align*}
 P(X=k) = \Big\{ \begin{array}{@{}lr@{}}
        p_X(k) \quad \text{ for } k \in R_X \\
        0 \quad \quad \quad \text{ otherwise} \\
        \end{array}
\end{align*}
$$
</div>
<p>We can also refer to \(p_X(k)\) as just \(p(k)\) if the random variable is clear from the context. 
<br />
<br />
<b>Example 2:</b>
<br /> 
Suppose we roll the two dice again from example 2. Define a random variable \(X\) to be to the sum of the two dice. We know \(R_X = \{2,3,4,5,6,7,8,9,10,11,12\}\). Below is a graph of the \(PMF\) of \(X\), \(p_X(k)\) for all values in \(R_X\).
<img src="http://localhost:4000/assets/random/pmf.png" width="100%" />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Cumulative Distribution Function</b></h4>
<p>Suppose we’re interested in the probability that a random variables, \(X\), is less than or equal to a particular value, \(C\). One way to do this is to sum all the probabilities for all the values that \(X\) can take up to \(C\). An easier way to do this is to use the cumulative distribution function (CDF) that gives the probability that \(X\) is less than or equal to a particular value, specifically</p>
<div center="">
$$
\begin{align*}
F_X(k) = F(k) = P(X \leq k), \quad \text{ where } -\infty &lt; k &lt; \infty
\end{align*}
$$
</div>
<p>For a discrete random variable, this will be just the sum of all variables</p>
<div center="">
$$
\begin{align*}
F_X(k) = F(k) = \sum_{\text{ all } i \leq k} p(i)
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Expectation</b></h4>
<p>The expectation or expected value of a random variable \(X\) is defined as:</p>
<div center="">
$$
\begin{align*}
E[X] = \sum_{k:p(k)&gt;0} p(k)*k
\end{align*}
$$
</div>
<p>In other words, the expected value is a weighted average of the value of the random variable (values weighted by their probabilities).
<br />
<br />
<b>Example 4:</b>
<br /> 
Suppose we roll two dice again from example 2 and 3. Define a random variable \(X\) to be to the sum of the two dice. We can use our PMF from the previous section to compute the expected value as</p>
<div center="">
$$
\begin{align*}
E[X] &amp;= 2*P(X=2) + 3*P(X=3) + 4*P(X=4) + 5 * P(X=5) * 6*P(X=6) + 7*P(X=7) \\
\\ &amp;+ 8*P(X=8) + 9*P(X=9) + 10*P(X=10) + 11*P(X=11) * 12*P(X=12) \\
E[X] &amp;= 2*\frac{1}{36} + 3*\frac{2}{36} + 4*\frac{3}{36} + 5*\frac{4}{36} + 6*\frac{5}{36} + 7*\frac{6}{36} + 8*\frac{5}{36} + 9*\frac{4}{36} + 10*\frac{3}{36} \\
&amp;+ 11*\frac{2}{36} + 12*\frac{1}{36} = 7
\end{align*}
$$
</div>
<p><br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Expectation of a function of a random variable</b></h4>
<p>Suppose we have a random variable \(X\) and we have a function \(g\) where \(g\) is real-valued function. Suppose we want to calculate the expected value of \(g(X)\). Define</p>
<div center="">
$$
\begin{align*}
E[g(X)] = E[Y] &amp;= \sum_j y_jp(y_j) \\
&amp;= \sum_i g(x_i) p(x_i) \\
\end{align*}
$$
</div>
<p>PROOF?
<br />
<br />
<b>Example 5:</b>
<br /> 
Suppose we roll a die and define \(X\) to be the value on the die. Define a new random variable \(Y\) to be \(X^2\). What is \(E[Y]\)?<br />
<br />
Using the above, \(E[Y] = E[X^2] = \sum_i (k_i^2)p(k_i) = 1/6*(1+4+9+16+25+36) \approx 15.167\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Linearity of Expectation</b></h4>
<p>Expectation of the sum of two random variables is the sum of expectation of the two random variables.</p>
<div center="">
$$
\begin{align*}
 E[aX + bY + c] &amp;= aE[X] + bE[Y] + c
\end{align*}
$$
</div>
<p><b>Example 6:</b>
<br /> 
Suppose we roll a die and let \(X\) be a random variable representing the outcome of the roll. Suppose also that you will win a number of dollars equals to \(3X+5\). What is the expected value of your winnings? We can let \(Y\) be a random variable representing our winnings. Now we have</p>

<div center="">
$$
\begin{align*}
E[Y] = E[6X^2+5] &amp;= \sum_i (3x_i + 5)p(x_i) \\
&amp;= \frac{1}{6} \sum_{i=1}^6 3x_i+5 \\
&amp;= \frac{1}{6} (8+11+14+17+20+23) = 15.5
\end{align*}
$$
</div>

<p>However using the linearity of expectation, we know that \(E[X]=3.5\). Therefore we could do the following:</p>
<div center="">
$$
\begin{align*}
E[Y] = E[3X+5] &amp;= 3E[X]+5  \\
&amp;= 3(3.5) + 5 = 15.5
\end{align*}
$$
</div>

<p><b>Example 7:</b>
<br /> 
Suppose we roll two dice again and we’re interested in the expectation of the sum of two dice. We calculated this value previously in example 4 using the PMF. Let’s use the second property of expectation. Let \(X_1\) be a random variable representing the value of the first die and \(X_2\) be a random variable representing the sum value of the second die. Let the sum of the two dice be \(X_1 + X_2\).</p>
<div center="">
$$
\begin{align*}
E[X_1 + X_2] = E[X_1] + E[X_2] = 7
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 8: St. Petersburg Paradox</b></h4>
<p>A fair coin comes up heads with \(p = 0.5\). We flip the coin until we see the first tails. We will then win \(2^n\) dollars where \(n\) is the number of heads seen before the first tail. How much would you pay to play?
<br />
<br />
Let’s define the following random variables: <br />
Let \(Y\) be the number of “heads” before the the first “tails”.<br />
Let \(W\) be a random variable representing our winnings. \(W = 2^Y\). 
<br />
<br />
What is the probability of seeing \(i\) heads before seeing the first tail on the \(i+1\)th trial? \(P(Y = i) = (1/2) * (1/2) * ... = (1/2)^{i+1}\). This is because  we stop at the \(i+1\) flip which is a tail. Each outcome has a probability equals to \(1/2\).
<br />
<br />
What is the expected value of our winnings?<br /></p>
<div center="">
$$
\begin{align*}
E[W] = E[2^Y] &amp;= \sum_i 2^i P(Y=i) =  \sum_i 2^i p(i) \\
&amp;= (\frac{1}{2})^1 2^0 + (\frac{1}{2})^2 2^1 +  (\frac{1}{2})^3 2^2 + ... \\
&amp;= \sum_i^{\infty} (\frac{1}{2})^{i+1} 2^i = \infty
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Example 9: Roulette</b></h4>
<p>Consider an even money bet (betting “Red” in Roulette). \(p=18/38\) you win \(Y\) dollars, otherwise \(1-p\) you lose \(Y\) dollars. Consider the following strategy:</p>
<ol>
  <li>Let \(Y=1\). <br /></li>
  <li>Bet \(Y\).<br /></li>
  <li>If win then stop.<br /></li>
  <li>Else let \(Y=2Y\) go to step 2.<br /></li>
</ol>

<p>What is the expected value of our winning? <br />
Define \(Z\) to be our winnings until we stop. <br />
<br /></p>
<div center="">
$$
\begin{align*}
E[Z] &amp;= p*1 + (1-p)p*(2-1) + (1-p)^2p*(4-2-1) + ... \\
&amp;= \sum_{i=0}^{\infty} p(1-p)^i(2^i - \sum_{j=0}^{i-1}2^j) \\
&amp;= p\sum_{i=0}^{\infty} (1-p)^i = p\frac{1}{1-(1-p)} = 1
\end{align*}
$$
</div>
<!------------------------------------------------------------------------------------>
<h4><b>References</b></h4>
<p>My study notes from CS109 http://web.stanford.edu/class/archive/cs/cs109/cs109.1188// <br />
Specifically: http://web.stanford.edu/class/archive/cs/cs109/cs109.1188/lectures/06_random_variables.pdf
<br /></p>


  </div><div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = /jekyll/update/2019/07/26/random-variables.html;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier =  /jekyll/update/2019/07/26/random-variables; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://strncat-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a class="u-url" href="/jekyll/update/2019/07/26/random-variables.html" hidden></a>
</article>
		 
      </div>
    </main>

    <!--<footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">strncat&#39;s notebook</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">strncat&#39;s notebook</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>personal study notes</p>
      </div>
    </div>

  </div>

</footer>
-->

	
  </body>

</html>

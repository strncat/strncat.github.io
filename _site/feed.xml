<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-02-22T14:09:01-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">nemo’s notebook</title><subtitle>personal study notes</subtitle><entry><title type="html">Lecture 15: Quotient Groups</title><link href="http://localhost:4000/jekyll/update/2025/02/07/math417-15-quotient-groups.html" rel="alternate" type="text/html" title="Lecture 15: Quotient Groups" /><published>2025-02-07T00:01:36-08:00</published><updated>2025-02-07T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/07/math417-15-quotient-groups</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/07/math417-15-quotient-groups.html"><![CDATA[<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Let \(G\) be a group and let \(H\) be a subgroup. For \(a, b \in G\), define \(a \sim_H b\) to mean 
$$
\begin{align*}
b = ah \quad \text{ for some } h \in H
\end{align*}
$$
</div>
<!----------------------------------------------------------------------------->
<p><br />
Exercise: \(\sim_H\) is an equivalence relation. [TODO]
<br />
<br />
The equivalence classes are the left cosets \(aH = \{ah \ | \ h \in H\}\). 
<br />
<br />
Now define \(G / H\) to be the collection of left \(H\)-cosets in \(G\) so \(G / H = \{ aH \ | \ a \in G\}\). The Quotient function</p>
<div>
$$
\begin{align*}
\pi \ : \ &amp;G \rightarrow G / H \\
     &amp;\pi(g) = gH
\end{align*}
$$
</div>
<p>We can do the same thing for right cosets. We need a different notation so we’ll use a backward slash for right cosets \(G \backslash H\). So \(G \backslash H = \{ Ha \ | \ a \in G\}\). The Quotient function</p>
<div>
$$
\begin{align*}
\pi' \ : \ &amp;G \rightarrow G \backslash H \\
     &amp;\pi'(g) = Hg
\end{align*}
$$
</div>
<p><br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Let \(G = \mathbf{Z}\) and let \(H = \mathbf{Z}n\) where \(n \geq 0\) (multiples of \(n\)). Then the set of left cosets is</p>
<div>
$$
\begin{align*}
G / H &amp;= \{[a]_n \ | \ a \in \mathbf{Z}\} \\
      &amp;= \mathbf{Z}_n
\end{align*}
$$
</div>
<p>Side note: Why? so say \(H = \mathbf{Z}3\), then \(H = \{...,-6,-3,0,3,6,9,...\}\) and the left cosets are</p>
<div>
$$
\begin{align*}
0 + H, 1 + H, 2 + H, 3 + H, ...
\end{align*}
$$
</div>
<p>For example</p>
<div>
$$
\begin{align*}
0 + H &amp;= \{...,-6,-3,0,3,6,9,...\} = [0]_3 \\
1 + H &amp;= \{...,-5,-2,1,4,7,10,...\} = [1]_3 \\
2 + H &amp;= \{...,-4,-1,2,5,8,11,...\} = [2]_3 \\
3 + H &amp;= \{...,-3,0,3,6,9,12,...\} = 0 + H \\
4 + H &amp;= \{...,-2,1,4,7,10,13,...\} = 1 + H \\
\end{align*}
$$
</div>
<p>From this we see that \(3H = 0H\), \(4H = 1H\) and so on. There are exactly 3 distinct left cosets. These three left cosets are exactly \(Z_3 = \{[0], [1], [2]\}\).
<br />
<br />
So now we see that \(G / H = \mathbf{Z}_n\). This is a group. In fact \(\pi \ : \ \mathbf{Z} \rightarrow \mathbf{Z}/\mathbf{Z}n\) is a homomorphism.
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Quotient Group</b></h4>
<p>The question now is if we can do this in general. If we have a group \(G\) and a subgroup \(H \leq G\). We want to put a group structure on the set of left \(H\)-cosets, \(G / H\) such that \(\pi \ : \ G \rightarrow G / H\) is a homomorphism? This is called the “Quotient Group”.
<br />
<br />
Also if we make that happen and \(\pi\) is a homomorphism. What would the kernel of \(\pi\) be? By definition:</p>
<div>
$$
\begin{align*}
ker(\pi) = \{g \in G \ | \ \pi(g) = e_{G/H}\}.
\end{align*}
$$
</div>
<p>But since \(\pi\) is a homomorphism, then \(\pi(e_G) = e_{G/H}\). And by the definition of \(\pi\), \(\pi(a) = aH\) so \(\pi(e_G) = eH\). So</p>
<div>
$$
\begin{align*}
ker(\pi) &amp;= \{g \in G \ | \ \pi(g) = e_{G/H}\} \\
         &amp;= \{g \in G \ | \ gH = eH\} \\
		 &amp;= H.
\end{align*}
$$
</div>
<p>But we also know that kernels are normal subgroups so this means that \(H\) is a normal subgroup.
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Let \(G\) be a group and let \(N\) be a normal subgroup. Define the operation on \(G/N\) by
$$
\begin{align*}
aN \cdot bN = (ab)N
\end{align*}
$$
</div>
<!----------------------------------------------------------------------------->
<p><br />
The first thing we need to show is that this operation is well defined. So we need to show that if \(aN = a'N\) and \(bN = b'N\), then \((ab)N = (a'b')N\).
<br />
<br />
<b>Proof</b>
<br />
Since \(aN = a'N\), then \(a'\) is in the coset \(aN\) and we can write \(a' = an_1\) for some \(n_1 \in N\). Similarly, \(bN = b'N\) so we can write \(b' = bn_2\) for some \(n_2 \in N\). We want to show that \(a'b' = abn\) for some \(n \in N\). Now,</p>
<div>
$$
\begin{align*}
a'b' &amp;= an_1bn_2 \\
     &amp;= a(bb^{-1})n_1bn_2 \\
	 &amp;= (ab)(b^{-1}n_1bn_2)
\end{align*}
$$
</div>
<p>So now we want to show that \(b^{-1}n_1bn_2 \in N\). We know that \(N\) is a normal subgroup. So if we conjugate \(n\) by \(b^{-1}\), then we know that \(b^{-1}nb \in N\) because \(N\) is normal. Moreover, \((b^{-1}nb)(n_2) \in N\) since \(N\) is a subgroup. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition Let \(G\) be a group and let \(H\) be a subgroup. For \(a, b \in G\), define \(a \sim_H b\) to mean $$ \begin{align*} b = ah \quad \text{ for some } h \in H \end{align*} $$ Exercise: \(\sim_H\) is an equivalence relation. [TODO] The equivalence classes are the left cosets \(aH = \{ah \ | \ h \in H\}\). Now define \(G / H\) to be the collection of left \(H\)-cosets in \(G\) so \(G / H = \{ aH \ | \ a \in G\}\). The Quotient function $$ \begin{align*} \pi \ : \ &amp;G \rightarrow G / H \\ &amp;\pi(g) = gH \end{align*} $$ We can do the same thing for right cosets. We need a different notation so we’ll use a backward slash for right cosets \(G \backslash H\). So \(G \backslash H = \{ Ha \ | \ a \in G\}\). The Quotient function $$ \begin{align*} \pi' \ : \ &amp;G \rightarrow G \backslash H \\ &amp;\pi'(g) = Hg \end{align*} $$ Example Let \(G = \mathbf{Z}\) and let \(H = \mathbf{Z}n\) where \(n \geq 0\) (multiples of \(n\)). Then the set of left cosets is $$ \begin{align*} G / H &amp;= \{[a]_n \ | \ a \in \mathbf{Z}\} \\ &amp;= \mathbf{Z}_n \end{align*} $$ Side note: Why? so say \(H = \mathbf{Z}3\), then \(H = \{...,-6,-3,0,3,6,9,...\}\) and the left cosets are $$ \begin{align*} 0 + H, 1 + H, 2 + H, 3 + H, ... \end{align*} $$ For example $$ \begin{align*} 0 + H &amp;= \{...,-6,-3,0,3,6,9,...\} = [0]_3 \\ 1 + H &amp;= \{...,-5,-2,1,4,7,10,...\} = [1]_3 \\ 2 + H &amp;= \{...,-4,-1,2,5,8,11,...\} = [2]_3 \\ 3 + H &amp;= \{...,-3,0,3,6,9,12,...\} = 0 + H \\ 4 + H &amp;= \{...,-2,1,4,7,10,13,...\} = 1 + H \\ \end{align*} $$ From this we see that \(3H = 0H\), \(4H = 1H\) and so on. There are exactly 3 distinct left cosets. These three left cosets are exactly \(Z_3 = \{[0], [1], [2]\}\). So now we see that \(G / H = \mathbf{Z}_n\). This is a group. In fact \(\pi \ : \ \mathbf{Z} \rightarrow \mathbf{Z}/\mathbf{Z}n\) is a homomorphism. Quotient Group The question now is if we can do this in general. If we have a group \(G\) and a subgroup \(H \leq G\). We want to put a group structure on the set of left \(H\)-cosets, \(G / H\) such that \(\pi \ : \ G \rightarrow G / H\) is a homomorphism? This is called the “Quotient Group”. Also if we make that happen and \(\pi\) is a homomorphism. What would the kernel of \(\pi\) be? By definition: $$ \begin{align*} ker(\pi) = \{g \in G \ | \ \pi(g) = e_{G/H}\}. \end{align*} $$ But since \(\pi\) is a homomorphism, then \(\pi(e_G) = e_{G/H}\). And by the definition of \(\pi\), \(\pi(a) = aH\) so \(\pi(e_G) = eH\). So $$ \begin{align*} ker(\pi) &amp;= \{g \in G \ | \ \pi(g) = e_{G/H}\} \\ &amp;= \{g \in G \ | \ gH = eH\} \\ &amp;= H. \end{align*} $$ But we also know that kernels are normal subgroups so this means that \(H\) is a normal subgroup. Definition Let \(G\) be a group and let \(N\) be a normal subgroup. Define the operation on \(G/N\) by $$ \begin{align*} aN \cdot bN = (ab)N \end{align*} $$ The first thing we need to show is that this operation is well defined. So we need to show that if \(aN = a'N\) and \(bN = b'N\), then \((ab)N = (a'b')N\). Proof Since \(aN = a'N\), then \(a'\) is in the coset \(aN\) and we can write \(a' = an_1\) for some \(n_1 \in N\). Similarly, \(bN = b'N\) so we can write \(b' = bn_2\) for some \(n_2 \in N\). We want to show that \(a'b' = abn\) for some \(n \in N\). Now, $$ \begin{align*} a'b' &amp;= an_1bn_2 \\ &amp;= a(bb^{-1})n_1bn_2 \\ &amp;= (ab)(b^{-1}n_1bn_2) \end{align*} $$ So now we want to show that \(b^{-1}n_1bn_2 \in N\). We know that \(N\) is a normal subgroup. So if we conjugate \(n\) by \(b^{-1}\), then we know that \(b^{-1}nb \in N\) because \(N\) is normal. Moreover, \((b^{-1}nb)(n_2) \in N\) since \(N\) is a subgroup. \(\ \blacksquare\) References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 14: Lagrange’s Theorem, Order Theorem &amp;amp; Equivalence Relations</title><link href="http://localhost:4000/jekyll/update/2025/02/06/math417-14-lagrange-order-equivalence.html" rel="alternate" type="text/html" title="Lecture 14: Lagrange’s Theorem, Order Theorem &amp;amp; Equivalence Relations" /><published>2025-02-06T00:01:36-08:00</published><updated>2025-02-06T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/06/math417-14-lagrange-order-equivalence</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/06/math417-14-lagrange-order-equivalence.html"><![CDATA[<p>Last time, we studied <b>Lagrange’s Theorem</b> which stated that given a finite group \(G\) and a subgroup \(H\) of \(G\), then \(|H|\) divides \(|G|\). Moreover, \(|H| / |G|\) is the number of \(H-\) left cosets in \(G\). In fact, this number was defined to be the index of a group \([G : H]\). So</p>
<div>
$$
\begin{align*}
[G : H] = \frac{|H|}{|G|}.
\end{align*}
$$
</div>
<p>As a consequence, this led to the <b>Order Theorem</b> which stated that if \(G\) was a finite group, then for any \(g \in G\), \(o(g)\) divides \(|G|\). 
<br />
<br />
But now as we see, both theorems are stated for finite groups \(G\) and we know from last lecture that the index of a group can be still defined even if \(G\) is infinite. So this led to the generalized version of Lagrange Theorem as follows:
<!----------------------------------------------------------------------------->
<br /></p>
<div class="yellowheaderdiv">
Generalized Lagrange Theorem
</div>
<div class="yellowbodydiv">
Let \(G \geq H \geq K\). Then for any \([G: K] = [G : H] [H : K]\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
Note here that if \(K\) is the trivial subgroup so \(K = \{e\}\), then \([H:\{e\}] = |H|\). The cosets of the trivial subgroups have size 1 so we’re dividing \(H\) isto subsets of size 1 and therefore we get back the earlier Lagrange’s Theorem
<br />
<br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Suppose we have \(\mathbf{Z} \geq \mathbf{Z_3} \geq \mathbf{Z}_{12}\) where \(G = \mathbf{Z}\), \(H = \mathbf{Z}_{3}\) and \(K = \mathbf{Z}_{12}\). We know that \([\mathbf{Z} : \mathbf{Z}_{12}] = 12\) and \([\mathbf{Z} : \mathbf{Z}_{3}] = 3\) so</p>
<div>
$$
\begin{align*}
[\mathbf{Z} : \mathbf{Z}_{12}] = [\mathbf{Z} : \mathbf{Z}_{3}]  [\mathbf{Z}_{3} : \mathbf{Z}_{12}] \\
12 = 3[\mathbf{Z}_{3} : \mathbf{Z}_{12}]
\end{align*}
$$
</div>
<p>From this we can deduce that the index of \(\mathbf{Z}_{12}\) inside \(\mathbf{Z}_3\) is 4.
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Proof of Generalized Lagrange</b></h4>
<p>\([H: K]\) is the number of left \(K\)-cosets inside \(H\). So \(aK \subseteq H\). Observe that for any \(aH\), the number of left \(K\)-cosets in \(aH\) is equal to \([H : K]\). Consider the bijection</p>
<div>
$$
\begin{align*}
H &amp;\rightarrow aH \\
h &amp;\rightarrow ah
\end{align*}
$$
</div>
<p>Then \(hk\) under this bijection will be \(ahK\). 
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Let \(D_4 = \{e, r, r^2, r^3, j, rj, r^2j, r^3j\}\). Consider:</p>
<div>
$$
\begin{align*}
H &amp;= \langle r^2, j \rangle = \{e, r^2, j, r^2j\} \\
K &amp;= \langle r^2 \rangle = \{e, r^2\}
\end{align*}
$$
</div>
<p>Then the index \([G : H] = \frac{|H|}{|G|} = 2\) which is the number of \(H\)-left cosets in \(G\). Similarly, \([H : K] = 2\) which is the number of \(K-\) left cosets in \(H\). For example</p>
<div>
$$
\begin{align*}
eH &amp;= \{e, r^2, j, r^2j\} \ | \ eK = \{e, r^2\}, \ jK = \{j, r^2j\} \\
rH &amp;= \{r, r^3, rj, r^3j\} \ | \ rK = \{r, r^3\}, \ rjK = \{rj, r^3\}.
\end{align*}
$$
</div>
<p>If you look at \(eH\), observe that it contains both \(K\)-cosets and if you look at \(rH\), you’ll see that it also contains both of the \(K\) cosets.
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Order Theorem</b></h4>
<p>Back to the Order Theorem. For example, for \(|G| = 12\), the order of the elements inside \(G\) are \(o(g) \in \{1,2,3,4,6,12\}\). The question is do we know if there must be a subgroup of order 6? 4? what about 2? For 2, if the order of the group is even, then we must have an element with order 2. To see why, we have the Even Order Theorem as follows:
<!----------------------------------------------------------------------------->
<br /></p>
<div class="yellowheaderdiv">
Even Order Theorem
</div>
<div class="yellowbodydiv">
If \(|G| = n\) and \(n\) is even, then there exists a \(g \in G\) with \(o(g) = 2\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
Observe that if \(a \in G\), then \(a^2 = 2\) if and only if \(a^{-1} = a\). In this case, the order must either be 1 or 2 so \(o(a) \in \{1,2\}\). Now, let \(a \in G\). For each \(a\), produce a subset \(C\) such that \(C = \{a, a^{-1}\}\). This is a subset of \(G\) of order 1 or 2 depending on whether \(a = a^{-1}\). 
<br />
<br />
Claim: For \(\{a, a^{-1}\}\) and \(C' = \{b, b^{-1}\}\). Either \(C = C'\) or \(C \cap C' = \emptyset\). Moreover</p>
<div>
$$
\begin{align*}
\bigcup_{a \in G} \{a, a^{-1}\} = G.
\end{align*}
$$
</div>
<p>The union of all these subsets is \(G\). So we get a partition of the set \(G\) into pairwise disjoint subsets of size 1 or 2. So \(n = |G| = r + 2s\). where \(r\) is the number of subsets \(\{a, a^{-1}\}\) of size 1 and \(s\) is the number of subsets \(\{a, a^{-1}\}\) of size \(2\). Notice here that \(r\) is counting all the elements such that each element is its own inverse. So \(r = |\{a \in G \ | \ a^2 = e\}|\). In fact, \(r\) is the number of elements in \(G\) of order 1 or 2. 
<br />
<br />
So we showed that \(n = |G| = r + 2s\) but by assumption, \(n\) is even and since it’s even then 2 divides \(n\). So 2 must divide \(r + 2s\). Therefore, \(2\) must divide \(r\). So \(r\) is even. We also know that \(r\) is at least 1 because the identity element has order 1. Therefore, there must exist at least another element whose order is 2. So there exists a \(g \in G\) such that \(o(g) = 2\). \(\ \blacksquare\).
<br />
<br />
There is a generalization of this theorem that we’ll prove later. But if \(p\) is prime and it divides \(|G|\), then there exists an element of order \(p\).
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Equivalence Relations</b></h4>
<p>Review of equivalence relations</p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A relation on a set \(X\) is a subset \(R \subseteq X \times X\). We write \(a \sim b\) for \((a,b) \in R\).
</div>
<!----------------------------------------------------------------------------->
<p><br />
For example, let \(X = \mathbf{Z}\), then examples of relations are \(=, &gt;, \geq, \leq, &lt; ...\), “coprime”, \(\equiv \bmod n\) and so on.
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A equivalence relation \(\sim\) on \(X\) is one such that
<ol>
	<li>Reflexive: \(a \sim a \ \forall a \in X\).</li>
	<li>Symmetric: \(a \sim b \implies b \sim a \ \forall a, b \in X\).</li>
	<li>Transitive: \(a \sim b, b \sim c \implies a \sim c \ \forall a, b, c \in X\).</li>
</ol>
</div>
<!----------------------------------------------------------------------------->
<p><br />
Given a set \(X\) with an equivalence relation \(\sim\), we have an equivalence class which is a subset of \(X\) of the form</p>
<div>
$$
\begin{align*}
[a] = \{b \in X \ | \ a \sim b\} \quad \text{ for some } a \in X
\end{align*}
$$
</div>
<p>Fact: Either \([a] = [b]\) or \([a] \cap [b] = \emptyset\) so \([a] = [b] \implies a \sim b\). 
<br />
<br />
So this equivalence relations gives us a way to partition a given set \(X\) into pairwise disjoint nonempty subsets. In fact we have a bijection between the equivalence relation on \(X\) and the partitions of \(X\). What does this mean? It means that we can go either direction, if we have an equivalence relation, we can get a partition of \(X\) into subsets. And if we have a set of disjoint subsets that partitions \(X\), then we can get an equivalence relation from that. How? any two elements will be in the same equivalence class if they’re in the same subset. So we’re kind of talking about the same thing here. 
<br />
<br />
<!----------------------------------------------------------------------------->
So now let \((X, \sim)\) be a set with equivalence relation. Define \(Y\) as the set of equivalence classes of \(\sim\). We sometimes denotes \(Y\) with \(X / \sim\) “quotient set of equivalence relation”. Define</p>
<div>
$$
\begin{align*}
\pi \ : \ &amp;X \rightarrow \\
     &amp;\pi(a) = [a]
\end{align*}
$$
</div>
<p>\(\pi\) is quotient function. \(\pi\) is surjective. Every equivalence class, has an element \(a\) that is in the set \(X\) by definition. So now given \(\pi\), we can recover the equivalence relation.
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Last time, we studied Lagrange’s Theorem which stated that given a finite group \(G\) and a subgroup \(H\) of \(G\), then \(|H|\) divides \(|G|\). Moreover, \(|H| / |G|\) is the number of \(H-\) left cosets in \(G\). In fact, this number was defined to be the index of a group \([G : H]\). So $$ \begin{align*} [G : H] = \frac{|H|}{|G|}. \end{align*} $$ As a consequence, this led to the Order Theorem which stated that if \(G\) was a finite group, then for any \(g \in G\), \(o(g)\) divides \(|G|\). But now as we see, both theorems are stated for finite groups \(G\) and we know from last lecture that the index of a group can be still defined even if \(G\) is infinite. So this led to the generalized version of Lagrange Theorem as follows: Generalized Lagrange Theorem Let \(G \geq H \geq K\). Then for any \([G: K] = [G : H] [H : K]\). Note here that if \(K\) is the trivial subgroup so \(K = \{e\}\), then \([H:\{e\}] = |H|\). The cosets of the trivial subgroups have size 1 so we’re dividing \(H\) isto subsets of size 1 and therefore we get back the earlier Lagrange’s Theorem Example Suppose we have \(\mathbf{Z} \geq \mathbf{Z_3} \geq \mathbf{Z}_{12}\) where \(G = \mathbf{Z}\), \(H = \mathbf{Z}_{3}\) and \(K = \mathbf{Z}_{12}\). We know that \([\mathbf{Z} : \mathbf{Z}_{12}] = 12\) and \([\mathbf{Z} : \mathbf{Z}_{3}] = 3\) so $$ \begin{align*} [\mathbf{Z} : \mathbf{Z}_{12}] = [\mathbf{Z} : \mathbf{Z}_{3}] [\mathbf{Z}_{3} : \mathbf{Z}_{12}] \\ 12 = 3[\mathbf{Z}_{3} : \mathbf{Z}_{12}] \end{align*} $$ From this we can deduce that the index of \(\mathbf{Z}_{12}\) inside \(\mathbf{Z}_3\) is 4. Proof of Generalized Lagrange \([H: K]\) is the number of left \(K\)-cosets inside \(H\). So \(aK \subseteq H\). Observe that for any \(aH\), the number of left \(K\)-cosets in \(aH\) is equal to \([H : K]\). Consider the bijection $$ \begin{align*} H &amp;\rightarrow aH \\ h &amp;\rightarrow ah \end{align*} $$ Then \(hk\) under this bijection will be \(ahK\). Example Let \(D_4 = \{e, r, r^2, r^3, j, rj, r^2j, r^3j\}\). Consider: $$ \begin{align*} H &amp;= \langle r^2, j \rangle = \{e, r^2, j, r^2j\} \\ K &amp;= \langle r^2 \rangle = \{e, r^2\} \end{align*} $$ Then the index \([G : H] = \frac{|H|}{|G|} = 2\) which is the number of \(H\)-left cosets in \(G\). Similarly, \([H : K] = 2\) which is the number of \(K-\) left cosets in \(H\). For example $$ \begin{align*} eH &amp;= \{e, r^2, j, r^2j\} \ | \ eK = \{e, r^2\}, \ jK = \{j, r^2j\} \\ rH &amp;= \{r, r^3, rj, r^3j\} \ | \ rK = \{r, r^3\}, \ rjK = \{rj, r^3\}. \end{align*} $$ If you look at \(eH\), observe that it contains both \(K\)-cosets and if you look at \(rH\), you’ll see that it also contains both of the \(K\) cosets. Order Theorem Back to the Order Theorem. For example, for \(|G| = 12\), the order of the elements inside \(G\) are \(o(g) \in \{1,2,3,4,6,12\}\). The question is do we know if there must be a subgroup of order 6? 4? what about 2? For 2, if the order of the group is even, then we must have an element with order 2. To see why, we have the Even Order Theorem as follows: Even Order Theorem If \(|G| = n\) and \(n\) is even, then there exists a \(g \in G\) with \(o(g) = 2\). Proof Observe that if \(a \in G\), then \(a^2 = 2\) if and only if \(a^{-1} = a\). In this case, the order must either be 1 or 2 so \(o(a) \in \{1,2\}\). Now, let \(a \in G\). For each \(a\), produce a subset \(C\) such that \(C = \{a, a^{-1}\}\). This is a subset of \(G\) of order 1 or 2 depending on whether \(a = a^{-1}\). Claim: For \(\{a, a^{-1}\}\) and \(C' = \{b, b^{-1}\}\). Either \(C = C'\) or \(C \cap C' = \emptyset\). Moreover $$ \begin{align*} \bigcup_{a \in G} \{a, a^{-1}\} = G. \end{align*} $$ The union of all these subsets is \(G\). So we get a partition of the set \(G\) into pairwise disjoint subsets of size 1 or 2. So \(n = |G| = r + 2s\). where \(r\) is the number of subsets \(\{a, a^{-1}\}\) of size 1 and \(s\) is the number of subsets \(\{a, a^{-1}\}\) of size \(2\). Notice here that \(r\) is counting all the elements such that each element is its own inverse. So \(r = |\{a \in G \ | \ a^2 = e\}|\). In fact, \(r\) is the number of elements in \(G\) of order 1 or 2. So we showed that \(n = |G| = r + 2s\) but by assumption, \(n\) is even and since it’s even then 2 divides \(n\). So 2 must divide \(r + 2s\). Therefore, \(2\) must divide \(r\). So \(r\) is even. We also know that \(r\) is at least 1 because the identity element has order 1. Therefore, there must exist at least another element whose order is 2. So there exists a \(g \in G\) such that \(o(g) = 2\). \(\ \blacksquare\). There is a generalization of this theorem that we’ll prove later. But if \(p\) is prime and it divides \(|G|\), then there exists an element of order \(p\). Equivalence Relations Review of equivalence relations Definition A relation on a set \(X\) is a subset \(R \subseteq X \times X\). We write \(a \sim b\) for \((a,b) \in R\). For example, let \(X = \mathbf{Z}\), then examples of relations are \(=, &gt;, \geq, \leq, &lt; ...\), “coprime”, \(\equiv \bmod n\) and so on. Definition A equivalence relation \(\sim\) on \(X\) is one such that Reflexive: \(a \sim a \ \forall a \in X\). Symmetric: \(a \sim b \implies b \sim a \ \forall a, b \in X\). Transitive: \(a \sim b, b \sim c \implies a \sim c \ \forall a, b, c \in X\). Given a set \(X\) with an equivalence relation \(\sim\), we have an equivalence class which is a subset of \(X\) of the form $$ \begin{align*} [a] = \{b \in X \ | \ a \sim b\} \quad \text{ for some } a \in X \end{align*} $$ Fact: Either \([a] = [b]\) or \([a] \cap [b] = \emptyset\) so \([a] = [b] \implies a \sim b\). So this equivalence relations gives us a way to partition a given set \(X\) into pairwise disjoint nonempty subsets. In fact we have a bijection between the equivalence relation on \(X\) and the partitions of \(X\). What does this mean? It means that we can go either direction, if we have an equivalence relation, we can get a partition of \(X\) into subsets. And if we have a set of disjoint subsets that partitions \(X\), then we can get an equivalence relation from that. How? any two elements will be in the same equivalence class if they’re in the same subset. So we’re kind of talking about the same thing here. So now let \((X, \sim)\) be a set with equivalence relation. Define \(Y\) as the set of equivalence classes of \(\sim\). We sometimes denotes \(Y\) with \(X / \sim\) “quotient set of equivalence relation”. Define $$ \begin{align*} \pi \ : \ &amp;X \rightarrow \\ &amp;\pi(a) = [a] \end{align*} $$ \(\pi\) is quotient function. \(\pi\) is surjective. Every equivalence class, has an element \(a\) that is in the set \(X\) by definition. So now given \(\pi\), we can recover the equivalence relation. References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 13: Cosets</title><link href="http://localhost:4000/jekyll/update/2025/02/05/math417-13-cosets.html" rel="alternate" type="text/html" title="Lecture 13: Cosets" /><published>2025-02-05T00:01:36-08:00</published><updated>2025-02-05T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/05/math417-13-cosets</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/05/math417-13-cosets.html"><![CDATA[<div class="mintheaderdiv">
Definition 2.4.14
</div>
<div class="mintbodydiv">
Let \(H\) be subgroup of a group \(G\). <br />
\(gH = \{gh \ | \ h \in H\}\) is called a left coset of \(H\) in \(G\). 
<br />
\(Hg = \{hg \ | \ h \in H\}\) is called a right coset of \(H\) in \(G\).
</div>
<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<p>Example 1: Let \(D_4 = \{e, r, r^2, r^3, j, rj, r^2j, r^3j\}\). where \(r^4 = e = j^2\) and \(jr = r^{-1}j\).
<br /> Define the subgroup \(H = \langle j \rangle = \{e, j\}\). The left cosets are:</p>
<div>
$$
\begin{align*}
eH &amp;= \{e, j\} = jH \\
rH &amp;= \{r, rj\} = rjH \\
r^2H &amp;= \{r^2, r^2j\} = r^2jH \\
r^3H &amp;= \{r^3, r^3j\} = r^3jH \\
\end{align*}
$$
</div>
<p>Notice here that none of the elements overlap between the sets so this gives us a way to partition the set \(G\) into four pairwise disjoint subsets (We’ll prove this next). The right cosets are</p>
<div>
$$
\begin{align*}
He &amp;= \{e, j\} = Hj \\
Hr &amp;= \{r, jr\} = \{e, r^3j\} = Hr^3j \\
Hr^2 &amp;= \{r^2, r^2j\} = Hr^2j \\
Hr^3 &amp;= \{r^3, rj\} = Hrj \\
\end{align*}
$$
</div>
<p>Example 2: Let \(G = \mathbf{Z}\) (with addition) and take \(H = \mathbf{Z}n \leq G\) where \(n \geq 1\). <br />
The left coset is \(a + H = a + \mathbf{Z}n = \{a + kn \ | \ k \in \mathbf{Z}\}\) <br />
The left coset is \(H + a = \mathbf{Z}n + a\) which is the same as the right coset. This happens because the group is abelian!<br />
Another name for these cosets are the congruence class \([a]_n\). 
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Cosets are Pairwise Disjoint</b></h4>
<p>Next we show why these subets must be pairwise disjoint.
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition (2.5.4)
</div>
<div class="peachbodydiv">
Let \(H\) be a subgroup of a group \(G\). If \(X, Y \subseteq G\) are left \(H-\)cosets, then either
<ol>
	<li>\(X \cap Y = \emptyset\).</li>
	<li>\(X = Y\).</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------>
<b>Proof</b>
<br />
We’ll prove that not (1) implies (2) (to prove an or statement). <br />
Suppose that \(g \in X \cap Y\). We want to show that \(X = Y\). Since \(X\) and \(Y\) are left cosets, then we can write \(X = xH\) and \(Y = yH\) for some \(x, y \in G\). Since \(g \in X \cap Y\), then we can write \(g = xh_1 = yh_2\) for some \(h_1, h_2 \in H\). Observe now that</p>
<div>
$$
\begin{align*}
x &amp;= gh_1^{-1} \\
  &amp;= (yh_2)h_1^{-1} \\
  &amp;= y(h_2h_1^{-1})
\end{align*}
$$
</div>
<p>Likewise</p>
<div>
$$
\begin{align*}
y &amp;= gh_2^{-1} \\
  &amp;= (xh_1)h_2^{-1} \\
  &amp;= x(h_1h_2^{-1})
\end{align*}
$$
</div>
<p>Now, let \(xh \in xH\), then</p>
<div>
$$
\begin{align*}
xh &amp;= (yh_2h_1^{-1})h \\
   &amp;= y(h_2h_1^{-1}h)
\end{align*}
$$
</div>
<p>But this implies that \(xh \in yH\). So \(xH \subseteq yH\). Likewise, let \(yh \in yH\), then</p>
<div>
$$
\begin{align*}
yh &amp;= (xh_1h_2^{-1})h \\
   &amp;= x(h_1h_2^{-1}h)
\end{align*}
$$
</div>
<p>so \(yh \in xH\) and \(yH \subseteq xH\). Therefore \(xH = yH\). \(\blacksquare\) 
<br />
<br />
Based on this, we have the following proposition
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 2.5.3
</div>
<div class="peachbodydiv">
Let \(H\) be a subgroup of a group \(G\), and let \(a\) and \(b\) be
elements of \(G\). The following conditions are equivalent:
<ol type="a">
	<li>\(a \in bH\).</li>
	<li>\(b \in aH\).</li>
	<li>\(aH = bH\).</li>
	<li>\(b^{-1}a \in H\).</li>
	<li>\(a^{-1}b \in H\).</li>
</ol>
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof (book)</b>
<br />
Suppose \((a)\) holds. Let \(a \in bH\). Then we can write \(a = bh\). Since \(H\) is a subgroup, then we know \(h^{-1} \in H\). So we can write \(b = ah^{-1}\). But \(ah^{-1}\) is in \(aH\) by the definition of a left coset which is what we wanted to show. With similar reason \((b)\) also implies \((a)\). 
<br />
<br />
For \((c)\), we want to show that \(aH \subseteq bH\) and \(bH \subseteq aH\). To show that \(bH \subseteq aH\), we want to show that for any arbitrary element \(x\) in \(bH\), that \(x\) is also in \(aH\). So consider any \(x \in bH\). By the definition of a coset, we can write \(x = bh\) for some \(h \in H\). Now suppose that \((b)\) holds and so we have \(b \in aH\). This means that we can write \(b = ah_1\) for some \(h_1 \in H\). But this means that we can write \(x = bh = ah_1h\). The product \(h_1h\) is in \(H\) because \(H\) is a subgroup. Furthermore, \(ah_1h\) must be in \(aH\) by the definition of a coset. Therefore, \(x = bh \in aH\) and so \(bH \subseteq aH\) as we wanted to show. Since \((b)\) also implies \((a)\) we can use a similar reasoning to show that \(aH \subseteq bH\).
<br />
<br />
For \((d)\) ….
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Lagrange Theorem</b></h4>
<p>Based on what we learned so far, we can now present the following important results
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(H\) be a subgroup of a group \(G\). Then all left \(H-\)cosets and right \(H-\)cosets have the same cardinality as \(H\).
</div>
<p><br />
This works well for infinite groups as well because all we need is a bijection to show they have the same cardinality.
<br />
<br />
<!------------------------------------------------------------------------>
<b>Proof</b>
<br />
We know the coset \(aH\) is constructed such that each element is appended on the left by \(a\). So naturally construct the following bijection</p>
<div>
$$
\begin{align*}
H &amp;\rightarrow aH \\
h &amp;\rightarrow ah
\end{align*}
$$
</div>
<p>This works. For any element in \(x \in aH\), the inverse is just \(a^{-1}x\). Likewise we can construct a bijection for the right coset as follows</p>
<div>
$$
\begin{align*}
H &amp;\rightarrow Ha \\
h &amp;\rightarrow ha
\end{align*}
$$
</div>
<p><br />
This leads to Lagrange Theorem.
<br />
<!-----------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lagrange Theorem
</div>
<div class="yellowbodydiv">
Let \(G\) be a finite group and let \(H\) be a subgroup of \(G\). Then \(|H|\) divides \(|G|\) and \(|G| / |H| = \) the number of left cosets of \(H\) in \(G =\) the number of right cosets of \(H\) in \(G\).
</div>
<p><br />
<b>Proof</b>
<br />
We know by the previous proposition that all cosets have the same cardinality as \(H\) itself. Moreover, we know that the collection of left cosets \(\{aH, a \in G\}\) partitions \(G\) into pairwise disjoint subsets. Therefore</p>
<div>
$$
\begin{align*}
|G| &amp;= \sum|aH| \\
    &amp;= \sum |H| \quad \text{(by the previous proposition)}
\end{align*}
$$
</div>
<p>From this we see that \(|G| = m|H|\) as we wanted to show. \(\ \blacksquare\)
<br />
<br />
This in turn leads to the following theorem:
<br />
<!-----------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Order Theorem
</div>
<div class="yellowbodydiv">
Let \(G\) be a finite group. Then for any \(g \in G\), \(o(g)\) divides \(|G|\).
</div>
<p><br />
<b>Proof</b>
<br />
[TODO]
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>More Definitions in Cosets</b></h4>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
	The index of a subgroup \(H \leq G\) is the number of left \(H-\)cosets.
	We denote the index by \([G:H]\) which is index of \(H\) in \(G\).
</div>
<p><br />
The index could be infinite but we only care when the index is finite. 
<br />
Using Lagrange’s Theorem also note that if \(G\) is finite, then \([G : H] = \frac{|G|}{|H|}\). 
<br />
Also note that \([G:H]\) can be finite even if \(G\) and \(H\) are infinte.
<br />
<br />
Example: Let \(G = \mathbf{Z}, H = \mathbf{Z_n}\) where \(n &gt; 0\). Then the index of \(\mathbf{Z}_n\) inside \(\mathbf{Z}\) is the number of left cosets which is the number of congruent classes, \([\mathbf{Z}:\mathbf{Z}_n] = n\)
<br />
<br />
We might ask why is the definition is in terms of the number of left cosets and not the right cosets. The answer is in the next proposition
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(H\) be a subgroup of a group \(G\). There is a bijection between the collection of left cosets and the collection of right cosets.
$$
\begin{align*}
\{aH, a \in G\} \rightarrow \{Ha, a \in G\}
\end{align*}
$$
</div>
<p><br />
The actual bijection is to take all the elements in the left cosets, take their inverses. The collection of inverses will be the elements in the right cosets. Why is this true?
<br />
If \(X = aH = \{aH \ | \ h \in H\}\), then \(X^{-1} = \{ (ah)^{-1} \ | \ h \in H \} = Ha^{-1}\).
<br />
<br />
So why not use \(aH \rightarrow Ha\)? This might not be defined.
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(H\) be a subgroup of a group \(G\). The following are equivalent
<ol>
	<li>\(H\) is a normal subgroup.</li>
	<li>Left \(H\)-cosets are the same as right \(H\)-cosets.</li>
	<li>Every left \(H\)-coset is contained in a right \(H\)-coset.</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------>
<b>Proof</b>
<br />
\((3) \rightarrow (1)\):<br />
Suppose every left \(H\)-coset is a subset of some right \(H\)-coset. Let \(a \in G\). We want to show that \(H\) is a normal subgroup. So we want to show that \(aHa^{-1} \subseteq H\). Given that every left coset in contained in a right coset, consider the left coset \(aH\). This coset is contained in some right coset. Since \(a \in aH\), then \(a\) must be in the right coset as well. We can claim that \(aH \subseteq Ha\). So for any \(h \in H\), \(ah = h'a\) for some \(h' \in H\). Observe that \(aha^{-1} = h'\) for some \(h' \in H\). In other words, \(aHa^{-1} \in H\) and \(H\) is normal. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Applications</b></h4>
<p>Let’s look at some applications of the order theorem.
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(|G| = p\) where \(p\) is prime, then \(G\) is cyclic.
</div>
<p><br />
<!------------------------------------------------------------------------>
<b>Proof</b>
<br />
Let \(g \in G\). By the order theorem, the order of \(g\) must divide \(|G|\) which is a prime number. So \(o(g) \in \{1, p\}\). \(\{e\}\) is the only group with order 1 and \(|G| = p &gt; 1\) so we must have an element \(g \in G\) such that \(g \neq e\). So \(o(g) = p\). But we also said that the order of an element is also the size of the cyclic group generated by \(g\) so \(|\langle g \rangle| = p\). Therefore, we must have \(G = \langle g \rangle\). \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(|G| = 4\), then \(G\) is isomorphic to \(\mathbf{Z}_4\) or \(V\) the symmetries of the rectangle.
</div>
<p><br />
<b>Proof</b>
<br />
Let \(g \in G\). The order of \(g\) has to divide 4 by the order theorem so \(o(g) \in \{1,2,4\}\). If \(o(g) = 4\), then \(o(g) = 4\) and \(\langle g \rangle = G\) so \(G\) is cyclic and so it is isomorphic to \(\mathbf{Z}_4\). If \(o(g) \neq 4\). Then \(G\) must have 4 distinct elements so \(G = \{a, b, c, d\}\)  none of the elements can have order 4. \(a, b, c\) can’t have order 1. So they must be of order 2 and their squares must be the identity. This gives us enough information fill out the multiplication table of this group as follows:</p>
<div>
<table style="max-width: 500px; margin: 20px auto;">
  <tr>
    <td></td>
    <td>\(e\)</td>
    <td>\(a\)</td>
	<td>\(b\)</td>
	<td>\(c\)</td>
  </tr>
  <tr>
    <td>\(e\)</td>
    <td>\(e\)</td>
    <td>\(a\)</td>
	<td>\(b\)</td>
	<td>\(c\)</td>
  </tr>
  <tr>
    <td>\(a\)</td>
    <td>\(a\)</td>
    <td>\(e\)</td>
	<td>\(c\)</td>
	<td>\(b\)</td>
  </tr>
  <tr>
    <td>\(b\)</td>
    <td>\(b\)</td>
    <td>\(c\)</td>
	<td>\(e\)</td>
	<td>\(a\)</td>
  </tr>
  <tr>
    <td>\(c\)</td>
    <td>\(c\)</td>
    <td>\(b\)</td>
	<td>\(a\)</td>
	<td>\(e\)</td>
  </tr>
</table>
</div>
<p><br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Subgroups of \(D_5\)</b></h4>
<p>Let’s use Lagrange’s Theorem next. Specifically, let’s analyze the subgroups of the dihedral group \(D_5\). We know \(|D_5| = 10\) so the orders of the elements must divide 10. In this case, we have \(o(r) = o(r^2) = o(r^3) = o(r^4) = 5\). While the flips have order \(2\). This is a result of the identities we established: \(j^2 = e\) and \(r^n = e\). Note here that both 2 and 5 divide 10 as we expect.</p>
<div>
$$
\begin{align*}
D_5 = \{e, r, r^2, r^3, r^4, j, rj, r^2j, r^3j, r^4,j\}
\end{align*}
$$
</div>
<p>Now, any subgroup of \(G\) must have order dividing the order of \(G\) so they must divide 10 by Lagrange’s Theorem. So \(|H| \in \{1,2,5,10\}\). Note here that 2 and 5 are prime! so by the previous proposition, they must be cyclic! We can draw the subgroups as follows by their orders:</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec13-cosets/d5.png" width="77%" class="center" /></p>
<p>Notice that there is 1 group of order 5 while there are 5 groups of order 2.
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Subgroups of \(D_9\)</b></h4>
<p>We know \(|D_9| = 18\) so the order of any subgroup \(H \leq D\) must divide 18 so \(|H| \in \{1,2,3,6,9,19\}\).</p>
<div>
$$
\begin{align*}
D_5 = \{e, r, r^2, r^3, r^4, r^5, r^6, r^7, r^8, j, rj, r^2j, r^3j, r^4j, r^5j, r^6j, r^7j, r^8j\}
\end{align*}
$$
</div>
<p>If the subgroup order was 2 or 3, then we know they must be cyclic. In this case, we know all the flips have order 2 so they’re all cyclic unique subgroups.</p>
<div>
$$
\begin{align*}
\langle j\rangle, \langle rj \rangle, \rangle r^2j \rangle, \langle r^3j \rangle, \langle r^4j \rangle, \langle r^5j \rangle, \langle r^6j \rangle, \langle r^7j \rangle, \langle r^8j \rangle
\end{align*}
$$
</div>
<p>But what about the rest of the subgroups? For order 3, we can observe that \(\langle r^3 \rangle\) has 3 elements. 
<br />
<br />
What about order 6? This one is not obvious. One thing we do know is that any element in that subgroup must have order dividing the order of the subgroup. So any element in it must divide 6. Here it’s trial and error. For example guessing \(\langle r^3, j \rangle\), we see that it consists of</p>
<div>
$$
\begin{align*}
\langle r^3, j \rangle = \{e, r^3, r^6, j, r^3j, r^6j\}.
\end{align*}
$$
</div>
<p>Notice here that \(jr^3 = r^6j\) by the identity \(jr^k = r^{-k}j\). Is there another group of order 6? Instead of \(j\), we can try another element of order 3:</p>
<div>
$$
\begin{align*}
\langle r^3, rj \rangle = \{e, r^3, r^6, rj, r^4j, r^7j\}.
\end{align*}
$$
</div>
<p>Overall, we’ll have the following subgroups. These lines indicate whether the subgroup is contained in another subgroup so \(\{e\}\) is contained in all of them. \(\langle r^3 \rangle\) is contained in \(\langle r^3, j \rangle\).</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec13-cosets/d9.png" width="90%" class="center" /></p>
<p><br />
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition 2.4.14 Let \(H\) be subgroup of a group \(G\). \(gH = \{gh \ | \ h \in H\}\) is called a left coset of \(H\) in \(G\). \(Hg = \{hg \ | \ h \in H\}\) is called a right coset of \(H\) in \(G\). Examples Example 1: Let \(D_4 = \{e, r, r^2, r^3, j, rj, r^2j, r^3j\}\). where \(r^4 = e = j^2\) and \(jr = r^{-1}j\). Define the subgroup \(H = \langle j \rangle = \{e, j\}\). The left cosets are: $$ \begin{align*} eH &amp;= \{e, j\} = jH \\ rH &amp;= \{r, rj\} = rjH \\ r^2H &amp;= \{r^2, r^2j\} = r^2jH \\ r^3H &amp;= \{r^3, r^3j\} = r^3jH \\ \end{align*} $$ Notice here that none of the elements overlap between the sets so this gives us a way to partition the set \(G\) into four pairwise disjoint subsets (We’ll prove this next). The right cosets are $$ \begin{align*} He &amp;= \{e, j\} = Hj \\ Hr &amp;= \{r, jr\} = \{e, r^3j\} = Hr^3j \\ Hr^2 &amp;= \{r^2, r^2j\} = Hr^2j \\ Hr^3 &amp;= \{r^3, rj\} = Hrj \\ \end{align*} $$ Example 2: Let \(G = \mathbf{Z}\) (with addition) and take \(H = \mathbf{Z}n \leq G\) where \(n \geq 1\). The left coset is \(a + H = a + \mathbf{Z}n = \{a + kn \ | \ k \in \mathbf{Z}\}\) The left coset is \(H + a = \mathbf{Z}n + a\) which is the same as the right coset. This happens because the group is abelian! Another name for these cosets are the congruence class \([a]_n\). Cosets are Pairwise Disjoint Next we show why these subets must be pairwise disjoint. Proposition (2.5.4) Let \(H\) be a subgroup of a group \(G\). If \(X, Y \subseteq G\) are left \(H-\)cosets, then either \(X \cap Y = \emptyset\). \(X = Y\). Proof We’ll prove that not (1) implies (2) (to prove an or statement). Suppose that \(g \in X \cap Y\). We want to show that \(X = Y\). Since \(X\) and \(Y\) are left cosets, then we can write \(X = xH\) and \(Y = yH\) for some \(x, y \in G\). Since \(g \in X \cap Y\), then we can write \(g = xh_1 = yh_2\) for some \(h_1, h_2 \in H\). Observe now that $$ \begin{align*} x &amp;= gh_1^{-1} \\ &amp;= (yh_2)h_1^{-1} \\ &amp;= y(h_2h_1^{-1}) \end{align*} $$ Likewise $$ \begin{align*} y &amp;= gh_2^{-1} \\ &amp;= (xh_1)h_2^{-1} \\ &amp;= x(h_1h_2^{-1}) \end{align*} $$ Now, let \(xh \in xH\), then $$ \begin{align*} xh &amp;= (yh_2h_1^{-1})h \\ &amp;= y(h_2h_1^{-1}h) \end{align*} $$ But this implies that \(xh \in yH\). So \(xH \subseteq yH\). Likewise, let \(yh \in yH\), then $$ \begin{align*} yh &amp;= (xh_1h_2^{-1})h \\ &amp;= x(h_1h_2^{-1}h) \end{align*} $$ so \(yh \in xH\) and \(yH \subseteq xH\). Therefore \(xH = yH\). \(\blacksquare\) Based on this, we have the following proposition Proposition 2.5.3 Let \(H\) be a subgroup of a group \(G\), and let \(a\) and \(b\) be elements of \(G\). The following conditions are equivalent: \(a \in bH\). \(b \in aH\). \(aH = bH\). \(b^{-1}a \in H\). \(a^{-1}b \in H\). Proof (book) Suppose \((a)\) holds. Let \(a \in bH\). Then we can write \(a = bh\). Since \(H\) is a subgroup, then we know \(h^{-1} \in H\). So we can write \(b = ah^{-1}\). But \(ah^{-1}\) is in \(aH\) by the definition of a left coset which is what we wanted to show. With similar reason \((b)\) also implies \((a)\). For \((c)\), we want to show that \(aH \subseteq bH\) and \(bH \subseteq aH\). To show that \(bH \subseteq aH\), we want to show that for any arbitrary element \(x\) in \(bH\), that \(x\) is also in \(aH\). So consider any \(x \in bH\). By the definition of a coset, we can write \(x = bh\) for some \(h \in H\). Now suppose that \((b)\) holds and so we have \(b \in aH\). This means that we can write \(b = ah_1\) for some \(h_1 \in H\). But this means that we can write \(x = bh = ah_1h\). The product \(h_1h\) is in \(H\) because \(H\) is a subgroup. Furthermore, \(ah_1h\) must be in \(aH\) by the definition of a coset. Therefore, \(x = bh \in aH\) and so \(bH \subseteq aH\) as we wanted to show. Since \((b)\) also implies \((a)\) we can use a similar reasoning to show that \(aH \subseteq bH\). For \((d)\) …. Lagrange Theorem Based on what we learned so far, we can now present the following important results Proposition Let \(H\) be a subgroup of a group \(G\). Then all left \(H-\)cosets and right \(H-\)cosets have the same cardinality as \(H\). This works well for infinite groups as well because all we need is a bijection to show they have the same cardinality. Proof We know the coset \(aH\) is constructed such that each element is appended on the left by \(a\). So naturally construct the following bijection $$ \begin{align*} H &amp;\rightarrow aH \\ h &amp;\rightarrow ah \end{align*} $$ This works. For any element in \(x \in aH\), the inverse is just \(a^{-1}x\). Likewise we can construct a bijection for the right coset as follows $$ \begin{align*} H &amp;\rightarrow Ha \\ h &amp;\rightarrow ha \end{align*} $$ This leads to Lagrange Theorem. Lagrange Theorem Let \(G\) be a finite group and let \(H\) be a subgroup of \(G\). Then \(|H|\) divides \(|G|\) and \(|G| / |H| = \) the number of left cosets of \(H\) in \(G =\) the number of right cosets of \(H\) in \(G\). Proof We know by the previous proposition that all cosets have the same cardinality as \(H\) itself. Moreover, we know that the collection of left cosets \(\{aH, a \in G\}\) partitions \(G\) into pairwise disjoint subsets. Therefore $$ \begin{align*} |G| &amp;= \sum|aH| \\ &amp;= \sum |H| \quad \text{(by the previous proposition)} \end{align*} $$ From this we see that \(|G| = m|H|\) as we wanted to show. \(\ \blacksquare\) This in turn leads to the following theorem: Order Theorem Let \(G\) be a finite group. Then for any \(g \in G\), \(o(g)\) divides \(|G|\). Proof [TODO] More Definitions in Cosets Definition The index of a subgroup \(H \leq G\) is the number of left \(H-\)cosets. We denote the index by \([G:H]\) which is index of \(H\) in \(G\). The index could be infinite but we only care when the index is finite. Using Lagrange’s Theorem also note that if \(G\) is finite, then \([G : H] = \frac{|G|}{|H|}\). Also note that \([G:H]\) can be finite even if \(G\) and \(H\) are infinte. Example: Let \(G = \mathbf{Z}, H = \mathbf{Z_n}\) where \(n &gt; 0\). Then the index of \(\mathbf{Z}_n\) inside \(\mathbf{Z}\) is the number of left cosets which is the number of congruent classes, \([\mathbf{Z}:\mathbf{Z}_n] = n\) We might ask why is the definition is in terms of the number of left cosets and not the right cosets. The answer is in the next proposition Proposition Let \(H\) be a subgroup of a group \(G\). There is a bijection between the collection of left cosets and the collection of right cosets. $$ \begin{align*} \{aH, a \in G\} \rightarrow \{Ha, a \in G\} \end{align*} $$ The actual bijection is to take all the elements in the left cosets, take their inverses. The collection of inverses will be the elements in the right cosets. Why is this true? If \(X = aH = \{aH \ | \ h \in H\}\), then \(X^{-1} = \{ (ah)^{-1} \ | \ h \in H \} = Ha^{-1}\). So why not use \(aH \rightarrow Ha\)? This might not be defined. Proposition Let \(H\) be a subgroup of a group \(G\). The following are equivalent \(H\) is a normal subgroup. Left \(H\)-cosets are the same as right \(H\)-cosets. Every left \(H\)-coset is contained in a right \(H\)-coset. Proof \((3) \rightarrow (1)\): Suppose every left \(H\)-coset is a subset of some right \(H\)-coset. Let \(a \in G\). We want to show that \(H\) is a normal subgroup. So we want to show that \(aHa^{-1} \subseteq H\). Given that every left coset in contained in a right coset, consider the left coset \(aH\). This coset is contained in some right coset. Since \(a \in aH\), then \(a\) must be in the right coset as well. We can claim that \(aH \subseteq Ha\). So for any \(h \in H\), \(ah = h'a\) for some \(h' \in H\). Observe that \(aha^{-1} = h'\) for some \(h' \in H\). In other words, \(aHa^{-1} \in H\) and \(H\) is normal. \(\ \blacksquare\) Applications Let’s look at some applications of the order theorem. Proposition If \(|G| = p\) where \(p\) is prime, then \(G\) is cyclic. Proof Let \(g \in G\). By the order theorem, the order of \(g\) must divide \(|G|\) which is a prime number. So \(o(g) \in \{1, p\}\). \(\{e\}\) is the only group with order 1 and \(|G| = p &gt; 1\) so we must have an element \(g \in G\) such that \(g \neq e\). So \(o(g) = p\). But we also said that the order of an element is also the size of the cyclic group generated by \(g\) so \(|\langle g \rangle| = p\). Therefore, we must have \(G = \langle g \rangle\). \(\ \blacksquare\) Proposition If \(|G| = 4\), then \(G\) is isomorphic to \(\mathbf{Z}_4\) or \(V\) the symmetries of the rectangle. Proof Let \(g \in G\). The order of \(g\) has to divide 4 by the order theorem so \(o(g) \in \{1,2,4\}\). If \(o(g) = 4\), then \(o(g) = 4\) and \(\langle g \rangle = G\) so \(G\) is cyclic and so it is isomorphic to \(\mathbf{Z}_4\). If \(o(g) \neq 4\). Then \(G\) must have 4 distinct elements so \(G = \{a, b, c, d\}\) none of the elements can have order 4. \(a, b, c\) can’t have order 1. So they must be of order 2 and their squares must be the identity. This gives us enough information fill out the multiplication table of this group as follows: \(e\) \(a\) \(b\) \(c\) \(e\) \(e\) \(a\) \(b\) \(c\) \(a\) \(a\) \(e\) \(c\) \(b\) \(b\) \(b\) \(c\) \(e\) \(a\) \(c\) \(c\) \(b\) \(a\) \(e\) Subgroups of \(D_5\) Let’s use Lagrange’s Theorem next. Specifically, let’s analyze the subgroups of the dihedral group \(D_5\). We know \(|D_5| = 10\) so the orders of the elements must divide 10. In this case, we have \(o(r) = o(r^2) = o(r^3) = o(r^4) = 5\). While the flips have order \(2\). This is a result of the identities we established: \(j^2 = e\) and \(r^n = e\). Note here that both 2 and 5 divide 10 as we expect. $$ \begin{align*} D_5 = \{e, r, r^2, r^3, r^4, j, rj, r^2j, r^3j, r^4,j\} \end{align*} $$ Now, any subgroup of \(G\) must have order dividing the order of \(G\) so they must divide 10 by Lagrange’s Theorem. So \(|H| \in \{1,2,5,10\}\). Note here that 2 and 5 are prime! so by the previous proposition, they must be cyclic! We can draw the subgroups as follows by their orders: Notice that there is 1 group of order 5 while there are 5 groups of order 2. Subgroups of \(D_9\) We know \(|D_9| = 18\) so the order of any subgroup \(H \leq D\) must divide 18 so \(|H| \in \{1,2,3,6,9,19\}\). $$ \begin{align*} D_5 = \{e, r, r^2, r^3, r^4, r^5, r^6, r^7, r^8, j, rj, r^2j, r^3j, r^4j, r^5j, r^6j, r^7j, r^8j\} \end{align*} $$ If the subgroup order was 2 or 3, then we know they must be cyclic. In this case, we know all the flips have order 2 so they’re all cyclic unique subgroups. $$ \begin{align*} \langle j\rangle, \langle rj \rangle, \rangle r^2j \rangle, \langle r^3j \rangle, \langle r^4j \rangle, \langle r^5j \rangle, \langle r^6j \rangle, \langle r^7j \rangle, \langle r^8j \rangle \end{align*} $$ But what about the rest of the subgroups? For order 3, we can observe that \(\langle r^3 \rangle\) has 3 elements. What about order 6? This one is not obvious. One thing we do know is that any element in that subgroup must have order dividing the order of the subgroup. So any element in it must divide 6. Here it’s trial and error. For example guessing \(\langle r^3, j \rangle\), we see that it consists of $$ \begin{align*} \langle r^3, j \rangle = \{e, r^3, r^6, j, r^3j, r^6j\}. \end{align*} $$ Notice here that \(jr^3 = r^6j\) by the identity \(jr^k = r^{-k}j\). Is there another group of order 6? Instead of \(j\), we can try another element of order 3: $$ \begin{align*} \langle r^3, rj \rangle = \{e, r^3, r^6, rj, r^4j, r^7j\}. \end{align*} $$ Overall, we’ll have the following subgroups. These lines indicate whether the subgroup is contained in another subgroup so \(\{e\}\) is contained in all of them. \(\langle r^3 \rangle\) is contained in \(\langle r^3, j \rangle\). References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 12: Homomorphism</title><link href="http://localhost:4000/jekyll/update/2025/02/04/math417-12-homomorphism.html" rel="alternate" type="text/html" title="Lecture 12: Homomorphism" /><published>2025-02-04T00:01:36-08:00</published><updated>2025-02-04T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/04/math417-12-homomorphism</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/04/math417-12-homomorphism.html"><![CDATA[<p>While isomorphisms need to be bijections, Homomorphisms do not.</p>
<div class="mintheaderdiv">
Definition 2.4.1
</div>
<div class="mintbodydiv">
A map between groups \(\varphi : G \rightarrow H\) is called a homomorphism if it preserves group multiplication, \(\varphi(g_1)(g_2) = \varphi(g_1)\varphi(g_2)\) for all \(g_1, g_2 \in G\). An endomorphism of \(G\) is a homomorphism \(\varphi: G \rightarrow G\).
</div>
<p><br />
<!----------------------------------------------------------------------------->
So Given a homomorphism, if we find that it’s a bijection, then it is an isomorphism.
<br />
<br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Some Facts about Homomorphisms</b></h4>
<!------------------------------------------------------------------------------>
<div class="peachheaderdiv">
Proposition 2.4.11
</div>
<div class="peachbodydiv">
Let \(\varphi : G \rightarrow H\) and \(\psi : G \rightarrow H\) be homomorphisms of groups.
<ol type="a">
	<li>\(\varphi(e_G) = e_H\)</li>
	<li>For each \(g \in G\), \(\varphi(g^{-1}) = (\varphi(g))^{-1}\)</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof (Book)</b>
<br />
For any \(g \in G\).</p>
<div>
	$$
	\begin{align*}
	\varphi(e_G)\varphi(g) &amp;= \varphi(e_Gg) \quad \text{(because $\varphi$ is a homomorphism)} \\
	                 &amp;= \varphi(g)
	\end{align*}
	$$
</div>
<p>So \(\varphi(e_G)\) is an identity element in \(H\) but by the uniqueness of the identity element, then \(\varphi(e_G) = e_H\). Similarly, for any \(\in G\),</p>
<div>
	$$
	\begin{align*}
	\varphi(g^{-1})\varphi(g) &amp;= \varphi(g^{-1}g) \quad \text{(because $\varphi$ is a homomorphism)} \\
	                 &amp;= \varphi(e_G) \\
					 &amp; = e_H
	\end{align*}
	$$
</div>
<p>And by the uniqueness of the inverse, \(\varphi(g^{-1}) = \varphi(g)^{-1}\). \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>The Image of a Homomorphism</b></h4>
<p>Given a homomorphism \(\varphi\) between two groups \(G\) and \(H\), the image of \(\varphi\) which is a subset of \(H\) is also a subgroup.
<br />
<!------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Given some homomorphism \(\varphi: G \rightarrow H\). The image of this function
	$$
	\begin{align*}
	\varphi(G) = \{\varphi(g) \ : \ g \in G\}
	\end{align*}
	$$
is a subgroup of \(H\).
</div>
<!------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
TODO
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>The Kernel of a Homomorphism</b></h4>
<p>The kernel of a group is simply all the elements such that \(\varphi(g)=e\). 
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition 2.4.14
</div>
<div class="mintbodydiv">
Let \(\varphi: G \rightarrow H\) be a homomorphism of groups. The kernel of the homomorphism \(\varphi\), denoted \(ker(\varphi)\), is \(\varphi^{-1}(e_H) = \{g \in G \ : \ \varphi(g) = e_H\}\).
</div>
<p><br />
In fact, The kernel of a group \(K = ker \ \varphi\) is a subgroup of \(G\). 
<br />
<br />
<b>Proof</b>
<br />
We will show this by showing that the kernel satisfies the subgroup properties:</p>
<ol>
	<li>We know by Proposition 2.4.11, that \(\varphi(e_G) = e_H\) so \(e_G \in K\).</li>
	<li>Closed under product: For any \(a,b \in K\), \(\varphi(a)\varphi(b) = e_He_H = e_H \in K\)</li>
	<li>Closed under inverses: For any \(a \in K\), \(\varphi(a^{-1}) = \varphi(a)^{-1} = e_H^{-1} = e_H\). Therefore,\(a^{-1} \in K\). \(\ \blacksquare\)</li>
</ol>
<p><br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<p><b>Example 1</b>: Consider the following with the addition operation</p>
<div>
	$$
	\begin{align*}
	\pi \ : \ &amp;\mathbf{Z} \rightarrow \mathbf{Z}_n\\
	          &amp;a \rightarrow [a]_n
	\end{align*}
	$$
</div>
<p>\(\pi\) is a homomorphism because \([a+b] = [a] + [b]\). Remember the rule is that \(\varphi(ab) = \varphi(a)\varphi(b)\) where the first operation comes from the first group while the second operation comes from the second group. Here, both groups have addition as their binary operation. 
<br />
<br />
\(\pi\) is also surjective. Since for any element \(h \in \mathbf{Z}_n\), we have an element \(g \in \mathbf{Z}\) such that \(\pi(g) = [g]\). Moreover, we see that \(ker(\pi) = \mathbf{Z}n = \langle n \rangle\).
<br />
<br />
<!----------------------------------------------------------------------------->
<b>Example 2</b>: Suppose \(g \in G\). Let</p>
<div>
	$$
	\begin{align*}
	\varphi \ : \ &amp;\mathbf{Z} \rightarrow G\\
	          &amp;k \rightarrow g^k
	\end{align*}
	$$
</div>
<p>We want to show that \(\varphi(ab) = \varphi(a)\varphi(b)\). But we know that \(\varphi(ab) = g^{a+b} =  g^ag^b = \varphi(a)\varphi(b)\). So \(\varphi\) is a homomorphism. 
<br />
<br />
Note here that the image of \(\varphi\) is the subgroup generated by \(g\), \(\langle g \rangle\). What about the kernel of \(\varphi\)?</p>
<div class="ediv">
  $$
  \begin{equation*}
  ker(\varphi) = \begin{cases} 
  \{0\} \quad &amp;\text{if } o(g) = \infty \\ 
  \mathbf{Z}d \quad \quad &amp;\text{if } o(g) = d
  \end{cases}
  \end{equation*}
  $$
</div>
<p><br />
<!----------------------------------------------------------------------------->
<b>Example 3: </b>Consider the following</p>
<div>
	$$
	\begin{align*}
	\varphi \ : \ &amp;D_n \rightarrow S_n\\
	          &amp;V \rightarrow Sym(V)
	\end{align*}
	$$
</div>
<p>where \(V\) is the vertices of the polygon. In fact \(\varphi(D_n)\) is isomorphic to \(D_n\) and it is a subgroup of \(S_n\).<br />
<br />
<br />
<!----------------------------------------------------------------------------->
<b>Example 4: </b>Consider the following</p>
<div>
	$$
	\begin{align*}
	\varphi \ : \ &amp;S_n \rightarrow GL(\mathbf{R}^{x})\\
	          &amp;\sigma \rightarrow P_{\sigma}
	\end{align*}
	$$
</div>
<p>where \(P_{\sigma}\) is the matrix associated with the permutation \(\sigma\). For example</p>
<div>
	$$
	\begin{align*}
	(1 \ 2 \ 3) \rightarrow 
	\begin{pmatrix}
	0 &amp; 0 &amp; 1 \\
	1 &amp; 0 &amp; 0 \\
	0 &amp; 1 &amp; 0
	\end{pmatrix}
	\end{align*}
	$$
</div>
<!----------------------------------------------------------------------------->
<p><b>Example 5: </b>Consider the following</p>
<div>
	$$
	\begin{align*}
	\psi \ : \ &amp;GL(\mathbf{R}^{x}) \rightarrow \mathbf{R}^{x}\\
	          &amp;P \rightarrow \det(P)
	\end{align*}
	$$
</div>
<p>This is another homomorphism. In fact, The composition of \(\psi \circ \varphi\) is a homomorphism. That is</p>
<div>
	$$
	\begin{align*}
	\psi \circ \varphi \ : \ &amp;S_n \rightarrow \mathbf{R}^{x}\\
	          &amp;\sigma \rightarrow \det(P_{\sigma})
	\end{align*}
	$$
</div>
<p>is a homomorphism. Fact: The composition of two homomorphism is a homomorphism.
<br />
<br />
<!----------------------------------------------------------------------------->
<b>Example 6: </b>Consider \(V\) where \(V\) is a vector space. Now consider the group \((V, +)\) (throw the scalar multiplication away). This is an abelian group. Consider the linear map</p>
<div>
	$$
	\begin{align*}
	T \ : \ &amp;V \rightarrow W
	\end{align*}
	$$
</div>
<p>This is a homomorphism (recall that linear maps need to also to preserve scalar multiplication). Furthermore, \(ker T = \{v \in V \ | \ T(v) = 0\}\) (observe that the kernel is also the nullspace of \(T\)). 
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Normal Subgroups</b></h4>
<p>It turns out that only a certain kind of subgroups could be kernels of homomorphism.
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
	A normal subgroup of \(G\) is a subgroup \(N \leq G\) such that \(gNg^{-1} = N\) for all \(g \in G\) where \(gNg^{-1} = \{gng^{-1} \ | \ n \in N\}\). 
</div>
<p><br />
<!----------------------------------------------------------------------------->
This operation \(x \rightarrow gxg^{-1}\) is called the conjugation of \(x\) by \(g\). The definition says that if we conjeguate all the elements of \(N\) by a fixed element \(g \in G\), then we should get \(N\) back for every \(g\). 
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
To show a subgroup \(N \leq G\) is normal, it suffies to show that \(gNg^{-1} \subseteq N\) for all \(g \in G\).
</div>
<p><br />
That is, we just need to check that each \(gNg^{-1}\) is a subset of \(N\).
<!------------------------------------------------------------------------------>
<br />
<br />
<b>Proof</b>
<br />
Given that \(gNg^{-1} \subseteq N\). We want to show that this implies that \(N \subseteq gNg^{-1}\) which means that \(gNg^{-1} = N\) which is what is required by the definition.
<br />
<br />
Let \(g \in G\) and \(n \in N\). Observe that</p>
<div>
	$$
	\begin{align*}
	n &amp;= (gg^{-1})n(gg^{-1}) \\
	  &amp;= g(g^{-1}ng)g^{-1} \\
	  &amp;= g(x)g^{-1}
	\end{align*}
	$$
</div>
<p>where \(x = g^{-1}ng\). If we show that \(gNg^{-1} \subseteq N\), then we need to show that for any \(n \in N\), this \(n\) can be written as \(n = g^{-1}ng = x\) which means that we want to show that \(x \in N\). But by the hypothesis</p>
<div>
	$$
	\begin{align*}
	 x &amp;= g^{-1}ng \\
	   &amp;= g^{-1}n(g^{-1})^{-1} \\
	   &amp;= ana^{-1} \quad \text{ (let $a = g^{-1}$ where $g^{-1} \in G$)}
	\end{align*}
	$$
</div>
<p>Since \(g^{-1}\) is just an arbitrary element in \(G\), then \(ana^{-1} \in N\) which is what we wanted to show. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Examples</b></h4>
<p>Take \(D_3 = \{e, r, r^2, j, rj, r^2j\}\) where \(r^3 = e = j^2\) and \(jr = r^{-1}j\). This rule also implies \(jr^k = r^{-k}j\). Now suppose we have the subgroup generated by \(j\), \(H = \langle j \rangle = \{e, j\}\). Is this a normal subgroup?
<br />
<br />
For every \(g \in G\), we want to show that \(gHg^{-1} \subseteq H\) so</p>
<div>
	$$
	\begin{align*}
	 eHe^{-1} &amp;= H. \\
	 rHr^{-1} &amp;= \{rer^{-1}, rjr^{-1}\} = \{e, r^2j\} \neq H.
	\end{align*}
	$$
</div>
<p>So we stop here. This is not a normal subgroup. Does \(D_3\) have any normal subgroups? The trivial subgroups are normal subgroups. What about any non-trivial subgroups? It turns out that \(N = \langle r \rangle = \{e,r,r^2\}\) is normal in \(D_3\). We have to check all 6 cases</p>
<div>
	$$
	\begin{align*}
	 eNe^{-1} &amp;= N \\
	 rNr^{-1} &amp;= N \\
	 r^2Nr^{-2} &amp;= N \\
	 jNr^{-1} &amp;= N \\
	 rjN(rj)^{-1} &amp;= N \\
	 r^2jN(r^2j)^{-1} &amp;= N.
	\end{align*}
	$$
</div>
<p>FACT: If \(G\) has some generating set like \(G = \langle g_1, ..., g_r \rangle\), then to check if \(H\) is normal, we just need to show that \(g_kHg_k^{-1}\) for each \(g_i\) in the generating set \(g_1, ... g_k\). So for \(D_3\), we know it is generated by \(\langle r, j \rangle\), so we can check those two.
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Kernels are Normal Subgroups</b></h4>
<p>Back to homomorphisms. It turns out that kernels of homomorphisms are normal subgroups.
<br /></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(\varphi \ : \ G \rightarrow H\) is a homomorphism, then \(K = ker \varphi = \{g \in G \ | \ \varphi(g) = e\} \) is a normal subgroup.
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof</b>
<br />
We know that \(k\) is a subgroup of \(G\). We need to show that given \(g \in G\) and \(x \in K\) that \(gxg^{-1} \in K\). By definition, to check if any element is in the kernel, we need to apply the homomorphism and see if the result is the identity element. So</p>
<div>
	$$
	\begin{align*}
	 \varphi(gNg^{-1}) &amp;= \varphi(g)\varphi(x)\varphi(g)^{-1} \\
					  &amp;= \varphi(g)e\varphi(g)^{-1} \\
					  &amp;= \varphi(g)\varphi(g)^{-1} \\
					  &amp;= e.
	\end{align*}
	$$
</div>
<p>From this, we see \(gKg^{-1} \subseteq K\) for all \(g \in G\). \(\blacksquare\)
<br />
<br />
Note also that all subgroups of abelian groups are normal.
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Injectivity of Homomorphisms</b></h4>
<p>Another useful fact:
<br /></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(\varphi \ : \ G \rightarrow H\) be a homomorphism, then \(\varphi\) is injective if and only if \(K = ker(\varphi) = \{e\} \).
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof</b>
<br />
\(\Longrightarrow\): Suppose that \(\varphi\) is injective. This means that if \(\varphi(a) = \varphi(e) = e\), then \(a = e\). But this means that the only element where \(\varphi(a) = e\) is the identity element itself. [why must \(varphi(e)=e\)? I can’t remember, verify].
<br />
<br />
\(\Longleftarrow\):Now suppose that \(K = ker(\varphi) = \{e\}\). We want to show that \(\varphi\) is injective. This means that for any elements \(a, b \in G\), if \(\varphi(a) = \varphi(b)\), then we must have \(a = b\). Let \(\varphi(a) = \varphi(b) = h \in H\). We want to show that \(a = b\). Observe that</p>
<div>
	$$
	\begin{align*}
	 \varphi(a^{-1}b) &amp;= \varphi(a)^{-1}\varphi(b) \\
					  &amp;= h^{-1}h \\
					  &amp;= e_H.
	\end{align*}
	$$
</div>
<p>Since \(\varphi(a^{-1}b) = e_H\), then this implies that \(a^{-1}b \in K\). But \(K\) has only a single element which is the identity. Then \(a^{-1}b = e\) which means that \(a = b\) as desired. \(\ \blacksquare\)
<br />
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[While isomorphisms need to be bijections, Homomorphisms do not. Definition 2.4.1 A map between groups \(\varphi : G \rightarrow H\) is called a homomorphism if it preserves group multiplication, \(\varphi(g_1)(g_2) = \varphi(g_1)\varphi(g_2)\) for all \(g_1, g_2 \in G\). An endomorphism of \(G\) is a homomorphism \(\varphi: G \rightarrow G\). So Given a homomorphism, if we find that it’s a bijection, then it is an isomorphism. Some Facts about Homomorphisms Proposition 2.4.11 Let \(\varphi : G \rightarrow H\) and \(\psi : G \rightarrow H\) be homomorphisms of groups. \(\varphi(e_G) = e_H\) For each \(g \in G\), \(\varphi(g^{-1}) = (\varphi(g))^{-1}\) Proof (Book) For any \(g \in G\). $$ \begin{align*} \varphi(e_G)\varphi(g) &amp;= \varphi(e_Gg) \quad \text{(because $\varphi$ is a homomorphism)} \\ &amp;= \varphi(g) \end{align*} $$ So \(\varphi(e_G)\) is an identity element in \(H\) but by the uniqueness of the identity element, then \(\varphi(e_G) = e_H\). Similarly, for any \(\in G\), $$ \begin{align*} \varphi(g^{-1})\varphi(g) &amp;= \varphi(g^{-1}g) \quad \text{(because $\varphi$ is a homomorphism)} \\ &amp;= \varphi(e_G) \\ &amp; = e_H \end{align*} $$ And by the uniqueness of the inverse, \(\varphi(g^{-1}) = \varphi(g)^{-1}\). \(\ \blacksquare\) The Image of a Homomorphism Given a homomorphism \(\varphi\) between two groups \(G\) and \(H\), the image of \(\varphi\) which is a subset of \(H\) is also a subgroup. Proposition Given some homomorphism \(\varphi: G \rightarrow H\). The image of this function $$ \begin{align*} \varphi(G) = \{\varphi(g) \ : \ g \in G\} \end{align*} $$ is a subgroup of \(H\). Proof TODO The Kernel of a Homomorphism The kernel of a group is simply all the elements such that \(\varphi(g)=e\). Definition 2.4.14 Let \(\varphi: G \rightarrow H\) be a homomorphism of groups. The kernel of the homomorphism \(\varphi\), denoted \(ker(\varphi)\), is \(\varphi^{-1}(e_H) = \{g \in G \ : \ \varphi(g) = e_H\}\). In fact, The kernel of a group \(K = ker \ \varphi\) is a subgroup of \(G\). Proof We will show this by showing that the kernel satisfies the subgroup properties: We know by Proposition 2.4.11, that \(\varphi(e_G) = e_H\) so \(e_G \in K\). Closed under product: For any \(a,b \in K\), \(\varphi(a)\varphi(b) = e_He_H = e_H \in K\) Closed under inverses: For any \(a \in K\), \(\varphi(a^{-1}) = \varphi(a)^{-1} = e_H^{-1} = e_H\). Therefore,\(a^{-1} \in K\). \(\ \blacksquare\) Examples Example 1: Consider the following with the addition operation $$ \begin{align*} \pi \ : \ &amp;\mathbf{Z} \rightarrow \mathbf{Z}_n\\ &amp;a \rightarrow [a]_n \end{align*} $$ \(\pi\) is a homomorphism because \([a+b] = [a] + [b]\). Remember the rule is that \(\varphi(ab) = \varphi(a)\varphi(b)\) where the first operation comes from the first group while the second operation comes from the second group. Here, both groups have addition as their binary operation. \(\pi\) is also surjective. Since for any element \(h \in \mathbf{Z}_n\), we have an element \(g \in \mathbf{Z}\) such that \(\pi(g) = [g]\). Moreover, we see that \(ker(\pi) = \mathbf{Z}n = \langle n \rangle\). Example 2: Suppose \(g \in G\). Let $$ \begin{align*} \varphi \ : \ &amp;\mathbf{Z} \rightarrow G\\ &amp;k \rightarrow g^k \end{align*} $$ We want to show that \(\varphi(ab) = \varphi(a)\varphi(b)\). But we know that \(\varphi(ab) = g^{a+b} = g^ag^b = \varphi(a)\varphi(b)\). So \(\varphi\) is a homomorphism. Note here that the image of \(\varphi\) is the subgroup generated by \(g\), \(\langle g \rangle\). What about the kernel of \(\varphi\)? $$ \begin{equation*} ker(\varphi) = \begin{cases} \{0\} \quad &amp;\text{if } o(g) = \infty \\ \mathbf{Z}d \quad \quad &amp;\text{if } o(g) = d \end{cases} \end{equation*} $$ Example 3: Consider the following $$ \begin{align*} \varphi \ : \ &amp;D_n \rightarrow S_n\\ &amp;V \rightarrow Sym(V) \end{align*} $$ where \(V\) is the vertices of the polygon. In fact \(\varphi(D_n)\) is isomorphic to \(D_n\) and it is a subgroup of \(S_n\). Example 4: Consider the following $$ \begin{align*} \varphi \ : \ &amp;S_n \rightarrow GL(\mathbf{R}^{x})\\ &amp;\sigma \rightarrow P_{\sigma} \end{align*} $$ where \(P_{\sigma}\) is the matrix associated with the permutation \(\sigma\). For example $$ \begin{align*} (1 \ 2 \ 3) \rightarrow \begin{pmatrix} 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \end{pmatrix} \end{align*} $$ Example 5: Consider the following $$ \begin{align*} \psi \ : \ &amp;GL(\mathbf{R}^{x}) \rightarrow \mathbf{R}^{x}\\ &amp;P \rightarrow \det(P) \end{align*} $$ This is another homomorphism. In fact, The composition of \(\psi \circ \varphi\) is a homomorphism. That is $$ \begin{align*} \psi \circ \varphi \ : \ &amp;S_n \rightarrow \mathbf{R}^{x}\\ &amp;\sigma \rightarrow \det(P_{\sigma}) \end{align*} $$ is a homomorphism. Fact: The composition of two homomorphism is a homomorphism. Example 6: Consider \(V\) where \(V\) is a vector space. Now consider the group \((V, +)\) (throw the scalar multiplication away). This is an abelian group. Consider the linear map $$ \begin{align*} T \ : \ &amp;V \rightarrow W \end{align*} $$ This is a homomorphism (recall that linear maps need to also to preserve scalar multiplication). Furthermore, \(ker T = \{v \in V \ | \ T(v) = 0\}\) (observe that the kernel is also the nullspace of \(T\)). Normal Subgroups It turns out that only a certain kind of subgroups could be kernels of homomorphism. Definition A normal subgroup of \(G\) is a subgroup \(N \leq G\) such that \(gNg^{-1} = N\) for all \(g \in G\) where \(gNg^{-1} = \{gng^{-1} \ | \ n \in N\}\). This operation \(x \rightarrow gxg^{-1}\) is called the conjugation of \(x\) by \(g\). The definition says that if we conjeguate all the elements of \(N\) by a fixed element \(g \in G\), then we should get \(N\) back for every \(g\). Proposition To show a subgroup \(N \leq G\) is normal, it suffies to show that \(gNg^{-1} \subseteq N\) for all \(g \in G\). That is, we just need to check that each \(gNg^{-1}\) is a subset of \(N\). Proof Given that \(gNg^{-1} \subseteq N\). We want to show that this implies that \(N \subseteq gNg^{-1}\) which means that \(gNg^{-1} = N\) which is what is required by the definition. Let \(g \in G\) and \(n \in N\). Observe that $$ \begin{align*} n &amp;= (gg^{-1})n(gg^{-1}) \\ &amp;= g(g^{-1}ng)g^{-1} \\ &amp;= g(x)g^{-1} \end{align*} $$ where \(x = g^{-1}ng\). If we show that \(gNg^{-1} \subseteq N\), then we need to show that for any \(n \in N\), this \(n\) can be written as \(n = g^{-1}ng = x\) which means that we want to show that \(x \in N\). But by the hypothesis $$ \begin{align*} x &amp;= g^{-1}ng \\ &amp;= g^{-1}n(g^{-1})^{-1} \\ &amp;= ana^{-1} \quad \text{ (let $a = g^{-1}$ where $g^{-1} \in G$)} \end{align*} $$ Since \(g^{-1}\) is just an arbitrary element in \(G\), then \(ana^{-1} \in N\) which is what we wanted to show. \(\ \blacksquare\) Examples Take \(D_3 = \{e, r, r^2, j, rj, r^2j\}\) where \(r^3 = e = j^2\) and \(jr = r^{-1}j\). This rule also implies \(jr^k = r^{-k}j\). Now suppose we have the subgroup generated by \(j\), \(H = \langle j \rangle = \{e, j\}\). Is this a normal subgroup? For every \(g \in G\), we want to show that \(gHg^{-1} \subseteq H\) so $$ \begin{align*} eHe^{-1} &amp;= H. \\ rHr^{-1} &amp;= \{rer^{-1}, rjr^{-1}\} = \{e, r^2j\} \neq H. \end{align*} $$ So we stop here. This is not a normal subgroup. Does \(D_3\) have any normal subgroups? The trivial subgroups are normal subgroups. What about any non-trivial subgroups? It turns out that \(N = \langle r \rangle = \{e,r,r^2\}\) is normal in \(D_3\). We have to check all 6 cases $$ \begin{align*} eNe^{-1} &amp;= N \\ rNr^{-1} &amp;= N \\ r^2Nr^{-2} &amp;= N \\ jNr^{-1} &amp;= N \\ rjN(rj)^{-1} &amp;= N \\ r^2jN(r^2j)^{-1} &amp;= N. \end{align*} $$ FACT: If \(G\) has some generating set like \(G = \langle g_1, ..., g_r \rangle\), then to check if \(H\) is normal, we just need to show that \(g_kHg_k^{-1}\) for each \(g_i\) in the generating set \(g_1, ... g_k\). So for \(D_3\), we know it is generated by \(\langle r, j \rangle\), so we can check those two. Kernels are Normal Subgroups Back to homomorphisms. It turns out that kernels of homomorphisms are normal subgroups. Proposition If \(\varphi \ : \ G \rightarrow H\) is a homomorphism, then \(K = ker \varphi = \{g \in G \ | \ \varphi(g) = e\} \) is a normal subgroup. Proof We know that \(k\) is a subgroup of \(G\). We need to show that given \(g \in G\) and \(x \in K\) that \(gxg^{-1} \in K\). By definition, to check if any element is in the kernel, we need to apply the homomorphism and see if the result is the identity element. So $$ \begin{align*} \varphi(gNg^{-1}) &amp;= \varphi(g)\varphi(x)\varphi(g)^{-1} \\ &amp;= \varphi(g)e\varphi(g)^{-1} \\ &amp;= \varphi(g)\varphi(g)^{-1} \\ &amp;= e. \end{align*} $$ From this, we see \(gKg^{-1} \subseteq K\) for all \(g \in G\). \(\blacksquare\) Note also that all subgroups of abelian groups are normal. Injectivity of Homomorphisms Another useful fact: Proposition Let \(\varphi \ : \ G \rightarrow H\) be a homomorphism, then \(\varphi\) is injective if and only if \(K = ker(\varphi) = \{e\} \). Proof \(\Longrightarrow\): Suppose that \(\varphi\) is injective. This means that if \(\varphi(a) = \varphi(e) = e\), then \(a = e\). But this means that the only element where \(\varphi(a) = e\) is the identity element itself. [why must \(varphi(e)=e\)? I can’t remember, verify]. \(\Longleftarrow\):Now suppose that \(K = ker(\varphi) = \{e\}\). We want to show that \(\varphi\) is injective. This means that for any elements \(a, b \in G\), if \(\varphi(a) = \varphi(b)\), then we must have \(a = b\). Let \(\varphi(a) = \varphi(b) = h \in H\). We want to show that \(a = b\). Observe that $$ \begin{align*} \varphi(a^{-1}b) &amp;= \varphi(a)^{-1}\varphi(b) \\ &amp;= h^{-1}h \\ &amp;= e_H. \end{align*} $$ Since \(\varphi(a^{-1}b) = e_H\), then this implies that \(a^{-1}b \in K\). But \(K\) has only a single element which is the identity. Then \(a^{-1}b = e\) which means that \(a = b\) as desired. \(\ \blacksquare\) References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 11: Dihedral Groups</title><link href="http://localhost:4000/jekyll/update/2025/02/03/math417-11-dihedral-groups.html" rel="alternate" type="text/html" title="Lecture 11: Dihedral Groups" /><published>2025-02-03T00:01:36-08:00</published><updated>2025-02-03T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/03/math417-11-dihedral-groups</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/03/math417-11-dihedral-groups.html"><![CDATA[<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
The Dihedral group is the group of rotational symmetries of a regular n-gon in \(\mathbf{R}^3\). It is a subgroup of the special orthogonal matrices, \(SO(3)\).
</div>
<p><br />
Before discussing the Dihedral group, we will discuss the symmetries of the disk. Why? if you inscribe a regular polygon inside a circle, observe that the symmetries of the polygon are a subset of the symmetries of the circle/disk. So it’s helpful to start there.
<br />
<br />
<!------------------------------------------------------------------------------></p>
<h4><b>Symmetries of the Disk</b></h4>
<p>Let \(D \leq SO(3)\) be the rotational symmetries of the unit disk: \(\{(x,y,0) \ | \ x^2 + y^2 = 1 \}\). There are two types of rotations in \(D\). A rotation \(g\) around the \(z-\)axis so the \(z-\)axis remains fixed and we’re spinning the disk around it. Here \(g(e_3) = e_3\). The other type is when we flip the disk so the \(z-\)axis is now reversed. Here \(g(e_3) = -e_3\).
<br />
<!------------------------------------------------------------------------------></p>
<h4><b>Rotations Around the \(z-\)axis</b></h4>
<p>A rotation around an arbitrary angle which is \(r_{\theta} = Rot_{e_3}(\theta)\). It is always a symmetry around the unit disk. Note here that \(r_0=e\) and if we rotate by more than \(2\pi\), then it’s a rotation we’ve seen before. So \(r_{\theta + 2\pi n} = r_{\theta}\) so we need to specify \(r_{\theta}\) where \(\theta \in [0, 2\pi)]\). Note also that \(r_{\theta}^{-1} = r_{-\theta}\).
<br />
<br />
<!------------------------------------------------------------------------------></p>
<h4><b>Rotations Around the a Line in the \(xy-\)axis (Flips)</b></h4>
<p>Here the \(z-\)axis will get reversed since we’re flipping the disk by \(180^{\circ}\) (so \(e_3\) will now be \(-e_3\) facing the opposite the direction). The rotation axis itself is parallel to the \(xy\) plane. And we write \(j_{\theta} = Rot_{u_{\theta}}(\pi)\). Just draw a disk and draw any line that goes through the center. This line will be the rotation axis that is fixed and we’re flipping over it.</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec11/disk.png" width="40%" class="center" /></p>
<p>The rotation vector can written as</p>
<div>
	$$
	\begin{align*}
	u_\theta = (\cos \theta)e_1 + (\sin \theta)e_2 + 0e_3
	\end{align*}
	$$
</div>
<p>This vector spans a line \(l_{\theta} = \mathbf{R}u_{\theta}\). This line is in the \(xy\) plane that goes through the vector \(u\). Note here that adding another rotation of \(\pi\) will not change the line so \(j_{\theta + \pi n} = j_{\theta}\). However, the vector \(u_{\theta}\) though will face the other direction after adding \(\pi\) and so \(u_{\theta+\pi} = -u_{\theta}\). Moreover, \(j^2_{\theta} = e\).
<br />
<br />
<!------------------------------------------------------------------------------></p>
<h4><b>Multiplication of Rotations and Flips</b></h4>
<p>To describe the group structure, we want to see what happens if we perform two rotations, two flips, a rotation followed by a flip and a flip followed by a rotation.</p>
<ul>
	<li><b>Two Rotations:</b> This case is easy, since two rotations around the \(z-\)axis (spinning around) is just another rotation so
		<div>
			$$
			\begin{align*}
			r_{\alpha}r_{\beta} = r_{\alpha+\beta}
			\end{align*}
			$$
		</div>
	</li>
	<!------ (2) ------->
	<li><b>A Flip by \(\beta\) followed by a Rotation of \(\alpha\)</b> \(r_{\alpha}j_{\beta}\): 
		<div>
			$$
			\begin{align*}
			r_{\alpha}j_{\beta} = j_{\beta+\frac{\alpha}{2}}
			\end{align*}
			$$
		</div>
		But why? We first flip the disk where \(l_{\beta}\) is fixed like before. After the flip, we rotate the disk around the \(z-\)axis by \(\alpha\) as illustrated below
		<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec11/flip.png" width="90%" class="center" /></p>
		So what we want is to compose these two operations into one and find where the fixed rotation axis will be. If you turn the third figure back to the front and now you want to use one flip to get to the same exact positions of the lines in the third figure, you'll see that the new axis will be \(u_{\beta+\frac{\alpha}{2}}\).
		<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec11/disk1.png" width="40%" class="center" /></p>
	</li>
	<!------ (3) ------->
	<li><b>A Rotation followed by a Flip</b> \(j_{\alpha}r_{\beta}\): 
		<div>
			$$
			\begin{align*}
			j_{\alpha}r_{\beta} = j_{\alpha-\frac{\beta}{2}}
			\end{align*}
			$$
		</div>
	</li>
	<li><b>Two Flips</b> \(j_{\alpha}j_{\beta}\). Now this is clearly a rotation since we're back to the same face. but we're flipping by a different axis each time. The final rotation is the difference of the two times two. (TODO: why times 2?)
		<div>
			$$
			\begin{align*}
			j_{\alpha}j_{\beta} = r_{2(\alpha-\beta)}
			\end{align*}
			$$
		</div>
	</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------></p>
<h4><b>Elements of \(D\)</b></h4>
<p>Based on the previous list, we can now list precisely the elements of (D). We have</p>
<ul>
	<li>\(r_{\theta}\) for unique \(\theta \in [0, 2\pi)\). Noting that \(r_{\theta + 2\pi n} = r_{\theta}\)</li>
	<li>\(j_{\theta}\) for unique \(\theta \in [0, \pi)\). Noting that \(j_{\theta + \pi n} = j_{\theta}\)</li>
</ul>
<p>In addition to the multiplication table based on the previous discussion.</p>
<ul>
	<li>\(r_{\alpha}r_{\beta} = r_{\alpha+\beta}\)</li>
	<li>\(r_{\alpha}j_{\beta} = j_{\beta+\frac{\alpha}{2}}\)</li>
	<li>\(j_{\alpha}r_{\beta} = j_{\alpha-\frac{\beta}{2}}\)</li>
	<li>\(j_{\alpha}j_{\beta} = r_{2(\alpha-\beta)}\)</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------></p>
<h4><b>Alternative Description of \(D\)</b></h4>
<p>Another description is that let \(j = j_{0}\). Then, \(j_{\theta} = r_{2\theta}j\). So every element of \(D\) can be written uniquely in one of the following two forms.</p>
<ul>
	<li>\(r_{\theta}, \theta \in [0, 2\pi]\)</li>
	<li>\(r_{\theta}j, \theta \in [0, 2\pi]\)</li>
</ul>
<p>where</p>
<ul>
	<li>\(r_{\theta + 2\pi n} = r_{\theta}\)</li>
	<li>\(r_{\alpha}r_{\beta} = r_{\alpha+\beta}\)</li>
	<li>\(r_{\alpha + \beta}\)</li>
	<li>\(j^2 = e\)</li>
	<li>\(jr_{\theta} = r_{\theta}^{-1}j\). (TODO: Show this using the previous rules)</li>
</ul>
<p>This is a complete description of \(D\).
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------></p>
<h4><b>Dihedral Groups</b></h4>
<p>Fix \(n \geq 3\). Let \(V = \{u_{\frac{2\pi}{n}k}, k = 0,...,n-1\}\) be the vertices of a regular \(n-\)gon. Note that \(D_n \leq D \leq SO(3)\). Now, the group \(D_n\) will include specifically the symmetries of the disk that take the vertices of the polygon to themselves or another vertex in the polygon. In \(D_n\),</p>
<div>
	$$
	\begin{align*}
	r_{\frac{2\pi}{n}} = r = Rot_{\frac{2\pi}{n}}(e_3)
	\end{align*}
	$$
</div>
<p>Rotations in \(D_n\) are therefore: \(e, r, r^2, r^3, ..., r^{n-1}\) where \(r^{k+n} = r^k\).<br />
Flips in \(D_n\) are \(j, rj, r^2,...,r^{n-1}j\) since we established that \(j_{\frac{\pi}{n}k} = r_{\frac{2\pi}{n}}j_0\). In general, we’ll have \(n\) flips for an \(n-\)polygon illustrated as follows</p>

<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec11/flips.png" width="70%" class="center" /></p>

<p>Note that \(D_n\) has \(2n\) symmetries total and we have the following identities:</p>
<ul>
	<li>\(r^n = e\)</li>
	<li>\(j^2 = e\)</li>
	<li>\(jr = r^{-1}j\)</li>
	<li>\(j^2 = e\)</li>
</ul>
<p>Notice also that this group is generated by two elements so \(D_n = \langle r, j\rangle\). Overall, you will see that</p>
<div>
	$$
	\begin{align*}
	D_3 &amp;= \{e, r, r^2, j, rj, r^2j\} \\
	D_4 &amp;= \{e, r, r^2, r^3, j, rj, r^2j, r^3j\}
	\end{align*}
	$$
</div>
<p><br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition The Dihedral group is the group of rotational symmetries of a regular n-gon in \(\mathbf{R}^3\). It is a subgroup of the special orthogonal matrices, \(SO(3)\). Before discussing the Dihedral group, we will discuss the symmetries of the disk. Why? if you inscribe a regular polygon inside a circle, observe that the symmetries of the polygon are a subset of the symmetries of the circle/disk. So it’s helpful to start there. Symmetries of the Disk Let \(D \leq SO(3)\) be the rotational symmetries of the unit disk: \(\{(x,y,0) \ | \ x^2 + y^2 = 1 \}\). There are two types of rotations in \(D\). A rotation \(g\) around the \(z-\)axis so the \(z-\)axis remains fixed and we’re spinning the disk around it. Here \(g(e_3) = e_3\). The other type is when we flip the disk so the \(z-\)axis is now reversed. Here \(g(e_3) = -e_3\). Rotations Around the \(z-\)axis A rotation around an arbitrary angle which is \(r_{\theta} = Rot_{e_3}(\theta)\). It is always a symmetry around the unit disk. Note here that \(r_0=e\) and if we rotate by more than \(2\pi\), then it’s a rotation we’ve seen before. So \(r_{\theta + 2\pi n} = r_{\theta}\) so we need to specify \(r_{\theta}\) where \(\theta \in [0, 2\pi)]\). Note also that \(r_{\theta}^{-1} = r_{-\theta}\). Rotations Around the a Line in the \(xy-\)axis (Flips) Here the \(z-\)axis will get reversed since we’re flipping the disk by \(180^{\circ}\) (so \(e_3\) will now be \(-e_3\) facing the opposite the direction). The rotation axis itself is parallel to the \(xy\) plane. And we write \(j_{\theta} = Rot_{u_{\theta}}(\pi)\). Just draw a disk and draw any line that goes through the center. This line will be the rotation axis that is fixed and we’re flipping over it. The rotation vector can written as $$ \begin{align*} u_\theta = (\cos \theta)e_1 + (\sin \theta)e_2 + 0e_3 \end{align*} $$ This vector spans a line \(l_{\theta} = \mathbf{R}u_{\theta}\). This line is in the \(xy\) plane that goes through the vector \(u\). Note here that adding another rotation of \(\pi\) will not change the line so \(j_{\theta + \pi n} = j_{\theta}\). However, the vector \(u_{\theta}\) though will face the other direction after adding \(\pi\) and so \(u_{\theta+\pi} = -u_{\theta}\). Moreover, \(j^2_{\theta} = e\). Multiplication of Rotations and Flips To describe the group structure, we want to see what happens if we perform two rotations, two flips, a rotation followed by a flip and a flip followed by a rotation. Two Rotations: This case is easy, since two rotations around the \(z-\)axis (spinning around) is just another rotation so $$ \begin{align*} r_{\alpha}r_{\beta} = r_{\alpha+\beta} \end{align*} $$ A Flip by \(\beta\) followed by a Rotation of \(\alpha\) \(r_{\alpha}j_{\beta}\): $$ \begin{align*} r_{\alpha}j_{\beta} = j_{\beta+\frac{\alpha}{2}} \end{align*} $$ But why? We first flip the disk where \(l_{\beta}\) is fixed like before. After the flip, we rotate the disk around the \(z-\)axis by \(\alpha\) as illustrated below So what we want is to compose these two operations into one and find where the fixed rotation axis will be. If you turn the third figure back to the front and now you want to use one flip to get to the same exact positions of the lines in the third figure, you'll see that the new axis will be \(u_{\beta+\frac{\alpha}{2}}\). A Rotation followed by a Flip \(j_{\alpha}r_{\beta}\): $$ \begin{align*} j_{\alpha}r_{\beta} = j_{\alpha-\frac{\beta}{2}} \end{align*} $$ Two Flips \(j_{\alpha}j_{\beta}\). Now this is clearly a rotation since we're back to the same face. but we're flipping by a different axis each time. The final rotation is the difference of the two times two. (TODO: why times 2?) $$ \begin{align*} j_{\alpha}j_{\beta} = r_{2(\alpha-\beta)} \end{align*} $$ Elements of \(D\) Based on the previous list, we can now list precisely the elements of (D). We have \(r_{\theta}\) for unique \(\theta \in [0, 2\pi)\). Noting that \(r_{\theta + 2\pi n} = r_{\theta}\) \(j_{\theta}\) for unique \(\theta \in [0, \pi)\). Noting that \(j_{\theta + \pi n} = j_{\theta}\) In addition to the multiplication table based on the previous discussion. \(r_{\alpha}r_{\beta} = r_{\alpha+\beta}\) \(r_{\alpha}j_{\beta} = j_{\beta+\frac{\alpha}{2}}\) \(j_{\alpha}r_{\beta} = j_{\alpha-\frac{\beta}{2}}\) \(j_{\alpha}j_{\beta} = r_{2(\alpha-\beta)}\) Alternative Description of \(D\) Another description is that let \(j = j_{0}\). Then, \(j_{\theta} = r_{2\theta}j\). So every element of \(D\) can be written uniquely in one of the following two forms. \(r_{\theta}, \theta \in [0, 2\pi]\) \(r_{\theta}j, \theta \in [0, 2\pi]\) where \(r_{\theta + 2\pi n} = r_{\theta}\) \(r_{\alpha}r_{\beta} = r_{\alpha+\beta}\) \(r_{\alpha + \beta}\) \(j^2 = e\) \(jr_{\theta} = r_{\theta}^{-1}j\). (TODO: Show this using the previous rules) This is a complete description of \(D\). Dihedral Groups Fix \(n \geq 3\). Let \(V = \{u_{\frac{2\pi}{n}k}, k = 0,...,n-1\}\) be the vertices of a regular \(n-\)gon. Note that \(D_n \leq D \leq SO(3)\). Now, the group \(D_n\) will include specifically the symmetries of the disk that take the vertices of the polygon to themselves or another vertex in the polygon. In \(D_n\), $$ \begin{align*} r_{\frac{2\pi}{n}} = r = Rot_{\frac{2\pi}{n}}(e_3) \end{align*} $$ Rotations in \(D_n\) are therefore: \(e, r, r^2, r^3, ..., r^{n-1}\) where \(r^{k+n} = r^k\). Flips in \(D_n\) are \(j, rj, r^2,...,r^{n-1}j\) since we established that \(j_{\frac{\pi}{n}k} = r_{\frac{2\pi}{n}}j_0\). In general, we’ll have \(n\) flips for an \(n-\)polygon illustrated as follows]]></summary></entry><entry><title type="html">Lecture 09/10: Subgroups</title><link href="http://localhost:4000/jekyll/update/2025/02/02/math417-09-subgroups.html" rel="alternate" type="text/html" title="Lecture 09/10: Subgroups" /><published>2025-02-02T00:01:36-08:00</published><updated>2025-02-02T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/02/math417-09-subgroups</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/02/math417-09-subgroups.html"><![CDATA[<div class="mintheaderdiv">
Definition 2.2.1
</div>
<div class="mintbodydiv">
A non-empty subset \(H\) of a group \(G\) is called a subgroup if \(H\) is itself a group with the group operation inherited from \(G\). We write \(H \leq G\) to indicate that \(H\) is a subgroup of \(G\).
</div>
<!------------------------------------------------------------------------------>
<p><br />
Example:</p>
<ul>
	<li>The group \(SO(3)\), the special orthogonal matrices is a subgroup of \(GL_3(\mathbf{R}\), the group of invertible \(3 \times 3\) matrices. Both of these are under the same operation.</li>
	<li>Non-example: \(\mathbf{Z}_n\): congruence classes modulo \(n\) with addition. We also have \(\phi(n)\): congruence classes with multiplicative inverses. This has the operation multiplication so it's not a subgroup! Even when you define \(\phi(4) = \{[1],[3]\}\) with addition, it will not satisfy the group requirements, so it's not a subgroup.</li>
</ul>
<p>Since we need to check a lot for subgroups. We have a set of necessary conditions.
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
The necessary conditions for a subset \(H\) of \(G\) to be a subgroup of \(G\) are:
<ol>
	<li>\(H\) is not empty</li>
	<li>\(H\) is closed under multiplication. That is, for all elements \(h_1\) and \(h_2\) of \(H\), the products \(h_1h_2\) is also an element of \(H\)</li>
	<li>\(H\) is closed under inverses. For all \(h \in H\), the inverse \(h^{-1}\) is an element of \(H\)</li>
</ol>
</div>
<p><br />
<b>Proof</b>
<br /></p>
<ul>
	<li>\(H\) is associative. For any \(a,b,c \in H\), \((ab)c = a(bc)\). We're inheriting the same operation from \(G\) so \(H\) must be associative.</li>
	<li>\(H\) has an identity element: We know \(H\) is non-empty by (1). We also know for any \(h \in H\), \(h^{-1} \in H\) by (3). By (2), \(H\) is closed under multiplication so \(hh^{-1} \in H\) but \(hh^{-1} = e\) so the identity element is in \(H\).  </li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Consider the group \(G = S_4\) (permutations of \(\{1,2,3,4\}\)). The order of this group is \(|G| = 4\). The following are subgroups of \(S_4\):</p>
<ul>
	<li>\(H=\{ \sigma \in S_4 \ | \ \sigma(4) = 4\}\). So this subgroup fixes \(4\) in the permutation. \(|H| = 3! = 6\). In fact, it is permuting only 3 numbers and it is isomorphic to \(S_3\).</li>
	<!---------------------------->
	<li>\(H'=\{e,(1 \ 2)(3 \ 4), (1 \ 3)(2 \ 4), (1 \ 4)(2 \ 3)\}\). It's not empty. It has the identity element. Every element is its own inverse. The one thing not too obvious is proving it is closed. This subgroup is isomorphic to the symmetry group of the rectangle. What's an isomorphism in this case? Assign \(A\) to 1, \(B\) to 2, \(C\) to 3, \(D\) to 4. Recall that the symmetries of the rectangle has the symmetries \(r_1, r_2, r_3, e\) where \(r_1\) is rotating around the \(x-\)axis. Observe now that \(r_1\)
		<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec10/rect-r1.png" width="45%" class="center" /></p>
	</li>
	rotates the vertices such that \(A\) and \(B\) switch positions and \(C\) and \(D\) switch positions. This is equivalent to the permutation \((1 \ 2)(3 \ 4)\). Following this, we'll see that \(r_2\) gets mapped to \((1 \ 4)(2 \ 3)\) and \(r_3\) gets mapped to \((1 \ 3)(2 \ 4)\).
	<!---------------------------->
	<li>\(H''=\{e,(1 \ 2 \ 3 \ 4)(4 \ 3 \ 2 \ 1), (1 \ 2)(3 \ 4), (1 \ 3)(2 \ 4), (1 \ 4)(2 \ 3), (1 \ 3),(2 \ 4)\}\). This one is isomorphic to \(D_4\) which is the symmetries of the square.</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------></p>
<h4><b>Generated Subgroups</b></h4>
<p>We begin with the following lemma which states that the intersection of a collection of subgroups is another subgroup.
<br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma (Book Proposition 2.2.8)
</div>
<div class="yellowbodydiv">
Let \(G\) be a group and let \(H_1, H_2,...,H_n\) be subgroups of \(G\). Then 
	$$
	\begin{align*}
	H = H_1 \cap H_2 \ \cap ... \cap \ H_n
	\end{align*}
	$$
is a subgroup of \(G\). More generally, if \(\{H_{\alpha}\}\) is any collection of subgroups, then \(\cap_{\alpha}\) is a subgroup.
<!------------------------------------------------------------------------------>
</div>
<p><br />
<b>Proof</b>
<br /></p>
<ol>
<li>Every \(H_i\) is a subgroup. Therefore \(e \in H_i\) for each \(i\) and thus \(e \in H\).</li>
<li>For any two elements \(a, b \in H\), we must have \(a, b \in H_i\) for each \(i\). Their product \(ab\) must also be in every \(H_i\) since each \(H_i\) is a subgroup. Therefore \(ab \in H\).</li>
<li>For any \(a \in H\), \(a\) must be in \(H_i\) for each \(i\). Therefore \(a^{-1} \in H_i \ \forall i\) and thus \(a^{-1} \in H\).</li>
</ol>
<p>Since any intersection of subgroups is another subgroups, we can then define a generated subgroups as follow
<br />
<!------------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Let \(G\) be a group and let \(S\) be a subset of \(G\). Then
	$$
	\begin{align*}
	 \langle S \rangle = \bigcap_{\text{All } H_i \leq G \text{ such that } S \subseteq H_i}
	\end{align*}
	$$
\(\langle S \rangle\) is called <b>the subgroup generated by</b> \(S\) and it is the smallest subgroup in \(G\) that contains \(S\).
</div>
<!------------------------------------------------------------------------------>
<p><br />
Observe that</p>
<ul>
<li>\(\langle S \rangle\) is a subgroup by the previous lemma since it is the intersection of subgroups.</li>
<li>\(S \subseteq \langle S \rangle\).</li>
<li>It is the smallest group that contains \(S\). Because for any subgroup \(K \leq G\) such that \(S \subseteq K\), we must have \(\langle S \rangle \leq K\) (why? because if \(S\) is contained in \(K\) and \(K\) is a group, then all the products of the elements of \(S\) are in \(K\). Same for the inverses. So the whole subgroup \(\langle S \rangle\) must also be contained in \(K\).)</li>
</ul>
<p>Additionally from the book:</p>
<ul>
<li>If \(S\) contains a single element, \(S = \{a\}\), then the subgroup generated by \(S\) is denoted by \(\langle a \rangle\). </li>
<li>If \(G = \langle S \rangle\), then \(G\) is generated by \(S\) or \(S\) generates \(G\)</li>
</ul>
<p>Another way to describe \(\langle S \rangle\) is take a bottom up approach to describe the elements.
<br />
<!------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Suppose \(G\) is a group and \(S\) is a subset of \(G\). Then \(\langle S \rangle\) is equal to the set of elements in \(G\) of the form
	$$
	\begin{align*}
	 g_1g_2...g_k \quad \text{ where either } g_i \in S \text{ or } g_i^{-1} \in S \text{ for all } i.
	\end{align*}
	$$
</div>
<!------------------------------------------------------------------------------>
<p><br />
In other words, \(\langle S \rangle\) is a subgroup such that that it contains all the possible products \(g_1g_2...g_n\) which are in \(S\) or an inverse to an element of \(S\). The set that contains such products is often called the “set of words in \(S\)” in group theory.
<br />
<br />
<b>Proof</b>
<br />
Let \(T\) be the set of words \(\{e\} \cup \{g_1...g_k\}\) where \(g_i \in S\) or \(g_i^{-1} \in S\) for all \(i = 1,...,k\). We need to show that</p>
<ol>
	<li>\(T\) is a subgroup of \(G\). [This is true because \(T\) has the identity element. For any two word, the product of these is just a longer word which is also in \(T\). It is closed under the inverses because \((g_1g_2...g_k)^{-1} = g_k^{-1}...g_1^{-1}\).]</li>
	<li>\(S \subseteq T\). [This is true because all the words of length 1 make up the set \(S\). It is true by construction.]</li>
	<li>If \(K \leq G\) is a subgroup such that \(S \subseteq K\), then \(T \subseteq K\). [This is true because if \(K\) contains \(S\) then it must contain all the inverses of these words and then also the products of all of these words since it's a group (closed) so it has all of these elements and it contains \(T\) itself.]</li>
</ol>
<p>Condition (1) and (2) imply that \(\langle S \rangle \subseteq T\). Conditions (1) and (3) imply that \(T \subseteq \langle S \rangle\). Therefore, \(T = \langle S \rangle\). \(\ \blacksquare\) We’ll use this proposition a lot. 
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Lattice of Subgroups</b></h4>
<p>Consider the group \(S_3 = \{e, (1 \ 2), (1 \ 3), (2 \ 3), (1 \ 2 \ 3), (1 \ 3 \ 2)\}\). We can list its subgroups in terms of its generating subsets as follows:</p>
<ul>
	<li>\(\langle (1 \ 2) \rangle = \{e, (1 \ 2)\}\). This says that the subgroup generated by \(\{(1 \ 2)\}\) is \(\{e, (1 \ 2)\} = \langle (1 \ 2) \rangle \)</li>
	<li>\(\langle (1 \ 3) \rangle = \{e, (1 \ 3)\}\).</li>
	<li>\(\langle (2 \ 3) \rangle = \{e, (2 \ 3)\}\).</li>
	<li>\(\langle (1 \ 2 \ 3) \rangle = \{e, (1 \ 2 \ 3), (1 \ 3 \ 2)\}\) = \(\langle (1 \ 3 \ 2) \rangle\) </li>
	<li>\(S_3 = \langle (1 \ 2), (1 \ 2 \ 3) \rangle\).</li>
</ul>
<p>We can then draw this in the following figure</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec10/lattice1.png" width="55%" class="center" /></p>

<p>Notice also that 	\(S_4 = \langle (1 \ 2 \ 3 \ 4), (2 \ 4) \rangle\).
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Cyclic Groups and Cyclic Subgroups</b></h4>
<p>We’ll start with the definition
<br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A group \(G\) is cyclic if \(G = \langle a \rangle\) for some \(a \in G\). Similarly, a subgroup \(H \leq G\) is cyclic if \(H = \langle a \rangle\) for some \(a \in G\). 
</div>
<!----------------------------------------------------------------------------->
<p><br />
In fact, we can describe all the elements in a cyclic subgroup as follows
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition (Book 2.2.9)
</div>
<div class="peachbodydiv">
Let \(a\) be an element of a group \(G\). The subgroup \(\langle a \rangle\) generated by \(a\) is \(\{a^k \ : \ k \in \mathbf{Z}\}\).
</div>
<p><br />
Note here that this subgroup is abelian!
<br />
<!----------------------------------------------------------------------------->
<br />
<b>Proof (book)</b>
<br />
Let \(H = \{a^k \ : \ k \in \mathbf{Z}\}\). We will show that \(\langle a \rangle = H\) as follows:
<br />
<br />
\(\langle a \rangle \subseteq H\): We know that \(G\) is a group and \(H\) is subset of \(G\). We claim that it is a subgroup of \(G\). It is closed under multiplication because for any \(a^k\) and \(a^l\) in \(H\), \(a^{k+l} \in H\). It is closed under inverses because for any \(a^k \in H\), \((a^{k})^{-1} = a^{-k} \in H\). Furthermore, \(H\) contains \(a\) and since \(H\) is a subgroup, then \(H\) contains all the powers of \(a\). Therefore, \(\langle a \rangle \subseteq H\). 
<br />
<br />
\(H \subseteq \langle a \rangle\): We showed that \(H = \{a^k \ : \ k \in \mathbf{Z}\}\) is a subgroup above. It is closed under multiplication and so it contains all powers of \(a\). Therefore, \(H \subseteq \langle a \rangle\). \(\ \blacksquare\) 
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Example</b></h4>
<p>Suppose \(G = (\mathbf{Z}, + )\). For any element \(a \in \mathbf{Z}\),</p>
<div>
	$$
	\begin{align*}
	 \langle a \rangle = \{ka \ : \ k \in \mathbf{Z}\} = \mathbf{Z}a.
	\end{align*}
	$$
</div>
<ul>
<li>The set of powers of \(a\) is the set of all multiples of \(a\) since the group operation is addition. So \(a+a+a+a+a\) is the fifth power.</li>

<li>If \(a = 0\), then \(\langle a \rangle = \mathbf{Z}0 = \{0\}\)  is the trivial subgroup. </li>

<li>If \(a \neq 0\), then \(\mathbf{Z}a\) is infinite. In fact it is isomorphic to \(\mathbf{Z}\) so \(\mathbf{Z}a \approx \mathbf{Z}\). </li>

<li>Note here that \(\mathbf{Z} \neq \mathbf{Z}a\) unless \(a = \pm 1\).</li>

<li>Also note, that \(\langle a \rangle  = \langle -a \rangle\).</li>
</ul>

<p>Now consider \(a, b \in \mathbf{Z}\). Suppose we want to find the subgroup generated by the set of \(\{a,b\}\), In other words, \(\langle a,b \rangle\). This is the set of all words composed of \(a\) and \(b\) and their inverses. In fact this is the set of all integer combinations of \(a\) and \(b\)</p>
<div>
	$$
	\begin{align*}
	 \langle a, b \rangle = \{ma + nb \ : \ m,n \in \mathbf{Z}\} = I(a,b)
	\end{align*}
	$$
</div>
<p>This is also a cyclic subgroup because \(\langle a, b \rangle = I(a,b) = \mathbf{Z}d\) where \(d = gcd(a,b)\) So the gcd is the generator of this subgroup. In fact, we will see next that all subgroups of \(\mathbf{Z}\) are cyclic
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Cyclic Subgroups in \(\mathbf{Z}\)</b></h4>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
<ol>
	<li>All subgroups of \((\mathbf{Z}, +)\) are cyclic except for the trivial subgroup \(\langle 0 \rangle = \{0\}\). </li>
	<li>All subgroups are infinite.</li>
	<li>Each subgroup is generated by  a unique \(d \geq 0\).</li>
	<li>Each non-trivial subgroup is isomorphic to \(\mathbf{Z}\).</li>
</ol>
</div>
<!----------------------------------------------------------------------------->
<p><br />
<b>Proof (1)</b>
<br />
To prove that all subgroups are cyclic, we need to find a generator for each of the subgroups. We have two cases:
<br />
If \(H = \{0\}\), then \(H = \mathbf{Z}0\) and we are done.
<br />
If \(H \neq \{0\}\), then \(H\) has at least a non-zero element. By the well ordering principle of \(\mathbf{N}\), there is a smallest element \(d \in H \cap \mathbf{N}\) (\(d\) is the smallest positive element in \(H\)). We claim that \(H = \mathbf{Z}d\). 
<br />
<br />
\(\mathbf{Z}d \subseteq H\): We know \(d \in H\) and \(H\) is a group. Therefore, any multiple of \(d\) is in \(H\) since it must be closed so \(\mathbf{Z}d \subseteq H\) as required.
<br />
<br />
\(H \subseteq \mathbf{Z}d\): Suppose \(x \in H\). We want to show that \(x\) is a multiple of \(d\). Use division with remainder (\(x \div d\)) to get \(x = qd + r\) such that \(q, r \in \mathbf{Z}\) and \(0 \leq r &lt; d\). Observe now that</p>
<div>
	$$
	\begin{align*}
	r = x - qd.
	\end{align*}
	$$
</div>
<p>\(x \in H\) by assumption. \(qd \in H\) since \(d \in H\). Therefore, we must have \(r \in H\). But \(d\) is the smallest positive element in \(H\) by the hypothesis and \(r &lt; d\) so \(r\) must be zero. Therefore, \(x = qd \in \mathbf{Z}d\) and \(H = \mathbf{Z}d\) as we wanted to show. \(\ \blacksquare\). 
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Lattice of subgroups of \(\mathbf{Z}\)</b></h4>
<p>We can organize all the subgroups of \(\mathbf{Z}\) in a lattice ordered by the subset relation. For example the all the multiples of 4 are contained in the multiples of 2, so \(\mathbf{Z}4 \subset \mathbf{Z}4\) and it it goes under \(\mathbf{Z}2\) and so. This lattice is also a divisibility lattice meaning that if \(\mathbf{Z}a \subseteq \mathbf{Z}b\), then \(b \ | \ a\). For example we see that \(\mathbf{Z}6 \subset \mathbf{Z}3\) in the lattice and so this implies that \(3 \ | \ 6\).</p>

<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec1/01-1.png" width="40%" class="center" /></p>
<p>[TODO add pic]
<br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>Order of an Element</b></h4>
<p>Suppose \(G\) is a group and \(a \in G\), then we denote the order of an element by \(o(a)\). We will define the order of \(a\) is as follows
<br />
<!-----------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
\(o(a) = |\langle a \rangle| \in \mathbf{N} \cap \{\infty\} \)
</div>
<p><br />
This says that the order of an element is equal to the size of its generated subgroup \(\langle a \rangle\). But in an earlier lecture, we also defined the order of an element as follows
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition (Book: 2.2.17)
</div>
<div class="peachbodydiv">
	<ul>
<li>If \(o(a) = n\), then \(n\) is the least positive integer such that \(a^n = e\). Furthermore, \(\langle a \rangle = \{a^k \ : \ 0 \leq k &lt; o(a)\}\).</li>
<li>If \(o(a) = \infty\), then \(a^n \neq e \ \forall n\).</li>
</ul>
</div>
<!----------------------------------------------------------------------------->
<p><br />
The claim is that these are equivalent. We will assume the definition and prove that it is equivalent to the order being the smallest positive integer such that \(a^n = e\).
<br />
<br />
<b>Proof</b>
<br />
By definition, the cyclic subgroup generated by \(a\) is \(\langle a \rangle = \{a^k \ | \ k \in \mathbf{Z} \}\). Suppose that \(o(a) = |\langle a \rangle| = n\). Since \(\langle a \rangle\) is finite, then two powers of \(a\) must coincide. So \(a^i = a^{j}\) for some \(i &lt; j\). This means that \(a^{j-i} = e\) where \(k = j - i &gt; 0\) (side note: why? think of the integers mod 7 with addition, \(2^2 = 2+2\) and \(2^9=18\) both leave a remainder of 4. While \(2^7\) is \(e\)). By the well-ordering principle, there a least \(k\) such that \(a^k = e\), We want to show that \(k\) is equal to the order of \(\langle a \rangle\) which is \(n\). 
<br />
<br />
Now, suppose we have some power \(m\) of \(a\). Write \(m = kq + r\) where \(0 \leq r &lt; k\) and \(r = rem_k(m)\). So \(a^m = (a^k)^qa^r = a^qa^r = a^r\). This means that</p>
<div>
	$$
	\begin{align*}
	 \langle a \rangle = \{e, a, a^2, ..., a^{k-1}\}
	\end{align*}
	$$
</div>
<p>Since \(n\) is the size of the set by assumption, then \(n \leq k\). But that means that that we have two powers in the set above that must coincide where \(a\) raised to the power of their difference is the identity element. But this is a contradiction since we said that \(k\) is the smallest positive number such that \(a^k = e\). Therefore, we must have \(n = k\). So the minimality of \(k\) implies their equality. 
<br />
<br />
If \(\langle a \rangle\) is infinite, we can use the same argument to show that if \(a^k = e\) for some \(k &gt; 0\), then all elements can be written as \(\langle a \rangle = \{e, a, a^2, ..., a^{k-1}\}\) but this is a finite set which is a contradiction. \(\ \blacksquare\)
<br />
<br />
The notion of order leads to the following result
<br />
<!-----------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition (Book 2.2.20)
</div>
<div class="peachbodydiv">
Let \(a\) be an element of a group \(G\).
<ol type="a">
	<li>If \(a\) has infinte order, then \(\langle a \rangle\) is isomorphic to \(\mathbf{Z}\)</li>
	<li>If \(a\) has finite order, then \(\langle a \rangle\) is isomorphic to the group \(\mathbf{Z}_n\)</li>
</ol>
</div>
<p><br />
<!----------------------------------------------------------------------------->
<b>Proof (book)</b>
<br />
For \((a)\), we want to show this by finding an example of an isomorphism. So define the map</p>
<div>
	$$
	\begin{align*}
	 \varphi \ : \ &amp;\mathbf{Z} \rightarrow \langle a \rangle \\
	 &amp;\varphi(k) = a^k.
	\end{align*}
	$$
</div>
<p>To show that this map is an isomorphism, we need to show that it is a bijection and also that for any two elements \(a, b \in \mathbf{Z}\), \(\varphi(ab) = \varphi(a)\varphi(b)\) (Definition 2.1.13).
<br />
<br />
To show that it is a bijection, observe that this map is surjective or onto by the definition of \(\langle a \rangle\). (Recall that that \(\langle a \rangle\) is of infinite order). It is also injective or 1-1 because all the elements of \(\langle a \rangle\) (powers of \(a\)) are distinct. Furthermore, observe that for any \(k, l \in \mathbf{Z}\)</p>
<div>
	$$
	\begin{align*}
	 \varphi(k + l) &amp;= a^{k + l}, \\
	 \varphi(k)\varphi(l) &amp;= a^k a^l = a^{k+1}.
	\end{align*}
	$$
</div>
<p>So \(\varphi\) is an isomorphism.
<br />
<br />
Similarly for \((b)\), we want to define an isomorphism. Note here that both \(\mathbf{Z}_n\) and \(\langle a \rangle\) have \(n\) elements so define the map</p>
<div>
	$$
	\begin{align*}
	 \varphi \ : \ &amp;\mathbf{Z}_n \rightarrow \langle a \rangle \\ 
	 &amp;\varphi([k]) = a^k.
	\end{align*}
	$$
</div>
<p>where \(0 \leq k \leq n-1\). In \(\mathbf{Z}_n\), This map is both injective and surjective. Furthermore, observe that \([k] + [l] = [k+l]\) but since we’re module class \(n\), then \([k+l] = [qn + r] = [0 + r] = [r]\) so</p>
<div>
	$$
	\begin{align*}
	 \varphi([k] + [l]) &amp;= a^{[k + l]} = a^{[r]}.
	\end{align*}
	$$
</div>
<p>while,</p>
<div>
	$$
	\begin{align*}
	 \varphi([k])\varphi([l]) &amp;= a^{[k]}a^{[l]} = a^{[k+l]} = a^{[r]}.
	\end{align*}
	$$
</div>
<p>Therefore \(\varphi\) is an isomorphism.
<br />
<br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>Subgroups of \(\mathbf{Z}_{12}\)</b></h4>
<p>We can also build a lattice for the subgroups of \(\mathbf{Z}_{12}\).</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec10/z12.png" width="80%" class="center" /></p>
<p>Note that</p>
<ul>
	<li>\(\langle [1] \rangle = \mathbf{Z}_{12} = \langle [5] \rangle = \langle [7] \rangle = \langle [11] \rangle\).</li>
	<li>\(\langle [2] \rangle = \{[0],[2],[4],[6],[8],[10]\}\).</li>
	<li>\(\langle [3] \rangle = \{[0],[3],[6],[9]\}\).</li>
	<li>\(\langle [4] \rangle = \{[0],[4],[8]\}\).</li>
	<li>\(\langle [6] \rangle = \{[0],[6]\}\).</li>
	<li>\(\langle [12] \rangle = \{[0]\}\).</li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>Subgroups in the Finite Cyclic Group \(\mathbf{Z}_n\)</b></h4>

<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
Let \(a\) be an element of a group \(G\).
<ol>
	<li>Every subgroup of \(\mathbf{Z}_n\) is cyclic.</li>
	<li>If \(a \in \mathbf{Z}\), then \(\langle [a] \rangle = \langle [d] \rangle\) where \(d = gcd(a,n)\).</li>
	<li>If \(a, b \ | \ n\), then \(\langle [a] \rangle \subseteq \langle [b] \rangle\) if and only if \(b \ | \ a\).</li>
	<li>Every subgroup of \(\mathbf{Z}\) is \(\langle d \rangle\) for a unique \(d &gt; 0\), \(d \ | \ n\) and \(|\langle d \rangle| = \frac{n}{d}\).</li>
</ol>
</div>
<!---------------------------------------------------------------------->
<p><br />
\((2)\) simply says that the standard representative/generator of the cyclic subgroup \(\langle a \rangle\) is \(gcd(a, n)\). We can replace \(a\) with \(gcd(a,n)\). They both represent the same congruence class.<br /> \((3)\) is similar to \(\mathbf{Z}\). Recall that \(\mathbf{Z}2\) (multiples of 2) contains the subgroup \(\mathbf{Z}4\) and we concluded that \(\mathbf{Z}4 \subseteq \mathbf{Z}2\) implies that \(2 \ | \ 4\). A similar thing here.
<br />
<br />
To prove this theorem we need the following lemma:
<br />
<!----------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma
</div>
<div class="yellowbodydiv">
Given a subset \(H \subseteq \mathbf{Z}_n\). Define
	$$
	\begin{align*}
	\tilde{H} &amp;= \{a \in \mathbf{Z} \ | \ [a]_n \in H \} \subseteq \mathbf{Z} \\
	          &amp;= \bigcup_{S \in H} S
 	\end{align*}
	$$
Then, \(H\) is a subgroup of \(\mathbf{Z}_n\) if and only if \(\tilde{H}\) is a subgroup of \(\mathbf{Z}\).
</div>
<p><br />
So \(H\) is a set of integers such that the elements are the representatives of the congruence classes in \(\mathbf{Z}_n\). The proof of this lemma is in the lecture notes.
<br />
<br />
<!---------------------------------------------------------------------->
<b>Theorem Proof</b>
<br />
For (1), Let \(H \leq \mathbf{Z}_n\) be a subgroup. We want to show that \(H\) is cyclic by proving that \(H\) is a cyclic group generated by some element. Consider \(\tilde{H}\). Since \(H\) is a subgroup, then \(\tilde{H}\) is a subgroup of \(\mathbf{Z}_n\) by the lemma. Moreover, \(\tilde{H} = \mathbf{Z}d\) for some \(d \in \mathbf{Z}\) by the previous theorem (every subgroup of \(\mathbf{Z}\) is cyclic and is generated by some \(d\)). Therefore, by the definition of \(\tilde{H}\), \([d]\) must be a congruence class in \(H\). This implies that \(\langle [d] \rangle \subseteq H\) since \(H\) is a group and all multiples of \(d\) must be in \(H\). 
<br />
<br />
To prove the other direction \(H \subseteq \langle [d] \rangle\), consider \([a] \in H\). This means that \(a \in \tilde{H}\) by the definition of \(\tilde{H}\). But \(\tilde{H} = \mathbf{Z}d\) so \(a\) is a multiple of \(d\) and we can write \(a = sd\) for some \(s \in \mathbf{Z}\). Therefore, \([a] = s[d]\) and \([a] \in \langle [d] \rangle\). Therefore, \(H = \langle d \rangle\) and \(H\) is cyclic as we wanted to show. \(\ \blacksquare\)
<br />
<br />
For (2), suppose that \(d = gcd(a,n)\). We want to show that \(\langle [a] \rangle = \langle [d] \rangle\). Since \(d\) is the gcd, then \(d\) divides both \(a\) and \(n\). Also \(d = I(a,n)\) and we can write \(d = sa + tn\) for some \(s, t \in \mathbf{Z}\). 
<br />
<br />
Since \(a \ | \ d\), then \(a = sd\) and so \([a] = s[d]\) so \(\langle [a] \rangle \subseteq \langle [d] \rangle\). Since \(d = sa + tn\), then \([d] = s[d] + t[n] = s[d]\) because \([n] = [0]\) since we’re in \(\mathbf{Z}_n\). Therefore, \(\langle [d] \rangle \subseteq \langle [a] \rangle\). So we’ve shown that \(\langle [a] \rangle = \langle [d] \rangle\) as we wanted to show. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>Subgroups of Finite Cyclic Groups</b></h4>
<p>In fact, not just the subgroups of \(\mathbf{Z}_n\) that are cyclic. All subgroups of any finite cyclic group \(G\) are cyclic. We can generalize the previous theorem as follows
<br />
<br /></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
Let G = \(\langle g \rangle\) and \(o(g) = n &lt; \infty\). Then
<ol>
	<li>Every subgroup of \(G\) is cyclic.</li>
	<li>\(\forall \ a \in \mathbf{Z}\), then \(\langle g^a \rangle = \langle g^d \rangle\) where \(d = gcd(a,n)\).</li>
	<li>If \(a, b \ | \ n\), then \(\langle g^a \rangle \subseteq \langle g^b \rangle\) if and only if \(b \ | \ a\).</li>
	<li>Every subgroup of \(G\) is of the form \(\langle g^d \rangle\) for a unique \(d &gt; 0\), \(d \ | \ n\) and it has order \(\frac{n}{d}\).</li>
</ol>
</div>
<p><br />
<br /></p>
<hr />

<p><br />
<!-----------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
	<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition 2.2.1 A non-empty subset \(H\) of a group \(G\) is called a subgroup if \(H\) is itself a group with the group operation inherited from \(G\). We write \(H \leq G\) to indicate that \(H\) is a subgroup of \(G\). Example: The group \(SO(3)\), the special orthogonal matrices is a subgroup of \(GL_3(\mathbf{R}\), the group of invertible \(3 \times 3\) matrices. Both of these are under the same operation. Non-example: \(\mathbf{Z}_n\): congruence classes modulo \(n\) with addition. We also have \(\phi(n)\): congruence classes with multiplicative inverses. This has the operation multiplication so it's not a subgroup! Even when you define \(\phi(4) = \{[1],[3]\}\) with addition, it will not satisfy the group requirements, so it's not a subgroup. Since we need to check a lot for subgroups. We have a set of necessary conditions. Proposition The necessary conditions for a subset \(H\) of \(G\) to be a subgroup of \(G\) are: \(H\) is not empty \(H\) is closed under multiplication. That is, for all elements \(h_1\) and \(h_2\) of \(H\), the products \(h_1h_2\) is also an element of \(H\) \(H\) is closed under inverses. For all \(h \in H\), the inverse \(h^{-1}\) is an element of \(H\) Proof \(H\) is associative. For any \(a,b,c \in H\), \((ab)c = a(bc)\). We're inheriting the same operation from \(G\) so \(H\) must be associative. \(H\) has an identity element: We know \(H\) is non-empty by (1). We also know for any \(h \in H\), \(h^{-1} \in H\) by (3). By (2), \(H\) is closed under multiplication so \(hh^{-1} \in H\) but \(hh^{-1} = e\) so the identity element is in \(H\). Example Consider the group \(G = S_4\) (permutations of \(\{1,2,3,4\}\)). The order of this group is \(|G| = 4\). The following are subgroups of \(S_4\): \(H=\{ \sigma \in S_4 \ | \ \sigma(4) = 4\}\). So this subgroup fixes \(4\) in the permutation. \(|H| = 3! = 6\). In fact, it is permuting only 3 numbers and it is isomorphic to \(S_3\). \(H'=\{e,(1 \ 2)(3 \ 4), (1 \ 3)(2 \ 4), (1 \ 4)(2 \ 3)\}\). It's not empty. It has the identity element. Every element is its own inverse. The one thing not too obvious is proving it is closed. This subgroup is isomorphic to the symmetry group of the rectangle. What's an isomorphism in this case? Assign \(A\) to 1, \(B\) to 2, \(C\) to 3, \(D\) to 4. Recall that the symmetries of the rectangle has the symmetries \(r_1, r_2, r_3, e\) where \(r_1\) is rotating around the \(x-\)axis. Observe now that \(r_1\) rotates the vertices such that \(A\) and \(B\) switch positions and \(C\) and \(D\) switch positions. This is equivalent to the permutation \((1 \ 2)(3 \ 4)\). Following this, we'll see that \(r_2\) gets mapped to \((1 \ 4)(2 \ 3)\) and \(r_3\) gets mapped to \((1 \ 3)(2 \ 4)\). \(H''=\{e,(1 \ 2 \ 3 \ 4)(4 \ 3 \ 2 \ 1), (1 \ 2)(3 \ 4), (1 \ 3)(2 \ 4), (1 \ 4)(2 \ 3), (1 \ 3),(2 \ 4)\}\). This one is isomorphic to \(D_4\) which is the symmetries of the square. Generated Subgroups We begin with the following lemma which states that the intersection of a collection of subgroups is another subgroup. Lemma (Book Proposition 2.2.8) Let \(G\) be a group and let \(H_1, H_2,...,H_n\) be subgroups of \(G\). Then $$ \begin{align*} H = H_1 \cap H_2 \ \cap ... \cap \ H_n \end{align*} $$ is a subgroup of \(G\). More generally, if \(\{H_{\alpha}\}\) is any collection of subgroups, then \(\cap_{\alpha}\) is a subgroup. Proof Every \(H_i\) is a subgroup. Therefore \(e \in H_i\) for each \(i\) and thus \(e \in H\). For any two elements \(a, b \in H\), we must have \(a, b \in H_i\) for each \(i\). Their product \(ab\) must also be in every \(H_i\) since each \(H_i\) is a subgroup. Therefore \(ab \in H\). For any \(a \in H\), \(a\) must be in \(H_i\) for each \(i\). Therefore \(a^{-1} \in H_i \ \forall i\) and thus \(a^{-1} \in H\). Since any intersection of subgroups is another subgroups, we can then define a generated subgroups as follow Definition Let \(G\) be a group and let \(S\) be a subset of \(G\). Then $$ \begin{align*} \langle S \rangle = \bigcap_{\text{All } H_i \leq G \text{ such that } S \subseteq H_i} \end{align*} $$ \(\langle S \rangle\) is called the subgroup generated by \(S\) and it is the smallest subgroup in \(G\) that contains \(S\). Observe that \(\langle S \rangle\) is a subgroup by the previous lemma since it is the intersection of subgroups. \(S \subseteq \langle S \rangle\). It is the smallest group that contains \(S\). Because for any subgroup \(K \leq G\) such that \(S \subseteq K\), we must have \(\langle S \rangle \leq K\) (why? because if \(S\) is contained in \(K\) and \(K\) is a group, then all the products of the elements of \(S\) are in \(K\). Same for the inverses. So the whole subgroup \(\langle S \rangle\) must also be contained in \(K\).) Additionally from the book: If \(S\) contains a single element, \(S = \{a\}\), then the subgroup generated by \(S\) is denoted by \(\langle a \rangle\). If \(G = \langle S \rangle\), then \(G\) is generated by \(S\) or \(S\) generates \(G\) Another way to describe \(\langle S \rangle\) is take a bottom up approach to describe the elements. Proposition Suppose \(G\) is a group and \(S\) is a subset of \(G\). Then \(\langle S \rangle\) is equal to the set of elements in \(G\) of the form $$ \begin{align*} g_1g_2...g_k \quad \text{ where either } g_i \in S \text{ or } g_i^{-1} \in S \text{ for all } i. \end{align*} $$ In other words, \(\langle S \rangle\) is a subgroup such that that it contains all the possible products \(g_1g_2...g_n\) which are in \(S\) or an inverse to an element of \(S\). The set that contains such products is often called the “set of words in \(S\)” in group theory. Proof Let \(T\) be the set of words \(\{e\} \cup \{g_1...g_k\}\) where \(g_i \in S\) or \(g_i^{-1} \in S\) for all \(i = 1,...,k\). We need to show that \(T\) is a subgroup of \(G\). [This is true because \(T\) has the identity element. For any two word, the product of these is just a longer word which is also in \(T\). It is closed under the inverses because \((g_1g_2...g_k)^{-1} = g_k^{-1}...g_1^{-1}\).] \(S \subseteq T\). [This is true because all the words of length 1 make up the set \(S\). It is true by construction.] If \(K \leq G\) is a subgroup such that \(S \subseteq K\), then \(T \subseteq K\). [This is true because if \(K\) contains \(S\) then it must contain all the inverses of these words and then also the products of all of these words since it's a group (closed) so it has all of these elements and it contains \(T\) itself.] Condition (1) and (2) imply that \(\langle S \rangle \subseteq T\). Conditions (1) and (3) imply that \(T \subseteq \langle S \rangle\). Therefore, \(T = \langle S \rangle\). \(\ \blacksquare\) We’ll use this proposition a lot. Lattice of Subgroups Consider the group \(S_3 = \{e, (1 \ 2), (1 \ 3), (2 \ 3), (1 \ 2 \ 3), (1 \ 3 \ 2)\}\). We can list its subgroups in terms of its generating subsets as follows: \(\langle (1 \ 2) \rangle = \{e, (1 \ 2)\}\). This says that the subgroup generated by \(\{(1 \ 2)\}\) is \(\{e, (1 \ 2)\} = \langle (1 \ 2) \rangle \) \(\langle (1 \ 3) \rangle = \{e, (1 \ 3)\}\). \(\langle (2 \ 3) \rangle = \{e, (2 \ 3)\}\). \(\langle (1 \ 2 \ 3) \rangle = \{e, (1 \ 2 \ 3), (1 \ 3 \ 2)\}\) = \(\langle (1 \ 3 \ 2) \rangle\) \(S_3 = \langle (1 \ 2), (1 \ 2 \ 3) \rangle\). We can then draw this in the following figure]]></summary></entry><entry><title type="html">Groups and Isomorphism</title><link href="http://localhost:4000/jekyll/update/2025/02/01/math417-08-groups-and-isomorphism.html" rel="alternate" type="text/html" title="Groups and Isomorphism" /><published>2025-02-01T00:01:36-08:00</published><updated>2025-02-01T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/02/01/math417-08-groups-and-isomorphism</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/02/01/math417-08-groups-and-isomorphism.html"><![CDATA[<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A group \((G, G \times G \rightarrow G)\) is a set with a binary operation on that set such that. 
<ol>
	<li>The operation is associative so that \((ab)c = a(bc), \forall a,b,c \in G\)</li>
	<li>There exists an identity element. \(\exists e \in G\) such that \(ae = a = ea \forall a \in G\).</li>
	<li>Every element has an inverse. \(\forall a \in G, \exists a^{-1} \in G\) such that \(aa^{-1} = e = a^{-1}a\).</li>
</ol>
Additionally, a group is commutative/abelian if \(ab = ba, \forall a, b \in G.\).
</div>
<!---------------------------------------------------------------------->
<p><br />
<br />
In addition to groups, we also have</p>
<ul> 
<li>Monoids which satisfy \((1)\) and \((2)\). </li>
<li>Semi-groups which satisfy \((1)\).</li>
<li>Magma \(G, \cdot\) with no additional properties. </li>
</ul>
<p><br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>Basic Properties of Groups</b></h4>
<p>In the next few propositions, we’ll prove that the identity element in a group is unique and similarly the inverses are unique.
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
The identity element is unique.
</div>
<p><br />
<b>Proof</b>
<br />
Let \(e\) and \(e'\) be identity elements. Then by definition for any \(x, y \in G\)</p>
<div>
	$$
	\begin{align*}
	 xe &amp;= x = ex \\
	 ye' &amp;= y = e'y
	\end{align*}
	$$
</div>
<p>If we let \(x = e'\) and let \(y = e\), then</p>
<div>
	$$
	\begin{align*}
	 e'e &amp;= e' = ee' \\
	 ee' &amp;= e = e'e
	\end{align*}
	$$
</div>
<p>From this we see that \(e = e'\) as desired. \(\ \blacksquare\)
<br />
<br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Inverses in a group are unique.
</div>
<p><br />
<!---------------------------------------------------------------------->
<b>Proof</b>
<br />
Let \(a \in G\) and suppose for the sake of contradiction that \(a\) has two inverses \(b\) and \(c\). That is \(ab = e = ba\) and \(ac = e = ca\). Then,</p>
<div>
	$$
	\begin{align*}
	 c = ec = (ba)c = b(ac) = be = b.
	\end{align*}
	$$
</div>
<p>Therefore, \(c = b\) which is a contradiction so the inverse must be unique. \(\ \blacksquare\)
<br />
<br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition (2.1.2)
</div>
<div class="peachbodydiv">
Let \(G\) be a group and let \(a, b \in G\). If \(ab = e\), then \(a = b^{-1}\). Likewise, if \(ba = e\), then \(b = a^{-1}\).
</div>
<p><br />
By definition, \(b\) an inverse of \(a\) if \(ab = ba = e\) so it’s an inverse on both sides. This proposition proposes that checking only one side is enough. That is if \(ab = e\), then \(a = b^{-1}\) and \(b\) is the inverse. So what we want to show here is that given \(ba = e\), then \(b\) is the inverse of \(a\). We don’t check the other side. One side is enough to imply the other.
<br />
<br />
<!---------------------------------------------------------------------->
<b>Proof</b>
<br />
We know from the previous proposition that \(a\) has an inverse \(a^{-1} \in G\). Now consider the expression \(a^{-1}ab\). By associativity, we can reduce this expression in two ways</p>
<div>
	$$
	\begin{align*}
	 (a^{-1}a)b &amp;= a^{-1}(ab)
	\end{align*}
	$$
</div>
<p>The left hand side</p>
<div>
	$$
	\begin{align*}
	 (a^{-1}a)b &amp;= eb = b
	\end{align*}
	$$
</div>
<p>The right hand side is</p>
<div>
	$$
	\begin{align*}
	 a^{-1}(ab) &amp;= a^{-1}
	\end{align*}
	$$
</div>
<p>So \(b = a^{-1}\) and therefore, \(ba = a^{-1}a = e\). 
<br />
<br />
<!---------------------------------------------------------------------->
<b>Proof (Book)</b>
<br />
Suppose \(hg = e\), then</p>
<div>
	$$
	\begin{align*}
	 h = h(gg^{-1}) = (hg)g^{-1}= eg^{-1} = g^{-1}.
	\end{align*}
	$$
</div>
<p>Suppose now that \(gh = e\), then</p>
<div>
	$$
	\begin{align*}
	 g = g(hh^{-1}) = (gh)h^{-1} = eh^{-1} = h^{-1}. \ \blacksquare
	\end{align*}
	$$
</div>
<p><br />
<br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Corollary 2.1.3
</div>
<div class="peachbodydiv">
Let \(g\) be an element of a group \(G\). We have \(g = (g^{-1})^{-1}\)
</div>
<p><br />
<b>Proof</b>
<br />
We know \(gg^{-1} = e\). By (2.1.2) \(g = (g^{-1})^{-1}\). \(\ \blacksquare\)
<br />
<br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 2.1.4
</div>
<div class="peachbodydiv">
Let \(G\) be a group and let \(a,b \in G\). Then We have \((ab)^{-1} = b^{-1}a^{-1}\)
</div>
<p><br />
<b>Proof</b>
<br />
Notice that \((ab)(b^{-1}a^{-1}) = a(b((b^{-1}a^{-1})) = a((bb^{-1})a^{-1}) = a(ea^{-1}) = aa^{-1} = e\). Therefore, \((ab)^{-1} = b^{-1}a^{-1}\).
<br />
<br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>The Left and Right Multiplication Maps</b></h4>

<div class="peachheaderdiv">
Proposition 2.1.5
</div>
<div class="peachbodydiv">
Let \(G\) be a group and \(a \in G\). <br />
The map \(L_a: G \rightarrow G\) defined by \(L_a(x) = ax\) is a bijection. Similarly, <br />
the map \(R_a: G \rightarrow G\) defined by \(R_a(x) = xa\) is a bijection.
</div>
<!---------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
To show that the map \(L_a\) is a bijection, we need to show that \(L_a\) is both one to one and onto or equivalently that \(L_a\) has an inverse. We claim that the left multiplication by \(a^{-1}\) or \(L_{a^{-1}}\) is the inverse of \(L_a\). To see that,</p>
<div>
	$$
	\begin{align*}
	L_{a^{-1}}(L_a(x)) = a^{-1}(ax) = (a^{-1}a)x = ex = x.
	\end{align*}
	$$
</div>
<p>Similarly,</p>
<div>
	$$
	\begin{align*}
	L_a(L_{a^{-1}}(x)) = a(a^{-1}x) = (aa^{-1})x = ex = x.
	\end{align*}
	$$
</div>
<p>So \(L_{a^{-1}}\) and \(L_a\) are inverse maps so both are bijective. \(\ \blacksquare\)
<br />
<br /></p>

<!---------------------------------------------------------------------->
<div class="peachheaderdiv">
Corollary 2.1.6
</div>
<div class="peachbodydiv">
Let \(G\) be a group and let \(a\) and \(b\) be elements of \(G\). The equation \(ax = b\) has a unique solution \(x\) in \(G\). and likewise the equation \(xa = b\) has a unique solution in \(G\).
</div>
<p><br />
<b>Proof</b>
<br />
For \(ax = b\) to have a solution. The map \(L_a\) needs to be onto or surjective. For the solution to be unique, the map needs to be one to one or injective. Similarly for \(xa = b\) to have a solution, we want \(R_a\) to be a bijective. Since we proved earlier that \(L_a\) and \(R_a\) are bijections, then both equations have unique solutions. \(\ \blacksquare\)
<br />
<br /></p>

<!---------------------------------------------------------------------->
<div class="peachheaderdiv">
Corollary 2.1.7 (Cancellation)
</div>
<div class="peachbodydiv">
Suppose \(a, x, y\) are elements of a group \(G\). If \(ax = ay\), then \(x = y\). Similarly, if \(xa = ya\), then \(x = y\).
</div>
<p><br />
<b>Proof</b>
<br />
Suppose \(ax = ay\). We know that \(L_a(x) = ax\) is one to one. So for any elements \(x, y \in G\), \(ax = ay\) must imply that \(x = y\) by definition of a one to one or injective map. A similar arguments shows that if \(xa = ya\) must imply that \(x = y\) by the injectivity of \(R_a\). \(\ \blacksquare\)
<br />
<br /></p>

<!---------------------------------------------------------------------->
<div class="peachheaderdiv">
Corollary 2.1.8
</div>
<div class="peachbodydiv">
If \(G\) is a finite group, each row and each column of the multiplication table of \(G\) contains each element of \(G\) exactly once.
</div>
<p><br />
<b>Proof (book)</b>
<br />
A row in the multiplication table can be represented by a left multiplication map \(G \rightarrow G\) if you fix the element multiplied on the left. We know the left multiplication map is a bijection. Therefore every element/result must be unique and each element of \(G\) must show up in the row. Similarly, each column can be represented by a right multiplication map. The map is a bijection and so each element must be unique and shown exactly once. (TODO clean up this proof)
<br />
<br /></p>
<hr />

<p><br />
<!---------------------------------------------------------------------></p>
<h4><b>Associativity in Groups</b></h4>
<p>We know by definition that the product is associative so for all \(a, b, c \in G\), we have \((ab)c = a(bc)\). What about the product of 4 or more elements? is it associative? For example, there are five ways to group four elements</p>
<div>
	$$
	\begin{align*}
	a(b(cd)), a((bc)d), (ab)(cd), (a(bc))d, ((ab)c)d
	\end{align*}
	$$
</div>
<p>\(a(b(cd))\) and \(((ab)c)d\) follow from the definition. For the rest, see that</p>
<div>
	$$
	\begin{align*}
	a(bcd) = a(b(cd)) = (ab)(cd) = ((ab)c)d = (abc)d
	\end{align*}
	$$
</div>
<p>How many ways are there to associate an \(n\)-fold product?</p>
<div>
	$$
	\begin{align*}
	\frac{1}{2}\binom{2n - 2}{n - 1}
	\end{align*}
	$$
</div>
<p>In general this works for any number of elements. Formally,
<br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 2.1.19 (General Associative law)
</div>
<div class="peachbodydiv">
Let \(M\) be a set with an associative operation, \(M \times M \rightarrow M\), denoted by juxtaposition. For every \(n \geq 1\), there is a unique product \(M^n \rightarrow M\),
	$$
	\begin{align*}
	(a_1, a_2,...,a_n) \rightarrow a_1a_2...a_n,
	\end{align*}
	$$
such that
<ol type="a">
	<li> The product of one element is that element \((a) = a\).</li>
	<li> The product of two elements agrees with the given operation \((ab) = ab\).</li>
	<li>For all \(n \geq 2\), for all \(a_1,...,a_n \in M\), and for all \(1 \leq k \leq n-1\), 
		$$
		\begin{align*}
		a_1a_2...a_n = (a_1...a_k)(a_{k-1}...a_n)
		\end{align*}
		$$
	</li>
</ol>
</div>
<!---------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
By induction on \(n\). <br />
Base Case: For \(n \leq 3\), property \((c)\) holds by definition.
<br />
Inductive Case: Suppose this is true for all \(1 \leq r \leq n\) where a unique product of \(r\) elements satisfies the properties \((a)-(c)\) above. Suppose now that we have \(n\) elements. Fix elements \(a_1, ...,a_n \in M\). By the inductive hypothesis, the \(n-1\) products</p>
<div>
	$$
	\begin{align*}
	p_k = (a_1...a_k)(a_{k+1}...a_n),
	\end{align*}
	$$
</div>
<p>are defined since we have at most \(n-1\) elements. … [TODO]
<br />
<br /></p>
<hr />

<p><br />
<!---------------------------------------------------------------------></p>
<h4><b>General Powers</b></h4>
<p>Now, we turn into defining powers of an element in a group
<br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
For \(a \in G\) where \(G\) is a group and \(n \in \mathbf{Z}\). Define \(a^n \in G\) by
<ol>
	<li>\(a^0 = e\).</li>
	<li>\(a^1 = a\).</li>
	<li>\(a^{-1} \) is the inverse of \(a\).</li>
	<li>\(n \geq 1\), \(a^{n+1} = a^n a\).</li>
	<li>\(n \leq -1\), \(a^{n-1} = a^n a^{-1}\).</li>
</ol>
</div>
<!---------------------------------------------------------------------->
<p><br />
Based on this definition we have the following proposition
<br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
	$$
	\begin{align*}
	a^{m}a^{n} &amp;= a^{m + n} \\
	(a^m)^{n} &amp;= a^{mn} \\	
	\end{align*}
	$$
</div>
<p><br />
<b>Proof (1)</b>
<br />
By induction on \(n\). <br />
Base Case \((n = 1)\): \(a^m a = a^{m+1}\) by definition.
<br />
Inductive Case: Suppose the inductive hypothesis is true for \(n\). That is \(a^m a^n = a^{m+n}\). Now observe that</p>
<div>
	$$
	\begin{align*}
	a^m a^{n+1} &amp;= a^m (a^n a) \text{ (by definition)} \\
	            &amp;= (a^m a^n) a \text{ (by associativity)} \\
	            &amp;= a^{m+n} a \text{ (by the inductive hypothesis)} \\
	            &amp;= a^{m+n+1} \text{ (by definition)}. \ \blacksquare
	\end{align*}
	$$
</div>
<p><br />
<b>Proof (2)</b>
By induction on \(n\). <br />
Base Case \((n = 1)\): \((a^{m})^1 = a^{m}\).
<br />
Inductive Case: Suppose the inductive hypothesis is true for \(n\). That is \((a^m)^n = a^{mn}\). Now observe that</p>
<div>
	$$
	\begin{align*}
	(a^{m})^{n+1} &amp;= (a^{m})^{n} (a^{m})^{1} \text{ (by definition)} \\
	              &amp;= (a^{m})^{n} a^{m} \\
	              &amp;= a^{mn} a^{m}  \text{ (by the inductive hypothesis)} \\
				  &amp;= a^{mn+m}  \text{ (by the previous proof)} \\
	            &amp;= a^{m(n+1)}. \ \blacksquare
	\end{align*}
	$$
</div>

<p><br />
<br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>Isomorphism</b></h4>
<p>One thing that we want to do is to compare two groups. For example take \((\mathbf{Z}_4, +)\), the symmetries of the rectangle, \((\phi(5), \cdot)\) and \((\phi(8), \cdot)\). These are all groups with exactly 4 elements. To compare two groups, we want to see if we can construct a bijection between the two groups. Formally, this is called an isomorphism as follows
<br />
<br />
<!----------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition 2.1.13
</div>
<div class="mintbodydiv">
We say two groups \(G\) and \(H\) are isomorphic if there is a bijection \(\varphi: G \rightarrow H\) such that for all \(a, b \in G\)
	$$
	\begin{align*}
	\varphi(ab) = \varphi(a)\varphi(b)	
	\end{align*}
	$$
where the first multiplication is in \(G\) while the second is in \(H\).<br />
 The map \(\varphi\) is called an isomorphism.
</div>
<p><br />
<br />
We write \(H \approx G\) for \(G\) is isomorphic to \(H\).
<br />
<br />
An an example consider the group of symmetries of the equilateral triangle \(D_3\) and the group \(S_3\) (permutations of \(\{1,2,3\}\)). Both groups contain exactly 6 elements. They turn out to be isomorphic. Observe here that if we assign the vertices \(A\) to \(1\), \(B\) to \(2\) and \(C\) to \(3\), then the rotation \(a\) flips the vertices \(B\) and \(C\). This is exactly the same as the permutation \((2 \ 3)\). Similarly, if you think about the rotation \(r\), you’ll notice that \(r\) permutes the vertices in the exact way as the permutation \((1 \ 2 \ 3)\). In fact, all permutations. Another example is the \(b\) rotation. This rotation fixes \(b\) and rotates \(a\) and \(c\). This is also the same as the permutation \((1 \ 3)\). We can map the rest of the symmetries as follows</p>
<div>
<table style="max-width: 500px; margin: 20px auto;">
  <tr>
    <td>\(D_3\)</td>
    <td>\(S_3\)</td>
  </tr>
  <tr>
    <td>\(id\)</td>
    <td>\(id\)</td>
  </tr>
  <tr>
    <td>\(r\)</td>
    <td>\((1 \quad 2 \quad 3)\)</td>
  </tr>
  <tr>
    <td>\(a\)</td>
    <td>\((2 \quad 3)\)</td>
  </tr>
  <tr>
    <td>\(r^2\)</td>
    <td>\((1 \quad 3 \quad 2)\)</td>
  </tr>
  <tr>
    <td>\(b\)</td>
    <td>\((1 \quad 3)\)</td>
  </tr>
  <tr>
    <td>\(c\)</td>
    <td>\((1 \quad 2)\)</td>
  </tr>
</table>
</div>
<p><br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
	If \(\varphi:G \rightarrow H\) is an isomorphism, then \(\varphi^{-1}: G \rightarrow H\) is also an isomorphism.
</div>
<p><br />
<b>Proof</b>
<br />
Let \(a', b' \in H\). We want to show that</p>
<div>
	$$
	\begin{align*}
	\varphi^{-1}(a'b') = \varphi^{-1}(a') \varphi^{-1}(b')
	\end{align*}
	$$
</div>
<p>Let \(a' = \varphi(a)\) and \(b' = \varphi(b)\) for some \(a, b \in G\). Since \(\varphi\) is injective then it suffices to show that</p>
<div>
	$$
	\begin{align*}
	\varphi(\varphi^{-1}(a'b')) = \varphi(\varphi^{-1}(a') \varphi^{-1}(b'))
	\end{align*}
	$$
</div>
<p>The right hand side is clearly just \(a'b'\). \(\varphi\) is an isomorphism so the left hand side becomes</p>
<div>
	$$
	\begin{align*}
	\varphi(\varphi^{-1}(a') \varphi^{-1}(b')) &amp;= 
	\varphi(\varphi^{-1}(a')) \varphi(\varphi^{-1}(b')) \\
	                          &amp;= a'b'
	\end{align*}
	$$
</div>
<p>Therefore \(\varphi^{-1}\) is an isomorphism as desired. \(\ \blacksquare\).
<br />
<br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>Groups of Small Order</b></h4>
<p>The order of a group is the number of elements in it. Formally,
<br />
<br />
<!----------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition 2.1.10
</div>
<div class="mintbodydiv">
The order of a group is its size or cardinality. We will denote the order of a group \(G\) by \(|G|\).
</div>
<p><br />
<br />
One interesting thing to do is to classify all groups of a given finite order. If we do that for small sizes, we get
<!---------------------------------------------------------------------></p>
<ol>
	<li>Order 0: None because we need to at least have the identity element.</li>
	<li>Order 1: \(G = \{e\}\). Other groups of order 1 can be \(G'=\{1\}\). These two groups are isomorphic. Technically, it's a different set but to us, they're the same group. So "up to isomorphism", there is only one group of size 1.</li>
	<li>Order 2: Up to isomorphism, the only unique group is \(\mathbf{Z}_2 = \{[0], [1], [2]\}\).</li>
	<li>Order 3: Up to isomorphism, the only unique group is \(\mathbf{Z}_3\). All other groups of size 3 will be isomorphic to \(\mathbf{Z}_3\).</li>
	<li>order 4: Up to isomorphism, there are two unique groups. \(\mathbf{Z}_4 \) and \(\mathbf{Z}_2 \times \mathbf{Z}_2\) (symmetries of the rectangle). Groups of order 4 can be isomorphic to either one.</li>
	<li>Order 5: Up to isomorphism, the only unique group is \(\mathbf{Z}_5\)</li>
	<li>Order 6: Up to isomorphism, we have two unique groups. \(\mathbf{Z}_6\) and \(S_3 \approx D_3\). These two groups are not isomorphic because \(S_3\) is non-abelian while \(\mathbf{Z}_6\) is abelian. The proof for this fact is next.</li>
</ol>
<p><br />
<!----------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(G \approx H\), then \(G\) is abelian if and only if \(H\) is abelian.
</div>
<p><br />
<b>Proof (Lecture Notes)</b>
<br />
Suppose that \(\phi: G \rightarrow H\) is an isomorphism. Furthermore, let \(a, b \in G\) and \(a', b' \in H\) such that \(\phi^{-1}(a') = a\) and \(\phi^{-1}(b') = b'\). We will prove both directions of the statement.
<br />
<br />
\(\Rightarrow\): Suppose that \(G\) is abelian. We will show that \(H\) is abelian. Observe that</p>
<div>
	$$
	\begin{align*}
	\phi(ab) &amp;= \phi(a)\phi(b) = a'b' \\
	\phi(ba) &amp;= \phi(b)\phi(a) = b'a'.
	\end{align*}
	$$
</div>
<p>But we know that \(G\) is abelian and so \(ab = ba\) so \(\phi(ab) = \phi(ba)\) and therefore we must have \(a'b' = b'a'\).
<br />
<br />
\(\Leftarrow\): Now suppose that \(H\) is abelian. Then,</p>
<div>
	$$
	\begin{align*}
	\phi(ab) &amp;= \phi(a)\phi(b) = a'b' \\
	\phi(ba) &amp;= \phi(b)\phi(a) = b'a'.
	\end{align*}
	$$
</div>
<p>We know that \(a'b' = b'a'\) because \(H\) is abelian. But since \(\phi\) is injective, this implies that \(ab = ba\). (remember injective means that \(f(a)=f(b) \implies a = b\)). \(\ \blacksquare\)
<br />
<br />
Note that for this direction, we could’ve instead relied on \(\phi^{-1}\) being an isomorphism itself. and so observe that</p>
<div>
	$$
	\begin{align*}
	\phi^{-1}(a'b') &amp;= \phi^{-}(a')\phi^{-}(b') = ab \\
	\phi^{-1}(b'a') &amp;= \phi^{-}(b')\phi^{-}(a') = ba.
	\end{align*}
	$$
</div>
<p>\(H\) is abelian so \(a'b' = b'a'\) so \(\phi^{-1}(a'b') = \phi^{-1}(b'a')\) and thus \(ab = ba\).
<br />
<br />
<br /></p>
<hr />

<p><br />
<br />
<!---------------------------------------------------------------------->
Extra Notes from the book: Two groups are isomorphic means that the multiplication tables match up. In fact, not only that but the identity elements and inverses of elements match up as well. The following propositions state these facts.
<br /></p>
<div class="peachheaderdiv">
Proposition 2.1.18
</div>
<div class="peachbodydiv">
If \(\phi : G \rightarrow H\) is an isomorphism, then \(\phi(e_G) = e_H\), and for each \(g \in G\), \(\phi(g^{-1}) = \phi(g)^{-1}\)
</div>
<p><br />
<b>Proof</b>
<br />
Since \(\phi\) is an isomorphism, then we know that for each \(h \in H\), there is a \(g \in G\) such that \(\phi(g) = h\). Therefore,</p>
<div>
	$$
	\begin{align*}
	\phi(e_G)h &amp;= \phi(e_G)\phi(g) \\
	           &amp;= \phi(e_Gg) \quad \text{$\phi$ is an isomorphism}\\
			   &amp;= \phi(g) \\
			   &amp;= h \\
	\end{align*}
	$$
</div>
<p>So \(\phi(e_G)\) is an identity element. But since the identity element is unique, then \(\phi(e_G) = \phi(e_H)\).
<br />
<br />
To show that \(\phi(g^{-1}) = \phi(g)^{-1}\), see that</p>
<div>
	$$
	\begin{align*}
	\phi(g^{-1})\phi(g) &amp;= \phi(g^{-1}g) \quad \text{$\phi$ is an isomorphism} \\
	        &amp;= \phi(e_G) \\
			&amp;= e_H \quad \text{by the previous result} 	
	\end{align*}
	$$
</div>
<p>So \(\phi(g)\) is the inverse of \(\phi(g^{-1})\) or in other words \(\phi(g)^{-1} = \phi(g^{-1})\) as we wanted to show. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!----------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
	<li>MATH417 by Charles Rezk</li>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition A group \((G, G \times G \rightarrow G)\) is a set with a binary operation on that set such that. The operation is associative so that \((ab)c = a(bc), \forall a,b,c \in G\) There exists an identity element. \(\exists e \in G\) such that \(ae = a = ea \forall a \in G\). Every element has an inverse. \(\forall a \in G, \exists a^{-1} \in G\) such that \(aa^{-1} = e = a^{-1}a\). Additionally, a group is commutative/abelian if \(ab = ba, \forall a, b \in G.\). In addition to groups, we also have Monoids which satisfy \((1)\) and \((2)\). Semi-groups which satisfy \((1)\). Magma \(G, \cdot\) with no additional properties. Basic Properties of Groups In the next few propositions, we’ll prove that the identity element in a group is unique and similarly the inverses are unique. Proposition The identity element is unique. Proof Let \(e\) and \(e'\) be identity elements. Then by definition for any \(x, y \in G\) $$ \begin{align*} xe &amp;= x = ex \\ ye' &amp;= y = e'y \end{align*} $$ If we let \(x = e'\) and let \(y = e\), then $$ \begin{align*} e'e &amp;= e' = ee' \\ ee' &amp;= e = e'e \end{align*} $$ From this we see that \(e = e'\) as desired. \(\ \blacksquare\) Proposition Inverses in a group are unique. Proof Let \(a \in G\) and suppose for the sake of contradiction that \(a\) has two inverses \(b\) and \(c\). That is \(ab = e = ba\) and \(ac = e = ca\). Then, $$ \begin{align*} c = ec = (ba)c = b(ac) = be = b. \end{align*} $$ Therefore, \(c = b\) which is a contradiction so the inverse must be unique. \(\ \blacksquare\) Proposition (2.1.2) Let \(G\) be a group and let \(a, b \in G\). If \(ab = e\), then \(a = b^{-1}\). Likewise, if \(ba = e\), then \(b = a^{-1}\). By definition, \(b\) an inverse of \(a\) if \(ab = ba = e\) so it’s an inverse on both sides. This proposition proposes that checking only one side is enough. That is if \(ab = e\), then \(a = b^{-1}\) and \(b\) is the inverse. So what we want to show here is that given \(ba = e\), then \(b\) is the inverse of \(a\). We don’t check the other side. One side is enough to imply the other. Proof We know from the previous proposition that \(a\) has an inverse \(a^{-1} \in G\). Now consider the expression \(a^{-1}ab\). By associativity, we can reduce this expression in two ways $$ \begin{align*} (a^{-1}a)b &amp;= a^{-1}(ab) \end{align*} $$ The left hand side $$ \begin{align*} (a^{-1}a)b &amp;= eb = b \end{align*} $$ The right hand side is $$ \begin{align*} a^{-1}(ab) &amp;= a^{-1} \end{align*} $$ So \(b = a^{-1}\) and therefore, \(ba = a^{-1}a = e\). Proof (Book) Suppose \(hg = e\), then $$ \begin{align*} h = h(gg^{-1}) = (hg)g^{-1}= eg^{-1} = g^{-1}. \end{align*} $$ Suppose now that \(gh = e\), then $$ \begin{align*} g = g(hh^{-1}) = (gh)h^{-1} = eh^{-1} = h^{-1}. \ \blacksquare \end{align*} $$ Corollary 2.1.3 Let \(g\) be an element of a group \(G\). We have \(g = (g^{-1})^{-1}\) Proof We know \(gg^{-1} = e\). By (2.1.2) \(g = (g^{-1})^{-1}\). \(\ \blacksquare\) Proposition 2.1.4 Let \(G\) be a group and let \(a,b \in G\). Then We have \((ab)^{-1} = b^{-1}a^{-1}\) Proof Notice that \((ab)(b^{-1}a^{-1}) = a(b((b^{-1}a^{-1})) = a((bb^{-1})a^{-1}) = a(ea^{-1}) = aa^{-1} = e\). Therefore, \((ab)^{-1} = b^{-1}a^{-1}\). The Left and Right Multiplication Maps]]></summary></entry><entry><title type="html">Lecture 06/07: Modular Arithmetic</title><link href="http://localhost:4000/jekyll/update/2025/01/30/math417-07-modular-arithmetic.html" rel="alternate" type="text/html" title="Lecture 06/07: Modular Arithmetic" /><published>2025-01-30T00:01:36-08:00</published><updated>2025-01-30T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/01/30/math417-07-modular-arithmetic</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/01/30/math417-07-modular-arithmetic.html"><![CDATA[<!------------------------------------------------------------------------------>
<div class="mintheaderdiv">
Definition (Book Definition 1.7.1)
</div>
<div class="mintbodydiv">
Given integers \(a\) and \(b\), and a natural number \(n\), we say that "\(a\) is congruent to \(b\) modulo \(n\)" and we write 
$$
\begin{align*}
a \equiv b \bmod n \quad \text{or} \quad a \equiv_n b
\end{align*}
$$
if \(a - b\) is divisible by \(n\) or \(n \ | \ a - b\). So there exists some \(t \in \mathbf{Z}\) such that \(a - b = tn\)
</div>
<!------------------------------------------------------------------------------>
<p><br />
<br />
Example: \((1 \bmod 7) = (8 \bmod 7) = 1\). Therefore, \(1 \equiv_7 8\).
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
For each integer \(a\), write
$$
\begin{align*}
[a] &amp;= [a]_n = \{x \in \mathbf{Z} \ | \ x \equiv a \bmod n\} \subseteq \mathbf{Z} \\
    &amp;= \{ a + ny \ | \ y \in \mathbf{Z} \}
\end{align*}
$$
The set \([a]\) is called the residue class or congruence class of \(a\) modulo \(n\).
</div>
<!------------------------------------------------------------------------------>
<p><br />
<br />
Example: \([2]_6 = \{2 + 6y \ | \ y \in \mathbf{Z}\} = \{ ...,-10,-4,2,8,14,20,... \}\)
<br />
\([2]_6 = [8]_6 = [-10]_6 = [602]_6 = ....\)
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>The Remainder Function</b></h4>
<p>Another important definition that we need is the following
<br />
<br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
	\(rem_n \ : \ \mathbf{Z} \rightarrow \{0,1,2,...,n-1\}\) is the remainder function after dividing by \(n\).
	<br />
	\(rem_n(a) = r\) is the unique remainder of \(a \div n\) such that \(0 \leq r &lt; n\) and \(a = qn + r\) for some \(q \in \mathbf{Z}\). Note that \(a - r\) is divisible by \(n\) or \(a \equiv_n r\).
</div>
<!------------------------------------------------------------------------------>
<p><br />
It’s important to note that the remainder is in the same congruence class as \(a\). In fact \([a]_n \cap \{0,...n-1\} = \{r\}\). Usually the remainder \(r\) is the standard/canonical name for the congruence class. So for example, we usually don’t write \([602]_6\) but write \([2]_6\). But we don’t have to put it in canonical form.
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Properties of Congruence</b></h4>
<p>Congruence is an equivalence relation. The following properties show this.
<br />
<br />
<!-------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma (Book 1.7.2)
</div>
<div class="yellowbodydiv">
	Properties of Congruence:
<ol>
	<li>Reflexive: For all \(a \in \mathbf{Z}\), \(a \equiv a \bmod n\).</li>
	<li>Symmetric: For all \(a, b \in \mathbf{Z}\), \(a \equiv b \bmod n\) if and only if \(b \equiv a \bmod n\).</li>
	<li>Transitive: For all \(a, b, c \in \mathbf{Z}\), if \(a \equiv b \bmod n\) and \(b \equiv c \bmod n\), then \(a \equiv c \bmod n\).</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof (book)</b>
<br />
For \((a)\), \(a - a = 0\) is divisible by \(n\). For \((b)\), if \(a - b\) is divisible by \(n\), then \(b - a\) is also divisible by \(n\) and vice versa. For \((c)\), if \(a - b\) is divisible by \(n\) and \(b - c\) is divisible by \(4n\), then \((a - b) + (b - c) = a - c\) is also divisible by \(n\). \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------>
Based on these properties, we have the following proposition
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Proposition (Book Lemma 1.7.3)
</div>
<div class="yellowbodydiv">
For \(a, b \in \mathbf{Z}\), the following are equivalent:
<ol type="a">
	<li>\(a \equiv b \bmod n\).</li>
	<li>\([a]_n = [b]_n\).</li>
	<li>\(\text{rem}_n(a) = \text{rem}_n(b)\).</li>
	<li>\([a]_n \cap [b]_n \neq \emptyset\).</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof (Book):</b>
<br />
\((a) \implies (b)\):
<br />
Suppose \(a \equiv b \bmod n\). We want to show that \([a]_n = [b]_n\). 
<br />
\([a]_n \subseteq [b]_n\): Let \(c \in \mathbf{Z}\). If \(c \equiv a \bmod n\), then \(c \equiv b \bmod n\) by Lemma 1.7.2 (c). Therefore \([a]_n \subseteq [b]_n\).
<br />
\([b]_n \subseteq [a]_n\): If \(c \equiv b \bmod n\), then \(c \equiv a \bmod n\) and so \([a] = [b]\) as required.
<br />
<br />
\((b) \implies (c)\):
<br />
By definition, \(\text{rem}_n(x)\) is the unique element of \([x]\) that lies inside \(\{0,1,...,n-1\}\). So if \([a]_n=[b]_n\), then it must be the same element.
<br />
<br />
\((c) \implies (d)\):
<br />
\((d)\) is an immediate application of \((c)\)
<br />
<br />
\((d) \implies (a)\):
Suppose that \([a]_n \cap [b]_n \neq \emptyset\). Let \(c \in [a]_n \cap [b]_n\). Then \(a \equiv c \bmod n\) and \(b \equiv c \bmod n\). But this implies that \(a \equiv b \bmod n\). \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Modular Arithmetic</b></h4>
<p>The following lemma establishes how modular arithmetic is done.
<br /></p>
<div class="yellowheaderdiv">
Proposition (Book Lemma 1.7.5)
</div>
<div class="yellowbodydiv">
Let \(a, a', b, b'\) be integers with \(a \equiv a' \bmod n\) and \(b \equiv b' \bmod n\). Then 
$$
\begin{align*}
a + b &amp;\equiv a' + b' \bmod n \\
ab &amp;\equiv a'b' \bmod n
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof</b>
<br />
[TODO]
<br />
<br />
<!------------------------------------------------------------------------------>
We can now use these modular arithmetic properties to define algebraic structures on a set.
<br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
	$$
	\begin{align*}
	\mathbf{Z}_n &amp;= \{ \text{ set of congruence classes mod } n \} \\
	             &amp;= \{ [a]_n \ | \ a \in \mathbf{Z} \} \\
				 &amp;= \{ [0]_n, [1]_n,...,[n-1]_n \ | \ a \in \mathbf{Z} \} \\
	\end{align*}
	$$
</div>
<p><br />
<br />
<!------------------------------------------------------------------------------>
So now we can use the operations we defined previously to turn this set into a commutative ring.
<br />
<br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Define operations \(+\), \(\cdot\) on \(\mathbf{Z}_n\) by
	$$
	\begin{align*}
	[a]_n + [b]_n &amp;= [a + b]_n \\
	[a]_n[b]_n &amp;= [ab]_n
	\end{align*}
	$$
</div>
<p><br />
\((\mathbf{Z}_n,+,\cdot)\) is commutative ring with identity while \((\mathbf{Z}_n,\cdot)\) is a commutative monoid. \([1]\) is the identity element.
<br />
<br />
Only some elements \([a] \in \mathbf{Z}_n\) have a multiplicative inverse. (such that \([a][b] = [1] = [b][a]\)). The question is when do we have a multiplicative inverse? The answer is in the following proposition.
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(n \geq 1, a \in \mathbf{Z}\). Then \([a]\) has a multiplicative inverse in \(\mathbf{Z}\) if and only if \(gcd(a,n) = 1\).
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof</b>
<br />
Suppose that \(gcd(a,n)=1\). Then there exists \(r, s \in \mathbf{Z}\) such that \(ar + ns = 1\). Re-writing this equation, we observe that</p>
<div>
$$
\begin{align*}
ar + ns = 1 &amp;\Longleftrightarrow ar = 1 + (-s)n \quad \text{ (so $ar$ and 1 differ by a multiple of $n$)}\\
             &amp;\Longleftrightarrow ar = 1 \bmod n \\
			 &amp;\Longleftrightarrow [a][r] = 1. \ \blacksquare \\
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------>
We will use \(\phi(n) = \{x \in \mathbf{Z}_n \ | \ x \text{ has a multiplicative inverse}\} \in \mathbf{Z}_n\). 
<br />
\((\phi(n))\) is a commutative group.
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Binomial Theorem</b></h4>
<p><br />
Next we have the binomial theorem which we need to prove a proposition which will then lead to Fermat’s Little Theorem.
<br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem (Binomial Theorem)
</div>
<div class="yellowbodydiv">
	\(a, b \in \mathbf{R}, n \in \mathbf{N}\). Then
	$$
	\begin{align*}
	(a + b)^n = \sum_{k=0}^{n} \binom{n}{k} a^{n-k} b^k
	\end{align*}
	$$
	where \(\binom{n}{k} = \frac{n!}{k!(n-k)!}\) for \(a \leq k \leq n\)
</div>
<p><br />
<b>Proof</b>
<br />
Use Pascal’s Identity: \(\binom{n}{k} = \binom{n-1}{k} + \binom{n-1}{k-1}\)… TODO
<br />
<br />
As a consequence of the binomial theorem, we have the next proposition
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(p\) be prime. For all \(a, b \in \mathbf{Z}\):
	$$
	\begin{align*}
	(a + b)^p \equiv a^p + b^p \bmod p
	\end{align*}
	$$
</div>
<p><br />
<br />
First observe that \((a+b)^5 = a^5 + 5a^4b + 10a^3b^2 + 10a^2b^3 + 5ab^4 + b^5\). So those middle terms all have coefficients divisible by 5. Therefore, they’ll go away if we apply mod \(5\). This happens when \(p\) is prime.
<br />
<br />
<!------------------------------------------------------------------------------>
<b>Proof</b>
<br />
Using the binomial theorem, we can first expand the sum \((a+b)^p\) as follows</p>
<div>
	$$
	\begin{align*}
	(a + b)^p &amp;= \sum_{k=0}^{n} \binom{p}{k} a^{p-k} b^k \\
	          &amp;= a^{p} + \binom{p}{1} a^{p-1} b + \binom{p}{2} a^{p-2} b^2 + ... + b^k \\
	\end{align*}
	$$
</div>
<p>What we need to show is that \(\binom{p}{k} \equiv 0 \bmod p\) if \(0 &lt; k &lt; p\). If we show this, then what’s left is the first and last terms only. Observe that</p>
<div>
	$$
	\begin{align*}
	\binom{p}{k} &amp;= \frac{p!}{k!(p-k)!} \\
	\binom{p}{k} k! (p-k)! &amp;= p! \\
	\end{align*}
	$$
</div>
<p>\(p! = p(p-1)...1\). So \(p \ | \ p!\). But \(p! = \binom{p}{k} k! (p-k)!\) so \(p\) divides this whole product. Since \(p\) is prime, then \(p\) must divide one of the factors. Now observe that \(p\) can’t divide \(k!\) since \(k &lt; p\). \(p\) doesn’t divide \((p - k)!\) either since \(p - k &lt; p\). Therefore, \(p\) must divide \(\binom{p}{k}\) as desired. \(\ \blacksquare\). 
<!------------------------------------------------------------------------------>
<br />
<br />
A consequence of this proof is Fermat’s Little Theorem
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Fermat's Little Theorem</b></h4>
<p>Next, we will prove Fermat’s Little Theorem.
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
	Let \(p\) be prime, \(a \in \mathbf{Z}\)
	<ol>
		<li>\(a^p \equiv a \bmod p\)</li>
		<li>If \(p \nmid a\), then \(a^{p-1} \equiv 1 \bmod p\)</li>
	</ol>
</div>
<!------------------------------------------------------------------------------>
<p><br />
<b>Proof of (1)</b>
<br /></p>
<div class="proofdiv">
By Induction on \(a\) for \(a \geq 1\).
<br />
Base Case (\(a = 1\)): \(1^p \equiv 1 \bmod p\) and so we're done.
<br />
<br />
Inductive Case (\(a &gt; 1\)): 
Assume it is true for \(a\). We will show that it is true for \(a+1\). 
<div>
	$$
	\begin{align*}
	(a + 1)^p &amp;\equiv a^p + 1^p \quad \text{(By the previous proposition)} \\
	          &amp;\equiv a + 1 \quad \text{(By the inductive hypothesis)}
	\end{align*}
	$$
</div>
</div>
<!------------------------------------------------------------------------>
<p><br />
Note that if \(a = 0\), then \(0^p = 0\). 
<br />
<!------------------------------------------------------------------------>
For \(a \leq 0\), we can use downward induction.</p>
<div class="proofdiv">
By Induction on \(a\) for \(a &lt; 0\).
<br />
Base Case (\(a = -1\)):  We need to show that \((-1)^p \equiv -1 \bmod p\). \(p\) is prime so we have two cases. If \(p = 2\), then \((-1)^2 = 1 = -1 \bmod 2\). If \(p\) is odd, then \((-1)^p = -1\).
<br />
<br />
Inductive Case (\(a &lt; -1\)): We want to show that \(a^p \equiv a\) implies \((a - 1)^p = a - 1\).
</div>
<p><br />
<!------------------------------------------------------------------------>
<b>Proof of (2)</b>
<br />
We are given that \(a \nmid p\). From part (1), we know that \(a^p \equiv a \bmod p\). So \(p \ | \ a^p - a = a(a^{p-1} - 1)\). But since \(p\) is prime and since it doesn’t divide \(p\), then it must divide \(a^{p-1} - 1\). 
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Two-Prime Fermat</b></h4>
<p>There is a more generalized version of Fermat’s Little Theorem. We will use Fermat’s theorem to prove it.
<br />
<br /></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
	Let \(p, q\) be distinct primes and let \(n = pq\). Let \(m\) be
	$$
	\begin{align*}
	   m = lcm(p-1, q-1) = \frac{(p-1)(q-1)}{gcd(p-1,q-1)}
	\end{align*}
	$$
If \(a \in \mathbf{Z}\), \(h \in \mathbf{N}\) such that \(h \equiv 1 \bmod m\), then \(a^h \equiv a \bmod n\)
</div>
<!------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
We know that \(h \equiv 1 \bmod m\) so \(h = 1 + tm\) for some \(t \in \mathbf{Z}\). We want to show that \(a^h \equiv a \bmod n\). In other words, we want to show that \(n \ | \ a^h - a\) which means that \(pq \ | \ a^h - a\). We can write \(a^h - a\) as follows</p>
<div>
	$$
	\begin{align*}
	   a^h - a &amp;= a^{1+tm} - a \\
	           &amp;= a(a^{tm} - 1).
	\end{align*}
	$$
</div>
<p>Therefore, want to show that \(pq\) divides \(a(a^{tm} - 1)\). Lecture 5 Proposition (Corollary 1.6.17 in the book) states that if \(a\) and \(b\) are relatively prime, \(a \ | \ n\) and \(b \ | \ n\), \(ab \ | \ n\). We’re given that \(p\) and \(q\) are distinct primes so they are relatively prime. So the goal is to prove that \(p\) divides \(a(a^{tm} - 1)\) and \(q\) divides \(a(a^{tm} - 1)\) to conclude that the product \(pq\) divides \(a(a^{tm} - 1)\).
<br />
<br />
To start, we want to show that \(p \ | \ a(a^{tm} - 1)\). But since \(p\) is prime, then it will have to divide \(a\) or \(a^{tm} - 1\). So we need to show that either \(p \ | \ a\) or \(p \ | \ a^{tm} - 1\). So suppose that \(p \nmid a\). We claim that \(p \ | \ a^{tm} - 1\). Recall that \(m = lcm(p-1, q-1)\). So \(m\) is a multiple of \(p-1\) and we can write \(m = (p - 1)s\) for some \(s \in \mathbf{N}\). So now we can write \(a^{tm}\) as follows</p>
<div>
	$$
	\begin{align*}
	   a^{tm} &amp;= a^{ts(p-1)} \\
	              &amp;= (a^{p-1})^{ts}.
	\end{align*}
	$$
</div>
<p>Since we assumed that \(p \nmid a\). Then we can use Fermat’s Little Theorem (part 2) to conclude that \(a^{p-1} \equiv 1 \bmod p\). Now we can use modular arithmetic to simplify the original expression.</p>
<div>
	$$
	\begin{align*}
	   (a^{p-1})^{ts} &amp;\equiv 1^{ts} \bmod p \text{ (because } a^{p-1} \equiv 1 \bmod p) \\
	                  &amp;\equiv 1 \bmod p.
	\end{align*}
	$$
</div>
<p>This implies that \(a^{tm} - 1\) must be divisible by \(p\) as we wanted to show. So \(p\) divides the product \(a(a^{tm} - 1)\). With a similar argument, we can show this for \(q\).
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>RSA Cryptosystem</b></h4>
<p>This encryption method is based on the two prime fermat theorem. It is widely used to encrypt many of the transactions that happen on the internet.
<br />
<br />
Symmetric Encryption:
We have some plain text (\(x \in \mathbf{Z}_n\)) that we want to encrypt. We have a function that takes a key (\(e \in \mathbf{Z}\)) to encrypt the plain text and turn it to encrypted text (\(y \in \mathbf{Z}_n\)). To decrypt it back, we have to use the same key again to turn it to plain text. The flaw in this method is that the encryption and decryption keys are the same and will need to be shared somehow. That’s why we have an alternative:
<br />
<br />
Asymmetric Encryption:
This is the same proces except that now we have a decryption key \((d \in \mathbf{Z})\). So now we have a pair of keys \((e, d)\). You will broadcast \(e\) so that anyone can encrypt a message and send it to you, but you are the only with the decryption key. The goal here is to design the pair such that one one can deduce \(d\) from \(e\). So how to design such a pair?
<br />
<br />
One way to implement this idea is the following (RSA):</p>
<ol>
	<li>Pick a prime number \(p,q\) large (100s of digits)</li>
	<li>\(n = pq\)</li>
	<li>\(m = lcm(p-1,q-1)\)</li>
	<li>Choose \(1 &lt; d, e &lt; m\) such that \(de \equiv 1 \bmod m\). You can first pick \(d\) and then you can pick a multiplicative inverse of \(d\) to be \(e\) using the Euclidean Algorithm.</li>
</ol>
<p>So now, you take the plain test \(x\) and raise it to the \(e\)th power. \(x^e\) is the encrypted text. \(e\) is the encryption key. The output \(y = x^e\) is the encrypted text. To decrypt it, raise the encrypted text to the \(d\)th power so \(y^d = x^{ed}\) and so now we have the following equation</p>
<div>
	$$
	\begin{align*}
	  x^{ed} \equiv x \bmod pq
	\end{align*}
	$$
</div>
<p>This is Two-prime Fermat.
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li>MATH417 by Charles Rezk</li>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition (Book Definition 1.7.1) Given integers \(a\) and \(b\), and a natural number \(n\), we say that "\(a\) is congruent to \(b\) modulo \(n\)" and we write $$ \begin{align*} a \equiv b \bmod n \quad \text{or} \quad a \equiv_n b \end{align*} $$ if \(a - b\) is divisible by \(n\) or \(n \ | \ a - b\). So there exists some \(t \in \mathbf{Z}\) such that \(a - b = tn\) Example: \((1 \bmod 7) = (8 \bmod 7) = 1\). Therefore, \(1 \equiv_7 8\). Definition For each integer \(a\), write $$ \begin{align*} [a] &amp;= [a]_n = \{x \in \mathbf{Z} \ | \ x \equiv a \bmod n\} \subseteq \mathbf{Z} \\ &amp;= \{ a + ny \ | \ y \in \mathbf{Z} \} \end{align*} $$ The set \([a]\) is called the residue class or congruence class of \(a\) modulo \(n\). Example: \([2]_6 = \{2 + 6y \ | \ y \in \mathbf{Z}\} = \{ ...,-10,-4,2,8,14,20,... \}\) \([2]_6 = [8]_6 = [-10]_6 = [602]_6 = ....\) The Remainder Function Another important definition that we need is the following Definition \(rem_n \ : \ \mathbf{Z} \rightarrow \{0,1,2,...,n-1\}\) is the remainder function after dividing by \(n\). \(rem_n(a) = r\) is the unique remainder of \(a \div n\) such that \(0 \leq r &lt; n\) and \(a = qn + r\) for some \(q \in \mathbf{Z}\). Note that \(a - r\) is divisible by \(n\) or \(a \equiv_n r\). It’s important to note that the remainder is in the same congruence class as \(a\). In fact \([a]_n \cap \{0,...n-1\} = \{r\}\). Usually the remainder \(r\) is the standard/canonical name for the congruence class. So for example, we usually don’t write \([602]_6\) but write \([2]_6\). But we don’t have to put it in canonical form. Properties of Congruence Congruence is an equivalence relation. The following properties show this. Lemma (Book 1.7.2) Properties of Congruence: Reflexive: For all \(a \in \mathbf{Z}\), \(a \equiv a \bmod n\). Symmetric: For all \(a, b \in \mathbf{Z}\), \(a \equiv b \bmod n\) if and only if \(b \equiv a \bmod n\). Transitive: For all \(a, b, c \in \mathbf{Z}\), if \(a \equiv b \bmod n\) and \(b \equiv c \bmod n\), then \(a \equiv c \bmod n\). Proof (book) For \((a)\), \(a - a = 0\) is divisible by \(n\). For \((b)\), if \(a - b\) is divisible by \(n\), then \(b - a\) is also divisible by \(n\) and vice versa. For \((c)\), if \(a - b\) is divisible by \(n\) and \(b - c\) is divisible by \(4n\), then \((a - b) + (b - c) = a - c\) is also divisible by \(n\). \(\ \blacksquare\) Based on these properties, we have the following proposition Proposition (Book Lemma 1.7.3) For \(a, b \in \mathbf{Z}\), the following are equivalent: \(a \equiv b \bmod n\). \([a]_n = [b]_n\). \(\text{rem}_n(a) = \text{rem}_n(b)\). \([a]_n \cap [b]_n \neq \emptyset\). Proof (Book): \((a) \implies (b)\): Suppose \(a \equiv b \bmod n\). We want to show that \([a]_n = [b]_n\). \([a]_n \subseteq [b]_n\): Let \(c \in \mathbf{Z}\). If \(c \equiv a \bmod n\), then \(c \equiv b \bmod n\) by Lemma 1.7.2 (c). Therefore \([a]_n \subseteq [b]_n\). \([b]_n \subseteq [a]_n\): If \(c \equiv b \bmod n\), then \(c \equiv a \bmod n\) and so \([a] = [b]\) as required. \((b) \implies (c)\): By definition, \(\text{rem}_n(x)\) is the unique element of \([x]\) that lies inside \(\{0,1,...,n-1\}\). So if \([a]_n=[b]_n\), then it must be the same element. \((c) \implies (d)\): \((d)\) is an immediate application of \((c)\) \((d) \implies (a)\): Suppose that \([a]_n \cap [b]_n \neq \emptyset\). Let \(c \in [a]_n \cap [b]_n\). Then \(a \equiv c \bmod n\) and \(b \equiv c \bmod n\). But this implies that \(a \equiv b \bmod n\). \(\ \blacksquare\) Modular Arithmetic The following lemma establishes how modular arithmetic is done. Proposition (Book Lemma 1.7.5) Let \(a, a', b, b'\) be integers with \(a \equiv a' \bmod n\) and \(b \equiv b' \bmod n\). Then $$ \begin{align*} a + b &amp;\equiv a' + b' \bmod n \\ ab &amp;\equiv a'b' \bmod n \end{align*} $$ Proof [TODO] We can now use these modular arithmetic properties to define algebraic structures on a set. Definition $$ \begin{align*} \mathbf{Z}_n &amp;= \{ \text{ set of congruence classes mod } n \} \\ &amp;= \{ [a]_n \ | \ a \in \mathbf{Z} \} \\ &amp;= \{ [0]_n, [1]_n,...,[n-1]_n \ | \ a \in \mathbf{Z} \} \\ \end{align*} $$ So now we can use the operations we defined previously to turn this set into a commutative ring. Definition Define operations \(+\), \(\cdot\) on \(\mathbf{Z}_n\) by $$ \begin{align*} [a]_n + [b]_n &amp;= [a + b]_n \\ [a]_n[b]_n &amp;= [ab]_n \end{align*} $$ \((\mathbf{Z}_n,+,\cdot)\) is commutative ring with identity while \((\mathbf{Z}_n,\cdot)\) is a commutative monoid. \([1]\) is the identity element. Only some elements \([a] \in \mathbf{Z}_n\) have a multiplicative inverse. (such that \([a][b] = [1] = [b][a]\)). The question is when do we have a multiplicative inverse? The answer is in the following proposition. Proposition Let \(n \geq 1, a \in \mathbf{Z}\). Then \([a]\) has a multiplicative inverse in \(\mathbf{Z}\) if and only if \(gcd(a,n) = 1\). Proof Suppose that \(gcd(a,n)=1\). Then there exists \(r, s \in \mathbf{Z}\) such that \(ar + ns = 1\). Re-writing this equation, we observe that $$ \begin{align*} ar + ns = 1 &amp;\Longleftrightarrow ar = 1 + (-s)n \quad \text{ (so $ar$ and 1 differ by a multiple of $n$)}\\ &amp;\Longleftrightarrow ar = 1 \bmod n \\ &amp;\Longleftrightarrow [a][r] = 1. \ \blacksquare \\ \end{align*} $$ We will use \(\phi(n) = \{x \in \mathbf{Z}_n \ | \ x \text{ has a multiplicative inverse}\} \in \mathbf{Z}_n\). \((\phi(n))\) is a commutative group. Binomial Theorem Next we have the binomial theorem which we need to prove a proposition which will then lead to Fermat’s Little Theorem. Theorem (Binomial Theorem) \(a, b \in \mathbf{R}, n \in \mathbf{N}\). Then $$ \begin{align*} (a + b)^n = \sum_{k=0}^{n} \binom{n}{k} a^{n-k} b^k \end{align*} $$ where \(\binom{n}{k} = \frac{n!}{k!(n-k)!}\) for \(a \leq k \leq n\) Proof Use Pascal’s Identity: \(\binom{n}{k} = \binom{n-1}{k} + \binom{n-1}{k-1}\)… TODO As a consequence of the binomial theorem, we have the next proposition Proposition Let \(p\) be prime. For all \(a, b \in \mathbf{Z}\): $$ \begin{align*} (a + b)^p \equiv a^p + b^p \bmod p \end{align*} $$ First observe that \((a+b)^5 = a^5 + 5a^4b + 10a^3b^2 + 10a^2b^3 + 5ab^4 + b^5\). So those middle terms all have coefficients divisible by 5. Therefore, they’ll go away if we apply mod \(5\). This happens when \(p\) is prime. Proof Using the binomial theorem, we can first expand the sum \((a+b)^p\) as follows $$ \begin{align*} (a + b)^p &amp;= \sum_{k=0}^{n} \binom{p}{k} a^{p-k} b^k \\ &amp;= a^{p} + \binom{p}{1} a^{p-1} b + \binom{p}{2} a^{p-2} b^2 + ... + b^k \\ \end{align*} $$ What we need to show is that \(\binom{p}{k} \equiv 0 \bmod p\) if \(0 &lt; k &lt; p\). If we show this, then what’s left is the first and last terms only. Observe that $$ \begin{align*} \binom{p}{k} &amp;= \frac{p!}{k!(p-k)!} \\ \binom{p}{k} k! (p-k)! &amp;= p! \\ \end{align*} $$ \(p! = p(p-1)...1\). So \(p \ | \ p!\). But \(p! = \binom{p}{k} k! (p-k)!\) so \(p\) divides this whole product. Since \(p\) is prime, then \(p\) must divide one of the factors. Now observe that \(p\) can’t divide \(k!\) since \(k &lt; p\). \(p\) doesn’t divide \((p - k)!\) either since \(p - k &lt; p\). Therefore, \(p\) must divide \(\binom{p}{k}\) as desired. \(\ \blacksquare\). A consequence of this proof is Fermat’s Little Theorem Fermat's Little Theorem Next, we will prove Fermat’s Little Theorem. Theorem Let \(p\) be prime, \(a \in \mathbf{Z}\) \(a^p \equiv a \bmod p\) If \(p \nmid a\), then \(a^{p-1} \equiv 1 \bmod p\) Proof of (1) By Induction on \(a\) for \(a \geq 1\). Base Case (\(a = 1\)): \(1^p \equiv 1 \bmod p\) and so we're done. Inductive Case (\(a &gt; 1\)): Assume it is true for \(a\). We will show that it is true for \(a+1\). $$ \begin{align*} (a + 1)^p &amp;\equiv a^p + 1^p \quad \text{(By the previous proposition)} \\ &amp;\equiv a + 1 \quad \text{(By the inductive hypothesis)} \end{align*} $$ Note that if \(a = 0\), then \(0^p = 0\). For \(a \leq 0\), we can use downward induction. By Induction on \(a\) for \(a &lt; 0\). Base Case (\(a = -1\)): We need to show that \((-1)^p \equiv -1 \bmod p\). \(p\) is prime so we have two cases. If \(p = 2\), then \((-1)^2 = 1 = -1 \bmod 2\). If \(p\) is odd, then \((-1)^p = -1\). Inductive Case (\(a &lt; -1\)): We want to show that \(a^p \equiv a\) implies \((a - 1)^p = a - 1\). Proof of (2) We are given that \(a \nmid p\). From part (1), we know that \(a^p \equiv a \bmod p\). So \(p \ | \ a^p - a = a(a^{p-1} - 1)\). But since \(p\) is prime and since it doesn’t divide \(p\), then it must divide \(a^{p-1} - 1\). Two-Prime Fermat There is a more generalized version of Fermat’s Little Theorem. We will use Fermat’s theorem to prove it. Theorem Let \(p, q\) be distinct primes and let \(n = pq\). Let \(m\) be $$ \begin{align*} m = lcm(p-1, q-1) = \frac{(p-1)(q-1)}{gcd(p-1,q-1)} \end{align*} $$ If \(a \in \mathbf{Z}\), \(h \in \mathbf{N}\) such that \(h \equiv 1 \bmod m\), then \(a^h \equiv a \bmod n\) Proof We know that \(h \equiv 1 \bmod m\) so \(h = 1 + tm\) for some \(t \in \mathbf{Z}\). We want to show that \(a^h \equiv a \bmod n\). In other words, we want to show that \(n \ | \ a^h - a\) which means that \(pq \ | \ a^h - a\). We can write \(a^h - a\) as follows $$ \begin{align*} a^h - a &amp;= a^{1+tm} - a \\ &amp;= a(a^{tm} - 1). \end{align*} $$ Therefore, want to show that \(pq\) divides \(a(a^{tm} - 1)\). Lecture 5 Proposition (Corollary 1.6.17 in the book) states that if \(a\) and \(b\) are relatively prime, \(a \ | \ n\) and \(b \ | \ n\), \(ab \ | \ n\). We’re given that \(p\) and \(q\) are distinct primes so they are relatively prime. So the goal is to prove that \(p\) divides \(a(a^{tm} - 1)\) and \(q\) divides \(a(a^{tm} - 1)\) to conclude that the product \(pq\) divides \(a(a^{tm} - 1)\). To start, we want to show that \(p \ | \ a(a^{tm} - 1)\). But since \(p\) is prime, then it will have to divide \(a\) or \(a^{tm} - 1\). So we need to show that either \(p \ | \ a\) or \(p \ | \ a^{tm} - 1\). So suppose that \(p \nmid a\). We claim that \(p \ | \ a^{tm} - 1\). Recall that \(m = lcm(p-1, q-1)\). So \(m\) is a multiple of \(p-1\) and we can write \(m = (p - 1)s\) for some \(s \in \mathbf{N}\). So now we can write \(a^{tm}\) as follows $$ \begin{align*} a^{tm} &amp;= a^{ts(p-1)} \\ &amp;= (a^{p-1})^{ts}. \end{align*} $$ Since we assumed that \(p \nmid a\). Then we can use Fermat’s Little Theorem (part 2) to conclude that \(a^{p-1} \equiv 1 \bmod p\). Now we can use modular arithmetic to simplify the original expression. $$ \begin{align*} (a^{p-1})^{ts} &amp;\equiv 1^{ts} \bmod p \text{ (because } a^{p-1} \equiv 1 \bmod p) \\ &amp;\equiv 1 \bmod p. \end{align*} $$ This implies that \(a^{tm} - 1\) must be divisible by \(p\) as we wanted to show. So \(p\) divides the product \(a(a^{tm} - 1)\). With a similar argument, we can show this for \(q\). RSA Cryptosystem This encryption method is based on the two prime fermat theorem. It is widely used to encrypt many of the transactions that happen on the internet. Symmetric Encryption: We have some plain text (\(x \in \mathbf{Z}_n\)) that we want to encrypt. We have a function that takes a key (\(e \in \mathbf{Z}\)) to encrypt the plain text and turn it to encrypted text (\(y \in \mathbf{Z}_n\)). To decrypt it back, we have to use the same key again to turn it to plain text. The flaw in this method is that the encryption and decryption keys are the same and will need to be shared somehow. That’s why we have an alternative: Asymmetric Encryption: This is the same proces except that now we have a decryption key \((d \in \mathbf{Z})\). So now we have a pair of keys \((e, d)\). You will broadcast \(e\) so that anyone can encrypt a message and send it to you, but you are the only with the decryption key. The goal here is to design the pair such that one one can deduce \(d\) from \(e\). So how to design such a pair? One way to implement this idea is the following (RSA): Pick a prime number \(p,q\) large (100s of digits) \(n = pq\) \(m = lcm(p-1,q-1)\) Choose \(1 &lt; d, e &lt; m\) such that \(de \equiv 1 \bmod m\). You can first pick \(d\) and then you can pick a multiplicative inverse of \(d\) to be \(e\) using the Euclidean Algorithm. So now, you take the plain test \(x\) and raise it to the \(e\)th power. \(x^e\) is the encrypted text. \(e\) is the encryption key. The output \(y = x^e\) is the encrypted text. To decrypt it, raise the encrypted text to the \(d\)th power so \(y^d = x^{ed}\) and so now we have the following equation $$ \begin{align*} x^{ed} \equiv x \bmod pq \end{align*} $$ This is Two-prime Fermat. References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">Lecture 06: Least Common Multiple</title><link href="http://localhost:4000/jekyll/update/2025/01/29/math417-06-lcm.html" rel="alternate" type="text/html" title="Lecture 06: Least Common Multiple" /><published>2025-01-29T00:01:36-08:00</published><updated>2025-01-29T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/01/29/math417-06-lcm</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/01/29/math417-06-lcm.html"><![CDATA[<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
A least common multiple (LCM) is \(m \in \mathbf{Z_{\geq 0}}\) such that:
<ol type="a">
	<li>\(a \ | \ m\) and \(b \ | \ m\)</li>
	<li>If \(n \in \mathbf{Z}\), \(a \ | \ n\) and \(b \ | \ n\), then \(m \ | \ n\).</li>
</ol>
</div>
<!------------------------------------------------------------------------>
<p><br />
<br />
In fact the LCM is unique if it exists. To prove it’s existence we’ll need the following definition
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition (Well Ordering Principle)
</div>
<div class="mintbodydiv">
A non-empty subset of \(\mathbf{N}\) has a smallest element
</div>
<!------------------------------------------------------------------------>
<p><br />
<br />
Next, we’ll prove the existence of the LCM.
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
The LCM always exists
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
Let \(a, b \in \mathbf{Z}\). Let \(J = \mathbf{Z}a \cap \mathbf{Z}b\). We want to show that \(J\) itself is a set of multiples so we can write \(J = \mathbf{Z}m\) for some \(m \in \mathbf{Z}_{\geq 0}\). This means that \(m\) must be the LCM of \(a\) and \(b\) by definition. [Why? If \(J = \mathbf{Z}m\), then \(m\) is the least element in \(J\), all the other elements are multiples of \(m\). We have \(a \ | \ m\) and \(b \ | \ m\) because \(J\) also contains common multiples of \(a\) and \(b\). And for any \(n \in \mathbf{Z}\), if \(a \ | \ n\) and \(b \ | \ n\), then \(m \ | \ n\). This is true because \(m\) is the smallest of all these common multiples.] We will use division by remainder to prove this!
<br />
<br />
Observe that \(J\) is closed under addition and subtraction. So if \(c, d \in J\), then any integer combination of \(c\) and \(d\) will be in \(J\). So for any \(m, n \in \mathbf{Z}\),  \(cm + dn \in J\).
<br />
<br />
We have two cases:
<br />
Case 1: If either \(a = 0\) or \(b = 0\), then \(J = \{0\} = \mathbf{Z}0\).
<br />
<br />
Case 2: If \(a \neq 0\) and \(b \neq 0\), then \(J\) is the set of common multiples of \(\mathbf{Z}a\) and \(\mathbf{Z}b\). Consider \(J \cap \mathbf{N}\). This is the set of positive common multiples. This set is not empty because it will at least include \(|ab|\). So \(J \cap \mathbf{N}\) is a non-empty subset of \(\mathbf{N}\). By the well-ordering principle, there is a smallest number in \(J \cap \mathbf{N}\). Let \(m \in J \cap \mathbf{N}\) be the smallest common multiple. (so we’re setting \(m\) to be the smallest positive common multiple of \(\mathbf{Z}a\) and \(\mathbf{Z}b\))
<br />
<br />
We claim that \(J = \mathbf{Z}m\) (the set of multiples of \(m\)). We will show this by proving that \(J \subseteq \mathbf{Z}m\) and that \(\mathbf{Z}m \subseteq J\). 
<br />
<br />
\(\mathbf{Z}m \subseteq J\): This is true since \(m \in J\) and we showed earlier that \(m\) is closed under addition and subtraction so any multiple of \(m\) is also in \(J\) and therefore \(\mathbf{Z}m \subseteq J\).
<br />
<br />
\(J \subseteq \mathbf{Z}m\): Suppose \(x \in J = \mathbf{Z}a \cap \mathbf{Z}b\). Consider what happens when we divide \(x\) by \(m\). We can write \(x = qm + r\). with \(q, r \in \mathbf{Z}\) and \(0 \leq r &lt; m\). Re-write the equation as</p>
<div>
$$
\begin{align*}
r = x - qm.
\end{align*}
$$
</div>
<p>Observe now that \(x \in J\) by assumption. \(qm\) is a multiple of \(m\) so it’s in \(J\). So their difference is also in \(J\) which means that \(r \in J\). If \(r = 0\), \(x = qm \in \mathbf{Z}m\) and we’re done. If \(r \neq 0\), then \(r \in J\), then \(r \in J \cap \mathbf{N}\) but also \(r &lt; m\). But that’s a contradiction because \(m\) is the smallest element in \(J \cap \mathbf{N}\) and so this case doesn’t happen. So \(J = \mathbf{Z}m\) as desired. \(\ \blacksquare\).
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Consequences of the LCM</b></h4>
<p>The next few propositions are some consequences of the LCM.
<br />
<br /></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(d = gcd(a,b) = 1\), then \(m = lcm(a,b) = ab\)
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
We are given that \(d = gcd(a,b) = 1\). This means that \(a\) and \(b\) are relatively prime. Condition 1 is true since \(a \ | \ ab\) and \(b \ | \ ab\). For condition two of the LCM definition, let \(n \in \mathbf{Z}\) such that \(a \ | \ n\) and \(b \ | \ n\). By the proposition from lecture 5, \(ab \ | \ n\). (Proposition: If \(a\) and \(b\) are relatively prime, then if \(a \ | \ n\) and \(b \ | \ n\), then \(ab \ | \ n\)). \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
Let \(e\) be a common divisor of \(a\) and \(b\) so \(e \ | \ a\) and \(e \ | \ b\). Then \(lcm(\frac{a}{e}, \frac{b}{e}) = \frac{1}{e} lcm(a,b)\). 
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
[TODO] \(x\) is a common divisor of \(\frac{a}{e}\) and \(\frac{b}{e}\) if and only if \(xe\) is a common divisor of \(a\) and \(b\). 
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(a, b \in \mathbf{N}\), \(d = gcd(a,b)\) and \(m = lcm(a,b)\), then \(m = \frac{ab}{d}\)
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
We need the previous two propositions</p>
<ol>
	<li>If \(d = 1\), then \(m = lcm(a,b) = ab\)</li>
	<li>If \(e \ | \ a\) and \(e \ | \ b\), then \(lcm(\frac{a}{e}, \frac{b}{e}) = \frac{1}{e} lcm(a,b)\)</li>
</ol>
<p>If we divide both \(a\) and \(b\) by \(d\), their gcd will become 1 so \(gcd(\frac{a}{d}, \frac{b}{d}) = 1\). Since the gcd is 1, then \(lcm(\frac{a}{d}, \frac{b}{d}) = \frac{b}{d}\frac{a}{d}\) by part \((1)\). So now let \(e = d\), so by \((2)\),</p>
<div>
$$
\begin{align*}
\frac{1}{d} lcm(a, b) &amp;= lcm(\frac{a}{d}, \frac{b}{d}) \\
\frac{m}{d}  &amp;= \frac{b}{d}\frac{a}{d} \\
m &amp;= \frac{ab}{d} \\
\end{align*}
$$
</div>
<p><br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Pairwise Relatively Prime</b></h4>
<p><br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
\(a_1,...,a_k \in \mathbf{Z}\) are pairwise relatively prime if \(gcd(a_i,a_j) = 1\) for all \(1 \leq i,j \leq k, i \neq j\)
</div>
<p><br />
<br />
Some facts based this:
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma
</div>
<div class="yellowbodydiv">
If \(a_1,...,a_k \in \mathbf{Z}\) are pairwise relatively prime, then \(a_k,b = a_1,...,a_{k-1}\) are relatively prime so \(gcd(a_k,b) = 1\). 
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
Suppose for the sake of contradiction that \(a_k\) and \(b\) are not relatively prime so they have a common divisor. Let \(p\) be a prime that is a common divisor of \(a_k\) and \(b\). So \(p \ | \ b\) which means that \(p \ | \ a_1a_2...a_{k-1}\). But since \(p\) is prime, then by the proposition from the previous lecture, \(p\) must divide one of the factors in \(a_1a_2...a_{k-1}\). Let \(p\) divide \(a_i\) for some \(1 \leq i \leq k - 1\). However \(p \ | \ p_k\). This means that \(gcd(a_i,a_k) \neq 1\). This is a contradiction since we assumed that \(a_1,...,a_k\) are pairwise relatively prime. Therefore, we must have \(a_k\) and \(b\) be relatively prime. \(\ \blacksquare\)
<br />
<br />
The consequence of this lemma is the following
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(a_1, a_2,...,a_k\) are pairwise relatively prime and if \(a_i \ | \ n\) for all \(i = 1,...,k\), then \(a_1a_2,...,a_k \ | \ n\) 
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
By Induction on \(k\) 
<br />
Base Case: If \(k=1\), then there is nothing to prove. 
<br />
If \(k = 2\), then \(gcd(a_1,a_2)=1\). If \(a_1 \ | \ n\) and \(a_1 \ | \ n\), then by the proposition from lecture 5, we must have \(ab \ | \ n\).
<br />
<br />
Inductive Case \(k \geq 3\): <br />
Let \(b = a_1a_2...a_{k-1}\).  By the previous lemma we know that \(gcd(a_k,b) = 1\). Also by the inductive hypothesis if \(a_1,...,a_{k-1} \ | \ n\), then \(a_1...a_{k-1} = b \ | \ n\). but \(gcd(a_k,b) = 1\) so \(a_k\) and \(b\) are relatively prime. Since they are relatively prime and they both divide \(n\), then \(ba_k = a_1...a_{k-1}a_k\) also divides \(n\) as we wanted to show. \(\ \blacksquare\)</p>

<p><br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li>MATH417 by Charles Rezk</li>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition A least common multiple (LCM) is \(m \in \mathbf{Z_{\geq 0}}\) such that: \(a \ | \ m\) and \(b \ | \ m\) If \(n \in \mathbf{Z}\), \(a \ | \ n\) and \(b \ | \ n\), then \(m \ | \ n\). In fact the LCM is unique if it exists. To prove it’s existence we’ll need the following definition Definition (Well Ordering Principle) A non-empty subset of \(\mathbf{N}\) has a smallest element Next, we’ll prove the existence of the LCM. Proposition The LCM always exists Proof Let \(a, b \in \mathbf{Z}\). Let \(J = \mathbf{Z}a \cap \mathbf{Z}b\). We want to show that \(J\) itself is a set of multiples so we can write \(J = \mathbf{Z}m\) for some \(m \in \mathbf{Z}_{\geq 0}\). This means that \(m\) must be the LCM of \(a\) and \(b\) by definition. [Why? If \(J = \mathbf{Z}m\), then \(m\) is the least element in \(J\), all the other elements are multiples of \(m\). We have \(a \ | \ m\) and \(b \ | \ m\) because \(J\) also contains common multiples of \(a\) and \(b\). And for any \(n \in \mathbf{Z}\), if \(a \ | \ n\) and \(b \ | \ n\), then \(m \ | \ n\). This is true because \(m\) is the smallest of all these common multiples.] We will use division by remainder to prove this! Observe that \(J\) is closed under addition and subtraction. So if \(c, d \in J\), then any integer combination of \(c\) and \(d\) will be in \(J\). So for any \(m, n \in \mathbf{Z}\), \(cm + dn \in J\). We have two cases: Case 1: If either \(a = 0\) or \(b = 0\), then \(J = \{0\} = \mathbf{Z}0\). Case 2: If \(a \neq 0\) and \(b \neq 0\), then \(J\) is the set of common multiples of \(\mathbf{Z}a\) and \(\mathbf{Z}b\). Consider \(J \cap \mathbf{N}\). This is the set of positive common multiples. This set is not empty because it will at least include \(|ab|\). So \(J \cap \mathbf{N}\) is a non-empty subset of \(\mathbf{N}\). By the well-ordering principle, there is a smallest number in \(J \cap \mathbf{N}\). Let \(m \in J \cap \mathbf{N}\) be the smallest common multiple. (so we’re setting \(m\) to be the smallest positive common multiple of \(\mathbf{Z}a\) and \(\mathbf{Z}b\)) We claim that \(J = \mathbf{Z}m\) (the set of multiples of \(m\)). We will show this by proving that \(J \subseteq \mathbf{Z}m\) and that \(\mathbf{Z}m \subseteq J\). \(\mathbf{Z}m \subseteq J\): This is true since \(m \in J\) and we showed earlier that \(m\) is closed under addition and subtraction so any multiple of \(m\) is also in \(J\) and therefore \(\mathbf{Z}m \subseteq J\). \(J \subseteq \mathbf{Z}m\): Suppose \(x \in J = \mathbf{Z}a \cap \mathbf{Z}b\). Consider what happens when we divide \(x\) by \(m\). We can write \(x = qm + r\). with \(q, r \in \mathbf{Z}\) and \(0 \leq r &lt; m\). Re-write the equation as $$ \begin{align*} r = x - qm. \end{align*} $$ Observe now that \(x \in J\) by assumption. \(qm\) is a multiple of \(m\) so it’s in \(J\). So their difference is also in \(J\) which means that \(r \in J\). If \(r = 0\), \(x = qm \in \mathbf{Z}m\) and we’re done. If \(r \neq 0\), then \(r \in J\), then \(r \in J \cap \mathbf{N}\) but also \(r &lt; m\). But that’s a contradiction because \(m\) is the smallest element in \(J \cap \mathbf{N}\) and so this case doesn’t happen. So \(J = \mathbf{Z}m\) as desired. \(\ \blacksquare\). Consequences of the LCM The next few propositions are some consequences of the LCM. Proposition If \(d = gcd(a,b) = 1\), then \(m = lcm(a,b) = ab\) Proof We are given that \(d = gcd(a,b) = 1\). This means that \(a\) and \(b\) are relatively prime. Condition 1 is true since \(a \ | \ ab\) and \(b \ | \ ab\). For condition two of the LCM definition, let \(n \in \mathbf{Z}\) such that \(a \ | \ n\) and \(b \ | \ n\). By the proposition from lecture 5, \(ab \ | \ n\). (Proposition: If \(a\) and \(b\) are relatively prime, then if \(a \ | \ n\) and \(b \ | \ n\), then \(ab \ | \ n\)). \(\ \blacksquare\) Proposition Let \(e\) be a common divisor of \(a\) and \(b\) so \(e \ | \ a\) and \(e \ | \ b\). Then \(lcm(\frac{a}{e}, \frac{b}{e}) = \frac{1}{e} lcm(a,b)\). Proof [TODO] \(x\) is a common divisor of \(\frac{a}{e}\) and \(\frac{b}{e}\) if and only if \(xe\) is a common divisor of \(a\) and \(b\). Proposition If \(a, b \in \mathbf{N}\), \(d = gcd(a,b)\) and \(m = lcm(a,b)\), then \(m = \frac{ab}{d}\) Proof We need the previous two propositions If \(d = 1\), then \(m = lcm(a,b) = ab\) If \(e \ | \ a\) and \(e \ | \ b\), then \(lcm(\frac{a}{e}, \frac{b}{e}) = \frac{1}{e} lcm(a,b)\) If we divide both \(a\) and \(b\) by \(d\), their gcd will become 1 so \(gcd(\frac{a}{d}, \frac{b}{d}) = 1\). Since the gcd is 1, then \(lcm(\frac{a}{d}, \frac{b}{d}) = \frac{b}{d}\frac{a}{d}\) by part \((1)\). So now let \(e = d\), so by \((2)\), $$ \begin{align*} \frac{1}{d} lcm(a, b) &amp;= lcm(\frac{a}{d}, \frac{b}{d}) \\ \frac{m}{d} &amp;= \frac{b}{d}\frac{a}{d} \\ m &amp;= \frac{ab}{d} \\ \end{align*} $$ Pairwise Relatively Prime Definition \(a_1,...,a_k \in \mathbf{Z}\) are pairwise relatively prime if \(gcd(a_i,a_j) = 1\) for all \(1 \leq i,j \leq k, i \neq j\) Some facts based this: Lemma If \(a_1,...,a_k \in \mathbf{Z}\) are pairwise relatively prime, then \(a_k,b = a_1,...,a_{k-1}\) are relatively prime so \(gcd(a_k,b) = 1\). Proof Suppose for the sake of contradiction that \(a_k\) and \(b\) are not relatively prime so they have a common divisor. Let \(p\) be a prime that is a common divisor of \(a_k\) and \(b\). So \(p \ | \ b\) which means that \(p \ | \ a_1a_2...a_{k-1}\). But since \(p\) is prime, then by the proposition from the previous lecture, \(p\) must divide one of the factors in \(a_1a_2...a_{k-1}\). Let \(p\) divide \(a_i\) for some \(1 \leq i \leq k - 1\). However \(p \ | \ p_k\). This means that \(gcd(a_i,a_k) \neq 1\). This is a contradiction since we assumed that \(a_1,...,a_k\) are pairwise relatively prime. Therefore, we must have \(a_k\) and \(b\) be relatively prime. \(\ \blacksquare\) The consequence of this lemma is the following Proposition If \(a_1, a_2,...,a_k\) are pairwise relatively prime and if \(a_i \ | \ n\) for all \(i = 1,...,k\), then \(a_1a_2,...,a_k \ | \ n\) Proof By Induction on \(k\) Base Case: If \(k=1\), then there is nothing to prove. If \(k = 2\), then \(gcd(a_1,a_2)=1\). If \(a_1 \ | \ n\) and \(a_1 \ | \ n\), then by the proposition from lecture 5, we must have \(ab \ | \ n\). Inductive Case \(k \geq 3\): Let \(b = a_1a_2...a_{k-1}\). By the previous lemma we know that \(gcd(a_k,b) = 1\). Also by the inductive hypothesis if \(a_1,...,a_{k-1} \ | \ n\), then \(a_1...a_{k-1} = b \ | \ n\). but \(gcd(a_k,b) = 1\) so \(a_k\) and \(b\) are relatively prime. Since they are relatively prime and they both divide \(n\), then \(ba_k = a_1...a_{k-1}a_k\) also divides \(n\) as we wanted to show. \(\ \blacksquare\)]]></summary></entry><entry><title type="html">Lecture 05: Greatest Common Divisor</title><link href="http://localhost:4000/jekyll/update/2025/01/28/math417-05-gcd.html" rel="alternate" type="text/html" title="Lecture 05: Greatest Common Divisor" /><published>2025-01-28T00:01:36-08:00</published><updated>2025-01-28T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2025/01/28/math417-05-gcd</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2025/01/28/math417-05-gcd.html"><![CDATA[<div class="mintheaderdiv">
Definition 1.6.8
</div>
<div class="mintbodydiv">
A natural number \(d\) is the greatest common divisor of integers \(a\) and \(b\) if
<ol type="a">
	<li>\(d\) is a common divisor. So \(d\) divides \(a\) and \(b\)</li>
	<li>Every common divisor \(e\) also divides \(d\). In other words, if \(e \ | \ a\) and \(e \ | \ b\), then \(e \ | \ d\)</li>
</ol>
</div>
<!------------------------------------------------------------------------>
<p><br />
If the greatest common exists, then it is unique. Why? suppose \(d\) and \(d'\) are both greatest common divisors. Then by definition, \(d \ | \ d'\) and \(d' \ | \ d\) because every common divisor divides the gcd and they each must divide each other. But this means that \(d = \pm 'd\) by the divisibility properties from last lecture. But also by definition, \(d\) is non-negative and so \(d = 'd\). \(\ \blacksquare\)
<br />
<br />
Note that in the book \(a\) and \(b\) are nonzero in the definition. With this definition, the set of divisors of \(0\) is \(\mathbf{Z}\). If \(a = 0\) and \(b \neq 0\), then \(|a|\) is the gcd of \(a\) and \(0\). If both \(a\) and \(b\) are zero, then \(0\) is the gcd of \(0\) and \(0\). 
<br />
<br />
<!------------------------------------------------------------------------>
Before addressing the question of whether the greatest common divisor exists, we’ll to define one more thing
<br /></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
Let \(a, b \in \mathbf{Z}\). An integer combination of \(a\) and \(b\) is any integer of the form
$$
\begin{align*}
I(a,b) = \{ra + sb \ | \ r, s \in \mathbf{Z}\}.
\end{align*}
$$
</div>
<!------------------------------------------------------------------------>
<p><br />
For example \(I(4,6) = \{4s + 6t \ | \ s, t \in \mathbf{Z}\}\). If we let \(s = -1\) and \(t = 1\), then \(2 \in I(4,6)\). In fact, this set produces all of the even integers. It includes all multiples of 2. In other words, we can also write that \(I(4,6) = \mathbf{Z}2\). In fact, this turns out to always be true, the set of integer combinations of two integers is also the set of multiples of a number and that number is the greatest common divisor! even when one of the integers is \(0\). So yes the GCD exists and can even be computed. Before formally proving its existence, we’ll present the way it can be computed next.
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>The Euclidean Algorithm</b></h4>
<p>Let \(\mathbf{Z}^2 = \{(a,b), a,b \in \mathbf{Z}\}\). 
<br />
Define \(F: \mathbf{Z}^2 \rightarrow \mathbf{Z}^2\) by</p>
<div class="ediv">
  $$
  \begin{equation*}
  F(m,n) = \begin{cases} (n,r), r = rem_n(m) \quad &amp;\text{if } n \neq 0 \\ (|m|,0) \quad \quad &amp;\text{if } n = 0\end{cases}
  \end{equation*}
  $$
</div>
<p><br />
\(rem_n(m)\) is the remainder of \(m \div n\) (recall that we can write \(m = qn + r\) where \(0 \leq r &lt; |n|)\)).
<br />
<br />
<b>Euclidean Algorithm:</b> Iterate \(F\) until stable.
<br />
<br />
Example:</p>
<div>
  $$
  \begin{align*}
  (42, -24) \xrightarrow{F} (-24, 18) \xrightarrow{F} (18, 12) \xrightarrow{F} (12, 6) \xrightarrow{F} (6, 0) \xrightarrow{F} (6, 0)
  \end{align*}
  $$
</div>
<p><br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>The GCD Theorem</b></h4>
<p>So now we have an algorithm to compute the GCD algorithm. Next, we will prove that it does compute the GCD and so the GCD does exist.
<br />
<!-------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem
</div>
<div class="yellowbodydiv">
Let \(a, b \in \mathbf{Z}\). Then
<ol>
	<li>For \(a, b\) have a GCD \(d \geq 0\).</li>
	<li>\(I(a,b) = \mathbf{Z}d\).</li>
	<li>\(d\) is computed by the Euclidean algorithm.</li>
</ol>
</div>
<p><br />
We’ll start from (3) and then prove that the answer produced by the algorithm is in fact an integer combination of the original input (statement 2). Finally, we’ll show that this just means that we have computed the GCD (statement). To do all of this we will also need the following lemmas
<br />
<br />
<!-------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma
</div>
<div class="yellowbodydiv">
If \(a, b \in I(c,d)\), then \(I(a,b) \subseteq I(c,d)\)
</div>
<p><br />
<b>Proof</b>: Homework Problem
<br />
<br />
<!-------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma
</div>
<div class="yellowbodydiv">
If \(F(m,n) = (a,b)\), then \(I(m,n) = I(a,b)\)
</div>
<p><br />
<b>Proof</b>:
<br />
We have two cases:
<br />
<br />
Case 1: \(n \neq 0\). In this case, \(F(m,n) = (n, r)\) where \(r\) is the remainder after dividing \(m\) by \(n\). So \(m = qn + r\) where \(0 \leq r &lt; |n|\). We want to show that the integer combinations of \(m\) and \(n\) is the same as the integer combinations of \(n\) and \(r\), that is, \(I(m,n) = I(n,r)\). To do this, we will show that \(I(m,n) \subseteq I(n,r)\) and \(I(n,r) \subseteq I(m,n)\). To show that \(I(m,n) \subseteq I(n,r)\), observe that \(m\) is an integer combination of \(n\) and \(r\) because we can write \(m\) as</p>
<div>
  $$
  \begin{align*}
  m &amp;= qn + 1r.  
  \end{align*}
  $$
</div>
<p>Similarly, \(n\) is also an integer combination of \(n\) and \(r\) because we can write \(n\) as</p>
<div>
  $$
  \begin{align*}
  n &amp;= 1n + 0r.
  \end{align*}
  $$
</div>
<p>Since \(m\) and \(n\) can both be written as integer combinations of \(n\) and \(r\), that is \(m \in I(n,r)\) and \(n \in I(n,r)\), then by the previous lemma,  \(I(m,n) \subseteq I(n,r)\). To see that \(I(m,n) \subseteq I(n,r)\), observe that we can write \(n\) as \(n = 0m + 1n\) so \(n \in I(m,n)\). Similarly, \(r = 1m + (-q)m\) so \(r \in I(m,n)\). Then, by the previous lemma, \(I(m,n) \subseteq I(n,r)\). Therefore, \(I(m,n) = I(n,r)\). 
<br />
<br />
Case 2: \(n = 0\). In this case, \(F(m,n) = F(m,0) = (|m|,0)\). In this case the integer combinations of \(0\) and \(m\) are just multiples of \(m\) so \(I(m,0) = \mathbf{Z}m\). But this is the same as the integer combinations of \(|m|\) and \(0\) so \(\mathbf{Z}m = I(|m|,0) = I(m,0)\) which is what we wanted to show. \(\blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Proof of the GCD Theorem</b></h4>
<p>We iterate the algorithm until \(n = 0\) and \(F(m,n) = (|m|,0)\). By the previous lemma we saw that \(I(m,n) = \mathbf{Z}d\) for some \(d \geq 0\). 
<br />
<br />
<b>Claim:</b> \(d\) is a GCD.<br /></p>
<ol>
	<li>\(m,n \in I(m,n) = \mathbf{Z}d\). So \(m\) and \(n\) are both multiples of \(d\) and d divides both of them. \(d \ | \ m\) and \(d \ | \ n\).</li>
	<li>So now for condition 2, suppose \(e\) is a common divisor of \(m\) and \(n\). We want to show that \(e\) divides \(d\). Since \(e \ | \ m\) and \(e \ | \ n\), then \(m\) and \(n\) are both multiples of \(e\). So we can write \(m = eu\) and \(n = ev\) for some \(u,v \in \mathbf{Z}\). 
	<br />
	<br />
	But we know that any integer combination of \(m\) and \(n\) is a multiple of \(d\). So we can write for some \(r, s \in \mathbf{Z}\) 
	<div>
	  $$
	  \begin{align*}
	  d &amp;= rm + sn \\
	   &amp;= reu + sev \\
	   &amp;= e(ru + sv).
	  \end{align*}
	  $$
	</div>
	So \(e\) must divide \(d\).
</li>
</ol>
<p>Therefore, \(d = gcd(m,n)\) as desired. \(\ \blacksquare\) 
<br />
Note that the Euclidean Algorithm gives a method for computing \(r, s \in \mathbf{Z}\), so \(d = rm + sn\).
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>GCD Example</b></h4>
<p>TODO … all I have now is this</p>
<p style="text-align:center;"><img src="http://localhost:4000/assets/math/abstract-algebra/lec05/1.png" width="55%" class="center" /></p>
<p><br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>Relatively Prime Integers</b></h4>
<p>Next, we’ll see how the GCD is used in the definition of relatively prime numbers.
<br /></p>
<div class="mintheaderdiv">
Definition (Book Definition 1.6.14)
</div>
<div class="mintbodydiv">
\(a, b \in \mathbf{Z}\) are relatively prime if gcd\((a,b) = 1\).
</div>
<!------------------------------------------------------------------------>
<p><br />
<br />
For example \(4\) and \(9\) are relatively prime. gcd\((4,9)=1\). 
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition (Book Proposition 1.6.15)
</div>
<div class="peachbodydiv">
\(a, b\) are relatively prime if and only if
$$
\begin{align*}
1 = ra + sb
\end{align*}
$$
for some \(r,s \in \mathbf{Z}\)
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
\(\Rightarrow:\) If \(a\) and \(b\) are relatively prime, then by definition gcd\((a,b)=1\). By the GCD Theorem, this means that \(I(a,b) = 1\) and so we’re done.
<br />
\(\Leftarrow:\) If \(1 = ra + sb\) for some \(r,s \in \mathbf{Z}\), then this means that \(1 \in I(a,b)\). But \(I(a,b)\) is also the set of multiples of some integer \(m\). But since \(1\) is in the set, then it must contains all multiples of \(1\). Therefore, we must have \(1 = I(a,b)\). By the GCD Theorem, \(1\) is therefore the gcd of \(a\) and \(b\) and so \(a\) and \(b\) are relatively prime. \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition (Book Corollary 1.6.17)
</div>
<div class="peachbodydiv">
If \(a, b\) are relatively prime and if \(a \ | \ n\) and \(b \ | \ n\), then \(ab \ | n\).
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
Suppose \(a\) and \(b\) are relatively prime. We are given that \(a \ | \ n\) so \(n = au\) for some \(u \in \mathbf{Z}\). Similarly, \(b \ | \ n\) and so \(n = bv\) for some \(v \in \mathbf{Z}\). Since \(a\) and \(b\) are relatively prime, then by definition gcd\((a,b)=1\). This means that \(I(a,b) = 1\) and we can write \(1 = ra + sb\) for some integers \(s, r \in \mathbf{Z}\). Multiply this equation by \(b\) as follows</p>
<div>
$$
\begin{align*}
1 &amp;= ra + sb \\
n &amp;= n(ra + sb) \\
  &amp;= nra + nsb \\
  &amp;= (bv)ra + (au)sb \\
  &amp;= (ab)vr + (ab)us \\
  &amp;= (ab)(vr + us). \\
\end{align*}
$$
</div>
<p>From this we see that \(ab \ | \ n\) as desired. \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition
</div>
<div class="peachbodydiv">
If \(p\) is prime and \(p \ | \ ab\), then either \(p \ | \ a\) or \(p \ | \ b\)
</div>
<!------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
Suppose that \(p \ | \ ab\). We’ll show that if \(p \nmid a\), then \(p \ | \ b\). Since \(p\) is prime and \(p \nmid a\), then gcd\((p,a)=1\). By Proposition (1.6.15), this implies that \(1 = pr + as\) for some \(r, s \in \mathbf{Z}\). Multiply this equation by \(b\) to see that</p>
<div>
$$
\begin{align*}
1 &amp;= pr + as \\
b &amp;= b(pr + as) \\
b &amp;= p(br) + (ab)s \\
\end{align*}
$$
</div>
<p>Clearly \(p\) divides the first term. \(p\) also divides the second term by the assumption we’re given. Therefore, \(p\) must divide \(b\) as we wanted to show. \(\ \blacksquare\)
<br />
<br />
Fact: If \(p \ | \ a_1a_2...a_k\), then \(p\) divides at least one of the factors. So \(p \ | \ a_i\) for some \(i \in \{1,...,k\}\)
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li>MATH417 by Charles Rezk</li>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition 1.6.8 A natural number \(d\) is the greatest common divisor of integers \(a\) and \(b\) if \(d\) is a common divisor. So \(d\) divides \(a\) and \(b\) Every common divisor \(e\) also divides \(d\). In other words, if \(e \ | \ a\) and \(e \ | \ b\), then \(e \ | \ d\) If the greatest common exists, then it is unique. Why? suppose \(d\) and \(d'\) are both greatest common divisors. Then by definition, \(d \ | \ d'\) and \(d' \ | \ d\) because every common divisor divides the gcd and they each must divide each other. But this means that \(d = \pm 'd\) by the divisibility properties from last lecture. But also by definition, \(d\) is non-negative and so \(d = 'd\). \(\ \blacksquare\) Note that in the book \(a\) and \(b\) are nonzero in the definition. With this definition, the set of divisors of \(0\) is \(\mathbf{Z}\). If \(a = 0\) and \(b \neq 0\), then \(|a|\) is the gcd of \(a\) and \(0\). If both \(a\) and \(b\) are zero, then \(0\) is the gcd of \(0\) and \(0\). Before addressing the question of whether the greatest common divisor exists, we’ll to define one more thing Definition Let \(a, b \in \mathbf{Z}\). An integer combination of \(a\) and \(b\) is any integer of the form $$ \begin{align*} I(a,b) = \{ra + sb \ | \ r, s \in \mathbf{Z}\}. \end{align*} $$ For example \(I(4,6) = \{4s + 6t \ | \ s, t \in \mathbf{Z}\}\). If we let \(s = -1\) and \(t = 1\), then \(2 \in I(4,6)\). In fact, this set produces all of the even integers. It includes all multiples of 2. In other words, we can also write that \(I(4,6) = \mathbf{Z}2\). In fact, this turns out to always be true, the set of integer combinations of two integers is also the set of multiples of a number and that number is the greatest common divisor! even when one of the integers is \(0\). So yes the GCD exists and can even be computed. Before formally proving its existence, we’ll present the way it can be computed next. The Euclidean Algorithm Let \(\mathbf{Z}^2 = \{(a,b), a,b \in \mathbf{Z}\}\). Define \(F: \mathbf{Z}^2 \rightarrow \mathbf{Z}^2\) by $$ \begin{equation*} F(m,n) = \begin{cases} (n,r), r = rem_n(m) \quad &amp;\text{if } n \neq 0 \\ (|m|,0) \quad \quad &amp;\text{if } n = 0\end{cases} \end{equation*} $$ \(rem_n(m)\) is the remainder of \(m \div n\) (recall that we can write \(m = qn + r\) where \(0 \leq r &lt; |n|)\)). Euclidean Algorithm: Iterate \(F\) until stable. Example: $$ \begin{align*} (42, -24) \xrightarrow{F} (-24, 18) \xrightarrow{F} (18, 12) \xrightarrow{F} (12, 6) \xrightarrow{F} (6, 0) \xrightarrow{F} (6, 0) \end{align*} $$ The GCD Theorem So now we have an algorithm to compute the GCD algorithm. Next, we will prove that it does compute the GCD and so the GCD does exist. Theorem Let \(a, b \in \mathbf{Z}\). Then For \(a, b\) have a GCD \(d \geq 0\). \(I(a,b) = \mathbf{Z}d\). \(d\) is computed by the Euclidean algorithm. We’ll start from (3) and then prove that the answer produced by the algorithm is in fact an integer combination of the original input (statement 2). Finally, we’ll show that this just means that we have computed the GCD (statement). To do all of this we will also need the following lemmas Lemma If \(a, b \in I(c,d)\), then \(I(a,b) \subseteq I(c,d)\) Proof: Homework Problem Lemma If \(F(m,n) = (a,b)\), then \(I(m,n) = I(a,b)\) Proof: We have two cases: Case 1: \(n \neq 0\). In this case, \(F(m,n) = (n, r)\) where \(r\) is the remainder after dividing \(m\) by \(n\). So \(m = qn + r\) where \(0 \leq r &lt; |n|\). We want to show that the integer combinations of \(m\) and \(n\) is the same as the integer combinations of \(n\) and \(r\), that is, \(I(m,n) = I(n,r)\). To do this, we will show that \(I(m,n) \subseteq I(n,r)\) and \(I(n,r) \subseteq I(m,n)\). To show that \(I(m,n) \subseteq I(n,r)\), observe that \(m\) is an integer combination of \(n\) and \(r\) because we can write \(m\) as $$ \begin{align*} m &amp;= qn + 1r. \end{align*} $$ Similarly, \(n\) is also an integer combination of \(n\) and \(r\) because we can write \(n\) as $$ \begin{align*} n &amp;= 1n + 0r. \end{align*} $$ Since \(m\) and \(n\) can both be written as integer combinations of \(n\) and \(r\), that is \(m \in I(n,r)\) and \(n \in I(n,r)\), then by the previous lemma, \(I(m,n) \subseteq I(n,r)\). To see that \(I(m,n) \subseteq I(n,r)\), observe that we can write \(n\) as \(n = 0m + 1n\) so \(n \in I(m,n)\). Similarly, \(r = 1m + (-q)m\) so \(r \in I(m,n)\). Then, by the previous lemma, \(I(m,n) \subseteq I(n,r)\). Therefore, \(I(m,n) = I(n,r)\). Case 2: \(n = 0\). In this case, \(F(m,n) = F(m,0) = (|m|,0)\). In this case the integer combinations of \(0\) and \(m\) are just multiples of \(m\) so \(I(m,0) = \mathbf{Z}m\). But this is the same as the integer combinations of \(|m|\) and \(0\) so \(\mathbf{Z}m = I(|m|,0) = I(m,0)\) which is what we wanted to show. \(\blacksquare\) Proof of the GCD Theorem We iterate the algorithm until \(n = 0\) and \(F(m,n) = (|m|,0)\). By the previous lemma we saw that \(I(m,n) = \mathbf{Z}d\) for some \(d \geq 0\). Claim: \(d\) is a GCD. \(m,n \in I(m,n) = \mathbf{Z}d\). So \(m\) and \(n\) are both multiples of \(d\) and d divides both of them. \(d \ | \ m\) and \(d \ | \ n\). So now for condition 2, suppose \(e\) is a common divisor of \(m\) and \(n\). We want to show that \(e\) divides \(d\). Since \(e \ | \ m\) and \(e \ | \ n\), then \(m\) and \(n\) are both multiples of \(e\). So we can write \(m = eu\) and \(n = ev\) for some \(u,v \in \mathbf{Z}\). But we know that any integer combination of \(m\) and \(n\) is a multiple of \(d\). So we can write for some \(r, s \in \mathbf{Z}\) $$ \begin{align*} d &amp;= rm + sn \\ &amp;= reu + sev \\ &amp;= e(ru + sv). \end{align*} $$ So \(e\) must divide \(d\). Therefore, \(d = gcd(m,n)\) as desired. \(\ \blacksquare\) Note that the Euclidean Algorithm gives a method for computing \(r, s \in \mathbf{Z}\), so \(d = rm + sn\). GCD Example TODO … all I have now is this Relatively Prime Integers Next, we’ll see how the GCD is used in the definition of relatively prime numbers. Definition (Book Definition 1.6.14) \(a, b \in \mathbf{Z}\) are relatively prime if gcd\((a,b) = 1\). For example \(4\) and \(9\) are relatively prime. gcd\((4,9)=1\). Proposition (Book Proposition 1.6.15) \(a, b\) are relatively prime if and only if $$ \begin{align*} 1 = ra + sb \end{align*} $$ for some \(r,s \in \mathbf{Z}\) Proof \(\Rightarrow:\) If \(a\) and \(b\) are relatively prime, then by definition gcd\((a,b)=1\). By the GCD Theorem, this means that \(I(a,b) = 1\) and so we’re done. \(\Leftarrow:\) If \(1 = ra + sb\) for some \(r,s \in \mathbf{Z}\), then this means that \(1 \in I(a,b)\). But \(I(a,b)\) is also the set of multiples of some integer \(m\). But since \(1\) is in the set, then it must contains all multiples of \(1\). Therefore, we must have \(1 = I(a,b)\). By the GCD Theorem, \(1\) is therefore the gcd of \(a\) and \(b\) and so \(a\) and \(b\) are relatively prime. \(\ \blacksquare\) Proposition (Book Corollary 1.6.17) If \(a, b\) are relatively prime and if \(a \ | \ n\) and \(b \ | \ n\), then \(ab \ | n\). Proof Suppose \(a\) and \(b\) are relatively prime. We are given that \(a \ | \ n\) so \(n = au\) for some \(u \in \mathbf{Z}\). Similarly, \(b \ | \ n\) and so \(n = bv\) for some \(v \in \mathbf{Z}\). Since \(a\) and \(b\) are relatively prime, then by definition gcd\((a,b)=1\). This means that \(I(a,b) = 1\) and we can write \(1 = ra + sb\) for some integers \(s, r \in \mathbf{Z}\). Multiply this equation by \(b\) as follows $$ \begin{align*} 1 &amp;= ra + sb \\ n &amp;= n(ra + sb) \\ &amp;= nra + nsb \\ &amp;= (bv)ra + (au)sb \\ &amp;= (ab)vr + (ab)us \\ &amp;= (ab)(vr + us). \\ \end{align*} $$ From this we see that \(ab \ | \ n\) as desired. \(\ \blacksquare\) Proposition If \(p\) is prime and \(p \ | \ ab\), then either \(p \ | \ a\) or \(p \ | \ b\) Proof Suppose that \(p \ | \ ab\). We’ll show that if \(p \nmid a\), then \(p \ | \ b\). Since \(p\) is prime and \(p \nmid a\), then gcd\((p,a)=1\). By Proposition (1.6.15), this implies that \(1 = pr + as\) for some \(r, s \in \mathbf{Z}\). Multiply this equation by \(b\) to see that $$ \begin{align*} 1 &amp;= pr + as \\ b &amp;= b(pr + as) \\ b &amp;= p(br) + (ab)s \\ \end{align*} $$ Clearly \(p\) divides the first term. \(p\) also divides the second term by the assumption we’re given. Therefore, \(p\) must divide \(b\) as we wanted to show. \(\ \blacksquare\) Fact: If \(p \ | \ a_1a_2...a_k\), then \(p\) divides at least one of the factors. So \(p \ | \ a_i\) for some \(i \in \{1,...,k\}\) References MATH417 by Charles Rezk Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry></feed>
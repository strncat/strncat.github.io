<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-12-08T11:44:10-08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">nemo’s notebook</title><subtitle>personal study notes</subtitle><entry><title type="html">Abstract Algebra</title><link href="http://localhost:4000/jekyll/update/2024/12/05/abstract-algebra.html" rel="alternate" type="text/html" title="Abstract Algebra" /><published>2024-12-05T08:01:36-08:00</published><updated>2024-12-05T08:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2024/12/05/abstract-algebra</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/12/05/abstract-algebra.html"><![CDATA[<!------------------------ [1.6] Divisibility in the Integers --------------------------->
<h4> [1.6] Divisibility in the Integers </h4>
<ol style="list-style-type:none;">
	   <li><a href="/jekyll/update/2024/11/01/1.6-z.html">
        1. Z (1.6.1 - 1.6.2)
       </a></li>
	   <li><a href="/jekyll/update/2024/11/02/1.6-primes.html">
        2. Prime Numbers (1.6.4 - 1.6.7)
       </a></li>
	   <li><a href="/jekyll/update/2024/11/04/1.6-gcd.html">
        4. Greatest Common Divisor (1.6.8 - 1.6.13)
       </a></li>
	   <li><a href="/jekyll/update/2024/11/05/1.6-relatively-prime.html">
        5. Relatively Prime Integers (1.6.14 - 1.6.21)
       </a></li>	   
	   <li><a href="/jekyll/update/2024/11/06/1.6-gcd-many.html">
        6. Greatest Common Divisor of Many Integers (1.6.22 - 1.6.25)
       </a></li>
   </ol>
<p><br />
<!------------------------ [1.7] Modular Arithmetic ---------------------------></p>
<h4> [1.7] Modular Arithmetic </h4>
<ol style="list-style-type:none;">
	   <li><a href="/jekyll/update/2024/11/07/1.7-modular-arthmetic.html">
        1. Z (1.6.1 - 1.6.2)
       </a></li>
   </ol>
<p><br /></p>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[[1.6] Divisibility in the Integers 1. Z (1.6.1 - 1.6.2) 2. Prime Numbers (1.6.4 - 1.6.7) 4. Greatest Common Divisor (1.6.8 - 1.6.13) 5. Relatively Prime Integers (1.6.14 - 1.6.21) 6. Greatest Common Divisor of Many Integers (1.6.22 - 1.6.25) [1.7] Modular Arithmetic 1. Z (1.6.1 - 1.6.2)]]></summary></entry><entry><title type="html">[1.7] Modular Arithmetic</title><link href="http://localhost:4000/jekyll/update/2024/11/07/1.7-modular-arthmetic.html" rel="alternate" type="text/html" title="[1.7] Modular Arithmetic" /><published>2024-11-07T00:01:36-08:00</published><updated>2024-11-07T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2024/11/07/1.7-modular-arthmetic</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/11/07/1.7-modular-arthmetic.html"><![CDATA[<p>Suppose we have a natural number \(n\), then \((i \mod n)\) is the remainder after dividing \(n\) by \(i\). For example \((1 \mod 7) = (8 \mod 7) = (15 \mod 7) = 1\) and \((7 \mod 7) = 0\). From this we observe that for two numbers \(a\) and \(b\) to leave the same remainder, they need to be \(n\) numbers apart on the numbers line or in other words, \(|a - b|\) is a multiple of \(n\). Formally,
<!------------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition 1.7.1
</div>
<div class="mintbodydiv">
Given integers \(a\) and \(b\), and a natural number \(n\), we say that "\(a\) is congruent to \(b\) modulo \(n\)" and we write \(a \equiv b \mod n\) if \(a - b\) is divisible by \(n\).
</div>
<p><br />
This relation \(a \equiv b \mod n\) has the following properties:
<br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma 1.7.2
</div>
<div class="yellowbodydiv">
<ol type="a">
	<li>For all \(a \in \mathbf{Z}\), \(a \equiv a \mod n\).</li>
	<li>For all \(a, b \in \mathbf{Z}\), \(a \equiv b \mod n\) if and only if \(b \equiv a \mod n\).</li>
	<li>For all \(a, b, c \in \mathbf{Z}\), if \(a \equiv b \mod n\) and \(b \equiv c \mod n\), then \(a \equiv c \mod n\).</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof</b>
<br />
For \((a)\), \(a - a = 0\) is divisible by \(n\). For \((b)\), if \(a - b\) is divisible by \(n\), then \(b - a\) is also divisible by \(n\) and vice versa. For \((c)\), if \(a - b\) is divisible by \(n\) and \(b - c\) is divisible by \(4n\), then \((a - b) + (b - c) = a - c\) is also divisible by \(n\). \(\ \blacksquare\). 
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition
</div>
<div class="mintbodydiv">
For each integer \(a\), write
$$
\begin{align*}
[a] &amp;= \{b \in \mathbf{Z} \ | \ a \equiv b \mod n\} \\
    &amp;= \{ a + kn \ | \ k \in \mathbf{Z} \}
\end{align*}
$$
The set \(a\) is called the residue class or congruence class of \(a\) modulo \(n\). <br />
Also let \(rem_n(a)\) be the unique number \(r\) such that \(0 \leq r &lt; n\) and \(a - r\) is divisible by \(n\).  So it is the unique element of \([a]\) that lies in the interval \( \{0,1,...,n-1\} \).
</div>
<p><br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma 1.7.3
</div>
<div class="yellowbodydiv">
For \(a, b \in \mathbf{Z}\), the following are equivalent:
<ol type="a">
	<li>\(a \equiv b \mod n\).</li>
	<li>\([a] = [b]\).</li>
	<li>\(\text{rem}_n(a) = \text{rem}_n(b)\).</li>
	<li>\([a] \cap [b] \neq \emptyset\).</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------>
<b>Proof</b>
<br />
\((a) \implies (b)\):
<br />
Suppose \(a \equiv b \mod n\). We want to show that \([a] = [b]\) by showing that \([a] \subseteq [b]\) and \([b] \subseteq [a]\). For any \(c \in \mathbf{Z}\), we know that if \(c \equiv a \mod n\), then \(c \equiv b \mod n\) by Lemma 1.7.2 (c). Therefore \([a] \subseteq [b]\). Similarly, if \(c \equiv b \mod n\), then \(c \equiv a \mod n\) and so \([a] = [b]\) as required.
<br />
<br />
\((b) \implies (c)\):
<br />
By definition, \(\text{rem}_n(x)\) is the unique element of \([x]\) that lies inside \(\{0,1,...,n-1\}\). So if \([a]=[b]\), then it must be the same element.
<br />
<br />
\((c) \implies (d)\):
<br />
\((d)\) is an immediate application of \((c)\)
<br />
<br />
\((d) \implies (a)\):
Suppose that \([a] \cap [b] \neq \emptyset\). Let \(c \in [a] \cap [b]\). Then \(a \equiv c \mod n\) and \(b \equiv c \mod n\). But this implies that \(a \equiv b \mod n\). \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Corollary 1.7.4
</div>
<div class="yellowbodydiv">
There exist exactly \(n\) distinct residue classes modulo \(n\) namely \([0], [1],...,[n-1]\). These classes are mutually disjoint.
</div>
<p><br />
<br />
<!------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma 1.7.5
</div>
<div class="yellowbodydiv">
Let \(a, a', b, b'\) be integers with \(a \equiv a' \mod n\) and \(b \equiv b' \mod n\). Then \(a + b \equiv a' + b' \mod n\) and \(ab \equiv a'b' \mod n\)
</div>
<p><br />
<!------------------------------------------------------------------------------>
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
<li><a href="https://www.youtube.com/watch?v=8cikffEcyPI&amp;t=5s">Michael Penn's Lectures</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Suppose we have a natural number \(n\), then \((i \mod n)\) is the remainder after dividing \(n\) by \(i\). For example \((1 \mod 7) = (8 \mod 7) = (15 \mod 7) = 1\) and \((7 \mod 7) = 0\). From this we observe that for two numbers \(a\) and \(b\) to leave the same remainder, they need to be \(n\) numbers apart on the numbers line or in other words, \(|a - b|\) is a multiple of \(n\). Formally, Definition 1.7.1 Given integers \(a\) and \(b\), and a natural number \(n\), we say that "\(a\) is congruent to \(b\) modulo \(n\)" and we write \(a \equiv b \mod n\) if \(a - b\) is divisible by \(n\). This relation \(a \equiv b \mod n\) has the following properties: Lemma 1.7.2 For all \(a \in \mathbf{Z}\), \(a \equiv a \mod n\). For all \(a, b \in \mathbf{Z}\), \(a \equiv b \mod n\) if and only if \(b \equiv a \mod n\). For all \(a, b, c \in \mathbf{Z}\), if \(a \equiv b \mod n\) and \(b \equiv c \mod n\), then \(a \equiv c \mod n\). Proof For \((a)\), \(a - a = 0\) is divisible by \(n\). For \((b)\), if \(a - b\) is divisible by \(n\), then \(b - a\) is also divisible by \(n\) and vice versa. For \((c)\), if \(a - b\) is divisible by \(n\) and \(b - c\) is divisible by \(4n\), then \((a - b) + (b - c) = a - c\) is also divisible by \(n\). \(\ \blacksquare\). Definition For each integer \(a\), write $$ \begin{align*} [a] &amp;= \{b \in \mathbf{Z} \ | \ a \equiv b \mod n\} \\ &amp;= \{ a + kn \ | \ k \in \mathbf{Z} \} \end{align*} $$ The set \(a\) is called the residue class or congruence class of \(a\) modulo \(n\). Also let \(rem_n(a)\) be the unique number \(r\) such that \(0 \leq r &lt; n\) and \(a - r\) is divisible by \(n\). So it is the unique element of \([a]\) that lies in the interval \( \{0,1,...,n-1\} \). Lemma 1.7.3 For \(a, b \in \mathbf{Z}\), the following are equivalent: \(a \equiv b \mod n\). \([a] = [b]\). \(\text{rem}_n(a) = \text{rem}_n(b)\). \([a] \cap [b] \neq \emptyset\). Proof \((a) \implies (b)\): Suppose \(a \equiv b \mod n\). We want to show that \([a] = [b]\) by showing that \([a] \subseteq [b]\) and \([b] \subseteq [a]\). For any \(c \in \mathbf{Z}\), we know that if \(c \equiv a \mod n\), then \(c \equiv b \mod n\) by Lemma 1.7.2 (c). Therefore \([a] \subseteq [b]\). Similarly, if \(c \equiv b \mod n\), then \(c \equiv a \mod n\) and so \([a] = [b]\) as required. \((b) \implies (c)\): By definition, \(\text{rem}_n(x)\) is the unique element of \([x]\) that lies inside \(\{0,1,...,n-1\}\). So if \([a]=[b]\), then it must be the same element. \((c) \implies (d)\): \((d)\) is an immediate application of \((c)\) \((d) \implies (a)\): Suppose that \([a] \cap [b] \neq \emptyset\). Let \(c \in [a] \cap [b]\). Then \(a \equiv c \mod n\) and \(b \equiv c \mod n\). But this implies that \(a \equiv b \mod n\). \(\ \blacksquare\) Corollary 1.7.4 There exist exactly \(n\) distinct residue classes modulo \(n\) namely \([0], [1],...,[n-1]\). These classes are mutually disjoint. Lemma 1.7.5 Let \(a, a', b, b'\) be integers with \(a \equiv a' \mod n\) and \(b \equiv b' \mod n\). Then \(a + b \equiv a' + b' \mod n\) and \(ab \equiv a'b' \mod n\) References Algebra: Abstract and Concrete by Frederick M. Goodman Michael Penn's Lectures]]></summary></entry><entry><title type="html">[1.6] Greatest Common Divisor of Many Integers (1.6.22 - 1.6.25)</title><link href="http://localhost:4000/jekyll/update/2024/11/06/1.6-gcd-many.html" rel="alternate" type="text/html" title="[1.6] Greatest Common Divisor of Many Integers (1.6.22 - 1.6.25)" /><published>2024-11-06T00:01:36-08:00</published><updated>2024-11-06T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2024/11/06/1.6-gcd-many</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/11/06/1.6-gcd-many.html"><![CDATA[<!------------------------------------------------------------------------------------>
<div class="mintheaderdiv">
Definition 1.6.22
</div>
<div class="mintbodydiv">
A natural number \(d\) is the greatest common divisor of nonzero integers \(a_1,a_2,...,a_n\) if
<ol type="a">
	<li>\(d\) divides each \(a_i\) and</li>
	<li>whenever \(x \in \mathbf{N}\) divides each \(a_i\), then \(x\) also divides \(d\)</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma 1.6.23
</div>
<div class="yellowbodydiv">
Given nonzero integers \(a_1,...,a_n (n \geq 2)\), there is a natural number \(d\) and an \(n\)-by-\(n\) integer matrix \(Q\) such that \(Q\) is invertible, \(Q^{-1}\) also has integer entries, and
$$
\begin{align*}
(d,0,...,0) = (a_1,a_2,...,a_n)Q.
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<b>Proof</b>
<br />
TODO
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.24
</div>
<div class="peachbodydiv">
The greatest common divisor of non-zero integers \(a_1,...,a_n\) exists, and is an integer linear combination of \(a_1, a_2,...,a_n\).
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<b>Proof</b>
<br />
TODO
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="mintheaderdiv">
Definition 1.6.25
</div>
<div class="mintbodydiv">
We say that non-zero integers \(a_1,...,a_n\) are relatively prime if their greatest common divisor is 1. 
We say that they are pairwise relatively prime if \(a_i\) and \(a_j\) are relatively prime whenever \(i \neq j\).
</div>
<p><br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma 1.6.26
</div>
<div class="yellowbodydiv">
Let \(a_1,...,a_n\) be pairwise relatively prime integers, and let \(a = a_1,...,a_n\). If an integer \(z\) is divisible by each \(a_i\), then \(z\) is divisible by \(a\).
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
TODO
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
<li><a href="https://www.youtube.com/watch?v=8cikffEcyPI&amp;t=5s">Michael Penn's Lectures</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition 1.6.22 A natural number \(d\) is the greatest common divisor of nonzero integers \(a_1,a_2,...,a_n\) if \(d\) divides each \(a_i\) and whenever \(x \in \mathbf{N}\) divides each \(a_i\), then \(x\) also divides \(d\) Lemma 1.6.23 Given nonzero integers \(a_1,...,a_n (n \geq 2)\), there is a natural number \(d\) and an \(n\)-by-\(n\) integer matrix \(Q\) such that \(Q\) is invertible, \(Q^{-1}\) also has integer entries, and $$ \begin{align*} (d,0,...,0) = (a_1,a_2,...,a_n)Q. \end{align*} $$ Proof TODO Proposition 1.6.24 The greatest common divisor of non-zero integers \(a_1,...,a_n\) exists, and is an integer linear combination of \(a_1, a_2,...,a_n\). Proof TODO Definition 1.6.25 We say that non-zero integers \(a_1,...,a_n\) are relatively prime if their greatest common divisor is 1. We say that they are pairwise relatively prime if \(a_i\) and \(a_j\) are relatively prime whenever \(i \neq j\). Lemma 1.6.26 Let \(a_1,...,a_n\) be pairwise relatively prime integers, and let \(a = a_1,...,a_n\). If an integer \(z\) is divisible by each \(a_i\), then \(z\) is divisible by \(a\). Proof TODO References Algebra: Abstract and Concrete by Frederick M. Goodman Michael Penn's Lectures]]></summary></entry><entry><title type="html">[1.6] Relatively Prime Integers (1.6.14 - 1.6.20)</title><link href="http://localhost:4000/jekyll/update/2024/11/05/1.6-relatively-prime.html" rel="alternate" type="text/html" title="[1.6] Relatively Prime Integers (1.6.14 - 1.6.20)" /><published>2024-11-05T00:01:36-08:00</published><updated>2024-11-05T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2024/11/05/1.6-relatively-prime</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/11/05/1.6-relatively-prime.html"><![CDATA[<!------------------------------------------------------------------------------------>
<div class="mintheaderdiv">
Definition 1.6.14
</div>
<div class="mintbodydiv">
Nonzero integers \(m\) and \(n\) are relatively prime if \(gcd(m,n) = 1\).
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.15
</div>
<div class="peachbodydiv">
Two nonzero integers \(m\) and \(n\) are relatively prime if and only if there exist integers \(s\) and \(t\) such that \(1 = sm + tn\).
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
\(\Rightarrow\): Suppose \(m\) and \(n\) are relatively prime. This means that \(gcd(m,n)=1\). By Proposition 1.6.11, \(1 \in I(m,n)\). This means that there exists integers \(s\) and \(t\) such that \(1 = sm + tn\) which what we wanted to show.
<br />
<br />
\(\Leftarrow\): Suppose that there exists integers \(s\) and \(t\) such that \(1 = sm + tn\). This implies that \(1 \in I(m,n)\). But 1 is obviously is a common divisor of \(m\) and \(n\). So now we have common divisor that is also contained in \(I(m,n)\). So by Lemma 1.6.10, 1 is the greatest common divisor of \(m\) and \(n\) as required. \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Corollary 1.6.17
</div>
<div class="peachbodydiv">
Suppose that \(a\) and \(b\) are relatively prime natural numbers, that \(x\) is an integer, and that both \(a\) and \(b\) divide \(x\). Then \(ab\) divides \(x\).
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
Since \(x\) and \(b\) are relatively prime, then this means that there exists integers \(s\) and \(t\) such that \(1 = sm + tn\). Multiply this equation by \(x\) to get</p>
<div>
$$
\begin{align*}
x = sax + tbx
\end{align*}
$$
</div>
<p>Since \(x\) divides both \(a\) and \(b\), then \(x = \alpha a\) and \(x = \beta b\). Substitute back</p>
<div>
$$
\begin{align*}
x &amp;= sa(\beta b) + tb(\alpha a) \\
  &amp;= (s\beta + t \alpha) (ab)
\end{align*}
$$
</div>
<p>From this we see that \(ab\) divides \(x\) as we wanted to show. \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.18
</div>
<div class="peachbodydiv">
If \(p\) is a prime number and \(a\) is any nonzero integer, then either \(p\) divides \(a\) or \(p\) and \(a\) are relatively prime.
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
Suppose that \(p\) is a prime number and \(a\) is a nonzero integer. Suppose that \(a &gt; 0\), if not then just consider \(-a\). \(a\) can be written as a product of prime numbers \(p_1,...,p_k\). We have two cases. Either \(p\) is one of the prime factors of \(a\) so \(p\) divides \(a\). Or \(p\) is not any of the prime factors of \(a\). So \(p\) doesn’t divide \(a\). But since \(p\) is a prime number, then it won’t have any other prime factors and therefore, \(p\) and \(a\) are relatively prime. \(\ \blacksquare\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Corollary 1.6.20
</div>
<div class="peachbodydiv">
Suppose that a prime number \(p\) divides a product \(a_1a_2...a_r\) of nonzero integers. Then \(p\) divides one of the factors.
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
By Induction on \(r\).<br />
Base Case (\(r = 1\)): This is covered by Proposition 1.6.18.
<br />
Inductive Case: Suppose this is true for a product of \(r-1\) factors. We want to show that this is true for a product of \(r\) factors. TODO….
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem 1.6.21
</div>
<div class="yellowbodydiv">
The prime factorization of a natural number is unique.
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
Suppose \(n\) is a natural number. We want to show that if \(n\) has the following factorizations</p>
<div>
$$
\begin{align*}
n = q_1q_2 ... q_r, \\
n = p_1p_2 ... p_s
\end{align*}
$$
</div>
<p>where \(q_1,...,q_r\) and \(p_1,...,p_s\) are prime numbers, \(q_1 \leq ... \leq q_s\) and \(p_1 \leq ... \leq p_s\), that these factorizations are the same. In other words, \(r = s\) and \(q_i = p_i\) for all \(i\). We will show this by induction on \(n\):
<br />
<br />
Base Case (\(n = 1\)): 1 can’t be written as a product of a non-empty collection of prime numbers. For \(n=2\), 2 has only one prime factor (itself) since it’s a prime number.
<br />
<br />
Inductive Case: Suppose the inductive hypothesis is true for any natural number less than \(n\). Now consider \(n\) and its factorizations above. Assume without the loss of generality that \(q_1 \leq p_1\). We know that \(q_1\) divides \(n\). By Proposition 1.6.20, \(q_1\) must divide the product \(p_1p_2...p_s\). So this means that \(q_1\) must be equal to one of the factors \(p_1,...,p_s\). But since \(q_1 \leq p_1 \leq p_2 ... \leq p_k\), then we must have \(p_1 = q_1\). So now divide both equations by \(q_1\) to see that</p>
<div>
$$
\begin{align*}
n/q_1 = q_2 ... q_r, \\
n/q_1 = p_2 ... p_s
\end{align*}
$$
</div>
<p>We can now apply the inductive hypothesis to conclude that \(r = s\) and \(q_i = p_i\) for all \(i \geq 2\). \(\ \blacksquare\).
<!------------------------------------------------------------------------------------>
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
<li><a href="https://www.youtube.com/watch?v=8cikffEcyPI&amp;t=5s">Michael Penn's Lectures</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition 1.6.14 Nonzero integers \(m\) and \(n\) are relatively prime if \(gcd(m,n) = 1\). Proposition 1.6.15 Two nonzero integers \(m\) and \(n\) are relatively prime if and only if there exist integers \(s\) and \(t\) such that \(1 = sm + tn\). Proof \(\Rightarrow\): Suppose \(m\) and \(n\) are relatively prime. This means that \(gcd(m,n)=1\). By Proposition 1.6.11, \(1 \in I(m,n)\). This means that there exists integers \(s\) and \(t\) such that \(1 = sm + tn\) which what we wanted to show. \(\Leftarrow\): Suppose that there exists integers \(s\) and \(t\) such that \(1 = sm + tn\). This implies that \(1 \in I(m,n)\). But 1 is obviously is a common divisor of \(m\) and \(n\). So now we have common divisor that is also contained in \(I(m,n)\). So by Lemma 1.6.10, 1 is the greatest common divisor of \(m\) and \(n\) as required. \(\ \blacksquare\) Corollary 1.6.17 Suppose that \(a\) and \(b\) are relatively prime natural numbers, that \(x\) is an integer, and that both \(a\) and \(b\) divide \(x\). Then \(ab\) divides \(x\). Proof Since \(x\) and \(b\) are relatively prime, then this means that there exists integers \(s\) and \(t\) such that \(1 = sm + tn\). Multiply this equation by \(x\) to get $$ \begin{align*} x = sax + tbx \end{align*} $$ Since \(x\) divides both \(a\) and \(b\), then \(x = \alpha a\) and \(x = \beta b\). Substitute back $$ \begin{align*} x &amp;= sa(\beta b) + tb(\alpha a) \\ &amp;= (s\beta + t \alpha) (ab) \end{align*} $$ From this we see that \(ab\) divides \(x\) as we wanted to show. \(\ \blacksquare\) Proposition 1.6.18 If \(p\) is a prime number and \(a\) is any nonzero integer, then either \(p\) divides \(a\) or \(p\) and \(a\) are relatively prime. Proof Suppose that \(p\) is a prime number and \(a\) is a nonzero integer. Suppose that \(a &gt; 0\), if not then just consider \(-a\). \(a\) can be written as a product of prime numbers \(p_1,...,p_k\). We have two cases. Either \(p\) is one of the prime factors of \(a\) so \(p\) divides \(a\). Or \(p\) is not any of the prime factors of \(a\). So \(p\) doesn’t divide \(a\). But since \(p\) is a prime number, then it won’t have any other prime factors and therefore, \(p\) and \(a\) are relatively prime. \(\ \blacksquare\). Corollary 1.6.20 Suppose that a prime number \(p\) divides a product \(a_1a_2...a_r\) of nonzero integers. Then \(p\) divides one of the factors. Proof By Induction on \(r\). Base Case (\(r = 1\)): This is covered by Proposition 1.6.18. Inductive Case: Suppose this is true for a product of \(r-1\) factors. We want to show that this is true for a product of \(r\) factors. TODO…. Theorem 1.6.21 The prime factorization of a natural number is unique. Proof Suppose \(n\) is a natural number. We want to show that if \(n\) has the following factorizations $$ \begin{align*} n = q_1q_2 ... q_r, \\ n = p_1p_2 ... p_s \end{align*} $$ where \(q_1,...,q_r\) and \(p_1,...,p_s\) are prime numbers, \(q_1 \leq ... \leq q_s\) and \(p_1 \leq ... \leq p_s\), that these factorizations are the same. In other words, \(r = s\) and \(q_i = p_i\) for all \(i\). We will show this by induction on \(n\): Base Case (\(n = 1\)): 1 can’t be written as a product of a non-empty collection of prime numbers. For \(n=2\), 2 has only one prime factor (itself) since it’s a prime number. Inductive Case: Suppose the inductive hypothesis is true for any natural number less than \(n\). Now consider \(n\) and its factorizations above. Assume without the loss of generality that \(q_1 \leq p_1\). We know that \(q_1\) divides \(n\). By Proposition 1.6.20, \(q_1\) must divide the product \(p_1p_2...p_s\). So this means that \(q_1\) must be equal to one of the factors \(p_1,...,p_s\). But since \(q_1 \leq p_1 \leq p_2 ... \leq p_k\), then we must have \(p_1 = q_1\). So now divide both equations by \(q_1\) to see that $$ \begin{align*} n/q_1 = q_2 ... q_r, \\ n/q_1 = p_2 ... p_s \end{align*} $$ We can now apply the inductive hypothesis to conclude that \(r = s\) and \(q_i = p_i\) for all \(i \geq 2\). \(\ \blacksquare\). References Algebra: Abstract and Concrete by Frederick M. Goodman Michael Penn's Lectures]]></summary></entry><entry><title type="html">[1.6] Greatest Common Divisor (1.6.8 - 1.6.13)</title><link href="http://localhost:4000/jekyll/update/2024/11/04/1.6-gcd.html" rel="alternate" type="text/html" title="[1.6] Greatest Common Divisor (1.6.8 - 1.6.13)" /><published>2024-11-04T00:01:36-08:00</published><updated>2024-11-04T00:01:36-08:00</updated><id>http://localhost:4000/jekyll/update/2024/11/04/1.6-gcd</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/11/04/1.6-gcd.html"><![CDATA[<!------------------------------------------------------------------------------------>
<div class="mintheaderdiv">
Definition 1.6.8
</div>
<div class="mintbodydiv">
A natural number \(d\) is the greatest common divisor of nonzero integers \(m\) and \(n\) if
<ol type="a">
	<li>\(d\) divides \(m\) and \(n\) and</li>
	<li>whenever \(x \in \mathbf{N}\) divides \(m\) and \(n\), then \(x\) also divides \(d\)</li>
</ol>
</div>
<p><br />
The greatest common is unique if it exists by 1.6.2 (why?)
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.9
</div>
<div class="peachbodydiv">
For integers \(n\) and \(m\), let
$$
\begin{align*}
I(m,n) = \{am + bn \ | \ a, b \in \mathbf{Z}\}.
\end{align*}
$$
<ol type="a">
	<li>For \(x, y \in I(m,n)\), \(x + y \in I(m,n)\) and \(-x \in I(m,n)\).</li>
	<li>For all \(x \in \mathbf{Z}\), \(xI(m,n) \subseteq I(m,n)\).</li>
	<li>If \(b \in \mathbf{Z}\) divides \(m\) and \(n\), then \(b\) divides all elements of \(I(m,n)\).</li>
</ol>
</div>
<!------------------------------------------------------------------------------------>
<p><br />
<b>Proof</b>
<br />
Suppose \(x, y \in I(m,n)\), then \(x = am + bn\) for some \(a\) and \(b\) in \(\mathbf{Z}\) and \(y = cm + dn\) for some \(c\) and \(d\) in \(\mathbf{Z}\). Therefore</p>
<div>
$$
\begin{align*}
x + y &amp;= am + bn + cm + dn \\
      &amp;= (a+c)m + (b+d)n
\end{align*}
$$
</div>
<p>And so \(x+y \in I(m,n)\). \(\ \blacksquare\)
<br />
\((b)\) and \((c)\) have similar proofs.
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Lemma 1.6.10
</div>
<div class="yellowbodydiv">
Let \(m\) and \(n\) be nonzero integers. If a natural number \(d\) is a common divisor of \(m\) and \(n\) and an element of \(I(m,n)\), then \(d\) is the greatest common divisor of \(m\) and \(n\).
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<b>Proof</b>
<br />
For any common divisor \(x\) of \(m\) and \(n\), \(x\) divides every element of \(I(m,n)\) by proposition 1.6.9(c) and in particular it divides \(d\). \(\ \blacksquare\)
<br />
<br />
Notes: \(d\) is an element of \(I(m,n)\). Therefore, \(d = am + bn\). For any other common divisor \(x\), \(x\) divides every element of \(I(m,n)\) so \(x\) divides \(d\) and we can write \(d = am + bn = qx\). 
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>Finding the Greatest Common Division</b></h4>
<p>Suppose \(m, n \in \mathbf{N}\) and suppose without the loss of generality that \(|m| \geq |n|\). Let \(q\) and \(r\) be the quotient and remainder when dividing \(m\) by \(n\)</p>
<div>
$$
\begin{align*}
m &amp;= nq_1 + r_1  \\
n &amp;= r_1q_2 + r_2  \\
r_1 &amp;= r_2q_3 + r_3 \\
\vdots \\
r_{n-3} &amp;= r_{n-2}q_{n-1} + r_{n-1} \\
r_{n-2} &amp;= r_{n-1}q_{n} + 0
\end{align*}
$$
</div>
<p>In the case where \(n_1 &gt; 0\), then define again \(q_2\) and \(n_2\) such that</p>
<div>
$$
\begin{align*}
n &amp;= q_2n_1 + n_2 \quad (\text{where } 0 \leq n_2 &lt; n_1) \\
\end{align*}
$$
</div>
<p><br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.11
</div>
<div class="peachbodydiv">
The natural number \(r_{n-1}\) is the greatest common divisor of \(m\) and \(n\) and furthermore \(r_{n-1} \in I(m,n)\)
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<b>Proof</b>
<br />
We first need to show that this process terminates. Observe that the sequence \(\{r_1,r_2,...,r\} \in \mathbf{N}\) is decreasing so it truncates say at \(r_{n-1}\) (the last non-zero element of the sequence). So it must terminates by the well ordering principle.
<br />
<br />
Next, we need to show that \(r_{n-1}\) divides both \(m\) and \(n\). Observe that from the algorithm above that</p>
<div>
$$
\begin{align*}
r_{n-2} &amp;= r_{n-1}q_{n}
\end{align*}
$$
</div>
<p>This shows that \(r_{n-1}| r_{n-2}\). Looking at the equation above this one, we see</p>
<div>
$$
\begin{align*}
r_{n-3} &amp;= r_{n-2}q_{n} + r_{n-1}
\end{align*}
$$
</div>
<p>And combining this with the previous conclusion that \(r_{n-1} | r_{n-2}\), we see that \(r_{n-1}| r_{n-3}\). If we continue this process, we will see that \(r_{n-1}|a\) and \(r_{n-1}|b\). 
<br />
<br />
Finally, we need to show that \(r_{n-1}\) is the greatest common divisor. So let \(d\) be a common divisor of \(m\) and \(n\). So that \(d | m\) and \(d | n\). Using the first equation in the algorithm above,</p>
<div>
$$
\begin{align*}
m = nq + r_1
\end{align*}
$$
</div>
<p>we see that since \(d\) divides both \(m\) and \(n\). Then it must divide \(r_1\). Continuing with the second equation, we can see that \(d\) divides \(r_2\). Eventually, we can conclude that \(d|r_{n_1}\). Since \(d\) is arbitrary and \(r_{n-1}\) is a common divisor, then \(r_{n-1}\) must the greatest common divisor by definition. \(\ \blacksquare\)
<br />
<br />
TODO: Proof from the book
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Corollary 1.6.11
</div>
<div class="peachbodydiv">
Let \(m\) and \(n\) be nonzero integers, and write \(d = gcd(m,n)\). Then
<ol type="a">
	<li>\(d\) is the least element of \(\mathbf{N} \cap I(m,n)\).</li>
	<li>\(I(m,n) = \mathbf{Z}d\), the set of all integers multiples of \(d\)</li>
</ol>
</div>
<p><br />
<b>Proof</b>
<br />
TODO
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
<li><a href="https://www.youtube.com/watch?v=8cikffEcyPI&amp;t=5s">Michael Penn's Lectures</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition 1.6.8 A natural number \(d\) is the greatest common divisor of nonzero integers \(m\) and \(n\) if \(d\) divides \(m\) and \(n\) and whenever \(x \in \mathbf{N}\) divides \(m\) and \(n\), then \(x\) also divides \(d\) The greatest common is unique if it exists by 1.6.2 (why?) Proposition 1.6.9 For integers \(n\) and \(m\), let $$ \begin{align*} I(m,n) = \{am + bn \ | \ a, b \in \mathbf{Z}\}. \end{align*} $$ For \(x, y \in I(m,n)\), \(x + y \in I(m,n)\) and \(-x \in I(m,n)\). For all \(x \in \mathbf{Z}\), \(xI(m,n) \subseteq I(m,n)\). If \(b \in \mathbf{Z}\) divides \(m\) and \(n\), then \(b\) divides all elements of \(I(m,n)\). Proof Suppose \(x, y \in I(m,n)\), then \(x = am + bn\) for some \(a\) and \(b\) in \(\mathbf{Z}\) and \(y = cm + dn\) for some \(c\) and \(d\) in \(\mathbf{Z}\). Therefore $$ \begin{align*} x + y &amp;= am + bn + cm + dn \\ &amp;= (a+c)m + (b+d)n \end{align*} $$ And so \(x+y \in I(m,n)\). \(\ \blacksquare\) \((b)\) and \((c)\) have similar proofs. Lemma 1.6.10 Let \(m\) and \(n\) be nonzero integers. If a natural number \(d\) is a common divisor of \(m\) and \(n\) and an element of \(I(m,n)\), then \(d\) is the greatest common divisor of \(m\) and \(n\). Proof For any common divisor \(x\) of \(m\) and \(n\), \(x\) divides every element of \(I(m,n)\) by proposition 1.6.9(c) and in particular it divides \(d\). \(\ \blacksquare\) Notes: \(d\) is an element of \(I(m,n)\). Therefore, \(d = am + bn\). For any other common divisor \(x\), \(x\) divides every element of \(I(m,n)\) so \(x\) divides \(d\) and we can write \(d = am + bn = qx\). Finding the Greatest Common Division Suppose \(m, n \in \mathbf{N}\) and suppose without the loss of generality that \(|m| \geq |n|\). Let \(q\) and \(r\) be the quotient and remainder when dividing \(m\) by \(n\) $$ \begin{align*} m &amp;= nq_1 + r_1 \\ n &amp;= r_1q_2 + r_2 \\ r_1 &amp;= r_2q_3 + r_3 \\ \vdots \\ r_{n-3} &amp;= r_{n-2}q_{n-1} + r_{n-1} \\ r_{n-2} &amp;= r_{n-1}q_{n} + 0 \end{align*} $$ In the case where \(n_1 &gt; 0\), then define again \(q_2\) and \(n_2\) such that $$ \begin{align*} n &amp;= q_2n_1 + n_2 \quad (\text{where } 0 \leq n_2 &lt; n_1) \\ \end{align*} $$ Proposition 1.6.11 The natural number \(r_{n-1}\) is the greatest common divisor of \(m\) and \(n\) and furthermore \(r_{n-1} \in I(m,n)\) Proof We first need to show that this process terminates. Observe that the sequence \(\{r_1,r_2,...,r\} \in \mathbf{N}\) is decreasing so it truncates say at \(r_{n-1}\) (the last non-zero element of the sequence). So it must terminates by the well ordering principle. Next, we need to show that \(r_{n-1}\) divides both \(m\) and \(n\). Observe that from the algorithm above that $$ \begin{align*} r_{n-2} &amp;= r_{n-1}q_{n} \end{align*} $$ This shows that \(r_{n-1}| r_{n-2}\). Looking at the equation above this one, we see $$ \begin{align*} r_{n-3} &amp;= r_{n-2}q_{n} + r_{n-1} \end{align*} $$ And combining this with the previous conclusion that \(r_{n-1} | r_{n-2}\), we see that \(r_{n-1}| r_{n-3}\). If we continue this process, we will see that \(r_{n-1}|a\) and \(r_{n-1}|b\). Finally, we need to show that \(r_{n-1}\) is the greatest common divisor. So let \(d\) be a common divisor of \(m\) and \(n\). So that \(d | m\) and \(d | n\). Using the first equation in the algorithm above, $$ \begin{align*} m = nq + r_1 \end{align*} $$ we see that since \(d\) divides both \(m\) and \(n\). Then it must divide \(r_1\). Continuing with the second equation, we can see that \(d\) divides \(r_2\). Eventually, we can conclude that \(d|r_{n_1}\). Since \(d\) is arbitrary and \(r_{n-1}\) is a common divisor, then \(r_{n-1}\) must the greatest common divisor by definition. \(\ \blacksquare\) TODO: Proof from the book Corollary 1.6.11 Let \(m\) and \(n\) be nonzero integers, and write \(d = gcd(m,n)\). Then \(d\) is the least element of \(\mathbf{N} \cap I(m,n)\). \(I(m,n) = \mathbf{Z}d\), the set of all integers multiples of \(d\) Proof TODO References Algebra: Abstract and Concrete by Frederick M. Goodman Michael Penn's Lectures]]></summary></entry><entry><title type="html">[1.6] Prime Numbers (1.6.4 - 1.6.7)</title><link href="http://localhost:4000/jekyll/update/2024/11/02/1.6-primes.html" rel="alternate" type="text/html" title="[1.6] Prime Numbers (1.6.4 - 1.6.7)" /><published>2024-11-02T01:01:36-07:00</published><updated>2024-11-02T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/11/02/1.6-primes</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/11/02/1.6-primes.html"><![CDATA[<!------------------------------------------------------------------------------------>
<div class="mintheaderdiv">
Definition 1.6.3
</div>
<div class="mintbodydiv">
A natural number is prime if it is greater than 1 and not divisible by any natural number other than 1 and itself.
</div>
<p><br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.4
</div>
<div class="peachbodydiv">
Any natural number other than 1 can be written as a product of prime numbers.
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<b>Proof</b><br />
By Induction. <br />
Base Case: \(n = 2:\) 2 is a prime number and it is a product of prime numbers (only one factor).
<br />
<br />
Inductive Case: Suppose that for any number \(r\), we have \(2 \leq r &lt; n\) and \(r\) is a product of prime numbers. Now, take \(n\). We have two cases. If \(n\) is a prime number, then \(n\) is a product of prime numbers and we’re done. Otherwise, \(n\) is not a prime number and we can write \(n\) as a product of two integers \(a\) and \(b\) (\(n = ab\)) such that \(1 &lt; a &lt; n\) and \(1 &lt; b &lt; n\) (by ?). We can now apply the inductive hypothesis to conclude that both \(a\) and \(b\) can be written as a product of prime numbers. There \(n = ab\) is also a product of prime numbers. \(\ \blacksquare\) 
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="yellowheaderdiv">
Theorem 1.6.6
</div>
<div class="yellowbodydiv">
There are infinitely many prime numbers.
</div>
<p><br />
Suppose for the sake of contradiction that there are finitely many primes \(p_1,p_2,...,p_k\). Consider \(p = p_1p_2...p_k + 1\). We know that \(p\) is greater than any of the prime numbers \(p_1,p_2,...,p_k\). By Proposition 1.6.4, we can express \(p\) as a product of prime numbers. Observe now that \(p\) can not be divisible by any of the prime numbers \(p_1, p_2, ..., p_k\) (Why? for any \(p_i\),  \(\frac{(p_1p_2...p_k)+1}{p_i} = p_1..p_{i-1}p_{i+1}...p_k + \frac{1}{p_i}\) which is not an integer). Therefore, we must have \(p\) be a prime number. This is a contradiction and therefore, there are infinitely many primes. \(\ \blacksquare\)
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.7
</div>
<div class="peachbodydiv">
Given integers \(a\) and \(d\) with \(d \geq 1\), there exists unique integers \(q\) and \(r\) such that 
$$
\begin{align*}
a = qd + r
\end{align*}
$$
where \(0 \leq r &lt; d\). 
</div>
<p><br />
<b>Proof</b>
<br />
We are given \(a\) and \(d\) such that \(d \geq 1\). <br />
We want to find unique integers \(q\) and \(r\) such that \(r &lt; d\).
<br />
<br />
We have two cases:
<br />
\(a \geq 0\): If \(d &gt; a\), then we just take \(q = 0\) and \(r = a\).<br />
Otherwise, suppose that \(d \leq a\). By Induction on a. Assume that for all non-negative integers smaller than \(a\), we can find such integers. In particular, suppose it holds for \(a - d\), then there exists integers \(q'\) and \(r\) such that</p>
<div> 
$$
\begin{align*}
(a - d) &amp;= q'd + r \quad (\text{where } 0 \leq r &lt; d) \\
a &amp;= q'd + d + r \\
a &amp;= q'(d + 1) + r 
\end{align*}
$$
</div>
<p>And we are done.
<br />
<br />
Case \(a &gt; 0\): If \(a\) is divisible by \(d\), then there exists integer \(q\) such that \(a = qd\). So we can set \(r = 0\) and we are done.
<br />
Otherwise, \(-a &gt; 0\) so by the first case (\(a \geq 0\)) there exists integers \(q'\) and \(r'\) such that \(-a = q'd + r'\) with \(0 &lt; r' &lt; d\). So</p>
<div> 
$$
\begin{align*}
-a &amp;= q'd + r' \\
a &amp;= -q'd - r' \\
a &amp;= -q'd - d + d - r' \\
a &amp;= (-q' - 1)d + (d - r') \\
  &amp;= (-q' - 1)d + (d - r').
\end{align*}
$$
</div>
<p>So \(q = (-q' - 1)\) and \(r = d - r'\) with \(0 &lt; d - r' &lt; d\) and we are done.
<br />
<br />
To show that \(q\) and \(r\) are unique, suppose for the sake of contradiction that they are not. Therefore suppose that \(a = qd + r = q'd + r'\) where \(0 \leq r,r' &lt; d\). Subtracting the equations, we see that</p>
<div> 
$$
\begin{align*}
(q - q')d = r - r'
\end{align*}
$$
</div>
<p>But this means that \(r - r'\) is divisible by d. However \(|r - r'| \leq \max\{r,r'\} &lt; d\), so we must have \(|r - r'| = 0\). This implies that \((q' - q)d = 0\) and so \(q' = q\) as we wanted to show. \(\ \blacksquare\)
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition 1.6.3 A natural number is prime if it is greater than 1 and not divisible by any natural number other than 1 and itself. Proposition 1.6.4 Any natural number other than 1 can be written as a product of prime numbers. Proof By Induction. Base Case: \(n = 2:\) 2 is a prime number and it is a product of prime numbers (only one factor). Inductive Case: Suppose that for any number \(r\), we have \(2 \leq r &lt; n\) and \(r\) is a product of prime numbers. Now, take \(n\). We have two cases. If \(n\) is a prime number, then \(n\) is a product of prime numbers and we’re done. Otherwise, \(n\) is not a prime number and we can write \(n\) as a product of two integers \(a\) and \(b\) (\(n = ab\)) such that \(1 &lt; a &lt; n\) and \(1 &lt; b &lt; n\) (by ?). We can now apply the inductive hypothesis to conclude that both \(a\) and \(b\) can be written as a product of prime numbers. There \(n = ab\) is also a product of prime numbers. \(\ \blacksquare\) Theorem 1.6.6 There are infinitely many prime numbers. Suppose for the sake of contradiction that there are finitely many primes \(p_1,p_2,...,p_k\). Consider \(p = p_1p_2...p_k + 1\). We know that \(p\) is greater than any of the prime numbers \(p_1,p_2,...,p_k\). By Proposition 1.6.4, we can express \(p\) as a product of prime numbers. Observe now that \(p\) can not be divisible by any of the prime numbers \(p_1, p_2, ..., p_k\) (Why? for any \(p_i\), \(\frac{(p_1p_2...p_k)+1}{p_i} = p_1..p_{i-1}p_{i+1}...p_k + \frac{1}{p_i}\) which is not an integer). Therefore, we must have \(p\) be a prime number. This is a contradiction and therefore, there are infinitely many primes. \(\ \blacksquare\) Proposition 1.6.7 Given integers \(a\) and \(d\) with \(d \geq 1\), there exists unique integers \(q\) and \(r\) such that $$ \begin{align*} a = qd + r \end{align*} $$ where \(0 \leq r &lt; d\). Proof We are given \(a\) and \(d\) such that \(d \geq 1\). We want to find unique integers \(q\) and \(r\) such that \(r &lt; d\). We have two cases: \(a \geq 0\): If \(d &gt; a\), then we just take \(q = 0\) and \(r = a\). Otherwise, suppose that \(d \leq a\). By Induction on a. Assume that for all non-negative integers smaller than \(a\), we can find such integers. In particular, suppose it holds for \(a - d\), then there exists integers \(q'\) and \(r\) such that $$ \begin{align*} (a - d) &amp;= q'd + r \quad (\text{where } 0 \leq r &lt; d) \\ a &amp;= q'd + d + r \\ a &amp;= q'(d + 1) + r \end{align*} $$ And we are done. Case \(a &gt; 0\): If \(a\) is divisible by \(d\), then there exists integer \(q\) such that \(a = qd\). So we can set \(r = 0\) and we are done. Otherwise, \(-a &gt; 0\) so by the first case (\(a \geq 0\)) there exists integers \(q'\) and \(r'\) such that \(-a = q'd + r'\) with \(0 &lt; r' &lt; d\). So $$ \begin{align*} -a &amp;= q'd + r' \\ a &amp;= -q'd - r' \\ a &amp;= -q'd - d + d - r' \\ a &amp;= (-q' - 1)d + (d - r') \\ &amp;= (-q' - 1)d + (d - r'). \end{align*} $$ So \(q = (-q' - 1)\) and \(r = d - r'\) with \(0 &lt; d - r' &lt; d\) and we are done. To show that \(q\) and \(r\) are unique, suppose for the sake of contradiction that they are not. Therefore suppose that \(a = qd + r = q'd + r'\) where \(0 \leq r,r' &lt; d\). Subtracting the equations, we see that $$ \begin{align*} (q - q')d = r - r' \end{align*} $$ But this means that \(r - r'\) is divisible by d. However \(|r - r'| \leq \max\{r,r'\} &lt; d\), so we must have \(|r - r'| = 0\). This implies that \((q' - q)d = 0\) and so \(q' = q\) as we wanted to show. \(\ \blacksquare\) References Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">[1.6] Divisibility in the Integers (1.6.1 - 1.6.2)</title><link href="http://localhost:4000/jekyll/update/2024/11/01/1.6-z.html" rel="alternate" type="text/html" title="[1.6] Divisibility in the Integers (1.6.1 - 1.6.2)" /><published>2024-11-01T01:01:36-07:00</published><updated>2024-11-01T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/11/01/1.6-z</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/11/01/1.6-z.html"><![CDATA[<!------------------------------------------------------------------------------------>
<p>We have the following proposition which we will take as is.</p>
<div class="peachheaderdiv">
Proposition 1.6.1
</div>
<div class="peachbodydiv">
<ol type="a">
	<li>Addition on \(\mathbf{Z}\) is commutative and associative.</li>
	<li>0 is an identity element for addition; that is, for all \(a \in \mathbf{Z}\), \(a + 0 = a\).</li>
	<li>Every element \(a\) of \(\mathbf{Z}\) has an additive inverse \(-a\), satisfying \(a + (-a) = a\). We write \(a - b\) for \(a + (-b)\).</li>
	<li>Multiplication on \(\mathbf{Z}\) is commutative and associative.</li>
	<li>1 is an identity element for multiplication; that is, for all \(a \in \mathbf{Z}\), \(1a = a\).</li>
	<li>The distributive law holds; For all \(a, b, c \in \mathbf{Z}\), \(a(b+c) = ab + ac\).</li>	
	<li>\(\mathbf{N}\) is closed under addition and multiplication. That is, the sum and product of positive integers is positive.</li>
	<li>The product of non-zero integers is non-zero. That is \(|ab| \geq \max\{|a|,|b|\} \) for non-zero integers \(a\) and \(b\).</li>
</ol>
</div>
<p><br />
Based on the proposition above, we can now conclude the following
<br />
<!------------------------------------------------------------------------------------></p>
<div class="peachheaderdiv">
Proposition 1.6.2
</div>
<div class="peachbodydiv">
<ol type="a">
	<li>If \(uv = 1\), then \(u = v = 1\) or \(u = v = =1\).</li>
	<li>If \(a|b\) and \(b|a\), then \(a = \pm b\).</li>
	<li>Divisibility is transitive: If \(a|b\) and \(b|c\), then \(a|c\).</li>
	<li>If \(a|b\) and \(a|c\), then \(a\) divides all integers that can be expressed in the form \(sb + tc\), where \(s\) and \(t\) are integers.</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<b>Proof (a)</b><br />
We know \(a\) or \(b\) can’t be zero. By Proposition 1.6.1, we know that \(|ab| \geq \max\{|a|,|b|\}\). So</p>
<div> 
$$
\begin{align*}
|uv| &amp;\geq \max\{|u|,|v|\} \\
1 &amp;\geq \max\{|u|,|v|\} \\
\end{align*}
$$
</div>
<p>From this we see that \(u = v = 1\) or \(u = v = -1\). <br />
<br />
<!------------------------------------------------------------------------------------>
<b>Proof (b)</b><br />
If \(a|b\), then \(b = ca\) for some integer \(c\). Similarly, if \(b|a\), then \(a = db\) for some integer \(d\). Therefore,</p>
<div> 
$$
\begin{align*}
b &amp;= ca \\ 
b &amp;= cdb \\
0 &amp;= (cd - 1)b
\end{align*}
$$
</div>
<p>Since the product of non-zero integers is non-zero, then either \(cd = 1\) or \(b=0\). If \(b = 0\), then \(a\) must be zero. If \(cd = 1\), then by (a), \(c = d = \pm 1\) and so \(c = d\).
<br />
<br />
<!------------------------------------------------------------------------------------>
<b>Proof (c)</b><br />
If \(a|b\), then \(b = ua\) for some integer \(u\). Similarly, if \(b|c\), then \(c = vb\) for some integer \(v\). Therefore,</p>
<div> 
$$
\begin{align*}
c &amp;= vb \\ 
c &amp;= (uv)a
\end{align*}
$$
</div>
<p>From this we see that \(a|c\).
<br />
<br />
<!------------------------------------------------------------------------------------>
<b>Proof (d)</b><br />
If \(a|b\), then \(b = ua\) for some integer \(u\). Similarly, if \(a|c\), then \(c = va\) for some integer \(v\). Now let \(s\) and \(t\) be integers. Observe that</p>
<div> 
$$
\begin{align*}
sb + tc &amp;= ua + va \\ 
        &amp;= (u+v)a
\end{align*}
$$
</div>
<p>From this we see that \(a|(sb + tc) \ \blacksquare\).
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://homepage.divms.uiowa.edu/~goodman/algebrabook.dir/algebrabook.html">Algebra: Abstract and Concrete by Frederick M. Goodman</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[We have the following proposition which we will take as is. Proposition 1.6.1 Addition on \(\mathbf{Z}\) is commutative and associative. 0 is an identity element for addition; that is, for all \(a \in \mathbf{Z}\), \(a + 0 = a\). Every element \(a\) of \(\mathbf{Z}\) has an additive inverse \(-a\), satisfying \(a + (-a) = a\). We write \(a - b\) for \(a + (-b)\). Multiplication on \(\mathbf{Z}\) is commutative and associative. 1 is an identity element for multiplication; that is, for all \(a \in \mathbf{Z}\), \(1a = a\). The distributive law holds; For all \(a, b, c \in \mathbf{Z}\), \(a(b+c) = ab + ac\). \(\mathbf{N}\) is closed under addition and multiplication. That is, the sum and product of positive integers is positive. The product of non-zero integers is non-zero. That is \(|ab| \geq \max\{|a|,|b|\} \) for non-zero integers \(a\) and \(b\). Based on the proposition above, we can now conclude the following Proposition 1.6.2 If \(uv = 1\), then \(u = v = 1\) or \(u = v = =1\). If \(a|b\) and \(b|a\), then \(a = \pm b\). Divisibility is transitive: If \(a|b\) and \(b|c\), then \(a|c\). If \(a|b\) and \(a|c\), then \(a\) divides all integers that can be expressed in the form \(sb + tc\), where \(s\) and \(t\) are integers. Proof (a) We know \(a\) or \(b\) can’t be zero. By Proposition 1.6.1, we know that \(|ab| \geq \max\{|a|,|b|\}\). So $$ \begin{align*} |uv| &amp;\geq \max\{|u|,|v|\} \\ 1 &amp;\geq \max\{|u|,|v|\} \\ \end{align*} $$ From this we see that \(u = v = 1\) or \(u = v = -1\). Proof (b) If \(a|b\), then \(b = ca\) for some integer \(c\). Similarly, if \(b|a\), then \(a = db\) for some integer \(d\). Therefore, $$ \begin{align*} b &amp;= ca \\ b &amp;= cdb \\ 0 &amp;= (cd - 1)b \end{align*} $$ Since the product of non-zero integers is non-zero, then either \(cd = 1\) or \(b=0\). If \(b = 0\), then \(a\) must be zero. If \(cd = 1\), then by (a), \(c = d = \pm 1\) and so \(c = d\). Proof (c) If \(a|b\), then \(b = ua\) for some integer \(u\). Similarly, if \(b|c\), then \(c = vb\) for some integer \(v\). Therefore, $$ \begin{align*} c &amp;= vb \\ c &amp;= (uv)a \end{align*} $$ From this we see that \(a|c\). Proof (d) If \(a|b\), then \(b = ua\) for some integer \(u\). Similarly, if \(a|c\), then \(c = va\) for some integer \(v\). Now let \(s\) and \(t\) be integers. Observe that $$ \begin{align*} sb + tc &amp;= ua + va \\ &amp;= (u+v)a \end{align*} $$ From this we see that \(a|(sb + tc) \ \blacksquare\). References Algebra: Abstract and Concrete by Frederick M. Goodman]]></summary></entry><entry><title type="html">4.1-4.2: Study Notes</title><link href="http://localhost:4000/jekyll/update/2024/09/19/4.1-4.2.html" rel="alternate" type="text/html" title="4.1-4.2: Study Notes" /><published>2024-09-19T01:01:36-07:00</published><updated>2024-09-19T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/09/19/4.1-4.2</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/09/19/4.1-4.2.html"><![CDATA[<!------------------------------------4.1------------------------------------------->
<p><br /></p>
<div class="purdiv">
Theorem 4.1
</div>
<div class="purbdiv">
The function \(\det: M_{2 \times 2}(\mathbf{F}) \rightarrow \mathbf{F}\) is a linear function of each of a \(2 \times 2\) matrix when the other row is held fixed. That is if \(u, v\) and \(w\) are in \(\mathbf{F}^2\) and \(k\) is a scalar, then
$$
\begin{align*}
\det \begin{pmatrix} u + kv \\ w \end{pmatrix}
= \det \begin{pmatrix} u \\ w \end{pmatrix} + k \det \begin{pmatrix} v \\ w \end{pmatrix}
\end{align*}
$$
and
$$
\begin{align*}
\det \begin{pmatrix} w \\ u + kv \end{pmatrix}
= \det \begin{pmatrix} w \\ u \end{pmatrix} + k \det \begin{pmatrix} w \\ v \end{pmatrix}
\end{align*}
$$
</div>
<p><br />
<b>Proof</b>
<br />
<br />
Let \(u = (a_1, a_2), v = (b_1, b_2)\) and \(w = (c_1, c_2)\) be in \(\mathbf{F}^2\) and let \(k\) be a scalar. Then</p>
<div>
$$
\begin{align*}
\det \begin{pmatrix} u \\ v \end{pmatrix} + \det k\begin{pmatrix} w \\ v \end{pmatrix}
&amp;= \det \begin{pmatrix} a_1 &amp; a_2 \\ c_1 &amp; c_2 \end{pmatrix} 
+ k \det \begin{pmatrix} b_1 &amp; b_2 \\ c_1 &amp; c_2 \end{pmatrix} 
\\
&amp;= (a_1c_2 - a_2c_1) + k(b_1c_2 - b_2c_1) \\
&amp;=  a_1c_2 - a_2c_1 + kb_1c_2 + kb_2c_1 \\
&amp;= c_2(a_1 + kb_1) - c_1(a_2 +kb_2) \\
&amp;= \det \begin{pmatrix} a_1+kb_1 &amp; a_2+kb_2 \\ c_1 &amp; c_2 \end{pmatrix} 
\end{align*}
$$
</div>
<p>The other direction is similarly calculated.
<br />
<!------------------------------------4.2------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 4.2
</div>
<div class="purbdiv">
Let \(A \in M_{2 \times 2}(\mathbf{F})\). Then the determinant of \(A\) is nonzero if and only if \(A\) is invertible. Moreover, if \(A\) is invertible, then
$$
\begin{align*}
A^{-1} = \frac{1}{\det(A)}
= \det \begin{pmatrix} A_{22} &amp; -A_{12} \\ -A_{21} &amp; A_{11} \end{pmatrix}
\end{align*}
$$
</div>
<!---------------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
<br />
We can construct the matrix such that we can show that \(AM = MA = I\) so this proves that \(A\) is invertible. Conversely, then \(A\) must have rank 2 and therefore we musteither have \(A_{21} \neq 0\) or \(A_{11} \neq 0\). If \(A_{11} \neq 0\), we can add \(-A_{21}/A_{11}\) times row 1 to row 2 to obtain</p>
<div>
$$
\begin{align*}
\begin{pmatrix} A_{11} &amp; -A_{12} \\ 0 &amp; A_{22} - \frac{A_{12}A_{21}}{A_{11}}\end{pmatrix}
\end{align*}
$$
</div>
<p>Because this is an elementary row operation, then we know the rank is preserved. Notice now that \(A_{21} = 0\). This means that \(A_{22} - \frac{A_{12}A_{21}}{A_{11}}\) can’t be zero. From this, we will see that the determinant is not zero. For the other case when \(A_{21} \neq 0\), we can instead add \(-A_{11}/A_{21}\) to achieve the same conclusion.å
<br />
<!---------------------------------------------------------------------------------->
<br /></p>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Let \(A \in M_{n \times n}(\mathbf{F})\). If \(n = 1\), so that \(A = (A_{11}\), we define \(\det(A) = A_{11}\). For \(n \geq 2\), we define \(\det(A)\) recursively as
$$
\begin{align*}
\det(A) = \sum_{j=1}^{n} (-1)^{1+j} A_{1j} \det(\tilde{A_{1j}}) 
\end{align*}
$$
The scalar \(\det(A)\) is called the <b>determinant</b> of \(A\) and is also denoted by \(|A|\). The scalar
$$
\begin{align*}
(-1)^{1+j} A_{1j} \det(\tilde{A_{1j}}) 
\end{align*}
$$
is called the <b>cofactor</b> of the entry \(A\) in row \(i\), column \(j\).
</div>
<p><br />
<!------------------------------------4.3------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 4.3
</div>
<div class="purbdiv">
The determinant of \(n \times n\) matrix is a linear function of each row when the remaining rows are held fixed. That is for \(1 \leq r \leq n\). we have
$$
\begin{align*}
\det \begin{pmatrix} a_1 \\ \vdots \\ a_{r-1} \\ u + kv \\ a_{r+1} \\ \vdots \\ a_n \end{pmatrix}
=
\det \begin{pmatrix} a_1 \\ \vdots \\ a_{r-1} \\ u \\ a_{r+1} \\ \vdots \\ a_n \end{pmatrix}
+
k
\det \begin{pmatrix} a_1 \\ \vdots \\ a_{r-1} \\ v \\ a_{r+1} \\ \vdots \\ a_n \end{pmatrix}
\end{align*}
$$
where \(k\) is a scalar and \(u,v\) are each \(a_i\) are row vectors in \(\mathbf{F}^n\)
</div>
<!---------------------------------------------------------------------------------->
<p><br />
<b>Proof</b>
<br />
<br />
By induction on \(n\). If \(n = 1\), the result is immediate. <br />
Now suppose that \(n \geq 2\) and assume the hypothesis is true for \(n-1\), that is the determinant of any \((n - 1) \times (n-1)\) is a linear function of each row when the remaining rows are held fixed. 
<br />
<br />
Let \(A\) be an \(n \times n\) matrix with rows \(a_1, a_2,...,a_n\), respectively and suppose that for some \(r\) where \((1 \leq r \leq n)\), we have \(a_r = u + kv\) for some \(u, v \in \mathbf{F}^n\) and scalar \(k\). Let \(u = (b_1,...,b_n)\) and let \(v = (c_1, ...,c_n)\). Now, let \(B\) and \(C\) be the matrices obtained from \(A\) by replacing row \(r\) of \(A\) by \(u\) and \(v\) respectively. We want to show that \(\det(A) = \det(B) + k\det(C)\).
<br />
<br />
Case \(r = 1\): TODO (it’s in lecture 18)
<br />
<br />
Case \(r &gt; 1\): For the matrices \(\tilde{A_{1j}}\), \(\tilde{B_{1j}}\), \(\tilde{C_{1j}}\) which are constructed by removing the first row and the \(j\)th column, we know that they are the same except for row \(r-1\) (\(r-1\) since the first row is removed, so the \(r\)‘th row is now the \(r-1\)th row). The row \(r-1\) specifically looks like</p>
<div>
$$
\begin{align*}
(b_1 + kc_1,...,b_{j-1} + kc_{j-1},b_{j+1} + kc_{j+1},...,b_n + kc_n)
\end{align*}
$$
</div>
<p>Moreover, these matrices are now of size \((n-1) \times (n-1)\) so we can invoke the inductive hypothesis to conclude that</p>
<div>
$$
\begin{align*}
\tilde{A_{1j}} = \tilde{B_{1j}} + k\tilde{C_{1j}}
\end{align*}
$$
</div>
<p>We also know that the first row is equal among all three matrices so \(A_{1j} = B_{1j} = C_{1j}\) for all \(j\). Let’s now compute the determinant using the definition above</p>
<div>
$$
\begin{align*}
\det(A) &amp;= \sum_{j=1}^{n} (-1)^{1+j} A_{1j} \det(\tilde{A_{1j}}) \\
        &amp;= \sum_{j=1}^{n} (-1)^{1+j} A_{1j} [\tilde{B_{1j}} + k\tilde{C_{1j}}] \\
        &amp;= \sum_{j=1}^{n} (-1)^{1+j} A_{1j} \tilde{B_{1j}} + k \sum_{j=1}^{n} (-1)^{1+j}  \tilde{C_{1j}}] \\
		&amp;= \det(B) + k\det(C).
\end{align*}
$$
</div>
<p>Therefore the inductive hypothesis is true for any \(n \times n\) matrix. \(\ \blacksquare\)
<br />
<br />
<!------------------------------------4.3(c)---------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 4.3 (Corollary)
</div>
<div class="purbdiv">
If \(A \in M_{n \times n}(\mathbf{F})\) has a row consisting entirely of zeros, then \(\det(A)=0\).
</div>
<p><br />
<b>Proof</b>
TODO (Exercise 4.2, 24)
<br />
<br />
<!------------------------------------Lemma---------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 4.3 (Corollary)
</div>
<div class="purbdiv">
Let \(B \in M_{n \times n}(\mathbf{F})\) where \(n \geq 2\). If row \(i\) of \(B\) equals \(e_k\) for some \(k \ (1 \leq k \leq n)\), then \(\det(B) = (-1)^{i+k}\det(\tilde{B_{ik}})\)
</div>
<p><br />
<!---------------------------------------------------------------------------------->
<b>Proof</b>
<br />
By Induction on \(n\). 
<br />
<br />
Base Case \(n = 2\): TODO
<br />
<br />
Inductive Case: Assume this is true for \((n - 1) \times (n - 1)\). We will show this is true for an \(n \times n\) matrix. Let \(B\) be an \(n \times\) matrix where the \(i\)th row is \(e_k\). If \(i = 1\), then we’re done by the definition of the determinant. Otherwise suppose that \(i \neq 1\). 
<br />
<br />
Now, for column \(j \neq k\), let \(C_{ij}\) be the \((n-2) \times (n-2)\) matrix obtained from \(B\) by deleting rows 1 and \(i\) and columns \(j\) and \(k\). Then, \(\tilde{B_{1j}}\) is the following vector in \(\mathbf{F}^{n-1}\)</p>
<div>
$$
\begin{align*}
\begin{cases} e_{k-1} \quad \text{ if }j &lt; k \\ 
              0 \quad \quad \ \text{ if } j = k \\
			  e_{k} \quad \quad \text{ if } j &gt; k
\end{cases}
\end{align*}
$$
</div>
<p>TODO ….
<br />
<!------------------------------------4.4------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 4.4
</div>
<div class="purbdiv">
The determinant of a square matrix can be evaluated by any cofactor expansion along any row. That is if \(A \in M_{n \times n}(\mathbf{F})\). Then for any integer \(i \ (1 \leq i \leq n)\)
	$$
	\begin{align*}
	\det(A) = \sum_{j=1}^{n} (-1)^{i+j} A_{ij} \det(\tilde{A_{ij}}) 
	\end{align*}
	$$
</div>
<p><br />
<b>Proof</b>
<br />
<br />
<br />
<br /></p>
<hr />

<p><br /></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://www.amazon.com/Linear-Algebra-5th-Stephen-Friedberg/dp/0134860241/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=">Linear Algebra 5th Edition</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Theorem 4.1 The function \(\det: M_{2 \times 2}(\mathbf{F}) \rightarrow \mathbf{F}\) is a linear function of each of a \(2 \times 2\) matrix when the other row is held fixed. That is if \(u, v\) and \(w\) are in \(\mathbf{F}^2\) and \(k\) is a scalar, then $$ \begin{align*} \det \begin{pmatrix} u + kv \\ w \end{pmatrix} = \det \begin{pmatrix} u \\ w \end{pmatrix} + k \det \begin{pmatrix} v \\ w \end{pmatrix} \end{align*} $$ and $$ \begin{align*} \det \begin{pmatrix} w \\ u + kv \end{pmatrix} = \det \begin{pmatrix} w \\ u \end{pmatrix} + k \det \begin{pmatrix} w \\ v \end{pmatrix} \end{align*} $$ Proof Let \(u = (a_1, a_2), v = (b_1, b_2)\) and \(w = (c_1, c_2)\) be in \(\mathbf{F}^2\) and let \(k\) be a scalar. Then $$ \begin{align*} \det \begin{pmatrix} u \\ v \end{pmatrix} + \det k\begin{pmatrix} w \\ v \end{pmatrix} &amp;= \det \begin{pmatrix} a_1 &amp; a_2 \\ c_1 &amp; c_2 \end{pmatrix} + k \det \begin{pmatrix} b_1 &amp; b_2 \\ c_1 &amp; c_2 \end{pmatrix} \\ &amp;= (a_1c_2 - a_2c_1) + k(b_1c_2 - b_2c_1) \\ &amp;= a_1c_2 - a_2c_1 + kb_1c_2 + kb_2c_1 \\ &amp;= c_2(a_1 + kb_1) - c_1(a_2 +kb_2) \\ &amp;= \det \begin{pmatrix} a_1+kb_1 &amp; a_2+kb_2 \\ c_1 &amp; c_2 \end{pmatrix} \end{align*} $$ The other direction is similarly calculated. Theorem 4.2 Let \(A \in M_{2 \times 2}(\mathbf{F})\). Then the determinant of \(A\) is nonzero if and only if \(A\) is invertible. Moreover, if \(A\) is invertible, then $$ \begin{align*} A^{-1} = \frac{1}{\det(A)} = \det \begin{pmatrix} A_{22} &amp; -A_{12} \\ -A_{21} &amp; A_{11} \end{pmatrix} \end{align*} $$ Proof We can construct the matrix such that we can show that \(AM = MA = I\) so this proves that \(A\) is invertible. Conversely, then \(A\) must have rank 2 and therefore we musteither have \(A_{21} \neq 0\) or \(A_{11} \neq 0\). If \(A_{11} \neq 0\), we can add \(-A_{21}/A_{11}\) times row 1 to row 2 to obtain $$ \begin{align*} \begin{pmatrix} A_{11} &amp; -A_{12} \\ 0 &amp; A_{22} - \frac{A_{12}A_{21}}{A_{11}}\end{pmatrix} \end{align*} $$ Because this is an elementary row operation, then we know the rank is preserved. Notice now that \(A_{21} = 0\). This means that \(A_{22} - \frac{A_{12}A_{21}}{A_{11}}\) can’t be zero. From this, we will see that the determinant is not zero. For the other case when \(A_{21} \neq 0\), we can instead add \(-A_{11}/A_{21}\) to achieve the same conclusion.å Definition Let \(A \in M_{n \times n}(\mathbf{F})\). If \(n = 1\), so that \(A = (A_{11}\), we define \(\det(A) = A_{11}\). For \(n \geq 2\), we define \(\det(A)\) recursively as $$ \begin{align*} \det(A) = \sum_{j=1}^{n} (-1)^{1+j} A_{1j} \det(\tilde{A_{1j}}) \end{align*} $$ The scalar \(\det(A)\) is called the determinant of \(A\) and is also denoted by \(|A|\). The scalar $$ \begin{align*} (-1)^{1+j} A_{1j} \det(\tilde{A_{1j}}) \end{align*} $$ is called the cofactor of the entry \(A\) in row \(i\), column \(j\). Theorem 4.3 The determinant of \(n \times n\) matrix is a linear function of each row when the remaining rows are held fixed. That is for \(1 \leq r \leq n\). we have $$ \begin{align*} \det \begin{pmatrix} a_1 \\ \vdots \\ a_{r-1} \\ u + kv \\ a_{r+1} \\ \vdots \\ a_n \end{pmatrix} = \det \begin{pmatrix} a_1 \\ \vdots \\ a_{r-1} \\ u \\ a_{r+1} \\ \vdots \\ a_n \end{pmatrix} + k \det \begin{pmatrix} a_1 \\ \vdots \\ a_{r-1} \\ v \\ a_{r+1} \\ \vdots \\ a_n \end{pmatrix} \end{align*} $$ where \(k\) is a scalar and \(u,v\) are each \(a_i\) are row vectors in \(\mathbf{F}^n\) Proof By induction on \(n\). If \(n = 1\), the result is immediate. Now suppose that \(n \geq 2\) and assume the hypothesis is true for \(n-1\), that is the determinant of any \((n - 1) \times (n-1)\) is a linear function of each row when the remaining rows are held fixed. Let \(A\) be an \(n \times n\) matrix with rows \(a_1, a_2,...,a_n\), respectively and suppose that for some \(r\) where \((1 \leq r \leq n)\), we have \(a_r = u + kv\) for some \(u, v \in \mathbf{F}^n\) and scalar \(k\). Let \(u = (b_1,...,b_n)\) and let \(v = (c_1, ...,c_n)\). Now, let \(B\) and \(C\) be the matrices obtained from \(A\) by replacing row \(r\) of \(A\) by \(u\) and \(v\) respectively. We want to show that \(\det(A) = \det(B) + k\det(C)\). Case \(r = 1\): TODO (it’s in lecture 18) Case \(r &gt; 1\): For the matrices \(\tilde{A_{1j}}\), \(\tilde{B_{1j}}\), \(\tilde{C_{1j}}\) which are constructed by removing the first row and the \(j\)th column, we know that they are the same except for row \(r-1\) (\(r-1\) since the first row is removed, so the \(r\)‘th row is now the \(r-1\)th row). The row \(r-1\) specifically looks like $$ \begin{align*} (b_1 + kc_1,...,b_{j-1} + kc_{j-1},b_{j+1} + kc_{j+1},...,b_n + kc_n) \end{align*} $$ Moreover, these matrices are now of size \((n-1) \times (n-1)\) so we can invoke the inductive hypothesis to conclude that $$ \begin{align*} \tilde{A_{1j}} = \tilde{B_{1j}} + k\tilde{C_{1j}} \end{align*} $$ We also know that the first row is equal among all three matrices so \(A_{1j} = B_{1j} = C_{1j}\) for all \(j\). Let’s now compute the determinant using the definition above $$ \begin{align*} \det(A) &amp;= \sum_{j=1}^{n} (-1)^{1+j} A_{1j} \det(\tilde{A_{1j}}) \\ &amp;= \sum_{j=1}^{n} (-1)^{1+j} A_{1j} [\tilde{B_{1j}} + k\tilde{C_{1j}}] \\ &amp;= \sum_{j=1}^{n} (-1)^{1+j} A_{1j} \tilde{B_{1j}} + k \sum_{j=1}^{n} (-1)^{1+j} \tilde{C_{1j}}] \\ &amp;= \det(B) + k\det(C). \end{align*} $$ Therefore the inductive hypothesis is true for any \(n \times n\) matrix. \(\ \blacksquare\) Theorem 4.3 (Corollary) If \(A \in M_{n \times n}(\mathbf{F})\) has a row consisting entirely of zeros, then \(\det(A)=0\). Proof TODO (Exercise 4.2, 24) Theorem 4.3 (Corollary) Let \(B \in M_{n \times n}(\mathbf{F})\) where \(n \geq 2\). If row \(i\) of \(B\) equals \(e_k\) for some \(k \ (1 \leq k \leq n)\), then \(\det(B) = (-1)^{i+k}\det(\tilde{B_{ik}})\) Proof By Induction on \(n\). Base Case \(n = 2\): TODO Inductive Case: Assume this is true for \((n - 1) \times (n - 1)\). We will show this is true for an \(n \times n\) matrix. Let \(B\) be an \(n \times\) matrix where the \(i\)th row is \(e_k\). If \(i = 1\), then we’re done by the definition of the determinant. Otherwise suppose that \(i \neq 1\). Now, for column \(j \neq k\), let \(C_{ij}\) be the \((n-2) \times (n-2)\) matrix obtained from \(B\) by deleting rows 1 and \(i\) and columns \(j\) and \(k\). Then, \(\tilde{B_{1j}}\) is the following vector in \(\mathbf{F}^{n-1}\) $$ \begin{align*} \begin{cases} e_{k-1} \quad \text{ if }j &lt; k \\ 0 \quad \quad \ \text{ if } j = k \\ e_{k} \quad \quad \text{ if } j &gt; k \end{cases} \end{align*} $$ TODO …. Theorem 4.4 The determinant of a square matrix can be evaluated by any cofactor expansion along any row. That is if \(A \in M_{n \times n}(\mathbf{F})\). Then for any integer \(i \ (1 \leq i \leq n)\) $$ \begin{align*} \det(A) = \sum_{j=1}^{n} (-1)^{i+j} A_{ij} \det(\tilde{A_{ij}}) \end{align*} $$ Proof References Linear Algebra 5th Edition]]></summary></entry><entry><title type="html">3.1-3.2: Study Notes</title><link href="http://localhost:4000/jekyll/update/2024/09/18/3.1-3.2.html" rel="alternate" type="text/html" title="3.1-3.2: Study Notes" /><published>2024-09-18T01:01:36-07:00</published><updated>2024-09-18T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/09/18/3.1-3.2</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/09/18/3.1-3.2.html"><![CDATA[<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Let \(A\) be an \(m \times n\). Any one of the following three operations on the rows [columns] of \(A\) is called an <b>elementary row [column] operation</b>
<ol type="1">
	<li>interchanging any two rows [columns] of \(A\);</li>
	<li>multiplying any row [column] of \(A\) by a non-zero scalar;</li>
	<li>adding any scalar multiple of a row [column] of \(A\) to another row [column].</li>
</ol>
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
An \(n \times n\) elementary matrix is a matrix obtained by performing an elementary operation on \(I_n\). The elementary matrix is said to be of <b>type 1, 2 or 3</b> according to whether the elementary operation performed on \(I_n\) is of type 1, 2 or 3 operation, respectively.
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 3.1
</div>
<div class="purbdiv">
Let \(A \in M_{n \times n}(\mathbf{F})\) and suppose that \(B\) is obtained from \(A\) by performing an elementary row [column] operation. Then, there exists an \(m \times m [n \times n]\) elementary matrix \(E\) such that \(B = EA [B = AE]\). In fact, \(E\) is obtained from \(I_m [I_n]\) by performing the same elementary row [column] operation as that which was performed on \(A\) to obtain \(B\). Conversely, if \(E\) is an elementary \(m \times m [n \times n]\) matrix, then \(EA [AE]\) is the matrix obtained from \(A\) by performing the same elementary row operation.
</div>
<p><br />
<!----------------------------------------3.2------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 3.2
</div>
<div class="purbdiv">
Elementary matrices are invertible, and the inverse of an elementary matrix is an elementary matrix of the same type.
</div>
<p><br />
<b>Proof</b>
<br />
<br />
Let \(E\) be an elementary \(n \times n\) matrix. Then \(E\) can be obtained by an elementary row operation on \(I_n\) by definition. Reverse the steps used to transform \(I_n\) into \(E\) to get \(I_n\) back. The result is that \(I_n\) can be obtained from \(E\) by an elementary row operation of the same type. By Theorem 3.1, there is an elementary matrix \(\overline{E}\) such that \(\overline{E}E = I_n\). But since \(\overline{E}E = I_n\), then by Exercise 10 from 2.4, \(\overline{E}\) and \(E\) are invertible and we have \(E^{-1} = \overline{E}\). \(\ \blacksquare\)
<br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
If \(A \in M_{n \times n}(\mathbf{F})\) we define the <b>rank</b> of \(A\), denoted \(\text{rank}(A)\), to be the rank of the linear transformation \(L_A: \mathbf{F}^n \rightarrow \mathbf{F}^m\)
</div>
<p><br />
One important implication here is that an \(n \times n\) matrix is invertible if and only if its rank is \(n\).
<br />
<br />
<!----------------------------------------3.3------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 3.3
</div>
<div class="purbdiv">
Let \(T: V \rightarrow W\) be a linear transformation between finite-dimensional vector spaces, and let \(\beta\) and \(\gamma\) be ordered bases for \(V\) and \(W\), respectively. Then \(rank(T) = rank([T]_{\beta}^{\gamma})\)
</div>
<p><br />
The rank of a linear transformation is the same as the rank of one its matrix representations.
<br />
<br />
<!--------------------------------------3.4-------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 3.4
</div>
<div class="purbdiv">
Let \(A\) be an \(m \times n\) matrix. If \(P\) and \(Q\) are invertible \(m \times m\) and \(n \times n\) matrices, respectively, then 
<ol type="a">
	<li>\(\text{rank}(AQ) = \text{rank}(A)\),</li>
	<li>\(\text{rank}(PA) = \text{rank}(A)\) and therefore,</li>
	<li>\(\text{rank}(PAQ) = \text{rank}(A)\)</li>
</ol>
</div>
<p><br />
<b>Proof</b>
<br />
<br />
(a) Observe that</p>
<div>
$$
\begin{align*}
R(L_{AQ}) &amp;= R(L_AL_Q) \\
          &amp;= L_AL_Q(\mathbf{F}) \quad \text{(to get the range, we apply the linear map)}\\
		  &amp;= L_A(L_Q(\mathbf{F})) \quad \text{(we apply $L_Q$ first)}\\
		  &amp;= L_A(\mathbf{F}) \quad \text{(because $L_Q$ is onto)}\\
		  &amp;= R(L_A)
\end{align*}
$$
</div>
<p>Therefore,</p>
<div>
$$
\begin{align*}
\text{rank}(AQ) &amp;= \dim(R(L_{AQ})) \quad \text{(the rank is the dimension of the range)} \\
                &amp;= \dim(R(L_A)) \quad \text{(by the previous result)}  \\
				&amp;= rank(A).
\end{align*}
$$
</div>
<p><br />
<!--------------------------------------3.4(c)------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 3.4 (Corollary)
</div>
<div class="purbdiv">
Elementary row and column operations on a matrix are rank-preserving.
</div>
<p><br />
<!--------------------------------------3.5-------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 3.5
</div>
<div class="purbdiv">
The rank of any matrix equals the maximum number of its linearly independent columns; that is, the rank of a matrix is the dimension of the subspace generated by its columns.
</div>
<p><br />
<!----------------------->
<b>Proof</b>
<br />
<br />
For any \(A \in M_{m \times n}(\mathbf{F})\),</p>
<div>
$$
\begin{align*}
\text{rank}(A) = \text{rank}(L_A) = \dim(R(L_A))
\end{align*}
$$
</div>
<p>Let \(\beta\) be the standard ordered basis for \(\mathbf{F}^n\). Then \(\beta\) spans \(\mathbf{F}^n\). Theorem 2.2 assets that \(R(T) = \text(T(\beta))\) so</p>
<div>
$$
\begin{align*}
R(L_A) &amp;= \text{span}(L_A(\beta)) \quad \text{(by Theorem 2.2)} \\
       &amp;= \text{span}(\{L_A(e_1),...,L_A(e_n)\})
\end{align*}
$$
</div>
<p>By theorem 2.13(b) \(L_A(e_j) = Ae_j = a_j\) where \(a_j\) is the \(j\)th column of \(A\). So</p>
<div>
$$
\begin{align*}
R(L_A) &amp;= \text{span}(\{a_1,...,a_n\})
\end{align*}
$$
</div>
<p>Therefore</p>
<div>
$$
\begin{align*}
\text{rank}(A) &amp;= \dim(R(L_A)) = \dim(\text{span}(\{a_1,...,a_n\})) \ \blacksquare
\end{align*}
$$
</div>
<p>Note: If you’ve forgotten 2.13 which you just did. Remember that by definition, matrix-vector multiplication \(Av\) is defined as \(a_1v_1 + a_2v_2 +...+ a_nv_n\) where \(a_1,...,a_n\) are the columns of \(A\) and \(v_1,...,v_n\) are the entries of the vector \(v\). Therefore, if you multiply \(Ae_j\) where \(e_j\) is from the standard basis, then we know that vector is all zeros except for the \(j\)th entry. So this means that \(Ae_j = a_j\). 
<br />
<br />
<!--------------------------------------3.6-------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 3.6
</div>
<div class="purbdiv">
Let \(A\) be an \(m \times n \) matrix of rank \(r\). Then \(r \leq m, r \leq n\), and by means of a finite number of elementary row and column operations, \(A\) can be transformed into the matrix
$$
\begin{align*}
D = \begin{pmatrix}
I_r &amp; O_1 \\
O_2 &amp; O_3
\end{pmatrix}
\end{align*}
$$
where \(O_1\), \(O_2\) and \(O_3\) are zero matrices. Thus \(D_{ii} = 1\) for \(i \leq r\) and \(D_{ij} = 0\) otherwise.
</div>
<p><br />
<!------------------------------------3.6(c)--------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 3.6 (Corollary 1)
</div>
<div class="purbdiv">
Let \(A\) be an \(m \times n \) matrix of rank \(r\). Then there exists invertible matrices \(B\) and \(C\) of sizes \(m \times m \) and \(n \times n\) respectively, such that \(D = BAC\) where
$$
\begin{align*}
D = \begin{pmatrix}
I_r &amp; O_1 \\
O_2 &amp; O_3
\end{pmatrix}
\end{align*}
$$
is the \(m \times n\) in which \(O_1\), \(O_2\) and \(O_3\) are zero matrices.
</div>
<p><br />
<b>Proof</b>
TODO
<br />
<!------------------------------------3.6(c)--------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 3.6 (Corollary 2)
</div>
<div class="purbdiv">
Let \(A\) be \(m \times n\) matrices. Then
<ol type="i">
</ol>
</div>
<p><br />
<b>Proof</b>
TODO
<br /></p>

<p><br />
<!------------------------------------3.6(c)--------------------------------------------->
<br /></p>
<div class="purdiv">
Theorem 3.6 (Corollary 3)
</div>
<div class="purbdiv">
Every invertible matrix is a product of elementary matrices
</div>
<p><br />
<b>Proof</b>
TODO
<br /></p>

<p><br />
<br /></p>
<hr />

<p><br /></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://www.amazon.com/Linear-Algebra-5th-Stephen-Friedberg/dp/0134860241/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=">Linear Algebra 5th Edition</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition Let \(A\) be an \(m \times n\). Any one of the following three operations on the rows [columns] of \(A\) is called an elementary row [column] operation interchanging any two rows [columns] of \(A\); multiplying any row [column] of \(A\) by a non-zero scalar; adding any scalar multiple of a row [column] of \(A\) to another row [column]. Definition An \(n \times n\) elementary matrix is a matrix obtained by performing an elementary operation on \(I_n\). The elementary matrix is said to be of type 1, 2 or 3 according to whether the elementary operation performed on \(I_n\) is of type 1, 2 or 3 operation, respectively. Theorem 3.1 Let \(A \in M_{n \times n}(\mathbf{F})\) and suppose that \(B\) is obtained from \(A\) by performing an elementary row [column] operation. Then, there exists an \(m \times m [n \times n]\) elementary matrix \(E\) such that \(B = EA [B = AE]\). In fact, \(E\) is obtained from \(I_m [I_n]\) by performing the same elementary row [column] operation as that which was performed on \(A\) to obtain \(B\). Conversely, if \(E\) is an elementary \(m \times m [n \times n]\) matrix, then \(EA [AE]\) is the matrix obtained from \(A\) by performing the same elementary row operation. Theorem 3.2 Elementary matrices are invertible, and the inverse of an elementary matrix is an elementary matrix of the same type. Proof Let \(E\) be an elementary \(n \times n\) matrix. Then \(E\) can be obtained by an elementary row operation on \(I_n\) by definition. Reverse the steps used to transform \(I_n\) into \(E\) to get \(I_n\) back. The result is that \(I_n\) can be obtained from \(E\) by an elementary row operation of the same type. By Theorem 3.1, there is an elementary matrix \(\overline{E}\) such that \(\overline{E}E = I_n\). But since \(\overline{E}E = I_n\), then by Exercise 10 from 2.4, \(\overline{E}\) and \(E\) are invertible and we have \(E^{-1} = \overline{E}\). \(\ \blacksquare\) Definition If \(A \in M_{n \times n}(\mathbf{F})\) we define the rank of \(A\), denoted \(\text{rank}(A)\), to be the rank of the linear transformation \(L_A: \mathbf{F}^n \rightarrow \mathbf{F}^m\) One important implication here is that an \(n \times n\) matrix is invertible if and only if its rank is \(n\). Theorem 3.3 Let \(T: V \rightarrow W\) be a linear transformation between finite-dimensional vector spaces, and let \(\beta\) and \(\gamma\) be ordered bases for \(V\) and \(W\), respectively. Then \(rank(T) = rank([T]_{\beta}^{\gamma})\) The rank of a linear transformation is the same as the rank of one its matrix representations. Theorem 3.4 Let \(A\) be an \(m \times n\) matrix. If \(P\) and \(Q\) are invertible \(m \times m\) and \(n \times n\) matrices, respectively, then \(\text{rank}(AQ) = \text{rank}(A)\), \(\text{rank}(PA) = \text{rank}(A)\) and therefore, \(\text{rank}(PAQ) = \text{rank}(A)\) Proof (a) Observe that $$ \begin{align*} R(L_{AQ}) &amp;= R(L_AL_Q) \\ &amp;= L_AL_Q(\mathbf{F}) \quad \text{(to get the range, we apply the linear map)}\\ &amp;= L_A(L_Q(\mathbf{F})) \quad \text{(we apply $L_Q$ first)}\\ &amp;= L_A(\mathbf{F}) \quad \text{(because $L_Q$ is onto)}\\ &amp;= R(L_A) \end{align*} $$ Therefore, $$ \begin{align*} \text{rank}(AQ) &amp;= \dim(R(L_{AQ})) \quad \text{(the rank is the dimension of the range)} \\ &amp;= \dim(R(L_A)) \quad \text{(by the previous result)} \\ &amp;= rank(A). \end{align*} $$ Theorem 3.4 (Corollary) Elementary row and column operations on a matrix are rank-preserving. Theorem 3.5 The rank of any matrix equals the maximum number of its linearly independent columns; that is, the rank of a matrix is the dimension of the subspace generated by its columns. Proof For any \(A \in M_{m \times n}(\mathbf{F})\), $$ \begin{align*} \text{rank}(A) = \text{rank}(L_A) = \dim(R(L_A)) \end{align*} $$ Let \(\beta\) be the standard ordered basis for \(\mathbf{F}^n\). Then \(\beta\) spans \(\mathbf{F}^n\). Theorem 2.2 assets that \(R(T) = \text(T(\beta))\) so $$ \begin{align*} R(L_A) &amp;= \text{span}(L_A(\beta)) \quad \text{(by Theorem 2.2)} \\ &amp;= \text{span}(\{L_A(e_1),...,L_A(e_n)\}) \end{align*} $$ By theorem 2.13(b) \(L_A(e_j) = Ae_j = a_j\) where \(a_j\) is the \(j\)th column of \(A\). So $$ \begin{align*} R(L_A) &amp;= \text{span}(\{a_1,...,a_n\}) \end{align*} $$ Therefore $$ \begin{align*} \text{rank}(A) &amp;= \dim(R(L_A)) = \dim(\text{span}(\{a_1,...,a_n\})) \ \blacksquare \end{align*} $$ Note: If you’ve forgotten 2.13 which you just did. Remember that by definition, matrix-vector multiplication \(Av\) is defined as \(a_1v_1 + a_2v_2 +...+ a_nv_n\) where \(a_1,...,a_n\) are the columns of \(A\) and \(v_1,...,v_n\) are the entries of the vector \(v\). Therefore, if you multiply \(Ae_j\) where \(e_j\) is from the standard basis, then we know that vector is all zeros except for the \(j\)th entry. So this means that \(Ae_j = a_j\). Theorem 3.6 Let \(A\) be an \(m \times n \) matrix of rank \(r\). Then \(r \leq m, r \leq n\), and by means of a finite number of elementary row and column operations, \(A\) can be transformed into the matrix $$ \begin{align*} D = \begin{pmatrix} I_r &amp; O_1 \\ O_2 &amp; O_3 \end{pmatrix} \end{align*} $$ where \(O_1\), \(O_2\) and \(O_3\) are zero matrices. Thus \(D_{ii} = 1\) for \(i \leq r\) and \(D_{ij} = 0\) otherwise. Theorem 3.6 (Corollary 1) Let \(A\) be an \(m \times n \) matrix of rank \(r\). Then there exists invertible matrices \(B\) and \(C\) of sizes \(m \times m \) and \(n \times n\) respectively, such that \(D = BAC\) where $$ \begin{align*} D = \begin{pmatrix} I_r &amp; O_1 \\ O_2 &amp; O_3 \end{pmatrix} \end{align*} $$ is the \(m \times n\) in which \(O_1\), \(O_2\) and \(O_3\) are zero matrices. Proof TODO Theorem 3.6 (Corollary 2) Let \(A\) be \(m \times n\) matrices. Then Proof TODO]]></summary></entry><entry><title type="html">7.1: Study Notes</title><link href="http://localhost:4000/jekyll/update/2024/09/17/7.1.html" rel="alternate" type="text/html" title="7.1: Study Notes" /><published>2024-09-17T01:01:36-07:00</published><updated>2024-09-17T01:01:36-07:00</updated><id>http://localhost:4000/jekyll/update/2024/09/17/7.1</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2024/09/17/7.1.html"><![CDATA[<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be a scalar. A non-zero vector \(x\) in \(V\) is called a generalized eigenvector of \(T\) corresponding to \(\lambda\) if \((T - \lambda I)^p(x) = 0\) for some positive integer \(p\).
</div>
<p><br />
Note here that if \(x\) is a generalized eigenvector of \(T\) corresponding to \(\lambda\) and \(p\) is the smallest positive integer for which \((T - \lambda I)^{p}(x) = 0\), then</p>
<div>
$$
\begin{align*}
(T - \lambda I)^{p-1}(x) &amp;= y \neq 0 \\
(T - \lambda I)(T - \lambda I)^{p-1}(x) &amp;= (T - \lambda I) y \\
(T - \lambda I)^{p}(x) &amp;= T(y) - \lambda y \\
\bar{0} &amp;= T(y) - \lambda y \\
T(y) &amp;= \lambda y
\end{align*}
$$
</div>
<p>So \(y\) is an eigenvector of \(T\).
<br />
<br />
<!------------------------------------------------------------------------------------></p>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). The generalized eigenspace of \(T\) corresponding to \(\lambda\) denoted \(K_{\lambda}\), is the subset of \(V\) defined by
$$
\begin{align*}
K_{\lambda} = \{ x \in V: (T - \lambda I)^p(x) = 0 \quad \text{for some positive integer $p$} \}
\end{align*}
$$
</div>
<p><br />
Note that \(K_{\lambda}\) consists of the zero vector and all generalized eigenvectors corresponding to \(\lambda\).
<br />
<br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 7.1
</div>
<div class="purbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). Then
<ol type="a">
	<li>\(K_{\lambda}\) is a \(T\)-invariant subspace of \(V\) containing \(E_{\lambda}\) (the eigenspace of \(T\) corresponding to \(\lambda\))</li>
	<li>For any eigenvalue \(\mu\) of \(T\) such that \(\mu \neq \lambda\), \(K_{\lambda} \cap K_{\mu} = \{0\}\)</li>
	<li>For any scalar \(\mu \neq \lambda\), the restriction of \(T - \mu I\) to \(K_{\lambda}\) is one-to-one and onto.</li>
</ol>
</div>
<p><br />
<b>Proof</b>
<br />
(a) Showing that \(K_{\lambda}\) is a subspace is straightforward. We need to show that \(\bar{0} \in K_{\lambda}\) and that \(K_{\lambda}\) is closed under scalar multiplication and addition.
<br />
<br />
To show that \(K_{\lambda}\) is \(T\)-invariant. We need to show for any \(x \in K_{\lambda}\), that \(T(x) \in K_{\lambda}\). By definition, let be \(p\) be a positive integer, then \((T - \lambda I)^p(x) = \bar{0}\). We know to show that \((T - \lambda I)^p(T(x)) = \bar{0}\). Observe that</p>
<div>
$$
\begin{align*}
(T - \lambda I)^p(T(x)) = T(T - \lambda I)^p(x) = T(\bar{0}) = \bar{0}
\end{align*}
$$
</div>
<p>(b) TODO
<br />
(c) Let \(\mu\) be a scalar such that \(\mu \neq \lambda\). Let \(x \in K_{\lambda}\).  Let \(p\) be the smallest integer such that \((T - \lambda I)^p x = 0\) and</p>
<div>
	$$
	\begin{align*}
	W = \text{span}\{x, (T - \lambda I)(x),...,(T - \lambda I)^{p-1}(x)\}
	\end{align*}
	$$
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 7.2
</div>
<div class="purbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) such that the characteristic polynomial splits. Suppose that \(\lambda\) is an eigenvalue of \(T\) with multiplicity \(m\). Then
<ol type="a">
	<li>\(\dim(K_{\lambda}) \leq m\)</li>
	<li>\(K_{\lambda} = N((T - \lambda I)^m)\)</li>
</ol>
</div>
<p><br />
<b>Proof</b>
<br />
(a) Let \(W = K_{\lambda}\). Let the characteristic polynomial of \(W\) be \(h(t)\) We know by Theorem 7.1, that \(W\) is a \(T\)-invariant subspace of \(V\). Therefore, by Theorem 5.20, \(h(t)\) divides the characteristic polynomial of \(T\). From Theorem 7.1(b), we know that \(\lambda\) is the only eigenvalue of \(T_W\). Therefore \(h(t) = (-1)^d(t - \lambda)^d\) where \(d = \dim(W)\) and \(d \leq m\). 
<br />
<br />
(b) By definition, we know that \(N(T)=\{x \in V \ | \ T(x) = 0\}\). We also know that \(K_{\lambda} =\{ x \in V \ | \ (T - \lambda I)^p = 0 \ \text{ for }p &gt; 0 \}\). So we can see that for any \(x \in N((T - \lambda I)^m)\)</p>
<div>
	$$
	\begin{align*}
	(T - \lambda I)^m(x) = 0
	\end{align*}
	$$
</div>
<p>Since \(m\) is the multiplicity of an eigenvalue, then it’s positive and so \(x \in K_{\lambda}\) by definition. So \(N((T - \lambda I)^m) \in K_{\lambda}\).
<br />
<br />
Now, suppose that \(x \in K_{\lambda}\). We want to show that \(x \in N((T - \lambda I)^m)\) where \(m\) is the multiplicity of \(\lambda\). Since the characteristic polynomial of \(T\) splits, then let it be of the form \(f(t) = (t - \lambda)^m g(t)\) where \(g(t)\) is the product of powers of the form \(t - \mu\) for eigenvalues \(\mu \neq \lambda\). By Theorem 7.1, \(g(T)\) is one-to-one on \(K_{\lambda}\)[TODO: WHY?]. It is also onto since \(K_{\lambda}\) is finite dimensional. Since  \(x \in K_{\lambda}\), then there exists some \(y\) such that \(g(T)(x) = y\). [WHY?]. Hence</p>
<div>
	$$
	\begin{align*}
	(T - \lambda I)^m(x) = (T - \lambda I)^m g(T)(y) = f(T)(y) = \bar{0}
	\end{align*}
	$$
</div>
<p>Why? ….. [TODO]
<br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 7.3
</div>
<div class="purbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) such that characteristic polynomial of \(T\) splits, and let \(\lambda_1,\lambda_2,..., \lambda_k\) be the distinct eigenvalues of \(T\). Then, for every \(x \in V\), there are exist unique vectors \(v_i \in K_{\lambda}\), for \(i = 1,2,...,k\) such that
$$
\begin{align*}
x = v_1 + v_2 + ... + v_k
\end{align*}
$$
</div>
<p><br />
<b>Proof</b>
<br />
TODO
<br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 7.4
</div>
<div class="purbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) whose characteristic polynomial \((t - \lambda_1)^{m_1}(t - \lambda_2)^{m_2}...(t - \lambda_k)^{m_k}\) splits. For \(i = 1,2,...,k\), let \(\beta_i\) be an ordered basis for \(K_{\lambda_i}\). Then
<ol type="a">
	<li>\(\beta_i \cap \beta_j = \emptyset \text{ for } i \neq j\)</li>
	<li>\(\beta = \beta_1 \cup \beta_2 \cup ... \cup \beta_k \) is an ordered basis for \(V\)</li>
	<li>\(\dim(K_{\lambda_j}) = m_i\) for all \(i\)</li>
</ol>
</div>
<p><br />
<b>Proof</b>
<br />
(a) Consequence of Theorem 7.1(b)
<br />
<br />
(b) We need to show that \(\beta\) is linearly independent and that \(\beta\) spans \(V\). To see that \(\beta\) is linearly independent. 
<br />
<br />
(c) 
<br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 7.6
</div>
<div class="purbdiv">
Let \(T\) be a linear operator on a vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). Suppose that \(\gamma_1, \gamma_2,...,\gamma_q\) are cycles of generalized eigenvectors of \(T\) corresponding to \(\lambda\) such that the initial vectors of the \(\gamma_i\)'s are distinct and form a linearly independent set. Then, the \(\gamma_i\)'s are disjoint and their union \(\gamma = \bigcup\limits_{i=1}^q \gamma_i\) is linearly independent.
</div>
<p><br />
<b>Proof</b>
<br />
TODO
<br />
<!------------------------------------------------------------------------------------></p>
<div class="purdiv">
Corollary (7.6)
</div>
<div class="purbdiv">
Every cycle of generalized eigenvectors of a linear operator is linearly independent
</div>
<p><br />
<!------------------------------------------------------------------------------------>
<br /></p>
<div class="purdiv">
Theorem 7.7
</div>
<div class="purbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). Then \(K_{\lambda}\) has an ordered basis consisting of a union of disjoint cycles of generalized eigenvectors corresponding to \(\lambda\).
</div>
<p><br />
<b>Proof</b>
<br />
TODO
<br />
<!------------------------------------------------------------------------------------></p>
<div class="purdiv">
Corollary 1 (7.7)
</div>
<div class="purbdiv">
Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) whose characteristic polynomial splits. Then \(T\) has a Jordan canonical form.
</div>
<p><br />
<b>Proof</b>
<br />
TODO
<br />
<!------------------------------------------------------------------------------------>
<br />
<br /></p>
<hr />

<p><br />
<!------------------------------------------------------------------------------------></p>
<h4><b>References</b></h4>
<ul>
<li><a href="https://www.amazon.com/Linear-Algebra-5th-Stephen-Friedberg/dp/0134860241/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=">Linear Algebra 5th Edition</a></li>
</ul>]]></content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html"><![CDATA[Definition Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be a scalar. A non-zero vector \(x\) in \(V\) is called a generalized eigenvector of \(T\) corresponding to \(\lambda\) if \((T - \lambda I)^p(x) = 0\) for some positive integer \(p\). Note here that if \(x\) is a generalized eigenvector of \(T\) corresponding to \(\lambda\) and \(p\) is the smallest positive integer for which \((T - \lambda I)^{p}(x) = 0\), then $$ \begin{align*} (T - \lambda I)^{p-1}(x) &amp;= y \neq 0 \\ (T - \lambda I)(T - \lambda I)^{p-1}(x) &amp;= (T - \lambda I) y \\ (T - \lambda I)^{p}(x) &amp;= T(y) - \lambda y \\ \bar{0} &amp;= T(y) - \lambda y \\ T(y) &amp;= \lambda y \end{align*} $$ So \(y\) is an eigenvector of \(T\). Definition Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). The generalized eigenspace of \(T\) corresponding to \(\lambda\) denoted \(K_{\lambda}\), is the subset of \(V\) defined by $$ \begin{align*} K_{\lambda} = \{ x \in V: (T - \lambda I)^p(x) = 0 \quad \text{for some positive integer $p$} \} \end{align*} $$ Note that \(K_{\lambda}\) consists of the zero vector and all generalized eigenvectors corresponding to \(\lambda\). Theorem 7.1 Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). Then \(K_{\lambda}\) is a \(T\)-invariant subspace of \(V\) containing \(E_{\lambda}\) (the eigenspace of \(T\) corresponding to \(\lambda\)) For any eigenvalue \(\mu\) of \(T\) such that \(\mu \neq \lambda\), \(K_{\lambda} \cap K_{\mu} = \{0\}\) For any scalar \(\mu \neq \lambda\), the restriction of \(T - \mu I\) to \(K_{\lambda}\) is one-to-one and onto. Proof (a) Showing that \(K_{\lambda}\) is a subspace is straightforward. We need to show that \(\bar{0} \in K_{\lambda}\) and that \(K_{\lambda}\) is closed under scalar multiplication and addition. To show that \(K_{\lambda}\) is \(T\)-invariant. We need to show for any \(x \in K_{\lambda}\), that \(T(x) \in K_{\lambda}\). By definition, let be \(p\) be a positive integer, then \((T - \lambda I)^p(x) = \bar{0}\). We know to show that \((T - \lambda I)^p(T(x)) = \bar{0}\). Observe that $$ \begin{align*} (T - \lambda I)^p(T(x)) = T(T - \lambda I)^p(x) = T(\bar{0}) = \bar{0} \end{align*} $$ (b) TODO (c) Let \(\mu\) be a scalar such that \(\mu \neq \lambda\). Let \(x \in K_{\lambda}\). Let \(p\) be the smallest integer such that \((T - \lambda I)^p x = 0\) and $$ \begin{align*} W = \text{span}\{x, (T - \lambda I)(x),...,(T - \lambda I)^{p-1}(x)\} \end{align*} $$ Theorem 7.2 Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) such that the characteristic polynomial splits. Suppose that \(\lambda\) is an eigenvalue of \(T\) with multiplicity \(m\). Then \(\dim(K_{\lambda}) \leq m\) \(K_{\lambda} = N((T - \lambda I)^m)\) Proof (a) Let \(W = K_{\lambda}\). Let the characteristic polynomial of \(W\) be \(h(t)\) We know by Theorem 7.1, that \(W\) is a \(T\)-invariant subspace of \(V\). Therefore, by Theorem 5.20, \(h(t)\) divides the characteristic polynomial of \(T\). From Theorem 7.1(b), we know that \(\lambda\) is the only eigenvalue of \(T_W\). Therefore \(h(t) = (-1)^d(t - \lambda)^d\) where \(d = \dim(W)\) and \(d \leq m\). (b) By definition, we know that \(N(T)=\{x \in V \ | \ T(x) = 0\}\). We also know that \(K_{\lambda} =\{ x \in V \ | \ (T - \lambda I)^p = 0 \ \text{ for }p &gt; 0 \}\). So we can see that for any \(x \in N((T - \lambda I)^m)\) $$ \begin{align*} (T - \lambda I)^m(x) = 0 \end{align*} $$ Since \(m\) is the multiplicity of an eigenvalue, then it’s positive and so \(x \in K_{\lambda}\) by definition. So \(N((T - \lambda I)^m) \in K_{\lambda}\). Now, suppose that \(x \in K_{\lambda}\). We want to show that \(x \in N((T - \lambda I)^m)\) where \(m\) is the multiplicity of \(\lambda\). Since the characteristic polynomial of \(T\) splits, then let it be of the form \(f(t) = (t - \lambda)^m g(t)\) where \(g(t)\) is the product of powers of the form \(t - \mu\) for eigenvalues \(\mu \neq \lambda\). By Theorem 7.1, \(g(T)\) is one-to-one on \(K_{\lambda}\)[TODO: WHY?]. It is also onto since \(K_{\lambda}\) is finite dimensional. Since \(x \in K_{\lambda}\), then there exists some \(y\) such that \(g(T)(x) = y\). [WHY?]. Hence $$ \begin{align*} (T - \lambda I)^m(x) = (T - \lambda I)^m g(T)(y) = f(T)(y) = \bar{0} \end{align*} $$ Why? ….. [TODO] Theorem 7.3 Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) such that characteristic polynomial of \(T\) splits, and let \(\lambda_1,\lambda_2,..., \lambda_k\) be the distinct eigenvalues of \(T\). Then, for every \(x \in V\), there are exist unique vectors \(v_i \in K_{\lambda}\), for \(i = 1,2,...,k\) such that $$ \begin{align*} x = v_1 + v_2 + ... + v_k \end{align*} $$ Proof TODO Theorem 7.4 Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) whose characteristic polynomial \((t - \lambda_1)^{m_1}(t - \lambda_2)^{m_2}...(t - \lambda_k)^{m_k}\) splits. For \(i = 1,2,...,k\), let \(\beta_i\) be an ordered basis for \(K_{\lambda_i}\). Then \(\beta_i \cap \beta_j = \emptyset \text{ for } i \neq j\) \(\beta = \beta_1 \cup \beta_2 \cup ... \cup \beta_k \) is an ordered basis for \(V\) \(\dim(K_{\lambda_j}) = m_i\) for all \(i\) Proof (a) Consequence of Theorem 7.1(b) (b) We need to show that \(\beta\) is linearly independent and that \(\beta\) spans \(V\). To see that \(\beta\) is linearly independent. (c) Theorem 7.6 Let \(T\) be a linear operator on a vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). Suppose that \(\gamma_1, \gamma_2,...,\gamma_q\) are cycles of generalized eigenvectors of \(T\) corresponding to \(\lambda\) such that the initial vectors of the \(\gamma_i\)'s are distinct and form a linearly independent set. Then, the \(\gamma_i\)'s are disjoint and their union \(\gamma = \bigcup\limits_{i=1}^q \gamma_i\) is linearly independent. Proof TODO Corollary (7.6) Every cycle of generalized eigenvectors of a linear operator is linearly independent Theorem 7.7 Let \(T\) be a linear operator on a finite-dimensional vector space \(V\), and let \(\lambda\) be an eigenvalue of \(T\). Then \(K_{\lambda}\) has an ordered basis consisting of a union of disjoint cycles of generalized eigenvectors corresponding to \(\lambda\). Proof TODO Corollary 1 (7.7) Let \(T\) be a linear operator on a finite-dimensional vector space \(V\) whose characteristic polynomial splits. Then \(T\) has a Jordan canonical form. Proof TODO References Linear Algebra 5th Edition]]></summary></entry></feed>
---
layout: post
title:  "Lecture 39: Jordan Blocks and Generalized Eigenvectors"
date:   2024-09-16 01:01:36 -0700
categories: jekyll update
mathjax: true
---
Last lecture, we saw why matrices in Jordan Canonical form are useful and we spent the entire lecture  understanding the following major theorem
<br>
<div class="purdiv">
Theorem (JCF)
</div>
<div class="purbdiv">
Suppose \(V\) is finite dimensional. If the characteristic polynomial of \(T: V \rightarrow V\) splits, then there is a basis \(\beta\) of \(V\) such that \([T]_{\beta}^{\beta}\) is in Jordan Canonical form.
</div>
<!------------------------------------------------------------------------------------>
<br>
Specifically, we looked at the first Jordan block ($$A_1$$) in $$[T]_{\beta}^{\beta}$$ and analyzed what these basis elements need to be in order for $$[T]_{\beta}^{\beta}$$ to be in Jordan Canonical form. This led to FACT 1 which was that a Jordan Canonical Basis must consists of generalized eigenvectors. We saw observed that
<div>
$$
\begin{align*}
(T - \lambda_1 I_V)(v_1) &= \bar{0}_V \\
(T - \lambda_1 I_V)^2(v_2) &= \bar{0}_V \\
(T - \lambda_1 I_V)^3(v_3) &= \bar{0}_V \\
\vdots \\
(T - \lambda_1 I_V)^{n_1}(v_{n_1}) &= \bar{0}_V
\end{align*}
$$
</div>
From this we see that
<div>
$$
\begin{align*}
(T - \lambda_1 I_V)^{n_1 - 1}(v_{n_1}) &= v_1 \\
(T - \lambda_1 I_V)^{n_1 - 2}(v_{n_1}) &= v_2 \\
(T - \lambda_1 I_V)^{n_1 - 3}(v_{n_1}) &= v_3 \\
\vdots \\
(T - \lambda I_V)(v_{n_1}) &= v_{n_1-1} \\
v_{n_1} &= v_{n_1}
\end{align*}
$$
</div>
In other words,
<div>
$$
\begin{align*}
\{v_1,...v_{n_1-1},v_{n_1}\} = \{(T - \lambda_1 I_V)^{n_1 - 1}(v_{n_1}),...,(T - \lambda_1 I_V)^{2}(v_{n_1}), (T - \lambda_1 I_V)(v_{n_1}), v_{n_1}\}
\end{align*}
$$
</div>
So we can see here that the first $$n_1$$ basis vectors coming from the $$A_1$$ block are all obtained from the last vector and applying the maps over and over again. This led to FACT 2 which was
<!------------------------------------------------------------------------------------>
that A Jordan Canonical Basis is made of "cyclic pieces". The basis is not only made of generalized eigenvectors but they also appear in this cyclic pattern. This leads us to the following definition
<br>
<div class="bdiv">
Definition
</div>
<div class="bbdiv">
Let \(x \in K_{\lambda}\) and \(p\) be the smallest integer such that \((T - \lambda_i I_V)^p(x) = \bar{0}_V\). Let 
$$
\begin{align*}
\gamma = \{(T - \lambda_i I_V)^{p-1}(x),..., (T - \lambda_i I_V)(x),x\}
\end{align*}
$$
\(\gamma\) is the cycle of generalized eigenvectors generated by \(x\). The length of \(\gamma\) is \(p\). The initial vector of \(\gamma\) is \((T - \lambda_i I_V)^{p-1}(x)\)
</div>
<!------------------------------------------------------------------------------------>
<br>
<br>
What can we say about these objects?
<br>
<br>
<div class="purdiv">
Theorem 2.1
</div>
<div class="purbdiv">
<ol type="a">
	<li>\(\gamma\) is linearly independent</li>
	<li>\(W = \text{span}(\gamma)\) is \(T\)-invariant</li>
	<li>The matrix representation of the restriction of \(T\) to \(W\), \([T_W]_{\gamma}^{\gamma}\) is a Jordan block</li>
</ol>
</div>
<!------------------------------------------------------------------------------------>
<br>
<b>Proof</b>
<br>
<br>
Re-write $$\gamma$$ as
<div>
$$
\begin{align*}
\gamma &= \{(T - \lambda_i I_V)^{p-1}(x),..., (T - \lambda_i I_V)(x),x\} \\
       &= \{v_1, ..., v_n\}
\end{align*}
$$
</div>
These satisfy the following relations
<div>
$$
\begin{align*}
(T - \lambda I_V)(v_1) &= (T - \lambda I_V)^p(x) = \bar{0}_V\\
(T - \lambda I_V)(v_i) &= (T - \lambda I_V)^p(v_{i-1})
\end{align*}
$$
</div>
We can re-write these equations as
<div>
$$
\begin{align*}
T(v_1) &= \lambda v_1\\
T(v_i) &= \lambda v_i + v_{i-1}
\end{align*}
$$
</div>
This means that $$T$$ maps $$v_i$$ to a linear combination of $$v_i$$'s again (which are in $$\gamma$$). This implies that $$T(v_j) \in \text{span}(\gamma) \quad \forall j=1,...,p$$. This means that $$T(W) \subseteq W$$. Therefore, $$W$$ is $$T$$-invariant and (b) holds.
<br>
<br>
We can also write the matrix representative of $$T$$ with respect to $$W$$
<div>
$$
\begin{align*}
[T_W]_{\gamma}^{\gamma} = 
\begin{pmatrix}
\lambda & 1 & 0 & \cdots & 0 \\
0 & \lambda & 1 & \cdots & 0 \\
0 & 0 & \lambda & \ddots & \vdots \\
\vdots & \vdots & \vdots & \ddots & 1 \\
0 & 0 & 0 & \cdots & \lambda
\end{pmatrix}
\end{align*}
$$
</div>
From this we see that $$(c)$$ holds. 
<br>
<br>
So now we only need to prove $$(a)$$. We need to build a basis of each $$K_{\lambda}$$ out of cycles. To show this we need the next two results
<br>
<!------------------------------------------------------------------------------------>
<div class="purdiv">
Theorem 2.2
</div>
<div class="purbdiv">
Let \(\gamma_1,...,\gamma_m\) be cycles for \(\lambda\) with linearly independent initial vectors. Then
$$
\begin{align*}
\gamma = \cup_{j=1}^m \gamma_j
\end{align*}
$$
is linearly independent.
</div>
<!------------------------------------------------------------------------------------>
<br>
and
<br>
<div class="purdiv">
Theorem 2.3
</div>
<div class="purbdiv">
Each \(K_{\lambda}\) has a basis consisting of disjoint cycles.
</div>
<br>
<!------------------------------------------------------------------------------------>
<h3>The JCF Proof</h3>
Theorems 1.1 to 2.3 combined prove the JCF Theorem! To see how. Let $$\lambda_1,...,\lambda_k$$ be the disjoint eigenvalues of $$T$$. For $$\lambda_j$$ find a basis $$\beta_j$$ of $$K_{\lambda_j}$$ consisting of disjoint cycles (Theorem 2.3).
<br>
By Theorem 1.4, $$\beta = \beta_1 \cup ... \cup \beta_k$$ is a basis of $$V$$. And by Theorem 2.1, $$[T]_{\beta}^{\beta}$$ is in JCF.
<hr>

<!------------------------------------------------------------------------------------>
<h3>Example</h3>
Let $$A = \begin{pmatrix}
3 & 1 & -2 \\
-1 & 0 & 5 \\
-1 & -1 & 4
\end{pmatrix}
$$. Put $$A$$ in JCF if possible. Here $$T$$ is $$L_A: \mathbf{R}^3 \rightarrow \mathbf{R}^3$$. 
<br>
<br>
We first need to check if the characteristic polynomial splits.
<div>
$$
\begin{align*}
\det(A - tI_3) = (3 - t)(2 - t)^2
\end{align*}
$$
</div>
So the characteristic polynomial splits. (In fact $$\lambda_1$$ has algebraic multiplicity 1 and $$\lambda_2$$ has algebraic multiplicity 2).
<br>
<br>
We know the general form of the Jordan Canonical Basis where $$\beta = \beta_1 \cup ... \cup \beta_m$$ where $$\beta_j = \gamma_1^j \cup \gamma_2^j \cup ... \cup \gamma_1^{k_j}$$, a collection of disjoint cycles. So let's build these pieces starting with the first eigenvalue as follows
<br>
<br>
$$\lambda_1 = 3$$: The algebraic multiplicity of $$\lambda_1$$ is 1. This implies that the generalized eigenspace $$K_{\lambda_1} = E_{\lambda_1}$$ why is that? The dimension of the generalized eigenspace is equal to the algebraic multiplicity so its dimension is 1. But we know that $$E_{\lambda_1}$$ has a non-zero dimension and that it sits inside $$K_{\lambda_1}$$. Therefore $$K_{\lambda_1} = E_{\lambda_1}$$. What about the cycles of this generalized eigenspace? the length of the cycle is ($$p=1$$). So all we need to do is find the nullspace of this eigenspace.
<div>
$$
\begin{align*}
A - 3I_3 = 
A = \begin{pmatrix}
0 & 1 & -2 \\
-1 & -3 & 5 \\
-1 & -1 & 1
\end{pmatrix}
\end{align*}
$$
</div>
Putting this in echelon form, we see
<div>
$$
\begin{align*}
\begin{pmatrix}
1 & 0 & 1 \\
0 & 1 & -2 \\
0 & 0 & 0
\end{pmatrix}
\end{align*}
$$
</div>
The solution will this lead to
<div>
$$
\begin{align*}
\beta_1 = \left\{
\begin{pmatrix}
-1 \\
2 \\
1
\end{pmatrix}
\right\}
\end{align*}
$$
</div>
<!------------------------------------------------------------------------------------>
$$\lambda_2 = 2$$: By Theorem 1.2, $$K_{\lambda_2} = N((A - 2I_3)^2)$$ so
<div>
$$
(A - 2I_3)^2 = 
\begin{align*}
A - 2I_3 = 
\begin{pmatrix}
1 & 1 & -2 \\
-1 & -2 & 5 \\
-1 & -1 & 2
\end{pmatrix}^2 
= 
\begin{pmatrix}
2 & 1 & -1 \\
-4 & -2 & 2 \\
-2 & -1 & 1
\end{pmatrix}
\end{align*}
$$
</div>
Putting this in echelon form, we see
<div>
$$
\begin{align*}
\begin{pmatrix}
1 & \frac{1}{2} & -\frac{1}{2} \\
0 & 0 & 0 \\
0 & 0 & 0
\end{pmatrix}
\end{align*}
$$
</div>
The solution set is then
<div>
$$
\begin{align*}
K_{\lambda_2} = \text{span}\left\{
\begin{pmatrix} 1 \\ -2 \\ 1 \end{pmatrix}
\begin{pmatrix} 1 \\ 0 \\ 2 \end{pmatrix}
\right\}
\end{align*}
$$
</div>
So we have a basis but we don't have cycles yet. So we need to start generating cycles. Let's choose the second vector above.
<div>
$$
\begin{align*}
(A - 2I_3)(x) = 
\begin{pmatrix}
1 & 1 & -2 \\
-1 & -2 & 5 \\
-1 & -1 & 2
\end{pmatrix}
\begin{pmatrix}
1 \\
0 \\
2
\end{pmatrix}
=
\begin{pmatrix}
-3 \\
9 \\
3
\end{pmatrix}
\end{align*}
$$
</div>
So given $$x \in K_{\lambda} \implies \gamma=\{(T - \lambda I_V)^{p-1}(x),...,x\}$$. The term above is the second term from last. So the term remaining is just when $$p = 0$$ which means it's $$x$$ itself. Therefore
<div>
$$
\begin{align*}
\gamma = \left\{
\begin{pmatrix}
-3 \\
9 \\
3
\end{pmatrix},
\begin{pmatrix}
1 \\
0 \\
2
\end{pmatrix}
\right\} = \beta_2
\end{align*}
$$
</div>
Therefore, the Jordan Canonical Basis is
<div>
$$
\begin{align*}
\beta = \beta_1 \cup \beta_2 
= \left\{
\begin{pmatrix}
	-1 \\
	2 \\
	1
\end{pmatrix},
\begin{pmatrix}
-3 \\
9 \\
3
\end{pmatrix},
\begin{pmatrix}
1 \\
0 \\
2
\end{pmatrix}
\right\}
\end{align*}
$$
</div>
and
<div>
$$
\begin{align*}
[L_A]_{\beta}^{\beta} =
\begin{pmatrix}
3 & 0 & 0 \\
0 & 2 & 1 \\
0 & 0 & 2
\end{pmatrix}
\end{align*}
$$
</div>
The diagonal elements are the eigenvalues. What about other non-zero elements? The second block is generated by a cycle of length 2 So there is a 1 in that block.
<hr>

<!------------------------------------------------------------------------------------>
<h3>Determining the Jordan Block for an Eigenvalue</h3>
But can we get to the end JCF form without having to compute all of these cycles?
<br>
<div class="purdiv">
Theorem
</div>
<div class="purbdiv">
Let \(\lambda\) be an eigenvalue of \(T\) with algebraic multiplicity \(m\). 
$$
\begin{align*}
r_1 &= \dim(V) - rank(T - \lambda I_V) \\
r_i &= rank((T - \lambda I_V)^{i-1}) - rank((T - \lambda I_V)^i)
\end{align*}
$$
Using \(r_1, r_2, ...\) form the diagram
$$
\begin{align*}
\begin{matrix}
\circ & \circ & \cdots & \circ & \quad & r_1\text{ dots} \\
\circ & \circ & \cdots & \circ & \quad & r_2\text{ dots} \\
\vdots & \vdots \\
\circ & \circ &        &       & \quad & r_j\text{ dots} \\
\end{matrix}
\end{align*}
$$
Then each column corresponds to Jordan block of \(\lambda\) of size the number of the dots in each column 
</div>
<br>
Observation:
<ul>
	<li>\(r_1 \geq r_2 \geq r_3 \geq ...\)</li>
	<li>\(r_1 + r_2 + r_3 + ... = m\)</li>
	<li>\(r_1 =\) the number of Jordan Blocks for \(\lambda\)</li>
</ul>
<hr>

<!------------------------------------------------------------------------------------>
<h3>References</h3>
<ul>
<li>Math416 by Ely Kerman</li>
</ul>






















